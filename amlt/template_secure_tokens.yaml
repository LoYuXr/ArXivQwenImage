# ============================================================
# AMLT Template for Secure Token Management
# ============================================================
# This template demonstrates how to handle sensitive tokens in AMLT
# 
# OPTION 1 (Recommended): Use Azure Key Vault secrets
#   - Store tokens in Azure Key Vault
#   - Reference them with $${{secrets.SECRET_NAME}}
#
# OPTION 2: Use amlt secrets
#   - Store with: amlt secret set HF_TOKEN "your_token"
#   - Reference with: $${{secrets.HF_TOKEN}}
#
# OPTION 3: Set in submit_args.env (tokens not in git)
#   - Set environment variables at job submission time
#   - Reference the secret yaml file that's in .gitignore
# ============================================================

target:
  name: msrresrchvc
  service: sing
  workspace_name: mcgvisionflowws

environment:
  image: amlt-sing/acpt-torch2.7.1-py3.10-cuda12.6-ubuntu22.04

storage:
  data:
    container_name: yuxuanluo
    mount_dir: /mnt/data
    storage_account_name: mcgvisionflowsa

code:
  local_dir: /home/v-yuxluo/WORK_local/ArXivQwenImage

description: Template for secure token management

jobs:
- name: example_job
  process_count_per_node: 1
  sku: 1x80G4-A100
  
  command:
  - sudo apt-get update
  - sudo apt-get install -y libglib2.0-0 libgl1 curl libaio-dev poppler-utils
  
  # Install dependencies
  - pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
  - pip install git+https://github.com/huggingface/diffusers
  - pip install transformers==4.55.0 accelerate protobuf wandb
  - pip install opencv-python pandas pyarrow datasets ftfy sentencepiece einops scikit-learn timm==0.9.2 mmengine tqdm
  - pip install bitsandbytes>=0.43.0 peft pydantic ray[train] prodigyopt
  
  # ============================================================
  # OPTION 1: Use AMLT secrets (recommended)
  # First, store secrets with: amlt secret set HF_TOKEN "your_hf_token"
  # Then reference them here:
  # ============================================================
  - export HF_TOKEN=$${{secrets.HF_TOKEN}}
  - export WANDB_API_KEY=$${{secrets.WANDB_API_KEY}}$${{secrets.WANDB_API_KEY}}
  
  # WandB configuration (non-sensitive)
  - export WANDB_ENTITY=v-yuxluo
  - export WANDB_PROJECT=ArXivQwenImage-Run
  - export WANDB_BASE_URL="https://microsoft-research.wandb.io"
  
  # Login to services
  - huggingface-cli login --token $$HF_TOKEN
  - wandb login $$WANDB_API_KEY$$WANDB_API_KEY
  
  # Run training
  - accelerate launch
    --config_file accelerate_cfg/deepspeed_zero2_bf16.yaml
    train_OpenSciDraw_fulltune.py
    configs/260126/flux2klein_fulltune_50000_amlt_ga4_5e-6.py

  identity: managed
  submit_args:
    env:
      _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/e56674e8-8a8b-4559-8a24-4149e2e4565b/resourcegroups/mcg_vision_flow_rg/providers/Microsoft.ManagedIdentity/userAssignedIdentities/mcgvisionflowid
    max_run_duration_seconds: 1200000
  sla_tier: premium
  execution_mode: basic
  priority: high
  tags: ["Project_Name:VisionFlow"]
