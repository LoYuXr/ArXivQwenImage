import os
import pandas as pd
import numpy as np
import torch
import itertools
from pathlib import Path
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import pyarrow.parquet as pq
from OpenSciDraw.registry import DATASETS
from torch.utils.data import Dataset, Sampler
import torch.distributed as dist

'''
ParquetDataset:
æˆ‘ä»¬æ‰“åŒ…æ•°æ®é›†ä¸ºå¤šä¸ª Parquet æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å«è‹¥å¹²æ ·æœ¬çš„ Latents å’Œ Text Embedsã€‚
'''

@DATASETS.register_module()
class ArXiVParquetDataset(Dataset):
    def __init__(
            self,
            base_dir: str,
            parquet_base_path: str,
            num_workers: int = 64,
            num_train_examples: int = 1000000,
            pin_memory: bool = True,
            persistent_workers: bool = True,
            debug_mode: bool = False
            ):
 
        self.base_path = Path(base_dir)
        self.data_base_path = self.base_path / parquet_base_path
        
        # 1. å¿«é€Ÿè·å–æ–‡ä»¶åˆ—è¡¨ (Glob è¿˜æ˜¯æ¯”è¾ƒå¿«çš„)
        print(f"ğŸ” Scanning parquet files in {self.data_base_path}...")
        # å‡è®¾ç›®å½•ç»“æ„æ˜¯ year/xxx.parquet
        parquet_paths = [sorted(year_base_path.glob("*.parquet")) for year_base_path in sorted(self.data_base_path.iterdir()) if year_base_path.is_dir()]
        self.parquet_paths = list(itertools.chain.from_iterable(parquet_paths))
        
        
        if debug_mode:
            self.parquet_paths = self.parquet_paths[:10]  # ä»…ç”¨äºæµ‹è¯•ï¼Œé™åˆ¶è¯»å–æ–‡ä»¶æ•°
        
        if not self.parquet_paths:
            raise RuntimeError(f"No parquet files found in {self.data_base_path}")

        print(f"Found {len(self.parquet_paths)} files. Starting PARALLEL metadata loading (No cache)...")

        # 2. å¹¶å‘æ‰«ææ‰€æœ‰æ–‡ä»¶çš„ Header
        # è¿™ä¸€æ­¥æ˜¯æ›¿ä»£ Cache æ–‡ä»¶çš„å…³é”®
        self.meta_df = self._parallel_load_metadata(self.parquet_paths, max_workers=num_workers, num_train_examples=num_train_examples)
        
        print(f"âœ… Total valid samples loaded: {len(self.meta_df)}")
        
        # 3. è¿è¡Œæ—¶æ–‡ä»¶å¥æŸ„ç¼“å­˜ (LRU)
        # é¿å… __getitem__ æ—¶åå¤æ‰“å¼€å…³é—­æ–‡ä»¶
        self.parquet_handles = {} 

    def _parallel_load_metadata(self, paths, max_workers, num_train_examples):
        """
        åˆ©ç”¨å¤šçº¿ç¨‹å¹¶å‘è¯»å– Metadata
        """
        meta_list = []
        
        # å®šä¹‰å•ä¸ªæ–‡ä»¶çš„è¯»å–å‡½æ•°
        def load_one_header(path):
            try:
                # ä½¿ç”¨ PyArrow ParquetFile åªè¯»å…ƒæ•°æ®ï¼Œæå¿«
                pf = pq.ParquetFile(path)
                
                # åªè¯»å–å¿…è¦çš„åˆ—ç”¨äºåˆ†ç»„ï¼Œç»å¯¹ä¸è¦è¯» latents
                # read_row_group(0) æˆ–è€… read() é…åˆ columns å‚æ•°
                # æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶ç¡®å®æŸåï¼Œè¿™é‡Œä¼šæŠ›å‡ºå¼‚å¸¸
                df = pf.read(columns=['bucket_w', 'bucket_h', 'latent_shape', 'text_embeds_shape', 'image_path', 'caption']).to_pandas()
                
                # æ³¨å…¥å®šä½ä¿¡æ¯
                df['source_file'] = str(path)
                df['local_index'] = range(len(df))
                return df
            except Exception as e:
                # ä»…æ‰“å°ç®€çŸ­é”™è¯¯ï¼Œé˜²æ­¢åˆ·å±
                return f"Error: {path} | {str(e)}"

        # å¯åŠ¨çº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_path = {executor.submit(load_one_header, p): p for p in paths}
            
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
            for future in tqdm(as_completed(future_to_path), total=len(paths), desc="Scanning Headers"):
                result = future.result()
                if isinstance(result, pd.DataFrame):
                    meta_list.append(result)
                else:
                    # å¦‚æœæ˜¯é”™è¯¯å­—ç¬¦ä¸²
                    print(f"âš ï¸ {result}")

        if not meta_list:
            raise RuntimeError("All files failed to load!")

        # åˆå¹¶æ‰€æœ‰ç»“æœ
        return pd.concat(meta_list, ignore_index=True).iloc[:num_train_examples]

    def _get_parquet_handle(self, file_path):
        """
        è¿è¡Œæ—¶ç¼“å­˜æ‰“å¼€çš„æ–‡ä»¶å¥æŸ„ï¼Œé˜²æ­¢é¢‘ç¹ Open/Close
        """
        if file_path in self.parquet_handles:
            return self.parquet_handles[file_path]
        
        # ç®€å•çš„ LRU: å¦‚æœè¶…è¿‡ 16 ä¸ªæ‰“å¼€çš„æ–‡ä»¶ï¼Œæ¸…ç†æ‰æœ€æ—©çš„ä¸€ä¸ª
        if len(self.parquet_handles) > 16:
            key_to_remove = next(iter(self.parquet_handles))
            self.parquet_handles.pop(key_to_remove)
            
        pf = pq.ParquetFile(file_path) 
        self.parquet_handles[file_path] = pf
        return pf

    def __len__(self):
        return len(self.meta_df)

    def __getitem__(self, index):
        # 1. Look up metadata
        meta_row = self.meta_df.iloc[index]
        file_path = meta_row['source_file']
        local_idx = meta_row['local_index']
        
        # 2. Get file handle
        pf = self._get_parquet_handle(file_path)
        
        # 3. Read data
        full_df = pf.read().to_pandas() 
        row = full_df.iloc[local_idx]
        
        # --- Restore Tensors (Corrected Version) ---
        
        # 1. Latents: Must be float32 because that's how parquet stores it
        latents_np = np.frombuffer(row['latents'], dtype=np.float32)
        # Force convert shape to list of ints
        latents_shape = [int(x) for x in meta_row['latent_shape']]
        latents = torch.from_numpy(latents_np.copy()).reshape(latents_shape)
        
        # 2. Text Embeds: Usually float16
        text_embeds_np = np.frombuffer(row['text_embeds'], dtype=np.float16)
        text_shape = [int(x) for x in meta_row['text_embeds_shape']]
        text_embeds = torch.from_numpy(text_embeds_np.copy()).reshape(text_shape)
        
        # 3. Text Mask: int8
        text_mask_np = np.frombuffer(row['text_mask'], dtype=np.int8)
        text_mask = torch.from_numpy(text_mask_np.copy())
        
        return {
            "latents": latents,
            "text_embeds": text_embeds,
            "text_mask": text_mask,
            "bucket_size": (meta_row['bucket_h'], meta_row['bucket_w']),
            "caption": meta_row['caption']
        }

    def collate_fn(self, batch):
        # 1. å¤„ç† Latents (BucketSampler ä¿è¯äº†å®½é«˜ä¸€è‡´ï¼Œç›´æ¥ Stack)
        latents = torch.stack([x['latents'] for x in batch])

        # 2. å¤„ç† Text Embeds (å˜é•¿åºåˆ— -> åŠ¨æ€ Padding)
        # ä½ çš„ Parquet é‡Œå­˜çš„æ˜¯ä¸åŒé•¿åº¦çš„åºåˆ—ï¼Œæ¯”å¦‚ [525, 3584] å’Œ [616, 3584]
        
        embeds_list = [x['text_embeds'] for x in batch]
        masks_list = [x['text_mask'] for x in batch]

        # å¼•å…¥ pad_sequence å·¥å…·
        from torch.nn.utils.rnn import pad_sequence
        
        # batch_first=True: è¾“å‡º [Batch, Max_Len, Dim]
        # padding_value=0: ç¼ºçš„åœ°æ–¹è¡¥0 (Qwen çš„ Mask é€»è¾‘é€šå¸¸ 1æ˜¯æœ‰æ•ˆï¼Œ0æ˜¯æ— æ•ˆ)
        padded_embeds = pad_sequence(embeds_list, batch_first=True, padding_value=0)
        padded_masks = pad_sequence(masks_list, batch_first=True, padding_value=0)   ####ASKASKASKASK!!! LYXASK

        # æ­¤æ—¶ padded_embeds çš„å½¢çŠ¶ä¼šè‡ªåŠ¨å˜æˆ [Batch, max_len_in_this_batch, 3584]
        # æ¯”å¦‚ [4, 616, 3584]ï¼Œè€Œä¸æ˜¯å›ºå®šçš„ 2048ï¼Œè¿™èƒ½åŠ é€Ÿè®­ç»ƒï¼

        return {
            "latents": latents,
            "text_embeds": padded_embeds,
            "text_mask": padded_masks,
            "captions": [x['caption'] for x in batch],
            "bucket_size": batch[0]['bucket_size'],  # å…¨éƒ¨ä¸€æ ·
        }
        
@DATASETS.register_module()
class BucketSampler(Sampler):
    def __init__(self, dataset, batch_size, drop_last=False, shuffle=True):
        self.dataset = dataset
        self.batch_size = batch_size
        self.drop_last = drop_last
        self.shuffle = shuffle
        
        # --- æ ¸å¿ƒç®€åŒ–ï¼šç›´æ¥åˆ©ç”¨ DataFrame çš„åˆ—è¿›è¡Œåˆ†ç»„ ---
        print("Grouping by pre-computed bucket_w/h...")
        
        # è¿™ä¸€æ­¥æå¿«ï¼Œpandas å†…éƒ¨ä¼˜åŒ–çš„ hash group
        # keys ä¼šå˜æˆ: (768, 1024), (512, 512) ç­‰ç­‰
        self.groups = self.dataset.meta_df.groupby(['bucket_h', 'bucket_w']).indices
        
        print(f"Found {len(self.groups)} unique resolutions.")
        for k, v in list(self.groups.items())[:3]:
            print(f"  Bucket {k}: {len(v)} samples")

    def __iter__(self):
        batch_lists = []
        
        for bucket_key, indices in self.groups.items():
            # è½¬æ¢æˆ list ä»¥ä¾¿æ“ä½œ
            indices = list(indices)
            
            # 1. æ¡¶å†… Shuffle (æ»¡è¶³"åŒä¸€åˆ†è¾¨ç‡ä¸‹ shuffle")
            if self.shuffle:
                np.random.shuffle(indices)
            
            # 2. ç”Ÿæˆ Batch
            for i in range(0, len(indices), self.batch_size):
                batch = indices[i : i + self.batch_size]
                
                if len(batch) < self.batch_size and self.drop_last:
                    continue
                
                batch_lists.append(batch)
        
        # 3. æ¡¶é—´ Shuffle (è®©è®­ç»ƒæ•°æ®åœ¨ä¸åŒåˆ†è¾¨ç‡é—´éšæœºåˆ‡æ¢)
        if self.shuffle:
            np.random.shuffle(batch_lists)
            
        for batch in batch_lists:
            yield batch

    def __len__(self):
        count = 0
        for indices in self.groups.values():
            if self.drop_last:
                count += len(indices) // self.batch_size
            else:
                count += (len(indices) + self.batch_size - 1) // self.batch_size
        return count
    
    
@DATASETS.register_module()
class DistributedBucketSampler(Sampler):
    def __init__(
        self, 
        dataset, 
        batch_size, 
        num_replicas=None, 
        rank=None, 
        drop_last=False, 
        shuffle=True
    ):
        super().__init__(dataset)
        self.dataset = dataset
        self.batch_size = batch_size
        self.drop_last = drop_last
        self.shuffle = shuffle
        
        # 1. è·å–åˆ†å¸ƒå¼ä¿¡æ¯
        if num_replicas is None:
            if not dist.is_available():
                raise RuntimeError("Requires distributed package to be available")
            try:
                # å°è¯•è‡ªåŠ¨è·å–
                num_replicas = dist.get_world_size()
                rank = dist.get_rank()
            except:
                # å¦‚æœæ²¡åˆå§‹åŒ– DDPï¼Œé»˜è®¤ä¸ºå•å¡æ¨¡å¼
                print("Warning: Distributed not initialized, assuming single GPU.")
                num_replicas = 1
                rank = 0
                
        self.num_replicas = num_replicas
        self.rank = rank
        
        # 2. é¢„åˆ†ç»„ (å’Œä¹‹å‰ä¸€æ ·ï¼Œåˆ©ç”¨ pandas group)
        print(f"[Rank {self.rank}] Grouping by pre-computed bucket_w/h...")
        # self.groups ç»“æ„: { (h, w): [idx1, idx2, ...], ... }
        self.groups = self.dataset.meta_df.groupby(['bucket_h', 'bucket_w']).indices
        
        # 3. è®¡ç®—æ€»æ ·æœ¬æ•° (ä¸ºäº† __len__)
        # åœ¨ DDP ä¸­ï¼Œå¿…é¡»ä¿è¯æ¯å¼ å¡çœ‹åˆ°çš„ batch æ•°é‡æ˜¯ä¸€æ ·çš„ï¼Œå¦åˆ™è®­ç»ƒä¼šå¡æ­»
        self.num_samples_per_replica = 0
        for indices in self.groups.values():
            # æ¯ä¸ªæ¡¶é‡Œçš„æ•°æ®å…ˆåˆ†ç»™ N å¼ å¡
            count_per_bucket = int(math.ceil(len(indices) / self.num_replicas))
            # å†çœ‹èƒ½ç»„æˆå¤šå°‘ä¸ª batch
            if self.drop_last:
                self.num_samples_per_replica += (count_per_bucket // self.batch_size) * self.batch_size
            else:
                self.num_samples_per_replica += int(math.ceil(count_per_bucket / self.batch_size)) * self.batch_size
        
        self.total_size = self.num_samples_per_replica * self.num_replicas
        print(f"[Rank {self.rank}] Initialized. World Size: {self.num_replicas}, Rank: {self.rank}")

    def __iter__(self):
        # ç¡®å®šæ€§ç§å­ï¼šä¿è¯ä¸åŒ epoch çš„ shuffle ç»“æœä¸åŒï¼Œä½†ä¸åŒ GPU ä¸Šçš„ shuffle é€»è¾‘ä¸€è‡´
        g = torch.Generator()
        g.manual_seed(self.epoch if hasattr(self, 'epoch') else 0)
        
        batch_lists = []
        
        for bucket_key, indices in self.groups.items():
            indices = list(indices)
            
            # --- DDP æ ¸å¿ƒé€»è¾‘ 1: å¯¹ç´¢å¼•è¿›è¡Œ Shuffle ---
            # å¿…é¡»åœ¨åˆ‡åˆ†å‰ shuffleï¼Œå¹¶ä¸”æ‰€æœ‰ GPU ä½¿ç”¨ç›¸åŒçš„ç§å­ï¼Œç¡®ä¿æ•°æ®è¢«æ‰“æ•£ä½†è§†è§’ä¸€è‡´
            if self.shuffle:
                # ä½¿ç”¨ numpy æˆ– torch çš„ shuffleï¼Œè¿™é‡Œä¸ºäº†ç®€å•ç”¨ numpy
                # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç”¨ self.rank åšç§å­ï¼Œå¿…é¡»å…¨å±€ç»Ÿä¸€
                indices = np.array(indices)
                np.random.seed(self.epoch if hasattr(self, 'epoch') else 0) 
                np.random.shuffle(indices)
                indices = indices.tolist()
            
            # --- DDP æ ¸å¿ƒé€»è¾‘ 2: Padding (è¡¥é½) ---
            # ç¡®ä¿æ¯ä¸ªæ¡¶çš„æ•°æ®é‡èƒ½è¢« num_replicas æ•´é™¤ï¼Œé˜²æ­¢æŸå¼ å¡æœ€åæ²¡æ•°æ®è¯»
            total_size = int(math.ceil(len(indices) / self.num_replicas)) * self.num_replicas
            # å¦‚æœä¸å¤Ÿï¼Œå¾ªç¯è¡¥é½ (Round Robin)
            indices += indices[:(total_size - len(indices))]
            assert len(indices) == total_size
            
            # --- DDP æ ¸å¿ƒé€»è¾‘ 3: åˆ‡åˆ† (Subsampling) ---
            # å½“å‰å¡åªå¤„ç†å±äºè‡ªå·±çš„ä¸€éƒ¨åˆ†: index, index+world_size, ...
            # ä¾‹å¦‚ 4å¡: Rank 0 å– [0, 4, 8...], Rank 1 å– [1, 5, 9...]
            indices = indices[self.rank:total_size:self.num_replicas]
            assert len(indices) == len(indices) # just valid check
            
            # --- DDP æ ¸å¿ƒé€»è¾‘ 4: æ¡¶å†…å† Shuffle (å¯é€‰) ---
            # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è®©å½“å‰å¡å†…éƒ¨çš„æ•°æ®æ›´éšæœº
            if self.shuffle:
                np.random.seed(self.epoch + self.rank if hasattr(self, 'epoch') else 0)
                np.random.shuffle(indices)
                
            # --- ç”Ÿæˆ Batch ---
            for i in range(0, len(indices), self.batch_size):
                batch = indices[i : i + self.batch_size]
                
                # å¤„ç†æœ€åä¸€ä¸ªä¸å®Œæ•´çš„ batch
                if len(batch) < self.batch_size:
                    if self.drop_last:
                        continue
                    # å¦‚æœä¸ drop_lastï¼Œå¯èƒ½éœ€è¦è¡¥é½æˆ–è€…ç›´æ¥è¿”å›å° batch
                    # ä¸ºäº† DDP å®‰å…¨ï¼Œé€šå¸¸å»ºè®® drop_last=True æˆ–è€…è‡ªè¡Œè¡¥é½
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå…è®¸è¿”å›å° batch (æ³¨æ„ collate_fn å¯èƒ½ä¼šé‡åˆ°é—®é¢˜ï¼Œå»ºè®® drop_last=True)
                
                batch_lists.append(batch)
                
        # --- å…¨å±€ Batch é—´ Shuffle ---
        # æ‰“ä¹±ä¸åŒåˆ†è¾¨ç‡ Batch çš„é¡ºåºï¼Œè®©æ¨¡å‹äº¤æ›¿çœ‹åˆ°ä¸åŒåˆ†è¾¨ç‡
        if self.shuffle:
            np.random.shuffle(batch_lists)
            
        for batch in batch_lists:
            yield batch

    def __len__(self):
        # è¿”å› batch çš„æ•°é‡
        return self.num_samples_per_replica // self.batch_size
    
    def set_epoch(self, epoch):
        self.epoch = epoch