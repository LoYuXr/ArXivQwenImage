W0122 07:45:14.813000 213013 site-packages/torch/distributed/run.py:793] 
W0122 07:45:14.813000 213013 site-packages/torch/distributed/run.py:793] *****************************************
W0122 07:45:14.813000 213013 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0122 07:45:14.813000 213013 site-packages/torch/distributed/run.py:793] *****************************************
Config (path: configs/260122/flux2klein_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': '***REMOVED***', 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 2, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_test', 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-FullTune', 'run_name': 'flux2klein_9b_fulltune_5000steps', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 200, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application’s source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet’s denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure’s caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 1024, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260122/flux2klein_fulltune_5000.py'}
Config (path: configs/260122/flux2klein_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': '***REMOVED***', 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 2, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_test', 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-FullTune', 'run_name': 'flux2klein_9b_fulltune_5000steps', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 200, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application’s source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet’s denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure’s caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 1024, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260122/flux2klein_fulltune_5000.py'}
Config (path: configs/260122/flux2klein_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': '***REMOVED***', 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 2, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_test', 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-FullTune', 'run_name': 'flux2klein_9b_fulltune_5000steps', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 200, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application’s source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet’s denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure’s caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 1024, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260122/flux2klein_fulltune_5000.py'}
Config (path: configs/260122/flux2klein_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': '***REMOVED***', 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 2, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_test', 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-FullTune', 'run_name': 'flux2klein_9b_fulltune_5000steps', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 200, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application’s source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet’s denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure’s caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 1024, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260122/flux2klein_fulltune_5000.py'}
01/22/2026 07:45:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/22/2026 07:45:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/22/2026 07:45:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/22/2026 07:45:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/22/2026 07:45:23 - INFO - __main__ - [INFO] Using model type: Flux2Klein
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory - 🏭 Model Factory Initialized
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Model Type: Flux2Klein
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Pretrained Path: black-forest-labs/FLUX.2-klein-base-9B
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Cache Dir: None
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    VAE Class: AutoencoderKLFlux2
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Transformer Class: Flux2Transformer2DModel
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Text Encoder Class: Qwen3ForCausalLM
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory -    Pipeline Class: Flux2KleinPipeline
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading tokenizer: Qwen2TokenizerFast
01/22/2026 07:45:23 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoder: Qwen3ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 52.12it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 52.85it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 51.82it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 53.65it/s]
01/22/2026 07:45:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading VAE: AutoencoderKLFlux2
All model checkpoint weights were used when initializing AutoencoderKLFlux2.

All the weights of AutoencoderKLFlux2 were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKLFlux2 for predictions without further training.
01/22/2026 07:45:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading transformer: Flux2Transformer2DModel
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 32263.88it/s]
Instantiating Flux2Transformer2DModel model under default dtype torch.bfloat16.
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 14768.68it/s]
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 15196.75it/s]
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 6765.01it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 74.29it/s]
All model checkpoint weights were used when initializing Flux2Transformer2DModel.

All the weights of Flux2Transformer2DModel were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Flux2Transformer2DModel for predictions without further training.
01/22/2026 07:45:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] Fine-tuning the full model ...
01/22/2026 07:45:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] Enabling gradient checkpointing for transformer
01/22/2026 07:45:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading scheduler: FlowMatchEulerDiscreteScheduler
01/22/2026 07:45:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoding pipeline: Flux2KleinPipeline
{'is_distilled'} was not found in config. Values will be initialized to default values.
Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 4632.03it/s]
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:343: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:344: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
01/22/2026 07:45:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] VAE scale factor: 16
01/22/2026 07:45:25 - INFO - __main__ - [INFO] DeepSpeed detected - keeping transformer in bf16 for ZeRO-3
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:343: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
01/22/2026 07:45:25 - INFO - __main__ - [INFO] Configuring model devices and offloading
01/22/2026 07:45:25 - INFO - __main__ - [INFO] Using parquet dataset - VAE and text encoder remain on CPU
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:344: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:343: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:344: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:343: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:344: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
01/22/2026 07:45:25 - INFO - __main__ - [INFO] DeepSpeed mode: transformer stays on CPU, ZeRO-3 will handle placement
01/22/2026 07:45:25 - INFO - __main__ - [INFO] Gradient checkpointing enabled
01/22/2026 07:45:25 - INFO - __main__ - [INFO] Number of trainable parameters: 9078.58M
01/22/2026 07:45:25 - INFO - __main__ - [INFO] Loading dataset
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_test...
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_test...
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_test...
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_test...
⏳ Loading/parsing metadata (parquet: path only) from 84 parquet files...
⏳ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]⏳ Loading/parsing metadata (parquet: path only) from 84 parquet files...
⏳ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:   6%|▌         | 5/84 [00:00<00:01, 46.83it/s]Scanning Parquet Files:   6%|▌         | 5/84 [00:00<00:01, 41.78it/s]Scanning Parquet Files:   6%|▌         | 5/84 [00:00<00:01, 40.56it/s]Scanning Parquet Files:   6%|▌         | 5/84 [00:00<00:01, 45.00it/s]Scanning Parquet Files:  12%|█▏        | 10/84 [00:00<00:01, 47.72it/s]Scanning Parquet Files:  12%|█▏        | 10/84 [00:00<00:01, 45.41it/s]Scanning Parquet Files:  12%|█▏        | 10/84 [00:00<00:01, 44.38it/s]Scanning Parquet Files:  13%|█▎        | 11/84 [00:00<00:01, 43.68it/s]Scanning Parquet Files:  19%|█▉        | 16/84 [00:00<00:01, 51.06it/s]Scanning Parquet Files:  20%|██        | 17/84 [00:00<00:01, 51.01it/s]Scanning Parquet Files:  19%|█▉        | 16/84 [00:00<00:01, 46.66it/s]Scanning Parquet Files:  23%|██▎       | 19/84 [00:00<00:01, 54.14it/s]Scanning Parquet Files:  30%|██▉       | 25/84 [00:00<00:00, 62.87it/s]Scanning Parquet Files:  30%|██▉       | 25/84 [00:00<00:01, 56.57it/s]Scanning Parquet Files:  30%|██▉       | 25/84 [00:00<00:01, 57.08it/s]Scanning Parquet Files:  32%|███▏      | 27/84 [00:00<00:00, 62.27it/s]Scanning Parquet Files:  38%|███▊      | 32/84 [00:00<00:00, 64.59it/s]Scanning Parquet Files:  39%|███▉      | 33/84 [00:00<00:00, 56.39it/s]Scanning Parquet Files:  40%|████      | 34/84 [00:00<00:00, 57.38it/s]Scanning Parquet Files:  39%|███▉      | 33/84 [00:00<00:00, 55.28it/s]Scanning Parquet Files:  46%|████▋     | 39/84 [00:00<00:01, 40.48it/s]Scanning Parquet Files:  46%|████▋     | 39/84 [00:00<00:01, 41.32it/s]Scanning Parquet Files:  46%|████▋     | 39/84 [00:00<00:01, 40.02it/s]Scanning Parquet Files:  48%|████▊     | 40/84 [00:00<00:01, 35.44it/s]Scanning Parquet Files:  52%|█████▏    | 44/84 [00:01<00:01, 36.36it/s]Scanning Parquet Files:  52%|█████▏    | 44/84 [00:01<00:01, 34.91it/s]Scanning Parquet Files:  54%|█████▎    | 45/84 [00:01<00:01, 36.04it/s]Scanning Parquet Files:  54%|█████▎    | 45/84 [00:01<00:01, 31.75it/s]Scanning Parquet Files:  57%|█████▋    | 48/84 [00:01<00:01, 33.53it/s]Scanning Parquet Files:  57%|█████▋    | 48/84 [00:01<00:01, 33.10it/s]Scanning Parquet Files:  60%|█████▉    | 50/84 [00:01<00:00, 35.14it/s]Scanning Parquet Files:  60%|█████▉    | 50/84 [00:01<00:00, 34.85it/s]Scanning Parquet Files:  63%|██████▎   | 53/84 [00:01<00:00, 36.13it/s]Scanning Parquet Files:  63%|██████▎   | 53/84 [00:01<00:00, 35.24it/s]Scanning Parquet Files:  65%|██████▌   | 55/84 [00:01<00:00, 37.58it/s]Scanning Parquet Files:  65%|██████▌   | 55/84 [00:01<00:00, 36.67it/s]Scanning Parquet Files:  70%|███████   | 59/84 [00:01<00:00, 40.78it/s]Scanning Parquet Files:  70%|███████   | 59/84 [00:01<00:00, 39.21it/s]Scanning Parquet Files:  74%|███████▍  | 62/84 [00:01<00:00, 44.72it/s]Scanning Parquet Files:  71%|███████▏  | 60/84 [00:01<00:00, 39.54it/s]Scanning Parquet Files:  76%|███████▌  | 64/84 [00:01<00:00, 42.42it/s]Scanning Parquet Files:  81%|████████  | 68/84 [00:01<00:00, 46.60it/s]Scanning Parquet Files:  80%|███████▉  | 67/84 [00:01<00:00, 45.48it/s]Scanning Parquet Files:  80%|███████▉  | 67/84 [00:01<00:00, 44.65it/s]Scanning Parquet Files:  83%|████████▎ | 70/84 [00:01<00:00, 45.86it/s]Scanning Parquet Files:  87%|████████▋ | 73/84 [00:01<00:00, 47.64it/s]Scanning Parquet Files:  88%|████████▊ | 74/84 [00:01<00:00, 45.11it/s]Scanning Parquet Files:  87%|████████▋ | 73/84 [00:01<00:00, 45.14it/s]Scanning Parquet Files:  90%|█████████ | 76/84 [00:01<00:00, 45.19it/s]Scanning Parquet Files:  94%|█████████▍| 79/84 [00:01<00:00, 46.97it/s]Scanning Parquet Files:  95%|█████████▌| 80/84 [00:01<00:00, 48.97it/s]Scanning Parquet Files:  96%|█████████▋| 81/84 [00:01<00:00, 45.05it/s]Scanning Parquet Files: 100%|██████████| 84/84 [00:01<00:00, 45.51it/s]
Scanning Parquet Files: 100%|██████████| 84/84 [00:01<00:00, 44.75it/s]
Scanning Parquet Files: 100%|██████████| 84/84 [00:01<00:00, 44.93it/s]
✅ Loaded 190237 samples.
Scanning Parquet Files:  99%|█████████▉| 83/84 [00:01<00:00, 48.37it/s]Scanning Parquet Files: 100%|██████████| 84/84 [00:01<00:00, 44.28it/s]
✅ Loaded 190237 samples.
✅ Loaded 190237 samples.
✅ Loaded 190237 samples.
Filtered dataset: 190132 samples remaining.
Filtered dataset: 190132 samples remaining.
Filtered dataset: 190132 samples remaining.
Filtered dataset: 190132 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
01/22/2026 07:45:27 - INFO - __main__ - [INFO] Set DeepSpeed train_micro_batch_size_per_gpu to 1
Before initializing optimizer states
MA 25.37 GB         Max_MA 29.59 GB         CA 29.6 GB         Max_CA 30 GB 
CPU Virtual Memory:  used = 140.55 GB, percent = 16.2%
After initializing optimizer states
MA 25.37 GB         Max_MA 33.82 GB         CA 38.06 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 132.87 GB, percent = 15.3%
After initializing ZeRO optimizer
MA 25.37 GB         Max_MA 25.37 GB         CA 38.06 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 109.03 GB, percent = 12.6%
01/22/2026 07:45:46 - INFO - __main__ - ***** Running training *****
01/22/2026 07:45:46 - INFO - __main__ -   Num examples = 190132
01/22/2026 07:45:46 - INFO - __main__ -   Num Epochs = 2
01/22/2026 07:45:46 - INFO - __main__ -   Instantaneous batch size per device = 1
01/22/2026 07:45:46 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
01/22/2026 07:45:46 - INFO - __main__ -   Gradient Accumulation steps = 4
01/22/2026 07:45:46 - INFO - __main__ -   Total optimization steps = 5000
Steps:   0%|          | 0/5000 [00:00<?, ?it/s]01/22/2026 07:45:46 - INFO - __main__ - [INFO] Using training iteration function: Flux2Klein_fulltune_train_iteration
01/22/2026 07:45:47 - INFO - __main__ - [INFO] Using validation function: Flux2Klein_fulltune_validation_func_parquet
01/22/2026 07:45:47 - INFO - __main__ - [INFO] Validation every 200 steps
wandb: Loaded settings from
wandb:   /home/v-yuxluo/.config/wandb/settings
wandb: [wandb.login()] Loaded credentials for https://microsoft-research.wandb.io from /home/v-yuxluo/.netrc.
wandb: Currently logged in as: v-yuxluo to https://microsoft-research.wandb.io. Use `wandb login --relogin` to force relogin
wandb: setting up run srfc5mxw
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /home/v-yuxluo/WORK_local/ArXivQwenImage/wandb/run-20260122_074548-srfc5mxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flux2klein_9b_fulltune_5000steps
wandb: ⭐️ View project at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-FullTune
wandb: 🚀 View run at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-FullTune/runs/srfc5mxw
01/22/2026 07:45:49 - INFO - __main__ - 
======================================================================
01/22/2026 07:45:49 - INFO - __main__ - Starting Training Loop
01/22/2026 07:45:49 - INFO - __main__ - ======================================================================

[Step 0] Training Debug Info:
  Loss: 0.599027
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0016, std: 0.8984
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0015, std: 1.3438
  Model pred mean: 0.0049, std: 1.2891
  Sigmas: [0.6171875]... (timesteps: [618.0])

[Step 0] Training Debug Info:
  Loss: 1.153212
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0481, std: 0.9297
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0481, std: 1.3672
  Model pred mean: -0.0284, std: 0.8555
  Sigmas: [0.041015625]... (timesteps: [41.0])

[Step 0] Training Debug Info:
  Loss: 0.641546
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0056, std: 0.9102
  Noise mean: 0.0040, std: 0.9961
  Target mean: -0.0015, std: 1.3516
  Model pred mean: 0.0015, std: 1.2812
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 0] Training Debug Info:
  Loss: 1.469110
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0054, std: 0.8672
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0021, std: 1.3203
  Model pred mean: 0.0066, std: 1.3906
  Sigmas: [0.400390625]... (timesteps: [400.0])
Steps:   0%|          | 1/5000 [00:19<27:23:09, 19.72s/it]Steps:   0%|          | 1/5000 [00:19<27:23:09, 19.72s/it, loss=1.4691, lr=2.00e-08]01/22/2026 07:46:06 - INFO - __main__ - 
🔍 Running validation at step 1...
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1 (parquet mode)...
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1...
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 07:46:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 07:46:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 07:46:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 07:46:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 07:46:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 07:47:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 07:47:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 07:47:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 07:47:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 07:47:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 07:47:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 07:48:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 07:48:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 07:48:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 07:48:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 07:48:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 07:48:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 07:49:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 07:49:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 07:49:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 07:49:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.47it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.44it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.43it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.43it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 07:49:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 07:49:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.16it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.47it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.44it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.43it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.43it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.43it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.43it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.43it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.43it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.43it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.43it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.43it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.43it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.43it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.43it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.43it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.43it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.43it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.43it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 07:50:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001/step000001_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 07:50:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 07:50:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 07:50:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000001
01/22/2026 07:50:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

Steps:   0%|          | 2/5000 [04:46<228:56:40, 164.91s/it, loss=1.4691, lr=2.00e-08]Steps:   0%|          | 2/5000 [04:46<228:56:40, 164.91s/it, loss=0.3842, lr=4.00e-08]Steps:   0%|          | 3/5000 [04:58<132:11:59, 95.24s/it, loss=0.3842, lr=4.00e-08] Steps:   0%|          | 3/5000 [04:58<132:11:59, 95.24s/it, loss=1.0442, lr=6.00e-08]Steps:   0%|          | 4/5000 [05:10<86:40:11, 62.45s/it, loss=1.0442, lr=6.00e-08] Steps:   0%|          | 4/5000 [05:10<86:40:11, 62.45s/it, loss=0.9792, lr=8.00e-08]Steps:   0%|          | 5/5000 [05:22<61:23:09, 44.24s/it, loss=0.9792, lr=8.00e-08]Steps:   0%|          | 5/5000 [05:22<61:23:09, 44.24s/it, loss=0.6916, lr=1.00e-07]Steps:   0%|          | 6/5000 [05:34<46:05:47, 33.23s/it, loss=0.6916, lr=1.00e-07]Steps:   0%|          | 6/5000 [05:34<46:05:47, 33.23s/it, loss=0.4616, lr=1.20e-07]Steps:   0%|          | 7/5000 [05:46<36:23:32, 26.24s/it, loss=0.4616, lr=1.20e-07]Steps:   0%|          | 7/5000 [05:46<36:23:32, 26.24s/it, loss=0.7303, lr=1.40e-07]Steps:   0%|          | 8/5000 [05:58<30:03:29, 21.68s/it, loss=0.7303, lr=1.40e-07]Steps:   0%|          | 8/5000 [05:58<30:03:29, 21.68s/it, loss=1.0901, lr=1.60e-07]Steps:   0%|          | 9/5000 [06:10<25:49:11, 18.62s/it, loss=1.0901, lr=1.60e-07]Steps:   0%|          | 9/5000 [06:10<25:49:11, 18.62s/it, loss=1.5314, lr=1.80e-07]Steps:   0%|          | 10/5000 [06:22<23:00:37, 16.60s/it, loss=1.5314, lr=1.80e-07]Steps:   0%|          | 10/5000 [06:22<23:00:37, 16.60s/it, loss=0.5584, lr=2.00e-07]
[Step 10] Training Debug Info:
  Loss: 1.936381
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0161, std: 0.9336
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0157, std: 1.3672
  Model pred mean: -0.0075, std: 1.4766
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 10] Training Debug Info:
  Loss: 1.298008
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0061, std: 0.9297
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0068, std: 1.3672
  Model pred mean: 0.0205, std: 0.8516
  Sigmas: [0.053955078125]... (timesteps: [54.0])

[Step 10] Training Debug Info:
  Loss: 2.329561
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0109, std: 0.8828
  Noise mean: 0.0035, std: 1.0000
  Target mean: 0.0145, std: 1.3359
  Model pred mean: 0.0410, std: 1.3125
  Sigmas: [0.2109375]... (timesteps: [211.0])

[Step 10] Training Debug Info:
  Loss: 0.386744
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0141, std: 0.9297
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0140, std: 1.3672
  Model pred mean: -0.0104, std: 1.2891
  Sigmas: [0.71875]... (timesteps: [719.0])
Steps:   0%|          | 11/5000 [06:34<21:00:11, 15.16s/it, loss=0.5584, lr=2.00e-07]Steps:   0%|          | 11/5000 [06:34<21:00:11, 15.16s/it, loss=0.3867, lr=2.20e-07]Steps:   0%|          | 12/5000 [06:46<19:39:44, 14.19s/it, loss=0.3867, lr=2.20e-07]Steps:   0%|          | 12/5000 [06:46<19:39:44, 14.19s/it, loss=0.3582, lr=2.40e-07]Steps:   0%|          | 13/5000 [06:58<18:45:42, 13.54s/it, loss=0.3582, lr=2.40e-07]Steps:   0%|          | 13/5000 [06:58<18:45:42, 13.54s/it, loss=1.3406, lr=2.60e-07]Steps:   0%|          | 14/5000 [07:10<18:05:27, 13.06s/it, loss=1.3406, lr=2.60e-07]Steps:   0%|          | 14/5000 [07:10<18:05:27, 13.06s/it, loss=0.8281, lr=2.80e-07]Steps:   0%|          | 15/5000 [07:22<17:37:01, 12.72s/it, loss=0.8281, lr=2.80e-07]Steps:   0%|          | 15/5000 [07:22<17:37:01, 12.72s/it, loss=0.4410, lr=3.00e-07]Steps:   0%|          | 16/5000 [07:34<17:18:00, 12.50s/it, loss=0.4410, lr=3.00e-07]Steps:   0%|          | 16/5000 [07:34<17:18:00, 12.50s/it, loss=0.6131, lr=3.20e-07]Steps:   0%|          | 17/5000 [07:46<17:06:32, 12.36s/it, loss=0.6131, lr=3.20e-07]Steps:   0%|          | 17/5000 [07:46<17:06:32, 12.36s/it, loss=0.3992, lr=3.40e-07]Steps:   0%|          | 18/5000 [07:58<16:55:21, 12.23s/it, loss=0.3992, lr=3.40e-07]Steps:   0%|          | 18/5000 [07:58<16:55:21, 12.23s/it, loss=0.3853, lr=3.60e-07]Steps:   0%|          | 19/5000 [08:09<16:47:22, 12.13s/it, loss=0.3853, lr=3.60e-07]Steps:   0%|          | 19/5000 [08:09<16:47:22, 12.13s/it, loss=1.7640, lr=3.80e-07]Steps:   0%|          | 20/5000 [08:21<16:40:24, 12.05s/it, loss=1.7640, lr=3.80e-07]Steps:   0%|          | 20/5000 [08:21<16:40:24, 12.05s/it, loss=0.3743, lr=4.00e-07]
[Step 20] Training Debug Info:
  Loss: 2.882026
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0125, std: 0.8477
  Noise mean: 0.0039, std: 1.0000
  Target mean: 0.0164, std: 1.3125
  Model pred mean: 0.0203, std: 1.5391
  Sigmas: [0.2353515625]... (timesteps: [235.0])

[Step 20] Training Debug Info:
  Loss: 0.467389
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0133, std: 0.9062
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0123, std: 1.3516
  Model pred mean: -0.0162, std: 1.2656
  Sigmas: [0.703125]... (timesteps: [703.0])

[Step 20] Training Debug Info:
  Loss: 2.029814
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0032, std: 0.8984
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0053, std: 1.3438
  Model pred mean: 0.0349, std: 1.1797
  Sigmas: [0.197265625]... (timesteps: [197.0])

[Step 20] Training Debug Info:
  Loss: 0.654222
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0347, std: 0.9102
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0378, std: 1.3594
  Model pred mean: -0.0305, std: 1.2656
  Sigmas: [0.6171875]... (timesteps: [619.0])
Steps:   0%|          | 21/5000 [08:33<16:34:53, 11.99s/it, loss=0.3743, lr=4.00e-07]Steps:   0%|          | 21/5000 [08:33<16:34:53, 11.99s/it, loss=0.6542, lr=4.20e-07]Steps:   0%|          | 22/5000 [08:45<16:35:03, 11.99s/it, loss=0.6542, lr=4.20e-07]Steps:   0%|          | 22/5000 [08:45<16:35:03, 11.99s/it, loss=1.5407, lr=4.40e-07]Steps:   0%|          | 23/5000 [08:57<16:38:23, 12.04s/it, loss=1.5407, lr=4.40e-07]Steps:   0%|          | 23/5000 [08:57<16:38:23, 12.04s/it, loss=2.0303, lr=4.60e-07]Steps:   0%|          | 24/5000 [09:09<16:36:32, 12.02s/it, loss=2.0303, lr=4.60e-07]Steps:   0%|          | 24/5000 [09:09<16:36:32, 12.02s/it, loss=0.5237, lr=4.80e-07]Steps:   0%|          | 25/5000 [09:21<16:34:20, 11.99s/it, loss=0.5237, lr=4.80e-07]Steps:   0%|          | 25/5000 [09:21<16:34:20, 11.99s/it, loss=1.2236, lr=5.00e-07]Steps:   1%|          | 26/5000 [09:33<16:32:52, 11.98s/it, loss=1.2236, lr=5.00e-07]Steps:   1%|          | 26/5000 [09:33<16:32:52, 11.98s/it, loss=0.3738, lr=5.20e-07]Steps:   1%|          | 27/5000 [09:45<16:33:01, 11.98s/it, loss=0.3738, lr=5.20e-07]Steps:   1%|          | 27/5000 [09:45<16:33:01, 11.98s/it, loss=0.3796, lr=5.40e-07]Steps:   1%|          | 28/5000 [09:57<16:33:05, 11.98s/it, loss=0.3796, lr=5.40e-07]Steps:   1%|          | 28/5000 [09:57<16:33:05, 11.98s/it, loss=0.5868, lr=5.60e-07]Steps:   1%|          | 29/5000 [10:09<16:28:50, 11.94s/it, loss=0.5868, lr=5.60e-07]Steps:   1%|          | 29/5000 [10:09<16:28:50, 11.94s/it, loss=0.6200, lr=5.80e-07]Steps:   1%|          | 30/5000 [10:21<16:33:13, 11.99s/it, loss=0.6200, lr=5.80e-07]Steps:   1%|          | 30/5000 [10:21<16:33:13, 11.99s/it, loss=0.5185, lr=6.00e-07]
[Step 30] Training Debug Info:
  Loss: 0.759809
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0045, std: 0.9023
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0031, std: 1.3438
  Model pred mean: -0.0007, std: 1.2969
  Sigmas: [0.53515625]... (timesteps: [535.0])

[Step 30] Training Debug Info:
  Loss: 0.383176
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0266, std: 0.9023
  Noise mean: 0.0008, std: 0.9961
  Target mean: 0.0275, std: 1.3438
  Model pred mean: 0.0159, std: 1.2266
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 30] Training Debug Info:
  Loss: 0.382290
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0231, std: 0.9297
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0249, std: 1.3672
  Model pred mean: -0.0242, std: 1.2500
  Sigmas: [0.84375]... (timesteps: [844.0])

[Step 30] Training Debug Info:
  Loss: 0.409008
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0043, std: 0.8945
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0040, std: 1.3438
  Model pred mean: -0.0059, std: 1.2422
  Sigmas: [0.79296875]... (timesteps: [792.0])
Steps:   1%|          | 31/5000 [10:33<16:36:05, 12.03s/it, loss=0.5185, lr=6.00e-07]Steps:   1%|          | 31/5000 [10:33<16:36:05, 12.03s/it, loss=0.4090, lr=6.20e-07]Steps:   1%|          | 32/5000 [10:45<16:34:22, 12.01s/it, loss=0.4090, lr=6.20e-07]Steps:   1%|          | 32/5000 [10:45<16:34:22, 12.01s/it, loss=0.6223, lr=6.40e-07]Steps:   1%|          | 33/5000 [10:57<16:31:14, 11.97s/it, loss=0.6223, lr=6.40e-07]Steps:   1%|          | 33/5000 [10:57<16:31:14, 11.97s/it, loss=1.6313, lr=6.60e-07]Steps:   1%|          | 34/5000 [11:09<16:32:08, 11.99s/it, loss=1.6313, lr=6.60e-07]Steps:   1%|          | 34/5000 [11:09<16:32:08, 11.99s/it, loss=0.5775, lr=6.80e-07]Steps:   1%|          | 35/5000 [11:21<16:29:50, 11.96s/it, loss=0.5775, lr=6.80e-07]Steps:   1%|          | 35/5000 [11:21<16:29:50, 11.96s/it, loss=0.4674, lr=7.00e-07]Steps:   1%|          | 36/5000 [11:33<16:29:58, 11.97s/it, loss=0.4674, lr=7.00e-07]Steps:   1%|          | 36/5000 [11:33<16:29:58, 11.97s/it, loss=1.0458, lr=7.20e-07]Steps:   1%|          | 37/5000 [11:45<16:32:58, 12.00s/it, loss=1.0458, lr=7.20e-07]Steps:   1%|          | 37/5000 [11:45<16:32:58, 12.00s/it, loss=0.4699, lr=7.40e-07]Steps:   1%|          | 38/5000 [11:57<16:31:29, 11.99s/it, loss=0.4699, lr=7.40e-07]Steps:   1%|          | 38/5000 [11:57<16:31:29, 11.99s/it, loss=0.3641, lr=7.60e-07]Steps:   1%|          | 39/5000 [12:09<16:28:47, 11.96s/it, loss=0.3641, lr=7.60e-07]Steps:   1%|          | 39/5000 [12:09<16:28:47, 11.96s/it, loss=1.7202, lr=7.80e-07]Steps:   1%|          | 40/5000 [12:21<16:30:31, 11.98s/it, loss=1.7202, lr=7.80e-07]Steps:   1%|          | 40/5000 [12:21<16:30:31, 11.98s/it, loss=1.2332, lr=8.00e-07]
[Step 40] Training Debug Info:
  Loss: 1.073024
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0229, std: 0.9570
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0214, std: 1.3828
  Model pred mean: -0.0183, std: 1.3281
  Sigmas: [0.435546875]... (timesteps: [436.0])

[Step 40] Training Debug Info:
  Loss: 0.612759
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0142, std: 0.9531
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0148, std: 1.3828
  Model pred mean: 0.0093, std: 1.1406
  Sigmas: [0.94140625]... (timesteps: [941.0])

[Step 40] Training Debug Info:
  Loss: 1.951675
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0227, std: 0.8594
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0222, std: 1.3203
  Model pred mean: 0.0413, std: 1.2969
  Sigmas: [0.291015625]... (timesteps: [291.0])

[Step 40] Training Debug Info:
  Loss: 0.625273
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0354, std: 0.9297
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0317, std: 1.3594
  Model pred mean: -0.0337, std: 1.2656
  Sigmas: [0.57421875]... (timesteps: [576.0])
Steps:   1%|          | 41/5000 [12:33<16:27:16, 11.95s/it, loss=1.2332, lr=8.00e-07]Steps:   1%|          | 41/5000 [12:33<16:27:16, 11.95s/it, loss=0.6253, lr=8.20e-07]Steps:   1%|          | 42/5000 [12:45<16:26:19, 11.94s/it, loss=0.6253, lr=8.20e-07]Steps:   1%|          | 42/5000 [12:45<16:26:19, 11.94s/it, loss=0.4022, lr=8.40e-07]Steps:   1%|          | 43/5000 [12:57<16:30:47, 11.99s/it, loss=0.4022, lr=8.40e-07]Steps:   1%|          | 43/5000 [12:57<16:30:47, 11.99s/it, loss=0.5520, lr=8.60e-07]Steps:   1%|          | 44/5000 [13:09<16:32:57, 12.02s/it, loss=0.5520, lr=8.60e-07]Steps:   1%|          | 44/5000 [13:09<16:32:57, 12.02s/it, loss=1.7024, lr=8.80e-07]Steps:   1%|          | 45/5000 [13:21<16:30:06, 11.99s/it, loss=1.7024, lr=8.80e-07]Steps:   1%|          | 45/5000 [13:21<16:30:06, 11.99s/it, loss=1.4121, lr=9.00e-07]Steps:   1%|          | 46/5000 [13:33<16:26:59, 11.95s/it, loss=1.4121, lr=9.00e-07]Steps:   1%|          | 46/5000 [13:33<16:26:59, 11.95s/it, loss=1.3267, lr=9.20e-07]Steps:   1%|          | 47/5000 [13:45<16:25:47, 11.94s/it, loss=1.3267, lr=9.20e-07]Steps:   1%|          | 47/5000 [13:45<16:25:47, 11.94s/it, loss=0.9300, lr=9.40e-07]Steps:   1%|          | 48/5000 [13:57<16:24:56, 11.93s/it, loss=0.9300, lr=9.40e-07]Steps:   1%|          | 48/5000 [13:57<16:24:56, 11.93s/it, loss=1.1577, lr=9.60e-07]Steps:   1%|          | 49/5000 [14:09<16:25:49, 11.95s/it, loss=1.1577, lr=9.60e-07]Steps:   1%|          | 49/5000 [14:09<16:25:49, 11.95s/it, loss=0.6492, lr=9.80e-07]Steps:   1%|          | 50/5000 [14:21<16:28:12, 11.98s/it, loss=0.6492, lr=9.80e-07]Steps:   1%|          | 50/5000 [14:21<16:28:12, 11.98s/it, loss=0.5031, lr=1.00e-06]
[Step 50] Training Debug Info:
  Loss: 1.171913
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0205, std: 0.8945
  Noise mean: -0.0031, std: 1.0000
  Target mean: 0.0175, std: 1.3438
  Model pred mean: 0.0283, std: 0.8086
  Sigmas: [0.0791015625]... (timesteps: [79.0])

[Step 50] Training Debug Info:
  Loss: 1.159772
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0145, std: 0.8711
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0125, std: 1.3281
  Model pred mean: 0.0070, std: 0.8828
  Sigmas: [0.306640625]... (timesteps: [306.0])

[Step 50] Training Debug Info:
  Loss: 0.656049
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0361, std: 0.9336
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0361, std: 1.3672
  Model pred mean: -0.0232, std: 1.1719
  Sigmas: [0.5234375]... (timesteps: [525.0])

[Step 50] Training Debug Info:
  Loss: 0.407215
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0152, std: 0.9102
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0173, std: 1.3516
  Model pred mean: 0.0112, std: 1.2109
  Sigmas: [0.80078125]... (timesteps: [802.0])
Steps:   1%|          | 51/5000 [14:32<16:25:21, 11.95s/it, loss=0.5031, lr=1.00e-06]Steps:   1%|          | 51/5000 [14:32<16:25:21, 11.95s/it, loss=0.4072, lr=1.02e-06]Steps:   1%|          | 52/5000 [14:44<16:26:34, 11.96s/it, loss=0.4072, lr=1.02e-06]Steps:   1%|          | 52/5000 [14:44<16:26:34, 11.96s/it, loss=1.0815, lr=1.04e-06]Steps:   1%|          | 53/5000 [14:56<16:25:46, 11.96s/it, loss=1.0815, lr=1.04e-06]Steps:   1%|          | 53/5000 [14:56<16:25:46, 11.96s/it, loss=0.4011, lr=1.06e-06]Steps:   1%|          | 54/5000 [15:08<16:23:44, 11.93s/it, loss=0.4011, lr=1.06e-06]Steps:   1%|          | 54/5000 [15:08<16:23:44, 11.93s/it, loss=0.5806, lr=1.08e-06]Steps:   1%|          | 55/5000 [15:20<16:22:51, 11.93s/it, loss=0.5806, lr=1.08e-06]Steps:   1%|          | 55/5000 [15:20<16:22:51, 11.93s/it, loss=1.2568, lr=1.10e-06]Steps:   1%|          | 56/5000 [15:32<16:22:51, 11.93s/it, loss=1.2568, lr=1.10e-06]Steps:   1%|          | 56/5000 [15:32<16:22:51, 11.93s/it, loss=1.2773, lr=1.12e-06]Steps:   1%|          | 57/5000 [15:44<16:26:09, 11.97s/it, loss=1.2773, lr=1.12e-06]Steps:   1%|          | 57/5000 [15:44<16:26:09, 11.97s/it, loss=0.6021, lr=1.14e-06]Steps:   1%|          | 58/5000 [15:56<16:26:46, 11.98s/it, loss=0.6021, lr=1.14e-06]Steps:   1%|          | 58/5000 [15:56<16:26:46, 11.98s/it, loss=1.1286, lr=1.16e-06]Steps:   1%|          | 59/5000 [16:08<16:25:00, 11.96s/it, loss=1.1286, lr=1.16e-06]Steps:   1%|          | 59/5000 [16:08<16:25:00, 11.96s/it, loss=0.3858, lr=1.18e-06]Steps:   1%|          | 60/5000 [16:20<16:24:26, 11.96s/it, loss=0.3858, lr=1.18e-06]Steps:   1%|          | 60/5000 [16:20<16:24:26, 11.96s/it, loss=0.4405, lr=1.20e-06]
[Step 60] Training Debug Info:
  Loss: 0.629648
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0134, std: 0.9180
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0132, std: 1.3594
  Model pred mean: -0.0114, std: 1.0703
  Sigmas: [0.6015625]... (timesteps: [601.0])

[Step 60] Training Debug Info:
  Loss: 0.380615
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0070, std: 0.9336
  Noise mean: -0.0040, std: 1.0000
  Target mean: -0.0110, std: 1.3672
  Model pred mean: -0.0066, std: 1.2109
  Sigmas: [0.7890625]... (timesteps: [788.0])

[Step 60] Training Debug Info:
  Loss: 0.588975
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0105, std: 0.9062
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0126, std: 1.3516
  Model pred mean: -0.0004, std: 1.0703
  Sigmas: [0.59375]... (timesteps: [592.0])

[Step 60] Training Debug Info:
  Loss: 0.558450
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0255, std: 0.9883
  Noise mean: 0.0054, std: 1.0000
  Target mean: -0.0200, std: 1.4062
  Model pred mean: -0.0282, std: 1.1719
  Sigmas: [0.8515625]... (timesteps: [852.0])
Steps:   1%|          | 61/5000 [16:32<16:25:19, 11.97s/it, loss=0.4405, lr=1.20e-06]Steps:   1%|          | 61/5000 [16:32<16:25:19, 11.97s/it, loss=0.5585, lr=1.22e-06]Steps:   1%|          | 62/5000 [16:44<16:22:42, 11.94s/it, loss=0.5585, lr=1.22e-06]Steps:   1%|          | 62/5000 [16:44<16:22:42, 11.94s/it, loss=1.2831, lr=1.24e-06]Steps:   1%|▏         | 63/5000 [16:56<16:22:58, 11.95s/it, loss=1.2831, lr=1.24e-06]Steps:   1%|▏         | 63/5000 [16:56<16:22:58, 11.95s/it, loss=0.4263, lr=1.26e-06]Steps:   1%|▏         | 64/5000 [17:08<16:24:51, 11.97s/it, loss=0.4263, lr=1.26e-06]Steps:   1%|▏         | 64/5000 [17:08<16:24:51, 11.97s/it, loss=0.3953, lr=1.28e-06]Steps:   1%|▏         | 65/5000 [17:20<16:24:16, 11.97s/it, loss=0.3953, lr=1.28e-06]Steps:   1%|▏         | 65/5000 [17:20<16:24:16, 11.97s/it, loss=0.4099, lr=1.30e-06]Steps:   1%|▏         | 66/5000 [17:32<16:20:55, 11.93s/it, loss=0.4099, lr=1.30e-06]Steps:   1%|▏         | 66/5000 [17:32<16:20:55, 11.93s/it, loss=1.0735, lr=1.32e-06]Steps:   1%|▏         | 67/5000 [17:44<16:23:55, 11.97s/it, loss=1.0735, lr=1.32e-06]Steps:   1%|▏         | 67/5000 [17:44<16:23:55, 11.97s/it, loss=0.4922, lr=1.34e-06]Steps:   1%|▏         | 68/5000 [17:56<16:22:54, 11.96s/it, loss=0.4922, lr=1.34e-06]Steps:   1%|▏         | 68/5000 [17:56<16:22:54, 11.96s/it, loss=1.1798, lr=1.36e-06]Steps:   1%|▏         | 69/5000 [18:08<16:20:37, 11.93s/it, loss=1.1798, lr=1.36e-06]Steps:   1%|▏         | 69/5000 [18:08<16:20:37, 11.93s/it, loss=0.8712, lr=1.38e-06]Steps:   1%|▏         | 70/5000 [18:20<16:22:38, 11.96s/it, loss=0.8712, lr=1.38e-06]Steps:   1%|▏         | 70/5000 [18:20<16:22:38, 11.96s/it, loss=0.4133, lr=1.40e-06]
[Step 70] Training Debug Info:
  Loss: 0.655856
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0089, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0088, std: 1.3516
  Model pred mean: 0.0056, std: 1.1641
  Sigmas: [0.54296875]... (timesteps: [544.0])

[Step 70] Training Debug Info:
  Loss: 0.393763
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0261, std: 0.9375
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0269, std: 1.3750
  Model pred mean: -0.0295, std: 1.2188
  Sigmas: [0.74609375]... (timesteps: [747.0])

[Step 70] Training Debug Info:
  Loss: 0.464154
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0010, std: 0.8828
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0030, std: 1.3359
  Model pred mean: 0.0003, std: 1.1641
  Sigmas: [0.703125]... (timesteps: [705.0])

[Step 70] Training Debug Info:
  Loss: 0.518823
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0242, std: 0.9219
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0254, std: 1.3594
  Model pred mean: -0.0293, std: 1.1797
  Sigmas: [0.66015625]... (timesteps: [659.0])
Steps:   1%|▏         | 71/5000 [18:32<16:25:30, 12.00s/it, loss=0.4133, lr=1.40e-06]Steps:   1%|▏         | 71/5000 [18:32<16:25:30, 12.00s/it, loss=0.5188, lr=1.42e-06]Steps:   1%|▏         | 72/5000 [18:44<16:22:46, 11.97s/it, loss=0.5188, lr=1.42e-06]Steps:   1%|▏         | 72/5000 [18:44<16:22:46, 11.97s/it, loss=0.5704, lr=1.44e-06]Steps:   1%|▏         | 73/5000 [18:56<16:22:12, 11.96s/it, loss=0.5704, lr=1.44e-06]Steps:   1%|▏         | 73/5000 [18:56<16:22:12, 11.96s/it, loss=0.6150, lr=1.46e-06]Steps:   1%|▏         | 74/5000 [19:08<16:23:39, 11.98s/it, loss=0.6150, lr=1.46e-06]Steps:   1%|▏         | 74/5000 [19:08<16:23:39, 11.98s/it, loss=0.7353, lr=1.48e-06]Steps:   2%|▏         | 75/5000 [19:20<16:23:30, 11.98s/it, loss=0.7353, lr=1.48e-06]Steps:   2%|▏         | 75/5000 [19:20<16:23:30, 11.98s/it, loss=0.6097, lr=1.50e-06]Steps:   2%|▏         | 76/5000 [19:32<16:25:49, 12.01s/it, loss=0.6097, lr=1.50e-06]Steps:   2%|▏         | 76/5000 [19:32<16:25:49, 12.01s/it, loss=1.1449, lr=1.52e-06]Steps:   2%|▏         | 77/5000 [19:44<16:28:51, 12.05s/it, loss=1.1449, lr=1.52e-06]Steps:   2%|▏         | 77/5000 [19:44<16:28:51, 12.05s/it, loss=0.8072, lr=1.54e-06]Steps:   2%|▏         | 78/5000 [19:56<16:23:40, 11.99s/it, loss=0.8072, lr=1.54e-06]Steps:   2%|▏         | 78/5000 [19:56<16:23:40, 11.99s/it, loss=0.9900, lr=1.56e-06]Steps:   2%|▏         | 79/5000 [20:08<16:25:46, 12.02s/it, loss=0.9900, lr=1.56e-06]Steps:   2%|▏         | 79/5000 [20:08<16:25:46, 12.02s/it, loss=1.0323, lr=1.58e-06]Steps:   2%|▏         | 80/5000 [20:20<16:24:31, 12.01s/it, loss=1.0323, lr=1.58e-06]Steps:   2%|▏         | 80/5000 [20:20<16:24:31, 12.01s/it, loss=0.5774, lr=1.60e-06]
[Step 80] Training Debug Info:
  Loss: 1.181740
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0031, std: 0.8984
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0006, std: 1.3438
  Model pred mean: -0.0079, std: 0.8047
  Sigmas: [0.1298828125]... (timesteps: [130.0])

[Step 80] Training Debug Info:
  Loss: 1.102991
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0310, std: 0.9062
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0332, std: 1.3516
  Model pred mean: -0.0299, std: 0.8516
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 80] Training Debug Info:
  Loss: 0.408402
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0009, std: 0.8906
  Noise mean: 0.0008, std: 0.9961
  Target mean: 0.0017, std: 1.3359
  Model pred mean: -0.0012, std: 1.1641
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 80] Training Debug Info:
  Loss: 0.511226
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0227, std: 0.8867
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0242, std: 1.3359
  Model pred mean: 0.0146, std: 1.0938
  Sigmas: [0.90234375]... (timesteps: [901.0])
Steps:   2%|▏         | 81/5000 [20:32<16:22:14, 11.98s/it, loss=0.5774, lr=1.60e-06]Steps:   2%|▏         | 81/5000 [20:32<16:22:14, 11.98s/it, loss=0.5112, lr=1.62e-06]Steps:   2%|▏         | 82/5000 [20:43<16:20:28, 11.96s/it, loss=0.5112, lr=1.62e-06]Steps:   2%|▏         | 82/5000 [20:43<16:20:28, 11.96s/it, loss=0.5431, lr=1.64e-06]Steps:   2%|▏         | 83/5000 [20:55<16:20:03, 11.96s/it, loss=0.5431, lr=1.64e-06]Steps:   2%|▏         | 83/5000 [20:55<16:20:03, 11.96s/it, loss=0.4673, lr=1.66e-06]Steps:   2%|▏         | 84/5000 [21:08<16:23:18, 12.00s/it, loss=0.4673, lr=1.66e-06]Steps:   2%|▏         | 84/5000 [21:08<16:23:18, 12.00s/it, loss=1.0156, lr=1.68e-06]Steps:   2%|▏         | 85/5000 [21:20<16:25:36, 12.03s/it, loss=1.0156, lr=1.68e-06]Steps:   2%|▏         | 85/5000 [21:20<16:25:36, 12.03s/it, loss=0.4158, lr=1.70e-06]Steps:   2%|▏         | 86/5000 [21:32<16:22:08, 11.99s/it, loss=0.4158, lr=1.70e-06]Steps:   2%|▏         | 86/5000 [21:32<16:22:08, 11.99s/it, loss=0.5020, lr=1.72e-06]Steps:   2%|▏         | 87/5000 [21:43<16:18:03, 11.94s/it, loss=0.5020, lr=1.72e-06]Steps:   2%|▏         | 87/5000 [21:43<16:18:03, 11.94s/it, loss=0.9787, lr=1.74e-06]Steps:   2%|▏         | 88/5000 [21:55<16:21:07, 11.98s/it, loss=0.9787, lr=1.74e-06]Steps:   2%|▏         | 88/5000 [21:55<16:21:07, 11.98s/it, loss=1.1990, lr=1.76e-06]Steps:   2%|▏         | 89/5000 [22:07<16:18:28, 11.95s/it, loss=1.1990, lr=1.76e-06]Steps:   2%|▏         | 89/5000 [22:07<16:18:28, 11.95s/it, loss=0.5976, lr=1.78e-06]Steps:   2%|▏         | 90/5000 [22:19<16:15:11, 11.92s/it, loss=0.5976, lr=1.78e-06]Steps:   2%|▏         | 90/5000 [22:19<16:15:11, 11.92s/it, loss=0.3995, lr=1.80e-06]
[Step 90] Training Debug Info:
  Loss: 0.594827
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0201, std: 0.8867
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0179, std: 1.3359
  Model pred mean: -0.0082, std: 1.0703
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 90] Training Debug Info:
  Loss: 0.739740
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0059, std: 0.9258
  Noise mean: -0.0036, std: 1.0000
  Target mean: -0.0095, std: 1.3672
  Model pred mean: -0.0081, std: 1.0625
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 90] Training Debug Info:
  Loss: 1.008379
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0366, std: 0.9414
  Noise mean: -0.0004, std: 0.9961
  Target mean: -0.0369, std: 1.3750
  Model pred mean: -0.0383, std: 0.9375
  Sigmas: [0.279296875]... (timesteps: [279.0])

[Step 90] Training Debug Info:
  Loss: 0.995544
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0050, std: 0.8594
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0046, std: 1.3203
  Model pred mean: -0.0012, std: 0.8672
  Sigmas: [0.390625]... (timesteps: [390.0])
Steps:   2%|▏         | 91/5000 [22:31<16:19:41, 11.97s/it, loss=0.3995, lr=1.80e-06]Steps:   2%|▏         | 91/5000 [22:31<16:19:41, 11.97s/it, loss=0.9955, lr=1.82e-06]Steps:   2%|▏         | 92/5000 [22:43<16:16:31, 11.94s/it, loss=0.9955, lr=1.82e-06]Steps:   2%|▏         | 92/5000 [22:43<16:16:31, 11.94s/it, loss=0.6526, lr=1.84e-06]Steps:   2%|▏         | 93/5000 [22:55<16:18:03, 11.96s/it, loss=0.6526, lr=1.84e-06]Steps:   2%|▏         | 93/5000 [22:55<16:18:03, 11.96s/it, loss=0.6009, lr=1.86e-06]Steps:   2%|▏         | 94/5000 [23:07<16:20:33, 11.99s/it, loss=0.6009, lr=1.86e-06]Steps:   2%|▏         | 94/5000 [23:07<16:20:33, 11.99s/it, loss=1.1672, lr=1.88e-06]Steps:   2%|▏         | 95/5000 [23:19<16:16:49, 11.95s/it, loss=1.1672, lr=1.88e-06]Steps:   2%|▏         | 95/5000 [23:19<16:16:49, 11.95s/it, loss=0.3306, lr=1.90e-06]Steps:   2%|▏         | 96/5000 [23:31<16:15:59, 11.94s/it, loss=0.3306, lr=1.90e-06]Steps:   2%|▏         | 96/5000 [23:31<16:15:59, 11.94s/it, loss=1.0814, lr=1.92e-06]Steps:   2%|▏         | 97/5000 [23:43<16:16:42, 11.95s/it, loss=1.0814, lr=1.92e-06]Steps:   2%|▏         | 97/5000 [23:43<16:16:42, 11.95s/it, loss=0.5777, lr=1.94e-06]Steps:   2%|▏         | 98/5000 [23:55<16:20:18, 12.00s/it, loss=0.5777, lr=1.94e-06]Steps:   2%|▏         | 98/5000 [23:55<16:20:18, 12.00s/it, loss=1.1814, lr=1.96e-06]Steps:   2%|▏         | 99/5000 [24:07<16:18:30, 11.98s/it, loss=1.1814, lr=1.96e-06]Steps:   2%|▏         | 99/5000 [24:07<16:18:30, 11.98s/it, loss=0.6986, lr=1.98e-06]Steps:   2%|▏         | 100/5000 [24:19<16:19:02, 11.99s/it, loss=0.6986, lr=1.98e-06]Steps:   2%|▏         | 100/5000 [24:19<16:19:02, 11.99s/it, loss=1.2057, lr=2.00e-06]01/22/2026 08:10:06 - INFO - __main__ - 
[Step 100] ✅ Loss in normal range (1.2057)
01/22/2026 08:10:06 - INFO - __main__ -   Loss avg (last 100): 0.7947
01/22/2026 08:10:06 - INFO - __main__ -   Loss range: [0.3306, 2.0303]

[Step 100] Training Debug Info:
  Loss: 0.717572
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0334, std: 0.9297
  Noise mean: 0.0053, std: 1.0000
  Target mean: -0.0281, std: 1.3672
  Model pred mean: -0.0354, std: 1.0781
  Sigmas: [0.4609375]... (timesteps: [461.0])

[Step 100] Training Debug Info:
  Loss: 0.782243
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0059, std: 0.9180
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0043, std: 1.3594
  Model pred mean: -0.0087, std: 1.0547
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 100] Training Debug Info:
  Loss: 0.475646
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0021, std: 0.9688
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0014, std: 1.3906
  Model pred mean: 0.0027, std: 1.2188
  Sigmas: [0.625]... (timesteps: [624.0])

[Step 100] Training Debug Info:
  Loss: 0.760370
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0198, std: 0.9883
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0195, std: 1.4062
  Model pred mean: -0.0229, std: 1.0859
  Sigmas: [0.953125]... (timesteps: [953.0])
Steps:   2%|▏         | 101/5000 [24:31<16:18:57, 11.99s/it, loss=1.2057, lr=2.00e-06]Steps:   2%|▏         | 101/5000 [24:31<16:18:57, 11.99s/it, loss=0.7604, lr=2.02e-06]Steps:   2%|▏         | 102/5000 [24:43<16:18:09, 11.98s/it, loss=0.7604, lr=2.02e-06]Steps:   2%|▏         | 102/5000 [24:43<16:18:09, 11.98s/it, loss=1.0469, lr=2.04e-06]Steps:   2%|▏         | 103/5000 [24:55<16:22:36, 12.04s/it, loss=1.0469, lr=2.04e-06]Steps:   2%|▏         | 103/5000 [24:55<16:22:36, 12.04s/it, loss=0.8199, lr=2.06e-06]Steps:   2%|▏         | 104/5000 [25:07<16:23:28, 12.05s/it, loss=0.8199, lr=2.06e-06]Steps:   2%|▏         | 104/5000 [25:07<16:23:28, 12.05s/it, loss=1.1347, lr=2.08e-06]Steps:   2%|▏         | 105/5000 [25:19<16:20:43, 12.02s/it, loss=1.1347, lr=2.08e-06]Steps:   2%|▏         | 105/5000 [25:19<16:20:43, 12.02s/it, loss=0.4803, lr=2.10e-06]Steps:   2%|▏         | 106/5000 [25:31<16:22:34, 12.05s/it, loss=0.4803, lr=2.10e-06]Steps:   2%|▏         | 106/5000 [25:31<16:22:34, 12.05s/it, loss=0.8611, lr=2.12e-06]Steps:   2%|▏         | 107/5000 [25:43<16:18:48, 12.00s/it, loss=0.8611, lr=2.12e-06]Steps:   2%|▏         | 107/5000 [25:43<16:18:48, 12.00s/it, loss=0.9233, lr=2.14e-06]Steps:   2%|▏         | 108/5000 [25:55<16:17:26, 11.99s/it, loss=0.9233, lr=2.14e-06]Steps:   2%|▏         | 108/5000 [25:55<16:17:26, 11.99s/it, loss=1.1054, lr=2.16e-06]Steps:   2%|▏         | 109/5000 [26:07<16:15:43, 11.97s/it, loss=1.1054, lr=2.16e-06]Steps:   2%|▏         | 109/5000 [26:07<16:15:43, 11.97s/it, loss=0.7254, lr=2.18e-06]Steps:   2%|▏         | 110/5000 [26:19<16:12:46, 11.94s/it, loss=0.7254, lr=2.18e-06]Steps:   2%|▏         | 110/5000 [26:19<16:12:46, 11.94s/it, loss=1.1875, lr=2.20e-06]
[Step 110] Training Debug Info:
  Loss: 0.570036
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0496, std: 0.9531
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0466, std: 1.3828
  Model pred mean: -0.0518, std: 1.1406
  Sigmas: [0.51171875]... (timesteps: [513.0])

[Step 110] Training Debug Info:
  Loss: 1.171174
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0017, std: 0.8750
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0015, std: 1.3281
  Model pred mean: 0.0012, std: 0.7695
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 110] Training Debug Info:
  Loss: 1.042234
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0212, std: 0.9375
  Noise mean: 0.0000, std: 0.9961
  Target mean: 0.0214, std: 1.3672
  Model pred mean: 0.0165, std: 0.8984
  Sigmas: [0.02001953125]... (timesteps: [20.0])

[Step 110] Training Debug Info:
  Loss: 0.424426
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0069, std: 0.9375
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0071, std: 1.3750
  Model pred mean: 0.0056, std: 1.2188
  Sigmas: [0.7421875]... (timesteps: [744.0])
Steps:   2%|▏         | 111/5000 [26:31<16:16:10, 11.98s/it, loss=1.1875, lr=2.20e-06]Steps:   2%|▏         | 111/5000 [26:31<16:16:10, 11.98s/it, loss=0.4244, lr=2.22e-06]Steps:   2%|▏         | 112/5000 [26:43<16:15:56, 11.98s/it, loss=0.4244, lr=2.22e-06]Steps:   2%|▏         | 112/5000 [26:43<16:15:56, 11.98s/it, loss=0.3605, lr=2.24e-06]Steps:   2%|▏         | 113/5000 [26:55<16:14:25, 11.96s/it, loss=0.3605, lr=2.24e-06]Steps:   2%|▏         | 113/5000 [26:55<16:14:25, 11.96s/it, loss=0.8639, lr=2.26e-06]Steps:   2%|▏         | 114/5000 [27:07<16:12:21, 11.94s/it, loss=0.8639, lr=2.26e-06]Steps:   2%|▏         | 114/5000 [27:07<16:12:21, 11.94s/it, loss=1.0831, lr=2.28e-06]Steps:   2%|▏         | 115/5000 [27:19<16:14:27, 11.97s/it, loss=1.0831, lr=2.28e-06]Steps:   2%|▏         | 115/5000 [27:19<16:14:27, 11.97s/it, loss=0.8855, lr=2.30e-06]Steps:   2%|▏         | 116/5000 [27:31<16:12:37, 11.95s/it, loss=0.8855, lr=2.30e-06]Steps:   2%|▏         | 116/5000 [27:31<16:12:37, 11.95s/it, loss=0.4428, lr=2.32e-06]Steps:   2%|▏         | 117/5000 [27:43<16:10:16, 11.92s/it, loss=0.4428, lr=2.32e-06]Steps:   2%|▏         | 117/5000 [27:43<16:10:16, 11.92s/it, loss=1.1028, lr=2.34e-06]Steps:   2%|▏         | 118/5000 [27:55<16:13:36, 11.97s/it, loss=1.1028, lr=2.34e-06]Steps:   2%|▏         | 118/5000 [27:55<16:13:36, 11.97s/it, loss=0.6525, lr=2.36e-06]Steps:   2%|▏         | 119/5000 [28:07<16:14:25, 11.98s/it, loss=0.6525, lr=2.36e-06]Steps:   2%|▏         | 119/5000 [28:07<16:14:25, 11.98s/it, loss=0.3810, lr=2.38e-06]Steps:   2%|▏         | 120/5000 [28:19<16:12:57, 11.96s/it, loss=0.3810, lr=2.38e-06]Steps:   2%|▏         | 120/5000 [28:19<16:12:57, 11.96s/it, loss=0.3887, lr=2.40e-06]
[Step 120] Training Debug Info:
  Loss: 0.388983
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0140, std: 0.9648
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0176, std: 1.3906
  Model pred mean: -0.0039, std: 1.2266
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.909134
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0030, std: 0.8594
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0040, std: 1.3203
  Model pred mean: -0.0001, std: 0.9180
  Sigmas: [0.43359375]... (timesteps: [433.0])

[Step 120] Training Debug Info:
  Loss: 0.402412
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0276, std: 0.9297
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0249, std: 1.3672
  Model pred mean: 0.0249, std: 1.2031
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.367097
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0072, std: 0.8906
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0053, std: 1.3359
  Model pred mean: -0.0055, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [826.0])
Steps:   2%|▏         | 121/5000 [28:31<16:14:16, 11.98s/it, loss=0.3887, lr=2.40e-06]Steps:   2%|▏         | 121/5000 [28:31<16:14:16, 11.98s/it, loss=0.3671, lr=2.42e-06]Steps:   2%|▏         | 122/5000 [28:42<16:09:48, 11.93s/it, loss=0.3671, lr=2.42e-06]Steps:   2%|▏         | 122/5000 [28:42<16:09:48, 11.93s/it, loss=1.0358, lr=2.44e-06]Steps:   2%|▏         | 123/5000 [28:54<16:09:18, 11.92s/it, loss=1.0358, lr=2.44e-06]Steps:   2%|▏         | 123/5000 [28:54<16:09:18, 11.92s/it, loss=0.7870, lr=2.46e-06]Steps:   2%|▏         | 124/5000 [29:06<16:11:58, 11.96s/it, loss=0.7870, lr=2.46e-06]Steps:   2%|▏         | 124/5000 [29:06<16:11:58, 11.96s/it, loss=1.0702, lr=2.48e-06]Steps:   2%|▎         | 125/5000 [29:18<16:13:21, 11.98s/it, loss=1.0702, lr=2.48e-06]Steps:   2%|▎         | 125/5000 [29:18<16:13:21, 11.98s/it, loss=0.4218, lr=2.50e-06]Steps:   3%|▎         | 126/5000 [29:30<16:10:48, 11.95s/it, loss=0.4218, lr=2.50e-06]Steps:   3%|▎         | 126/5000 [29:30<16:10:48, 11.95s/it, loss=1.1508, lr=2.52e-06]Steps:   3%|▎         | 127/5000 [29:42<16:09:27, 11.94s/it, loss=1.1508, lr=2.52e-06]Steps:   3%|▎         | 127/5000 [29:42<16:09:27, 11.94s/it, loss=0.6346, lr=2.54e-06]Steps:   3%|▎         | 128/5000 [29:54<16:07:10, 11.91s/it, loss=0.6346, lr=2.54e-06]Steps:   3%|▎         | 128/5000 [29:54<16:07:10, 11.91s/it, loss=0.3898, lr=2.56e-06]Steps:   3%|▎         | 129/5000 [30:06<16:07:52, 11.92s/it, loss=0.3898, lr=2.56e-06]Steps:   3%|▎         | 129/5000 [30:06<16:07:52, 11.92s/it, loss=0.6316, lr=2.58e-06]Steps:   3%|▎         | 130/5000 [30:18<16:09:31, 11.94s/it, loss=0.6316, lr=2.58e-06]Steps:   3%|▎         | 130/5000 [30:18<16:09:31, 11.94s/it, loss=1.1154, lr=2.60e-06]
[Step 130] Training Debug Info:
  Loss: 0.695485
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0297, std: 0.8711
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0297, std: 1.3281
  Model pred mean: -0.0311, std: 1.0156
  Sigmas: [0.546875]... (timesteps: [547.0])

[Step 130] Training Debug Info:
  Loss: 1.175847
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0342, std: 0.9023
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0349, std: 1.3438
  Model pred mean: 0.0317, std: 0.7969
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 130] Training Debug Info:
  Loss: 1.171928
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0023, std: 0.9023
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0001, std: 1.3438
  Model pred mean: -0.0001, std: 0.8047
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 130] Training Debug Info:
  Loss: 0.452913
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0037, std: 1.3594
  Model pred mean: -0.0083, std: 1.1797
  Sigmas: [0.93359375]... (timesteps: [935.0])
Steps:   3%|▎         | 131/5000 [30:30<16:12:24, 11.98s/it, loss=1.1154, lr=2.60e-06]Steps:   3%|▎         | 131/5000 [30:30<16:12:24, 11.98s/it, loss=0.4529, lr=2.62e-06]Steps:   3%|▎         | 132/5000 [30:42<16:09:24, 11.95s/it, loss=0.4529, lr=2.62e-06]Steps:   3%|▎         | 132/5000 [30:42<16:09:24, 11.95s/it, loss=0.8710, lr=2.64e-06]Steps:   3%|▎         | 133/5000 [30:54<16:10:14, 11.96s/it, loss=0.8710, lr=2.64e-06]Steps:   3%|▎         | 133/5000 [30:54<16:10:14, 11.96s/it, loss=1.0550, lr=2.66e-06]Steps:   3%|▎         | 134/5000 [31:06<16:09:06, 11.95s/it, loss=1.0550, lr=2.66e-06]Steps:   3%|▎         | 134/5000 [31:06<16:09:06, 11.95s/it, loss=0.7718, lr=2.68e-06]Steps:   3%|▎         | 135/5000 [31:18<16:07:57, 11.94s/it, loss=0.7718, lr=2.68e-06]Steps:   3%|▎         | 135/5000 [31:18<16:07:57, 11.94s/it, loss=0.5591, lr=2.70e-06]Steps:   3%|▎         | 136/5000 [31:30<16:05:05, 11.90s/it, loss=0.5591, lr=2.70e-06]Steps:   3%|▎         | 136/5000 [31:30<16:05:05, 11.90s/it, loss=0.7642, lr=2.72e-06]Steps:   3%|▎         | 137/5000 [31:41<16:04:41, 11.90s/it, loss=0.7642, lr=2.72e-06]Steps:   3%|▎         | 137/5000 [31:41<16:04:41, 11.90s/it, loss=0.5315, lr=2.74e-06]Steps:   3%|▎         | 138/5000 [31:54<16:07:59, 11.95s/it, loss=0.5315, lr=2.74e-06]Steps:   3%|▎         | 138/5000 [31:54<16:07:59, 11.95s/it, loss=1.1544, lr=2.76e-06]Steps:   3%|▎         | 139/5000 [32:06<16:09:16, 11.96s/it, loss=1.1544, lr=2.76e-06]Steps:   3%|▎         | 139/5000 [32:06<16:09:16, 11.96s/it, loss=0.8712, lr=2.78e-06]Steps:   3%|▎         | 140/5000 [32:18<16:09:26, 11.97s/it, loss=0.8712, lr=2.78e-06]Steps:   3%|▎         | 140/5000 [32:18<16:09:26, 11.97s/it, loss=1.0630, lr=2.80e-06]
[Step 140] Training Debug Info:
  Loss: 0.801107
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0016, std: 0.9180
  Noise mean: -0.0036, std: 1.0000
  Target mean: -0.0052, std: 1.3594
  Model pred mean: 0.0007, std: 1.0234
  Sigmas: [0.474609375]... (timesteps: [474.0])

[Step 140] Training Debug Info:
  Loss: 0.420609
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0097, std: 0.9062
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0075, std: 1.3516
  Model pred mean: 0.0186, std: 1.1562
  Sigmas: [0.9296875]... (timesteps: [931.0])

[Step 140] Training Debug Info:
  Loss: 0.413159
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0027, std: 0.9062
  Noise mean: 0.0039, std: 1.0000
  Target mean: 0.0066, std: 1.3516
  Model pred mean: 0.0055, std: 1.1719
  Sigmas: [0.8515625]... (timesteps: [851.0])

[Step 140] Training Debug Info:
  Loss: 0.356738
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0222, std: 0.9219
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0215, std: 1.3594
  Model pred mean: -0.0171, std: 1.2188
  Sigmas: [0.8125]... (timesteps: [811.0])
Steps:   3%|▎         | 141/5000 [32:29<16:06:53, 11.94s/it, loss=1.0630, lr=2.80e-06]Steps:   3%|▎         | 141/5000 [32:29<16:06:53, 11.94s/it, loss=0.3567, lr=2.82e-06]Steps:   3%|▎         | 142/5000 [32:41<16:09:00, 11.97s/it, loss=0.3567, lr=2.82e-06]Steps:   3%|▎         | 142/5000 [32:41<16:09:00, 11.97s/it, loss=0.6663, lr=2.84e-06]Steps:   3%|▎         | 143/5000 [32:53<16:08:03, 11.96s/it, loss=0.6663, lr=2.84e-06]Steps:   3%|▎         | 143/5000 [32:53<16:08:03, 11.96s/it, loss=1.0794, lr=2.86e-06]Steps:   3%|▎         | 144/5000 [33:05<16:07:16, 11.95s/it, loss=1.0794, lr=2.86e-06]Steps:   3%|▎         | 144/5000 [33:05<16:07:16, 11.95s/it, loss=1.1304, lr=2.88e-06]Steps:   3%|▎         | 145/5000 [33:17<16:09:32, 11.98s/it, loss=1.1304, lr=2.88e-06]Steps:   3%|▎         | 145/5000 [33:17<16:09:32, 11.98s/it, loss=0.5524, lr=2.90e-06]Steps:   3%|▎         | 146/5000 [33:29<16:06:20, 11.94s/it, loss=0.5524, lr=2.90e-06]Steps:   3%|▎         | 146/5000 [33:29<16:06:20, 11.94s/it, loss=0.9339, lr=2.92e-06]Steps:   3%|▎         | 147/5000 [33:41<16:04:01, 11.92s/it, loss=0.9339, lr=2.92e-06]Steps:   3%|▎         | 147/5000 [33:41<16:04:01, 11.92s/it, loss=0.8176, lr=2.94e-06]Steps:   3%|▎         | 148/5000 [33:53<16:05:55, 11.94s/it, loss=0.8176, lr=2.94e-06]Steps:   3%|▎         | 148/5000 [33:53<16:05:55, 11.94s/it, loss=0.7205, lr=2.96e-06]Steps:   3%|▎         | 149/5000 [34:05<16:05:33, 11.94s/it, loss=0.7205, lr=2.96e-06]Steps:   3%|▎         | 149/5000 [34:05<16:05:33, 11.94s/it, loss=0.7418, lr=2.98e-06]Steps:   3%|▎         | 150/5000 [34:17<16:05:01, 11.94s/it, loss=0.7418, lr=2.98e-06]Steps:   3%|▎         | 150/5000 [34:17<16:05:01, 11.94s/it, loss=1.1533, lr=3.00e-06]
[Step 150] Training Debug Info:
  Loss: 0.578234
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0134, std: 0.8906
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0125, std: 1.3359
  Model pred mean: -0.0033, std: 1.0938
  Sigmas: [0.97265625]... (timesteps: [974.0])

[Step 150] Training Debug Info:
  Loss: 0.460236
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0527, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0520, std: 1.3594
  Model pred mean: -0.0579, std: 1.1719
  Sigmas: [0.6953125]... (timesteps: [694.0])

[Step 150] Training Debug Info:
  Loss: 0.581724
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0161, std: 0.8945
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0184, std: 1.3438
  Model pred mean: -0.0177, std: 1.1094
  Sigmas: [0.59765625]... (timesteps: [598.0])

[Step 150] Training Debug Info:
  Loss: 0.470455
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0103, std: 0.8750
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0112, std: 1.3281
  Model pred mean: 0.0081, std: 1.1328
  Sigmas: [0.92578125]... (timesteps: [925.0])
Steps:   3%|▎         | 151/5000 [34:29<16:05:53, 11.95s/it, loss=1.1533, lr=3.00e-06]Steps:   3%|▎         | 151/5000 [34:29<16:05:53, 11.95s/it, loss=0.4705, lr=3.02e-06]Steps:   3%|▎         | 152/5000 [34:41<16:09:21, 12.00s/it, loss=0.4705, lr=3.02e-06]Steps:   3%|▎         | 152/5000 [34:41<16:09:21, 12.00s/it, loss=1.0400, lr=3.04e-06]Steps:   3%|▎         | 153/5000 [34:53<16:07:17, 11.97s/it, loss=1.0400, lr=3.04e-06]Steps:   3%|▎         | 153/5000 [34:53<16:07:17, 11.97s/it, loss=1.1069, lr=3.06e-06]Steps:   3%|▎         | 154/5000 [35:05<16:05:19, 11.95s/it, loss=1.1069, lr=3.06e-06]Steps:   3%|▎         | 154/5000 [35:05<16:05:19, 11.95s/it, loss=0.3458, lr=3.08e-06]Steps:   3%|▎         | 155/5000 [35:17<16:04:24, 11.94s/it, loss=0.3458, lr=3.08e-06]Steps:   3%|▎         | 155/5000 [35:17<16:04:24, 11.94s/it, loss=0.6982, lr=3.10e-06]Steps:   3%|▎         | 156/5000 [35:29<16:03:49, 11.94s/it, loss=0.6982, lr=3.10e-06]Steps:   3%|▎         | 156/5000 [35:29<16:03:49, 11.94s/it, loss=0.4135, lr=3.12e-06]Steps:   3%|▎         | 157/5000 [35:41<16:06:17, 11.97s/it, loss=0.4135, lr=3.12e-06]Steps:   3%|▎         | 157/5000 [35:41<16:06:17, 11.97s/it, loss=0.9118, lr=3.14e-06]Steps:   3%|▎         | 158/5000 [35:53<16:08:07, 12.00s/it, loss=0.9118, lr=3.14e-06]Steps:   3%|▎         | 158/5000 [35:53<16:08:07, 12.00s/it, loss=1.1457, lr=3.16e-06]Steps:   3%|▎         | 159/5000 [36:05<16:05:50, 11.97s/it, loss=1.1457, lr=3.16e-06]Steps:   3%|▎         | 159/5000 [36:05<16:05:50, 11.97s/it, loss=0.4523, lr=3.18e-06]Steps:   3%|▎         | 160/5000 [36:17<16:09:32, 12.02s/it, loss=0.4523, lr=3.18e-06]Steps:   3%|▎         | 160/5000 [36:17<16:09:32, 12.02s/it, loss=0.5765, lr=3.20e-06]
[Step 160] Training Debug Info:
  Loss: 1.117381
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0078, std: 0.8672
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0077, std: 1.3203
  Model pred mean: 0.0114, std: 0.8008
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 160] Training Debug Info:
  Loss: 1.089514
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0586, std: 0.9375
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0559, std: 1.3672
  Model pred mean: -0.0530, std: 0.8828
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 160] Training Debug Info:
  Loss: 0.636362
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0047, std: 0.9023
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0045, std: 1.3438
  Model pred mean: -0.0077, std: 1.1016
  Sigmas: [0.98828125]... (timesteps: [990.0])

[Step 160] Training Debug Info:
  Loss: 0.417967
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0269, std: 0.9023
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0272, std: 1.3438
  Model pred mean: -0.0248, std: 1.1797
  Sigmas: [0.73828125]... (timesteps: [739.0])
Steps:   3%|▎         | 161/5000 [36:29<16:06:36, 11.99s/it, loss=0.5765, lr=3.20e-06]Steps:   3%|▎         | 161/5000 [36:29<16:06:36, 11.99s/it, loss=0.4180, lr=3.22e-06]Steps:   3%|▎         | 162/5000 [36:41<16:05:28, 11.97s/it, loss=0.4180, lr=3.22e-06]Steps:   3%|▎         | 162/5000 [36:41<16:05:28, 11.97s/it, loss=0.4686, lr=3.24e-06]Steps:   3%|▎         | 163/5000 [36:52<16:01:00, 11.92s/it, loss=0.4686, lr=3.24e-06]Steps:   3%|▎         | 163/5000 [36:52<16:01:00, 11.92s/it, loss=0.5989, lr=3.26e-06]Steps:   3%|▎         | 164/5000 [37:04<15:59:54, 11.91s/it, loss=0.5989, lr=3.26e-06]Steps:   3%|▎         | 164/5000 [37:04<15:59:54, 11.91s/it, loss=0.4218, lr=3.28e-06]Steps:   3%|▎         | 165/5000 [37:16<16:02:21, 11.94s/it, loss=0.4218, lr=3.28e-06]Steps:   3%|▎         | 165/5000 [37:16<16:02:21, 11.94s/it, loss=0.8987, lr=3.30e-06]Steps:   3%|▎         | 166/5000 [37:29<16:06:25, 12.00s/it, loss=0.8987, lr=3.30e-06]Steps:   3%|▎         | 166/5000 [37:29<16:06:25, 12.00s/it, loss=0.8088, lr=3.32e-06]Steps:   3%|▎         | 167/5000 [37:40<16:04:59, 11.98s/it, loss=0.8088, lr=3.32e-06]Steps:   3%|▎         | 167/5000 [37:40<16:04:59, 11.98s/it, loss=0.4345, lr=3.34e-06]Steps:   3%|▎         | 168/5000 [37:52<16:02:59, 11.96s/it, loss=0.4345, lr=3.34e-06]Steps:   3%|▎         | 168/5000 [37:52<16:02:59, 11.96s/it, loss=1.1041, lr=3.36e-06]Steps:   3%|▎         | 169/5000 [38:04<16:04:35, 11.98s/it, loss=1.1041, lr=3.36e-06]Steps:   3%|▎         | 169/5000 [38:04<16:04:35, 11.98s/it, loss=0.5792, lr=3.38e-06]Steps:   3%|▎         | 170/5000 [38:16<16:03:45, 11.97s/it, loss=0.5792, lr=3.38e-06]Steps:   3%|▎         | 170/5000 [38:16<16:03:45, 11.97s/it, loss=0.7902, lr=3.40e-06]
[Step 170] Training Debug Info:
  Loss: 0.429088
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0339, std: 0.9023
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0349, std: 1.3516
  Model pred mean: -0.0306, std: 1.1875
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 170] Training Debug Info:
  Loss: 0.984208
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0055, std: 0.9141
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0085, std: 1.3516
  Model pred mean: -0.0099, std: 0.9141
  Sigmas: [0.34765625]... (timesteps: [347.0])

[Step 170] Training Debug Info:
  Loss: 0.518660
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0325, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0310, std: 1.3516
  Model pred mean: 0.0334, std: 1.1562
  Sigmas: [0.66015625]... (timesteps: [661.0])

[Step 170] Training Debug Info:
  Loss: 1.081584
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0133, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0125, std: 1.3594
  Model pred mean: -0.0128, std: 0.8750
  Sigmas: [0.0439453125]... (timesteps: [44.0])
Steps:   3%|▎         | 171/5000 [38:28<16:02:08, 11.95s/it, loss=0.7902, lr=3.40e-06]Steps:   3%|▎         | 171/5000 [38:28<16:02:08, 11.95s/it, loss=1.0816, lr=3.42e-06]Steps:   3%|▎         | 172/5000 [38:40<16:05:25, 12.00s/it, loss=1.0816, lr=3.42e-06]Steps:   3%|▎         | 172/5000 [38:40<16:05:25, 12.00s/it, loss=0.4676, lr=3.44e-06]Steps:   3%|▎         | 173/5000 [38:52<16:03:27, 11.98s/it, loss=0.4676, lr=3.44e-06]Steps:   3%|▎         | 173/5000 [38:52<16:03:27, 11.98s/it, loss=1.0284, lr=3.46e-06]Steps:   3%|▎         | 174/5000 [39:04<16:02:05, 11.96s/it, loss=1.0284, lr=3.46e-06]Steps:   3%|▎         | 174/5000 [39:04<16:02:05, 11.96s/it, loss=1.1143, lr=3.48e-06]Steps:   4%|▎         | 175/5000 [39:16<16:00:56, 11.95s/it, loss=1.1143, lr=3.48e-06]Steps:   4%|▎         | 175/5000 [39:16<16:00:56, 11.95s/it, loss=0.4539, lr=3.50e-06]Steps:   4%|▎         | 176/5000 [39:28<15:59:26, 11.93s/it, loss=0.4539, lr=3.50e-06]Steps:   4%|▎         | 176/5000 [39:28<15:59:26, 11.93s/it, loss=0.3998, lr=3.52e-06]Steps:   4%|▎         | 177/5000 [39:40<15:59:20, 11.93s/it, loss=0.3998, lr=3.52e-06]Steps:   4%|▎         | 177/5000 [39:40<15:59:20, 11.93s/it, loss=0.9307, lr=3.54e-06]Steps:   4%|▎         | 178/5000 [39:52<15:59:51, 11.94s/it, loss=0.9307, lr=3.54e-06]Steps:   4%|▎         | 178/5000 [39:52<15:59:51, 11.94s/it, loss=0.6071, lr=3.56e-06]Steps:   4%|▎         | 179/5000 [40:04<16:02:37, 11.98s/it, loss=0.6071, lr=3.56e-06]Steps:   4%|▎         | 179/5000 [40:04<16:02:37, 11.98s/it, loss=0.5962, lr=3.58e-06]Steps:   4%|▎         | 180/5000 [40:16<16:01:44, 11.97s/it, loss=0.5962, lr=3.58e-06]Steps:   4%|▎         | 180/5000 [40:16<16:01:44, 11.97s/it, loss=1.1769, lr=3.60e-06]
[Step 180] Training Debug Info:
  Loss: 1.116898
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0128, std: 0.8789
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0131, std: 1.3281
  Model pred mean: 0.0161, std: 0.8086
  Sigmas: [0.318359375]... (timesteps: [319.0])

[Step 180] Training Debug Info:
  Loss: 1.162964
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0146, std: 0.8906
  Noise mean: -0.0012, std: 0.9961
  Target mean: 0.0134, std: 1.3359
  Model pred mean: 0.0176, std: 0.7852
  Sigmas: [0.10400390625]... (timesteps: [104.0])

[Step 180] Training Debug Info:
  Loss: 0.402160
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0364, std: 0.9414
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0371, std: 1.3750
  Model pred mean: -0.0378, std: 1.2031
  Sigmas: [0.6875]... (timesteps: [688.0])

[Step 180] Training Debug Info:
  Loss: 1.106279
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0089, std: 0.8398
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0076, std: 1.3047
  Model pred mean: 0.0111, std: 0.7734
  Sigmas: [0.33203125]... (timesteps: [332.0])
Steps:   4%|▎         | 181/5000 [40:28<15:59:21, 11.94s/it, loss=1.1769, lr=3.60e-06]Steps:   4%|▎         | 181/5000 [40:28<15:59:21, 11.94s/it, loss=1.1063, lr=3.62e-06]Steps:   4%|▎         | 182/5000 [40:40<16:00:00, 11.96s/it, loss=1.1063, lr=3.62e-06]Steps:   4%|▎         | 182/5000 [40:40<16:00:00, 11.96s/it, loss=0.4016, lr=3.64e-06]Steps:   4%|▎         | 183/5000 [40:52<15:58:36, 11.94s/it, loss=0.4016, lr=3.64e-06]Steps:   4%|▎         | 183/5000 [40:52<15:58:36, 11.94s/it, loss=1.2027, lr=3.66e-06]Steps:   4%|▎         | 184/5000 [41:04<16:02:51, 12.00s/it, loss=1.2027, lr=3.66e-06]Steps:   4%|▎         | 184/5000 [41:04<16:02:51, 12.00s/it, loss=0.3618, lr=3.68e-06]Steps:   4%|▎         | 185/5000 [41:16<16:03:06, 12.00s/it, loss=0.3618, lr=3.68e-06]Steps:   4%|▎         | 185/5000 [41:16<16:03:06, 12.00s/it, loss=0.9360, lr=3.70e-06]Steps:   4%|▎         | 186/5000 [41:28<16:01:08, 11.98s/it, loss=0.9360, lr=3.70e-06]Steps:   4%|▎         | 186/5000 [41:28<16:01:08, 11.98s/it, loss=0.4536, lr=3.72e-06]Steps:   4%|▎         | 187/5000 [41:40<16:04:33, 12.02s/it, loss=0.4536, lr=3.72e-06]Steps:   4%|▎         | 187/5000 [41:40<16:04:33, 12.02s/it, loss=1.1414, lr=3.74e-06]Steps:   4%|▍         | 188/5000 [41:52<16:01:07, 11.98s/it, loss=1.1414, lr=3.74e-06]Steps:   4%|▍         | 188/5000 [41:52<16:01:07, 11.98s/it, loss=0.6514, lr=3.76e-06]Steps:   4%|▍         | 189/5000 [42:04<15:59:57, 11.97s/it, loss=0.6514, lr=3.76e-06]Steps:   4%|▍         | 189/5000 [42:04<15:59:57, 11.97s/it, loss=1.1304, lr=3.78e-06]Steps:   4%|▍         | 190/5000 [42:16<16:01:46, 12.00s/it, loss=1.1304, lr=3.78e-06]Steps:   4%|▍         | 190/5000 [42:16<16:01:46, 12.00s/it, loss=0.5403, lr=3.80e-06]
[Step 190] Training Debug Info:
  Loss: 0.518414
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0145, std: 0.9648
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0125, std: 1.3906
  Model pred mean: -0.0123, std: 1.2031
  Sigmas: [0.63671875]... (timesteps: [636.0])

[Step 190] Training Debug Info:
  Loss: 0.378155
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0032, std: 0.8945
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0046, std: 1.3438
  Model pred mean: -0.0066, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 190] Training Debug Info:
  Loss: 0.582847
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0098, std: 0.8945
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0086, std: 1.3438
  Model pred mean: -0.0240, std: 1.0938
  Sigmas: [0.9921875]... (timesteps: [991.0])

[Step 190] Training Debug Info:
  Loss: 1.188596
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.9023
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0002, std: 1.3438
  Model pred mean: -0.0003, std: 0.7969
  Sigmas: [0.21875]... (timesteps: [219.0])
Steps:   4%|▍         | 191/5000 [42:28<16:00:00, 11.98s/it, loss=0.5403, lr=3.80e-06]Steps:   4%|▍         | 191/5000 [42:28<16:00:00, 11.98s/it, loss=1.1886, lr=3.82e-06]Steps:   4%|▍         | 192/5000 [42:40<16:00:58, 11.99s/it, loss=1.1886, lr=3.82e-06]Steps:   4%|▍         | 192/5000 [42:40<16:00:58, 11.99s/it, loss=1.0265, lr=3.84e-06]Steps:   4%|▍         | 193/5000 [42:52<15:59:18, 11.97s/it, loss=1.0265, lr=3.84e-06]Steps:   4%|▍         | 193/5000 [42:52<15:59:18, 11.97s/it, loss=0.4442, lr=3.86e-06]Steps:   4%|▍         | 194/5000 [43:04<15:57:48, 11.96s/it, loss=0.4442, lr=3.86e-06]Steps:   4%|▍         | 194/5000 [43:04<15:57:48, 11.96s/it, loss=0.7406, lr=3.88e-06]Steps:   4%|▍         | 195/5000 [43:15<15:55:51, 11.94s/it, loss=0.7406, lr=3.88e-06]Steps:   4%|▍         | 195/5000 [43:15<15:55:51, 11.94s/it, loss=0.4798, lr=3.90e-06]Steps:   4%|▍         | 196/5000 [43:27<15:57:10, 11.95s/it, loss=0.4798, lr=3.90e-06]Steps:   4%|▍         | 196/5000 [43:27<15:57:10, 11.95s/it, loss=0.5768, lr=3.92e-06]Steps:   4%|▍         | 197/5000 [43:39<15:56:30, 11.95s/it, loss=0.5768, lr=3.92e-06]Steps:   4%|▍         | 197/5000 [43:39<15:56:30, 11.95s/it, loss=1.0452, lr=3.94e-06]Steps:   4%|▍         | 198/5000 [43:51<15:55:21, 11.94s/it, loss=1.0452, lr=3.94e-06]Steps:   4%|▍         | 198/5000 [43:51<15:55:21, 11.94s/it, loss=0.5017, lr=3.96e-06]Steps:   4%|▍         | 199/5000 [44:03<15:57:20, 11.96s/it, loss=0.5017, lr=3.96e-06]Steps:   4%|▍         | 199/5000 [44:03<15:57:20, 11.96s/it, loss=0.5864, lr=3.98e-06]Steps:   4%|▍         | 200/5000 [44:15<15:56:42, 11.96s/it, loss=0.5864, lr=3.98e-06]Steps:   4%|▍         | 200/5000 [44:15<15:56:42, 11.96s/it, loss=1.0398, lr=4.00e-06]01/22/2026 08:30:02 - INFO - __main__ - 
[Step 200] ✅ Loss in normal range (1.0398)
01/22/2026 08:30:02 - INFO - __main__ -   Loss avg (last 100): 0.7658
01/22/2026 08:30:02 - INFO - __main__ -   Loss range: [0.3458, 1.2027]
01/22/2026 08:30:02 - INFO - __main__ - 
🔍 Running validation at step 200...
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 200 (parquet mode)...
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 200...
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 08:30:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 08:30:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 08:30:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 08:30:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 08:30:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.41it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 08:31:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 08:31:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 08:31:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 08:31:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 08:31:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 08:31:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 08:32:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 08:32:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 08:32:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 08:32:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 08:32:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 08:32:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 08:33:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 08:33:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 08:33:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 08:33:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 08:33:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 08:33:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.47it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 08:34:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200/step000200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 08:34:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 08:34:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 08:34:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000200
01/22/2026 08:34:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 200] Training Debug Info:
  Loss: 0.594251
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0231, std: 0.9219
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0253, std: 1.3594
  Model pred mean: -0.0248, std: 1.1406
  Sigmas: [0.9453125]... (timesteps: [947.0])

[Step 200] Training Debug Info:
  Loss: 1.161553
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0038, std: 0.9141
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0036, std: 1.3594
  Model pred mean: 0.0049, std: 0.8242
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 200] Training Debug Info:
  Loss: 0.518380
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0023, std: 0.9062
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0035, std: 1.3516
  Model pred mean: -0.0014, std: 1.1484
  Sigmas: [0.65625]... (timesteps: [656.0])

[Step 200] Training Debug Info:
  Loss: 0.538349
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0537, std: 0.9219
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0540, std: 1.3594
  Model pred mean: -0.0513, std: 1.1328
  Sigmas: [0.8828125]... (timesteps: [881.0])
Steps:   4%|▍         | 201/5000 [48:38<116:19:59, 87.27s/it, loss=1.0398, lr=4.00e-06]Steps:   4%|▍         | 201/5000 [48:38<116:19:59, 87.27s/it, loss=0.5383, lr=4.02e-06]Steps:   4%|▍         | 202/5000 [48:50<86:12:45, 64.69s/it, loss=0.5383, lr=4.02e-06] Steps:   4%|▍         | 202/5000 [48:50<86:12:45, 64.69s/it, loss=0.4426, lr=4.04e-06]Steps:   4%|▍         | 203/5000 [49:02<65:05:04, 48.84s/it, loss=0.4426, lr=4.04e-06]Steps:   4%|▍         | 203/5000 [49:02<65:05:04, 48.84s/it, loss=1.0460, lr=4.06e-06]Steps:   4%|▍         | 204/5000 [49:14<50:19:29, 37.78s/it, loss=1.0460, lr=4.06e-06]Steps:   4%|▍         | 204/5000 [49:14<50:19:29, 37.78s/it, loss=1.1653, lr=4.08e-06]Steps:   4%|▍         | 205/5000 [49:26<39:59:59, 30.03s/it, loss=1.1653, lr=4.08e-06]Steps:   4%|▍         | 205/5000 [49:26<39:59:59, 30.03s/it, loss=1.0992, lr=4.10e-06]Steps:   4%|▍         | 206/5000 [49:38<32:51:21, 24.67s/it, loss=1.0992, lr=4.10e-06]Steps:   4%|▍         | 206/5000 [49:38<32:51:21, 24.67s/it, loss=0.6470, lr=4.12e-06]Steps:   4%|▍         | 207/5000 [49:50<27:45:58, 20.86s/it, loss=0.6470, lr=4.12e-06]Steps:   4%|▍         | 207/5000 [49:50<27:45:58, 20.86s/it, loss=0.4542, lr=4.14e-06]Steps:   4%|▍         | 208/5000 [50:02<24:12:02, 18.18s/it, loss=0.4542, lr=4.14e-06]Steps:   4%|▍         | 208/5000 [50:02<24:12:02, 18.18s/it, loss=0.4141, lr=4.16e-06]Steps:   4%|▍         | 209/5000 [50:14<21:41:18, 16.30s/it, loss=0.4141, lr=4.16e-06]Steps:   4%|▍         | 209/5000 [50:14<21:41:18, 16.30s/it, loss=0.6709, lr=4.18e-06]Steps:   4%|▍         | 210/5000 [50:26<19:57:07, 15.00s/it, loss=0.6709, lr=4.18e-06]Steps:   4%|▍         | 210/5000 [50:26<19:57:07, 15.00s/it, loss=0.6098, lr=4.20e-06]
[Step 210] Training Debug Info:
  Loss: 0.342024
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0020, std: 0.8984
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0039, std: 1.3438
  Model pred mean: 0.0046, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [858.0])

[Step 210] Training Debug Info:
  Loss: 0.419837
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0002, std: 0.8984
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0011, std: 1.3438
  Model pred mean: 0.0010, std: 1.1797
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 210] Training Debug Info:
  Loss: 0.455550
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0181, std: 0.9375
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0205, std: 1.3750
  Model pred mean: -0.0190, std: 1.1875
  Sigmas: [0.65234375]... (timesteps: [652.0])

[Step 210] Training Debug Info:
  Loss: 0.507244
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0031, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0033, std: 1.3516
  Model pred mean: -0.0059, std: 1.1562
  Sigmas: [0.68359375]... (timesteps: [683.0])
Steps:   4%|▍         | 211/5000 [50:38<18:44:38, 14.09s/it, loss=0.6098, lr=4.20e-06]Steps:   4%|▍         | 211/5000 [50:38<18:44:38, 14.09s/it, loss=0.5072, lr=4.22e-06]Steps:   4%|▍         | 212/5000 [50:50<17:56:11, 13.49s/it, loss=0.5072, lr=4.22e-06]Steps:   4%|▍         | 212/5000 [50:50<17:56:11, 13.49s/it, loss=1.0798, lr=4.24e-06]Steps:   4%|▍         | 213/5000 [51:02<17:17:46, 13.01s/it, loss=1.0798, lr=4.24e-06]Steps:   4%|▍         | 213/5000 [51:02<17:17:46, 13.01s/it, loss=0.9390, lr=4.26e-06]Steps:   4%|▍         | 214/5000 [51:14<16:50:02, 12.66s/it, loss=0.9390, lr=4.26e-06]Steps:   4%|▍         | 214/5000 [51:14<16:50:02, 12.66s/it, loss=1.0364, lr=4.28e-06]Steps:   4%|▍         | 215/5000 [51:26<16:29:58, 12.41s/it, loss=1.0364, lr=4.28e-06]Steps:   4%|▍         | 215/5000 [51:26<16:29:58, 12.41s/it, loss=0.5229, lr=4.30e-06]Steps:   4%|▍         | 216/5000 [51:38<16:17:05, 12.25s/it, loss=0.5229, lr=4.30e-06]Steps:   4%|▍         | 216/5000 [51:38<16:17:05, 12.25s/it, loss=1.1060, lr=4.32e-06]Steps:   4%|▍         | 217/5000 [51:49<16:08:19, 12.15s/it, loss=1.1060, lr=4.32e-06]Steps:   4%|▍         | 217/5000 [51:49<16:08:19, 12.15s/it, loss=0.6078, lr=4.34e-06]Steps:   4%|▍         | 218/5000 [52:01<16:02:11, 12.07s/it, loss=0.6078, lr=4.34e-06]Steps:   4%|▍         | 218/5000 [52:01<16:02:11, 12.07s/it, loss=0.7667, lr=4.36e-06]Steps:   4%|▍         | 219/5000 [52:13<16:02:01, 12.07s/it, loss=0.7667, lr=4.36e-06]Steps:   4%|▍         | 219/5000 [52:13<16:02:01, 12.07s/it, loss=0.6411, lr=4.38e-06]Steps:   4%|▍         | 220/5000 [52:25<16:01:07, 12.06s/it, loss=0.6411, lr=4.38e-06]Steps:   4%|▍         | 220/5000 [52:25<16:01:07, 12.06s/it, loss=1.1042, lr=4.40e-06]
[Step 220] Training Debug Info:
  Loss: 0.870692
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0186, std: 0.9375
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0184, std: 1.3672
  Model pred mean: -0.0162, std: 1.0156
  Sigmas: [0.421875]... (timesteps: [421.0])

[Step 220] Training Debug Info:
  Loss: 1.143699
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0073, std: 0.9062
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0081, std: 1.3516
  Model pred mean: -0.0079, std: 0.8242
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 220] Training Debug Info:
  Loss: 1.142905
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0066, std: 0.8828
  Noise mean: 0.0039, std: 1.0000
  Target mean: 0.0106, std: 1.3359
  Model pred mean: 0.0076, std: 0.8086
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 220] Training Debug Info:
  Loss: 1.061618
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0530, std: 0.9648
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0515, std: 1.3906
  Model pred mean: -0.0488, std: 0.9414
  Sigmas: [0.037109375]... (timesteps: [37.0])
Steps:   4%|▍         | 221/5000 [52:37<15:57:46, 12.02s/it, loss=1.1042, lr=4.40e-06]Steps:   4%|▍         | 221/5000 [52:37<15:57:46, 12.02s/it, loss=1.0616, lr=4.42e-06]Steps:   4%|▍         | 222/5000 [52:49<15:53:39, 11.98s/it, loss=1.0616, lr=4.42e-06]Steps:   4%|▍         | 222/5000 [52:49<15:53:39, 11.98s/it, loss=0.9020, lr=4.44e-06]Steps:   4%|▍         | 223/5000 [53:01<15:50:42, 11.94s/it, loss=0.9020, lr=4.44e-06]Steps:   4%|▍         | 223/5000 [53:01<15:50:42, 11.94s/it, loss=0.5656, lr=4.46e-06]Steps:   4%|▍         | 224/5000 [53:13<15:52:21, 11.96s/it, loss=0.5656, lr=4.46e-06]Steps:   4%|▍         | 224/5000 [53:13<15:52:21, 11.96s/it, loss=0.4691, lr=4.48e-06]Steps:   4%|▍         | 225/5000 [53:25<15:49:13, 11.93s/it, loss=0.4691, lr=4.48e-06]Steps:   4%|▍         | 225/5000 [53:25<15:49:13, 11.93s/it, loss=1.1150, lr=4.50e-06]Steps:   5%|▍         | 226/5000 [53:37<15:52:58, 11.98s/it, loss=1.1150, lr=4.50e-06]Steps:   5%|▍         | 226/5000 [53:37<15:52:58, 11.98s/it, loss=1.0546, lr=4.52e-06]Steps:   5%|▍         | 227/5000 [53:49<15:50:42, 11.95s/it, loss=1.0546, lr=4.52e-06]Steps:   5%|▍         | 227/5000 [53:49<15:50:42, 11.95s/it, loss=0.3844, lr=4.54e-06]Steps:   5%|▍         | 228/5000 [54:01<15:50:05, 11.95s/it, loss=0.3844, lr=4.54e-06]Steps:   5%|▍         | 228/5000 [54:01<15:50:05, 11.95s/it, loss=1.1685, lr=4.56e-06]Steps:   5%|▍         | 229/5000 [54:13<15:53:09, 11.99s/it, loss=1.1685, lr=4.56e-06]Steps:   5%|▍         | 229/5000 [54:13<15:53:09, 11.99s/it, loss=0.8601, lr=4.58e-06]Steps:   5%|▍         | 230/5000 [54:25<15:51:59, 11.97s/it, loss=0.8601, lr=4.58e-06]Steps:   5%|▍         | 230/5000 [54:25<15:51:59, 11.97s/it, loss=1.0321, lr=4.60e-06]
[Step 230] Training Debug Info:
  Loss: 0.354286
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0195, std: 0.9453
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0188, std: 1.3750
  Model pred mean: 0.0199, std: 1.2422
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 230] Training Debug Info:
  Loss: 0.637213
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0396, std: 0.9531
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0415, std: 1.3750
  Model pred mean: -0.0371, std: 1.1328
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 230] Training Debug Info:
  Loss: 1.040745
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0065, std: 0.9531
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0074, std: 1.3828
  Model pred mean: -0.0037, std: 0.9336
  Sigmas: [0.01300048828125]... (timesteps: [13.0])

[Step 230] Training Debug Info:
  Loss: 0.529560
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0004, std: 0.8750
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0006, std: 1.3281
  Model pred mean: -0.0003, std: 1.1094
  Sigmas: [0.65234375]... (timesteps: [654.0])
Steps:   5%|▍         | 231/5000 [54:37<15:48:37, 11.93s/it, loss=1.0321, lr=4.60e-06]Steps:   5%|▍         | 231/5000 [54:37<15:48:37, 11.93s/it, loss=0.5296, lr=4.62e-06]Steps:   5%|▍         | 232/5000 [54:49<15:45:32, 11.90s/it, loss=0.5296, lr=4.62e-06]Steps:   5%|▍         | 232/5000 [54:49<15:45:32, 11.90s/it, loss=0.5863, lr=4.64e-06]Steps:   5%|▍         | 233/5000 [55:01<15:50:59, 11.97s/it, loss=0.5863, lr=4.64e-06]Steps:   5%|▍         | 233/5000 [55:01<15:50:59, 11.97s/it, loss=0.3724, lr=4.66e-06]Steps:   5%|▍         | 234/5000 [55:13<15:49:24, 11.95s/it, loss=0.3724, lr=4.66e-06]Steps:   5%|▍         | 234/5000 [55:13<15:49:24, 11.95s/it, loss=1.0187, lr=4.68e-06]Steps:   5%|▍         | 235/5000 [55:24<15:46:18, 11.92s/it, loss=1.0187, lr=4.68e-06]Steps:   5%|▍         | 235/5000 [55:24<15:46:18, 11.92s/it, loss=0.5455, lr=4.70e-06]Steps:   5%|▍         | 236/5000 [55:36<15:46:20, 11.92s/it, loss=0.5455, lr=4.70e-06]Steps:   5%|▍         | 236/5000 [55:36<15:46:20, 11.92s/it, loss=0.9001, lr=4.72e-06]Steps:   5%|▍         | 237/5000 [55:48<15:46:29, 11.92s/it, loss=0.9001, lr=4.72e-06]Steps:   5%|▍         | 237/5000 [55:48<15:46:29, 11.92s/it, loss=1.0845, lr=4.74e-06]Steps:   5%|▍         | 238/5000 [56:00<15:50:29, 11.98s/it, loss=1.0845, lr=4.74e-06]Steps:   5%|▍         | 238/5000 [56:00<15:50:29, 11.98s/it, loss=1.2003, lr=4.76e-06]Steps:   5%|▍         | 239/5000 [56:12<15:53:05, 12.01s/it, loss=1.2003, lr=4.76e-06]Steps:   5%|▍         | 239/5000 [56:12<15:53:05, 12.01s/it, loss=0.5077, lr=4.78e-06]Steps:   5%|▍         | 240/5000 [56:24<15:49:24, 11.97s/it, loss=0.5077, lr=4.78e-06]Steps:   5%|▍         | 240/5000 [56:24<15:49:24, 11.97s/it, loss=0.6620, lr=4.80e-06]
[Step 240] Training Debug Info:
  Loss: 0.449455
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0082, std: 0.9219
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0059, std: 1.3594
  Model pred mean: 0.0092, std: 1.1797
  Sigmas: [0.890625]... (timesteps: [889.0])

[Step 240] Training Debug Info:
  Loss: 0.566563
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0022, std: 0.9492
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0006, std: 1.3750
  Model pred mean: -0.0076, std: 1.1641
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 240] Training Debug Info:
  Loss: 0.476858
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0141, std: 0.9688
  Noise mean: 0.0030, std: 1.0000
  Target mean: -0.0111, std: 1.3906
  Model pred mean: -0.0136, std: 1.2109
  Sigmas: [0.63671875]... (timesteps: [638.0])

[Step 240] Training Debug Info:
  Loss: 1.115465
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0050, std: 0.9102
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0039, std: 1.3516
  Model pred mean: -0.0032, std: 0.8359
  Sigmas: [0.06787109375]... (timesteps: [68.0])
Steps:   5%|▍         | 241/5000 [56:36<15:48:01, 11.95s/it, loss=0.6620, lr=4.80e-06]Steps:   5%|▍         | 241/5000 [56:36<15:48:01, 11.95s/it, loss=1.1155, lr=4.82e-06]Steps:   5%|▍         | 242/5000 [56:48<15:50:57, 11.99s/it, loss=1.1155, lr=4.82e-06]Steps:   5%|▍         | 242/5000 [56:48<15:50:57, 11.99s/it, loss=0.4232, lr=4.84e-06]Steps:   5%|▍         | 243/5000 [57:00<15:50:09, 11.98s/it, loss=0.4232, lr=4.84e-06]Steps:   5%|▍         | 243/5000 [57:00<15:50:09, 11.98s/it, loss=0.4612, lr=4.86e-06]Steps:   5%|▍         | 244/5000 [57:12<15:48:25, 11.97s/it, loss=0.4612, lr=4.86e-06]Steps:   5%|▍         | 244/5000 [57:12<15:48:25, 11.97s/it, loss=1.2057, lr=4.88e-06]Steps:   5%|▍         | 245/5000 [57:24<15:45:33, 11.93s/it, loss=1.2057, lr=4.88e-06]Steps:   5%|▍         | 245/5000 [57:24<15:45:33, 11.93s/it, loss=0.4950, lr=4.90e-06]Steps:   5%|▍         | 246/5000 [57:36<15:48:17, 11.97s/it, loss=0.4950, lr=4.90e-06]Steps:   5%|▍         | 246/5000 [57:36<15:48:17, 11.97s/it, loss=0.5995, lr=4.92e-06]Steps:   5%|▍         | 247/5000 [57:48<15:50:02, 11.99s/it, loss=0.5995, lr=4.92e-06]Steps:   5%|▍         | 247/5000 [57:48<15:50:02, 11.99s/it, loss=0.6163, lr=4.94e-06]Steps:   5%|▍         | 248/5000 [58:00<15:47:47, 11.97s/it, loss=0.6163, lr=4.94e-06]Steps:   5%|▍         | 248/5000 [58:00<15:47:47, 11.97s/it, loss=0.4397, lr=4.96e-06]Steps:   5%|▍         | 249/5000 [58:12<15:45:58, 11.95s/it, loss=0.4397, lr=4.96e-06]Steps:   5%|▍         | 249/5000 [58:12<15:45:58, 11.95s/it, loss=0.8472, lr=4.98e-06]Steps:   5%|▌         | 250/5000 [58:24<15:47:34, 11.97s/it, loss=0.8472, lr=4.98e-06]Steps:   5%|▌         | 250/5000 [58:24<15:47:34, 11.97s/it, loss=0.4355, lr=5.00e-06]
[Step 250] Training Debug Info:
  Loss: 0.513963
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0090, std: 0.9609
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0056, std: 1.3906
  Model pred mean: -0.0027, std: 1.1875
  Sigmas: [0.76171875]... (timesteps: [760.0])

[Step 250] Training Debug Info:
  Loss: 0.971114
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0454, std: 0.9023
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0469, std: 1.3438
  Model pred mean: 0.0469, std: 0.9297
  Sigmas: [0.380859375]... (timesteps: [381.0])

[Step 250] Training Debug Info:
  Loss: 0.419685
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0054, std: 0.8906
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0055, std: 1.3359
  Model pred mean: 0.0073, std: 1.1797
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 250] Training Debug Info:
  Loss: 0.449712
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0229, std: 0.8945
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0244, std: 1.3438
  Model pred mean: -0.0182, std: 1.1641
  Sigmas: [0.73046875]... (timesteps: [732.0])
Steps:   5%|▌         | 251/5000 [58:36<15:45:10, 11.94s/it, loss=0.4355, lr=5.00e-06]Steps:   5%|▌         | 251/5000 [58:36<15:45:10, 11.94s/it, loss=0.4497, lr=5.02e-06]Steps:   5%|▌         | 252/5000 [58:48<15:44:56, 11.94s/it, loss=0.4497, lr=5.02e-06]Steps:   5%|▌         | 252/5000 [58:48<15:44:56, 11.94s/it, loss=0.5347, lr=5.04e-06]Steps:   5%|▌         | 253/5000 [59:00<15:48:10, 11.98s/it, loss=0.5347, lr=5.04e-06]Steps:   5%|▌         | 253/5000 [59:00<15:48:10, 11.98s/it, loss=0.7305, lr=5.06e-06]Steps:   5%|▌         | 254/5000 [59:12<15:44:53, 11.95s/it, loss=0.7305, lr=5.06e-06]Steps:   5%|▌         | 254/5000 [59:12<15:44:53, 11.95s/it, loss=1.0348, lr=5.08e-06]Steps:   5%|▌         | 255/5000 [59:24<15:44:49, 11.95s/it, loss=1.0348, lr=5.08e-06]Steps:   5%|▌         | 255/5000 [59:24<15:44:49, 11.95s/it, loss=0.4745, lr=5.10e-06]Steps:   5%|▌         | 256/5000 [59:36<15:47:25, 11.98s/it, loss=0.4745, lr=5.10e-06]Steps:   5%|▌         | 256/5000 [59:36<15:47:25, 11.98s/it, loss=0.6356, lr=5.12e-06]Steps:   5%|▌         | 257/5000 [59:48<15:45:59, 11.97s/it, loss=0.6356, lr=5.12e-06]Steps:   5%|▌         | 257/5000 [59:48<15:45:59, 11.97s/it, loss=0.4216, lr=5.14e-06]Steps:   5%|▌         | 258/5000 [1:00:00<15:47:48, 11.99s/it, loss=0.4216, lr=5.14e-06]Steps:   5%|▌         | 258/5000 [1:00:00<15:47:48, 11.99s/it, loss=0.6218, lr=5.16e-06]Steps:   5%|▌         | 259/5000 [1:00:12<15:47:40, 11.99s/it, loss=0.6218, lr=5.16e-06]Steps:   5%|▌         | 259/5000 [1:00:12<15:47:40, 11.99s/it, loss=0.4032, lr=5.18e-06]Steps:   5%|▌         | 260/5000 [1:00:24<15:51:22, 12.04s/it, loss=0.4032, lr=5.18e-06]Steps:   5%|▌         | 260/5000 [1:00:24<15:51:22, 12.04s/it, loss=1.1282, lr=5.20e-06]
[Step 260] Training Debug Info:
  Loss: 0.745916
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0062, std: 0.9062
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0078, std: 1.3516
  Model pred mean: 0.0072, std: 1.0469
  Sigmas: [0.4921875]... (timesteps: [492.0])

[Step 260] Training Debug Info:
  Loss: 0.823729
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0177, std: 0.9336
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0161, std: 1.3672
  Model pred mean: -0.0171, std: 1.0078
  Sigmas: [0.39453125]... (timesteps: [395.0])

[Step 260] Training Debug Info:
  Loss: 0.478030
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0059, std: 0.8672
  Noise mean: 0.0008, std: 1.0078
  Target mean: -0.0051, std: 1.3281
  Model pred mean: -0.0055, std: 1.1328
  Sigmas: [0.703125]... (timesteps: [702.0])

[Step 260] Training Debug Info:
  Loss: 0.463301
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0212, std: 0.8398
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0198, std: 1.3047
  Model pred mean: 0.0225, std: 1.1172
  Sigmas: [0.734375]... (timesteps: [734.0])
Steps:   5%|▌         | 261/5000 [1:00:36<15:46:52, 11.99s/it, loss=1.1282, lr=5.20e-06]Steps:   5%|▌         | 261/5000 [1:00:36<15:46:52, 11.99s/it, loss=0.4633, lr=5.22e-06]Steps:   5%|▌         | 262/5000 [1:00:48<15:44:03, 11.96s/it, loss=0.4633, lr=5.22e-06]Steps:   5%|▌         | 262/5000 [1:00:48<15:44:03, 11.96s/it, loss=0.4493, lr=5.24e-06]Steps:   5%|▌         | 263/5000 [1:01:00<15:42:45, 11.94s/it, loss=0.4493, lr=5.24e-06]Steps:   5%|▌         | 263/5000 [1:01:00<15:42:45, 11.94s/it, loss=0.4341, lr=5.26e-06]Steps:   5%|▌         | 264/5000 [1:01:12<15:42:55, 11.95s/it, loss=0.4341, lr=5.26e-06]Steps:   5%|▌         | 264/5000 [1:01:12<15:42:55, 11.95s/it, loss=0.4867, lr=5.28e-06]Steps:   5%|▌         | 265/5000 [1:01:24<15:45:28, 11.98s/it, loss=0.4867, lr=5.28e-06]Steps:   5%|▌         | 265/5000 [1:01:24<15:45:28, 11.98s/it, loss=1.1138, lr=5.30e-06]Steps:   5%|▌         | 266/5000 [1:01:36<15:48:33, 12.02s/it, loss=1.1138, lr=5.30e-06]Steps:   5%|▌         | 266/5000 [1:01:36<15:48:33, 12.02s/it, loss=1.1775, lr=5.32e-06]Steps:   5%|▌         | 267/5000 [1:01:48<15:43:22, 11.96s/it, loss=1.1775, lr=5.32e-06]Steps:   5%|▌         | 267/5000 [1:01:48<15:43:22, 11.96s/it, loss=1.1316, lr=5.34e-06]Steps:   5%|▌         | 268/5000 [1:01:59<15:42:40, 11.95s/it, loss=1.1316, lr=5.34e-06]Steps:   5%|▌         | 268/5000 [1:01:59<15:42:40, 11.95s/it, loss=1.0788, lr=5.36e-06]Steps:   5%|▌         | 269/5000 [1:02:11<15:42:26, 11.95s/it, loss=1.0788, lr=5.36e-06]Steps:   5%|▌         | 269/5000 [1:02:11<15:42:26, 11.95s/it, loss=0.7434, lr=5.38e-06]Steps:   5%|▌         | 270/5000 [1:02:23<15:41:33, 11.94s/it, loss=0.7434, lr=5.38e-06]Steps:   5%|▌         | 270/5000 [1:02:23<15:41:33, 11.94s/it, loss=0.5275, lr=5.40e-06]
[Step 270] Training Debug Info:
  Loss: 0.434149
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0259, std: 0.9648
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0248, std: 1.3906
  Model pred mean: -0.0234, std: 1.2109
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 270] Training Debug Info:
  Loss: 0.427344
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.8906
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0017, std: 1.3359
  Model pred mean: -0.0068, std: 1.1562
  Sigmas: [0.94921875]... (timesteps: [950.0])

[Step 270] Training Debug Info:
  Loss: 0.708806
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0381, std: 1.0000
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0378, std: 1.4141
  Model pred mean: -0.0413, std: 1.1328
  Sigmas: [0.46875]... (timesteps: [468.0])

[Step 270] Training Debug Info:
  Loss: 1.087998
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0400, std: 0.9141
  Noise mean: 0.0032, std: 1.0000
  Target mean: -0.0369, std: 1.3594
  Model pred mean: -0.0420, std: 0.8594
  Sigmas: [0.17578125]... (timesteps: [176.0])
Steps:   5%|▌         | 271/5000 [1:02:35<15:40:32, 11.93s/it, loss=0.5275, lr=5.40e-06]Steps:   5%|▌         | 271/5000 [1:02:35<15:40:32, 11.93s/it, loss=1.0880, lr=5.42e-06]Steps:   5%|▌         | 272/5000 [1:02:47<15:45:46, 12.00s/it, loss=1.0880, lr=5.42e-06]Steps:   5%|▌         | 272/5000 [1:02:47<15:45:46, 12.00s/it, loss=0.5652, lr=5.44e-06]Steps:   5%|▌         | 273/5000 [1:02:59<15:47:31, 12.03s/it, loss=0.5652, lr=5.44e-06]Steps:   5%|▌         | 273/5000 [1:02:59<15:47:31, 12.03s/it, loss=1.0732, lr=5.46e-06]Steps:   5%|▌         | 274/5000 [1:03:11<15:46:19, 12.01s/it, loss=1.0732, lr=5.46e-06]Steps:   5%|▌         | 274/5000 [1:03:11<15:46:19, 12.01s/it, loss=1.1051, lr=5.48e-06]Steps:   6%|▌         | 275/5000 [1:03:23<15:44:11, 11.99s/it, loss=1.1051, lr=5.48e-06]Steps:   6%|▌         | 275/5000 [1:03:23<15:44:11, 11.99s/it, loss=1.0598, lr=5.50e-06]Steps:   6%|▌         | 276/5000 [1:03:35<15:42:22, 11.97s/it, loss=1.0598, lr=5.50e-06]Steps:   6%|▌         | 276/5000 [1:03:35<15:42:22, 11.97s/it, loss=1.1521, lr=5.52e-06]Steps:   6%|▌         | 277/5000 [1:03:47<15:41:24, 11.96s/it, loss=1.1521, lr=5.52e-06]Steps:   6%|▌         | 277/5000 [1:03:47<15:41:24, 11.96s/it, loss=1.0114, lr=5.54e-06]Steps:   6%|▌         | 278/5000 [1:03:59<15:39:44, 11.94s/it, loss=1.0114, lr=5.54e-06]Steps:   6%|▌         | 278/5000 [1:03:59<15:39:44, 11.94s/it, loss=1.1405, lr=5.56e-06]Steps:   6%|▌         | 279/5000 [1:04:11<15:45:45, 12.02s/it, loss=1.1405, lr=5.56e-06]Steps:   6%|▌         | 279/5000 [1:04:11<15:45:45, 12.02s/it, loss=1.1197, lr=5.58e-06]Steps:   6%|▌         | 280/5000 [1:04:23<15:46:45, 12.04s/it, loss=1.1197, lr=5.58e-06]Steps:   6%|▌         | 280/5000 [1:04:23<15:46:45, 12.04s/it, loss=0.5002, lr=5.60e-06]
[Step 280] Training Debug Info:
  Loss: 0.768129
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0051, std: 0.9023
  Noise mean: 0.0013, std: 1.0000
  Target mean: 0.0064, std: 1.3516
  Model pred mean: 0.0043, std: 1.0078
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 280] Training Debug Info:
  Loss: 0.399423
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0289, std: 0.8633
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0276, std: 1.3203
  Model pred mean: 0.0237, std: 1.1641
  Sigmas: [0.79296875]... (timesteps: [794.0])

[Step 280] Training Debug Info:
  Loss: 1.133757
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0137, std: 0.9297
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0112, std: 1.3672
  Model pred mean: -0.0112, std: 0.8477
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 280] Training Debug Info:
  Loss: 0.629902
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0134, std: 0.9062
  Noise mean: -0.0061, std: 1.0000
  Target mean: 0.0074, std: 1.3516
  Model pred mean: 0.0110, std: 1.0938
  Sigmas: [0.98046875]... (timesteps: [981.0])
Steps:   6%|▌         | 281/5000 [1:04:35<15:44:26, 12.01s/it, loss=0.5002, lr=5.60e-06]Steps:   6%|▌         | 281/5000 [1:04:35<15:44:26, 12.01s/it, loss=0.6299, lr=5.62e-06]Steps:   6%|▌         | 282/5000 [1:04:47<15:42:51, 11.99s/it, loss=0.6299, lr=5.62e-06]Steps:   6%|▌         | 282/5000 [1:04:47<15:42:51, 11.99s/it, loss=0.9317, lr=5.64e-06]Steps:   6%|▌         | 283/5000 [1:04:59<15:45:28, 12.03s/it, loss=0.9317, lr=5.64e-06]Steps:   6%|▌         | 283/5000 [1:04:59<15:45:28, 12.03s/it, loss=0.8391, lr=5.66e-06]Steps:   6%|▌         | 284/5000 [1:05:11<15:44:14, 12.01s/it, loss=0.8391, lr=5.66e-06]Steps:   6%|▌         | 284/5000 [1:05:11<15:44:14, 12.01s/it, loss=1.0778, lr=5.68e-06]Steps:   6%|▌         | 285/5000 [1:05:23<15:40:55, 11.97s/it, loss=1.0778, lr=5.68e-06]Steps:   6%|▌         | 285/5000 [1:05:23<15:40:55, 11.97s/it, loss=0.5161, lr=5.70e-06]Steps:   6%|▌         | 286/5000 [1:05:35<15:41:39, 11.99s/it, loss=0.5161, lr=5.70e-06]Steps:   6%|▌         | 286/5000 [1:05:35<15:41:39, 11.99s/it, loss=0.4435, lr=5.72e-06]Steps:   6%|▌         | 287/5000 [1:05:47<15:43:21, 12.01s/it, loss=0.4435, lr=5.72e-06]Steps:   6%|▌         | 287/5000 [1:05:47<15:43:21, 12.01s/it, loss=0.8724, lr=5.74e-06]Steps:   6%|▌         | 288/5000 [1:05:59<15:39:31, 11.96s/it, loss=0.8724, lr=5.74e-06]Steps:   6%|▌         | 288/5000 [1:05:59<15:39:31, 11.96s/it, loss=0.8978, lr=5.76e-06]Steps:   6%|▌         | 289/5000 [1:06:11<15:37:43, 11.94s/it, loss=0.8978, lr=5.76e-06]Steps:   6%|▌         | 289/5000 [1:06:11<15:37:43, 11.94s/it, loss=1.1707, lr=5.78e-06]Steps:   6%|▌         | 290/5000 [1:06:23<15:35:53, 11.92s/it, loss=1.1707, lr=5.78e-06]Steps:   6%|▌         | 290/5000 [1:06:23<15:35:53, 11.92s/it, loss=1.1856, lr=5.80e-06]
[Step 290] Training Debug Info:
  Loss: 1.131458
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0359, std: 0.9453
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0344, std: 1.3750
  Model pred mean: 0.0383, std: 0.8516
  Sigmas: [0.11181640625]... (timesteps: [112.0])

[Step 290] Training Debug Info:
  Loss: 1.113017
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0234, std: 0.9180
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0243, std: 1.3594
  Model pred mean: 0.0234, std: 0.8594
  Sigmas: [0.07421875]... (timesteps: [74.0])

[Step 290] Training Debug Info:
  Loss: 0.383852
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0135, std: 0.8633
  Noise mean: -0.0040, std: 1.0000
  Target mean: 0.0095, std: 1.3203
  Model pred mean: 0.0062, std: 1.1562
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 290] Training Debug Info:
  Loss: 1.104364
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0122, std: 0.8984
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0139, std: 1.3438
  Model pred mean: 0.0120, std: 0.8398
  Sigmas: [0.06298828125]... (timesteps: [63.0])
Steps:   6%|▌         | 291/5000 [1:06:35<15:34:40, 11.91s/it, loss=1.1856, lr=5.80e-06]Steps:   6%|▌         | 291/5000 [1:06:35<15:34:40, 11.91s/it, loss=1.1044, lr=5.82e-06]Steps:   6%|▌         | 292/5000 [1:06:47<15:37:22, 11.95s/it, loss=1.1044, lr=5.82e-06]Steps:   6%|▌         | 292/5000 [1:06:47<15:37:22, 11.95s/it, loss=0.5335, lr=5.84e-06]Steps:   6%|▌         | 293/5000 [1:06:59<15:40:50, 11.99s/it, loss=0.5335, lr=5.84e-06]Steps:   6%|▌         | 293/5000 [1:06:59<15:40:50, 11.99s/it, loss=0.7606, lr=5.86e-06]Steps:   6%|▌         | 294/5000 [1:07:11<15:38:28, 11.97s/it, loss=0.7606, lr=5.86e-06]Steps:   6%|▌         | 294/5000 [1:07:11<15:38:28, 11.97s/it, loss=1.0920, lr=5.88e-06]Steps:   6%|▌         | 295/5000 [1:07:23<15:40:49, 12.00s/it, loss=1.0920, lr=5.88e-06]Steps:   6%|▌         | 295/5000 [1:07:23<15:40:49, 12.00s/it, loss=0.8797, lr=5.90e-06]Steps:   6%|▌         | 296/5000 [1:07:35<15:41:06, 12.00s/it, loss=0.8797, lr=5.90e-06]Steps:   6%|▌         | 296/5000 [1:07:35<15:41:06, 12.00s/it, loss=0.4811, lr=5.92e-06]Steps:   6%|▌         | 297/5000 [1:07:47<15:37:15, 11.96s/it, loss=0.4811, lr=5.92e-06]Steps:   6%|▌         | 297/5000 [1:07:47<15:37:15, 11.96s/it, loss=1.2111, lr=5.94e-06]Steps:   6%|▌         | 298/5000 [1:07:59<15:36:03, 11.94s/it, loss=1.2111, lr=5.94e-06]Steps:   6%|▌         | 298/5000 [1:07:59<15:36:03, 11.94s/it, loss=0.5070, lr=5.96e-06]Steps:   6%|▌         | 299/5000 [1:08:11<15:34:59, 11.93s/it, loss=0.5070, lr=5.96e-06]Steps:   6%|▌         | 299/5000 [1:08:11<15:34:59, 11.93s/it, loss=0.4642, lr=5.98e-06]Steps:   6%|▌         | 300/5000 [1:08:23<15:37:30, 11.97s/it, loss=0.4642, lr=5.98e-06]Steps:   6%|▌         | 300/5000 [1:08:23<15:37:30, 11.97s/it, loss=0.5292, lr=6.00e-06]01/22/2026 08:54:09 - INFO - __main__ - 
[Step 300] ✅ Loss in normal range (0.5292)
01/22/2026 08:54:09 - INFO - __main__ -   Loss avg (last 100): 0.7804
01/22/2026 08:54:09 - INFO - __main__ -   Loss range: [0.3724, 1.2111]

[Step 300] Training Debug Info:
  Loss: 0.479741
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0109, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0117, std: 1.3516
  Model pred mean: -0.0092, std: 1.1641
  Sigmas: [0.6796875]... (timesteps: [681.0])

[Step 300] Training Debug Info:
  Loss: 1.026406
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0393, std: 0.8594
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0398, std: 1.3203
  Model pred mean: 0.0344, std: 0.8594
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 300] Training Debug Info:
  Loss: 0.490136
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0080, std: 0.8828
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0067, std: 1.3359
  Model pred mean: -0.0109, std: 1.1406
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 300] Training Debug Info:
  Loss: 0.398351
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0006, std: 0.8984
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0015, std: 1.3438
  Model pred mean: -0.0004, std: 1.1953
  Sigmas: [0.859375]... (timesteps: [859.0])
Steps:   6%|▌         | 301/5000 [1:08:35<15:39:04, 11.99s/it, loss=0.5292, lr=6.00e-06]Steps:   6%|▌         | 301/5000 [1:08:35<15:39:04, 11.99s/it, loss=0.3984, lr=6.02e-06]Steps:   6%|▌         | 302/5000 [1:08:47<15:37:13, 11.97s/it, loss=0.3984, lr=6.02e-06]Steps:   6%|▌         | 302/5000 [1:08:47<15:37:13, 11.97s/it, loss=1.2021, lr=6.04e-06]Steps:   6%|▌         | 303/5000 [1:08:59<15:35:07, 11.95s/it, loss=1.2021, lr=6.04e-06]Steps:   6%|▌         | 303/5000 [1:08:59<15:35:07, 11.95s/it, loss=1.1268, lr=6.06e-06]Steps:   6%|▌         | 304/5000 [1:09:11<15:36:00, 11.96s/it, loss=1.1268, lr=6.06e-06]Steps:   6%|▌         | 304/5000 [1:09:11<15:36:00, 11.96s/it, loss=0.6830, lr=6.08e-06]Steps:   6%|▌         | 305/5000 [1:09:22<15:34:43, 11.95s/it, loss=0.6830, lr=6.08e-06]Steps:   6%|▌         | 305/5000 [1:09:22<15:34:43, 11.95s/it, loss=0.8871, lr=6.10e-06]Steps:   6%|▌         | 306/5000 [1:09:34<15:35:06, 11.95s/it, loss=0.8871, lr=6.10e-06]Steps:   6%|▌         | 306/5000 [1:09:34<15:35:06, 11.95s/it, loss=0.5098, lr=6.12e-06]Steps:   6%|▌         | 307/5000 [1:09:46<15:36:32, 11.97s/it, loss=0.5098, lr=6.12e-06]Steps:   6%|▌         | 307/5000 [1:09:46<15:36:32, 11.97s/it, loss=0.4064, lr=6.14e-06]Steps:   6%|▌         | 308/5000 [1:09:58<15:33:36, 11.94s/it, loss=0.4064, lr=6.14e-06]Steps:   6%|▌         | 308/5000 [1:09:58<15:33:36, 11.94s/it, loss=1.0280, lr=6.16e-06]Steps:   6%|▌         | 309/5000 [1:10:10<15:32:37, 11.93s/it, loss=1.0280, lr=6.16e-06]Steps:   6%|▌         | 309/5000 [1:10:10<15:32:37, 11.93s/it, loss=0.8303, lr=6.18e-06]Steps:   6%|▌         | 310/5000 [1:10:22<15:34:03, 11.95s/it, loss=0.8303, lr=6.18e-06]Steps:   6%|▌         | 310/5000 [1:10:22<15:34:03, 11.95s/it, loss=0.7407, lr=6.20e-06]
[Step 310] Training Debug Info:
  Loss: 0.893533
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0013, std: 0.9180
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0010, std: 1.3594
  Model pred mean: -0.0043, std: 0.9922
  Sigmas: [0.40625]... (timesteps: [407.0])

[Step 310] Training Debug Info:
  Loss: 0.577767
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0217, std: 0.9609
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0209, std: 1.3906
  Model pred mean: -0.0232, std: 1.1562
  Sigmas: [0.6328125]... (timesteps: [633.0])

[Step 310] Training Debug Info:
  Loss: 1.150305
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0155, std: 0.8945
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0140, std: 1.3438
  Model pred mean: -0.0175, std: 0.8203
  Sigmas: [0.16015625]... (timesteps: [160.0])

[Step 310] Training Debug Info:
  Loss: 0.867537
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0041, std: 0.8945
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0058, std: 1.3438
  Model pred mean: 0.0033, std: 0.9727
  Sigmas: [0.4453125]... (timesteps: [446.0])
Steps:   6%|▌         | 311/5000 [1:10:34<15:30:34, 11.91s/it, loss=0.7407, lr=6.20e-06]Steps:   6%|▌         | 311/5000 [1:10:34<15:30:34, 11.91s/it, loss=0.8675, lr=6.22e-06]Steps:   6%|▌         | 312/5000 [1:10:46<15:30:33, 11.91s/it, loss=0.8675, lr=6.22e-06]Steps:   6%|▌         | 312/5000 [1:10:46<15:30:33, 11.91s/it, loss=0.7364, lr=6.24e-06]Steps:   6%|▋         | 313/5000 [1:10:58<15:32:12, 11.93s/it, loss=0.7364, lr=6.24e-06]Steps:   6%|▋         | 313/5000 [1:10:58<15:32:12, 11.93s/it, loss=0.6807, lr=6.26e-06]Steps:   6%|▋         | 314/5000 [1:11:10<15:35:35, 11.98s/it, loss=0.6807, lr=6.26e-06]Steps:   6%|▋         | 314/5000 [1:11:10<15:35:35, 11.98s/it, loss=1.1593, lr=6.28e-06]Steps:   6%|▋         | 315/5000 [1:11:22<15:34:13, 11.96s/it, loss=1.1593, lr=6.28e-06]Steps:   6%|▋         | 315/5000 [1:11:22<15:34:13, 11.96s/it, loss=1.1416, lr=6.30e-06]Steps:   6%|▋         | 316/5000 [1:11:34<15:35:05, 11.98s/it, loss=1.1416, lr=6.30e-06]Steps:   6%|▋         | 316/5000 [1:11:34<15:35:05, 11.98s/it, loss=1.1341, lr=6.32e-06]Steps:   6%|▋         | 317/5000 [1:11:46<15:33:51, 11.96s/it, loss=1.1341, lr=6.32e-06]Steps:   6%|▋         | 317/5000 [1:11:46<15:33:51, 11.96s/it, loss=0.6138, lr=6.34e-06]Steps:   6%|▋         | 318/5000 [1:11:58<15:31:02, 11.93s/it, loss=0.6138, lr=6.34e-06]Steps:   6%|▋         | 318/5000 [1:11:58<15:31:02, 11.93s/it, loss=0.9095, lr=6.36e-06]Steps:   6%|▋         | 319/5000 [1:12:10<15:33:20, 11.96s/it, loss=0.9095, lr=6.36e-06]Steps:   6%|▋         | 319/5000 [1:12:10<15:33:20, 11.96s/it, loss=1.1106, lr=6.38e-06]Steps:   6%|▋         | 320/5000 [1:12:22<15:35:14, 11.99s/it, loss=1.1106, lr=6.38e-06]Steps:   6%|▋         | 320/5000 [1:12:22<15:35:14, 11.99s/it, loss=0.5107, lr=6.40e-06]
[Step 320] Training Debug Info:
  Loss: 0.677188
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0034, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0029, std: 1.3594
  Model pred mean: -0.0013, std: 1.0859
  Sigmas: [0.546875]... (timesteps: [548.0])

[Step 320] Training Debug Info:
  Loss: 0.392153
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0201, std: 0.9141
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0195, std: 1.3594
  Model pred mean: -0.0175, std: 1.2031
  Sigmas: [0.77734375]... (timesteps: [779.0])

[Step 320] Training Debug Info:
  Loss: 0.527256
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0200, std: 0.9727
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0200, std: 1.3984
  Model pred mean: -0.0140, std: 1.1875
  Sigmas: [0.87109375]... (timesteps: [870.0])

[Step 320] Training Debug Info:
  Loss: 1.155332
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0038, std: 0.9062
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0044, std: 1.3516
  Model pred mean: 0.0080, std: 0.8047
  Sigmas: [0.1640625]... (timesteps: [164.0])
Steps:   6%|▋         | 321/5000 [1:12:34<15:32:32, 11.96s/it, loss=0.5107, lr=6.40e-06]Steps:   6%|▋         | 321/5000 [1:12:34<15:32:32, 11.96s/it, loss=1.1553, lr=6.42e-06]Steps:   6%|▋         | 322/5000 [1:12:46<15:34:44, 11.99s/it, loss=1.1553, lr=6.42e-06]Steps:   6%|▋         | 322/5000 [1:12:46<15:34:44, 11.99s/it, loss=1.0592, lr=6.44e-06]Steps:   6%|▋         | 323/5000 [1:12:58<15:32:02, 11.96s/it, loss=1.0592, lr=6.44e-06]Steps:   6%|▋         | 323/5000 [1:12:58<15:32:02, 11.96s/it, loss=0.5266, lr=6.46e-06]Steps:   6%|▋         | 324/5000 [1:13:10<15:30:46, 11.94s/it, loss=0.5266, lr=6.46e-06]Steps:   6%|▋         | 324/5000 [1:13:10<15:30:46, 11.94s/it, loss=0.3409, lr=6.48e-06]Steps:   6%|▋         | 325/5000 [1:13:22<15:30:39, 11.94s/it, loss=0.3409, lr=6.48e-06]Steps:   6%|▋         | 325/5000 [1:13:22<15:30:39, 11.94s/it, loss=0.7816, lr=6.50e-06]Steps:   7%|▋         | 326/5000 [1:13:34<15:30:55, 11.95s/it, loss=0.7816, lr=6.50e-06]Steps:   7%|▋         | 326/5000 [1:13:34<15:30:55, 11.95s/it, loss=1.1144, lr=6.52e-06]Steps:   7%|▋         | 327/5000 [1:13:46<15:33:34, 11.99s/it, loss=1.1144, lr=6.52e-06]Steps:   7%|▋         | 327/5000 [1:13:46<15:33:34, 11.99s/it, loss=0.6762, lr=6.54e-06]Steps:   7%|▋         | 328/5000 [1:13:58<15:34:42, 12.00s/it, loss=0.6762, lr=6.54e-06]Steps:   7%|▋         | 328/5000 [1:13:58<15:34:42, 12.00s/it, loss=0.5448, lr=6.56e-06]Steps:   7%|▋         | 329/5000 [1:14:09<15:30:29, 11.95s/it, loss=0.5448, lr=6.56e-06]Steps:   7%|▋         | 329/5000 [1:14:09<15:30:29, 11.95s/it, loss=0.8179, lr=6.58e-06]Steps:   7%|▋         | 330/5000 [1:14:21<15:29:17, 11.94s/it, loss=0.8179, lr=6.58e-06]Steps:   7%|▋         | 330/5000 [1:14:21<15:29:17, 11.94s/it, loss=0.7865, lr=6.60e-06]
[Step 330] Training Debug Info:
  Loss: 0.804009
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0064, std: 0.9180
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0061, std: 1.3594
  Model pred mean: -0.0043, std: 1.0078
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 330] Training Debug Info:
  Loss: 0.871215
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0178, std: 0.9688
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0179, std: 1.3906
  Model pred mean: -0.0140, std: 1.0234
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 330] Training Debug Info:
  Loss: 0.651921
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0271, std: 0.9375
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0271, std: 1.3672
  Model pred mean: -0.0280, std: 1.1094
  Sigmas: [0.921875]... (timesteps: [922.0])

[Step 330] Training Debug Info:
  Loss: 0.558660
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0198, std: 0.8828
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0170, std: 1.3359
  Model pred mean: 0.0153, std: 1.1016
  Sigmas: [0.9765625]... (timesteps: [975.0])
Steps:   7%|▋         | 331/5000 [1:14:33<15:30:33, 11.96s/it, loss=0.7865, lr=6.60e-06]Steps:   7%|▋         | 331/5000 [1:14:33<15:30:33, 11.96s/it, loss=0.5587, lr=6.62e-06]Steps:   7%|▋         | 332/5000 [1:14:45<15:27:34, 11.92s/it, loss=0.5587, lr=6.62e-06]Steps:   7%|▋         | 332/5000 [1:14:45<15:27:34, 11.92s/it, loss=1.0912, lr=6.64e-06]Steps:   7%|▋         | 333/5000 [1:14:57<15:26:29, 11.91s/it, loss=1.0912, lr=6.64e-06]Steps:   7%|▋         | 333/5000 [1:14:57<15:26:29, 11.91s/it, loss=1.1601, lr=6.66e-06]Steps:   7%|▋         | 334/5000 [1:15:09<15:29:39, 11.95s/it, loss=1.1601, lr=6.66e-06]Steps:   7%|▋         | 334/5000 [1:15:09<15:29:39, 11.95s/it, loss=0.7697, lr=6.68e-06]Steps:   7%|▋         | 335/5000 [1:15:21<15:27:49, 11.93s/it, loss=0.7697, lr=6.68e-06]Steps:   7%|▋         | 335/5000 [1:15:21<15:27:49, 11.93s/it, loss=0.4097, lr=6.70e-06]Steps:   7%|▋         | 336/5000 [1:15:33<15:28:22, 11.94s/it, loss=0.4097, lr=6.70e-06]Steps:   7%|▋         | 336/5000 [1:15:33<15:28:22, 11.94s/it, loss=0.3935, lr=6.72e-06]Steps:   7%|▋         | 337/5000 [1:15:45<15:30:46, 11.98s/it, loss=0.3935, lr=6.72e-06]Steps:   7%|▋         | 337/5000 [1:15:45<15:30:46, 11.98s/it, loss=0.6023, lr=6.74e-06]Steps:   7%|▋         | 338/5000 [1:15:57<15:28:59, 11.96s/it, loss=0.6023, lr=6.74e-06]Steps:   7%|▋         | 338/5000 [1:15:57<15:28:59, 11.96s/it, loss=0.8189, lr=6.76e-06]Steps:   7%|▋         | 339/5000 [1:16:09<15:26:12, 11.92s/it, loss=0.8189, lr=6.76e-06]Steps:   7%|▋         | 339/5000 [1:16:09<15:26:12, 11.92s/it, loss=1.1444, lr=6.78e-06]Steps:   7%|▋         | 340/5000 [1:16:21<15:27:34, 11.94s/it, loss=1.1444, lr=6.78e-06]Steps:   7%|▋         | 340/5000 [1:16:21<15:27:34, 11.94s/it, loss=0.8953, lr=6.80e-06]
[Step 340] Training Debug Info:
  Loss: 0.685648
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.9258
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0081, std: 1.3672
  Model pred mean: -0.0091, std: 1.0625
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 340] Training Debug Info:
  Loss: 0.997953
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0004, std: 0.8672
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0027, std: 1.3203
  Model pred mean: -0.0042, std: 0.8711
  Sigmas: [0.369140625]... (timesteps: [369.0])

[Step 340] Training Debug Info:
  Loss: 1.149622
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0072, std: 0.8945
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0039, std: 1.3438
  Model pred mean: -0.0112, std: 0.8125
  Sigmas: [0.25390625]... (timesteps: [252.99998474121094])

[Step 340] Training Debug Info:
  Loss: 0.453270
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0031, std: 0.9141
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0022, std: 1.3594
  Model pred mean: -0.0112, std: 1.1641
  Sigmas: [0.9375]... (timesteps: [939.0])
Steps:   7%|▋         | 341/5000 [1:16:33<15:30:13, 11.98s/it, loss=0.8953, lr=6.80e-06]Steps:   7%|▋         | 341/5000 [1:16:33<15:30:13, 11.98s/it, loss=0.4533, lr=6.82e-06]Steps:   7%|▋         | 342/5000 [1:16:45<15:28:04, 11.95s/it, loss=0.4533, lr=6.82e-06]Steps:   7%|▋         | 342/5000 [1:16:45<15:28:04, 11.95s/it, loss=1.0996, lr=6.84e-06]Steps:   7%|▋         | 343/5000 [1:16:57<15:26:19, 11.93s/it, loss=1.0996, lr=6.84e-06]Steps:   7%|▋         | 343/5000 [1:16:57<15:26:19, 11.93s/it, loss=0.7711, lr=6.86e-06]Steps:   7%|▋         | 344/5000 [1:17:09<15:26:12, 11.94s/it, loss=0.7711, lr=6.86e-06]Steps:   7%|▋         | 344/5000 [1:17:09<15:26:12, 11.94s/it, loss=0.7127, lr=6.88e-06]Steps:   7%|▋         | 345/5000 [1:17:20<15:24:12, 11.91s/it, loss=0.7127, lr=6.88e-06]Steps:   7%|▋         | 345/5000 [1:17:20<15:24:12, 11.91s/it, loss=0.5114, lr=6.90e-06]Steps:   7%|▋         | 346/5000 [1:17:33<15:28:58, 11.98s/it, loss=0.5114, lr=6.90e-06]Steps:   7%|▋         | 346/5000 [1:17:33<15:28:58, 11.98s/it, loss=0.7097, lr=6.92e-06]Steps:   7%|▋         | 347/5000 [1:17:45<15:31:11, 12.01s/it, loss=0.7097, lr=6.92e-06]Steps:   7%|▋         | 347/5000 [1:17:45<15:31:11, 12.01s/it, loss=0.7280, lr=6.94e-06]Steps:   7%|▋         | 348/5000 [1:17:57<15:28:25, 11.97s/it, loss=0.7280, lr=6.94e-06]Steps:   7%|▋         | 348/5000 [1:17:57<15:28:25, 11.97s/it, loss=0.5015, lr=6.96e-06]Steps:   7%|▋         | 349/5000 [1:18:09<15:28:55, 11.98s/it, loss=0.5015, lr=6.96e-06]Steps:   7%|▋         | 349/5000 [1:18:09<15:28:55, 11.98s/it, loss=0.8139, lr=6.98e-06]Steps:   7%|▋         | 350/5000 [1:18:20<15:26:28, 11.95s/it, loss=0.8139, lr=6.98e-06]Steps:   7%|▋         | 350/5000 [1:18:20<15:26:28, 11.95s/it, loss=0.5913, lr=7.00e-06]
[Step 350] Training Debug Info:
  Loss: 0.438760
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0068, std: 0.8945
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0065, std: 1.3438
  Model pred mean: 0.0064, std: 1.1797
  Sigmas: [0.734375]... (timesteps: [734.0])

[Step 350] Training Debug Info:
  Loss: 0.768499
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0060, std: 0.8945
  Noise mean: -0.0041, std: 1.0000
  Target mean: 0.0019, std: 1.3438
  Model pred mean: 0.0133, std: 1.0234
  Sigmas: [0.4765625]... (timesteps: [477.0])

[Step 350] Training Debug Info:
  Loss: 0.376463
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0087, std: 0.8945
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0073, std: 1.3438
  Model pred mean: 0.0061, std: 1.2031
  Sigmas: [0.828125]... (timesteps: [830.0])

[Step 350] Training Debug Info:
  Loss: 0.505680
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0089, std: 0.9375
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0082, std: 1.3672
  Model pred mean: -0.0064, std: 1.1875
  Sigmas: [0.70703125]... (timesteps: [708.0])
Steps:   7%|▋         | 351/5000 [1:18:32<15:24:50, 11.94s/it, loss=0.5913, lr=7.00e-06]Steps:   7%|▋         | 351/5000 [1:18:32<15:24:50, 11.94s/it, loss=0.5057, lr=7.02e-06]Steps:   7%|▋         | 352/5000 [1:18:44<15:23:42, 11.92s/it, loss=0.5057, lr=7.02e-06]Steps:   7%|▋         | 352/5000 [1:18:44<15:23:42, 11.92s/it, loss=0.7662, lr=7.04e-06]Steps:   7%|▋         | 353/5000 [1:18:56<15:24:23, 11.94s/it, loss=0.7662, lr=7.04e-06]Steps:   7%|▋         | 353/5000 [1:18:56<15:24:23, 11.94s/it, loss=0.3915, lr=7.06e-06]Steps:   7%|▋         | 354/5000 [1:19:08<15:28:11, 11.99s/it, loss=0.3915, lr=7.06e-06]Steps:   7%|▋         | 354/5000 [1:19:08<15:28:11, 11.99s/it, loss=0.6917, lr=7.08e-06]Steps:   7%|▋         | 355/5000 [1:19:20<15:30:19, 12.02s/it, loss=0.6917, lr=7.08e-06]Steps:   7%|▋         | 355/5000 [1:19:20<15:30:19, 12.02s/it, loss=1.1474, lr=7.10e-06]Steps:   7%|▋         | 356/5000 [1:19:32<15:27:29, 11.98s/it, loss=1.1474, lr=7.10e-06]Steps:   7%|▋         | 356/5000 [1:19:32<15:27:29, 11.98s/it, loss=0.3208, lr=7.12e-06]Steps:   7%|▋         | 357/5000 [1:19:44<15:26:18, 11.97s/it, loss=0.3208, lr=7.12e-06]Steps:   7%|▋         | 357/5000 [1:19:44<15:26:18, 11.97s/it, loss=0.4146, lr=7.14e-06]Steps:   7%|▋         | 358/5000 [1:19:56<15:28:27, 12.00s/it, loss=0.4146, lr=7.14e-06]Steps:   7%|▋         | 358/5000 [1:19:56<15:28:27, 12.00s/it, loss=1.0629, lr=7.16e-06]Steps:   7%|▋         | 359/5000 [1:20:08<15:26:00, 11.97s/it, loss=1.0629, lr=7.16e-06]Steps:   7%|▋         | 359/5000 [1:20:08<15:26:00, 11.97s/it, loss=1.1957, lr=7.18e-06]Steps:   7%|▋         | 360/5000 [1:20:20<15:24:22, 11.95s/it, loss=1.1957, lr=7.18e-06]Steps:   7%|▋         | 360/5000 [1:20:20<15:24:22, 11.95s/it, loss=0.7190, lr=7.20e-06]
[Step 360] Training Debug Info:
  Loss: 0.378979
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0615, std: 0.9609
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0588, std: 1.3828
  Model pred mean: -0.0640, std: 1.2344
  Sigmas: [0.60546875]... (timesteps: [605.0])

[Step 360] Training Debug Info:
  Loss: 0.372950
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0227, std: 0.8711
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0234, std: 1.3281
  Model pred mean: 0.0183, std: 1.1641
  Sigmas: [0.91796875]... (timesteps: [918.0])

[Step 360] Training Debug Info:
  Loss: 0.653141
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0162, std: 1.3516
  Model pred mean: -0.0116, std: 1.0859
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 360] Training Debug Info:
  Loss: 0.414677
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0058, std: 0.9180
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0063, std: 1.3594
  Model pred mean: -0.0077, std: 1.1953
  Sigmas: [0.828125]... (timesteps: [829.0])
Steps:   7%|▋         | 361/5000 [1:20:32<15:26:50, 11.99s/it, loss=0.7190, lr=7.20e-06]Steps:   7%|▋         | 361/5000 [1:20:32<15:26:50, 11.99s/it, loss=0.4147, lr=7.22e-06]Steps:   7%|▋         | 362/5000 [1:20:44<15:25:07, 11.97s/it, loss=0.4147, lr=7.22e-06]Steps:   7%|▋         | 362/5000 [1:20:44<15:25:07, 11.97s/it, loss=0.4280, lr=7.24e-06]Steps:   7%|▋         | 363/5000 [1:20:56<15:23:25, 11.95s/it, loss=0.4280, lr=7.24e-06]Steps:   7%|▋         | 363/5000 [1:20:56<15:23:25, 11.95s/it, loss=1.1001, lr=7.26e-06]Steps:   7%|▋         | 364/5000 [1:21:08<15:22:43, 11.94s/it, loss=1.1001, lr=7.26e-06]Steps:   7%|▋         | 364/5000 [1:21:08<15:22:43, 11.94s/it, loss=1.0735, lr=7.28e-06]Steps:   7%|▋         | 365/5000 [1:21:20<15:22:09, 11.94s/it, loss=1.0735, lr=7.28e-06]Steps:   7%|▋         | 365/5000 [1:21:20<15:22:09, 11.94s/it, loss=1.0643, lr=7.30e-06]Steps:   7%|▋         | 366/5000 [1:21:32<15:23:13, 11.95s/it, loss=1.0643, lr=7.30e-06]Steps:   7%|▋         | 366/5000 [1:21:32<15:23:13, 11.95s/it, loss=0.4297, lr=7.32e-06]Steps:   7%|▋         | 367/5000 [1:21:44<15:21:06, 11.93s/it, loss=0.4297, lr=7.32e-06]Steps:   7%|▋         | 367/5000 [1:21:44<15:21:06, 11.93s/it, loss=1.0894, lr=7.34e-06]Steps:   7%|▋         | 368/5000 [1:21:56<15:26:33, 12.00s/it, loss=1.0894, lr=7.34e-06]Steps:   7%|▋         | 368/5000 [1:21:56<15:26:33, 12.00s/it, loss=1.1859, lr=7.36e-06]Steps:   7%|▋         | 369/5000 [1:22:08<15:24:39, 11.98s/it, loss=1.1859, lr=7.36e-06]Steps:   7%|▋         | 369/5000 [1:22:08<15:24:39, 11.98s/it, loss=1.1263, lr=7.38e-06]Steps:   7%|▋         | 370/5000 [1:22:20<15:24:14, 11.98s/it, loss=1.1263, lr=7.38e-06]Steps:   7%|▋         | 370/5000 [1:22:20<15:24:14, 11.98s/it, loss=1.0158, lr=7.40e-06]
[Step 370] Training Debug Info:
  Loss: 0.388990
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0125, std: 0.9062
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0123, std: 1.3516
  Model pred mean: -0.0069, std: 1.1875
  Sigmas: [0.84765625]... (timesteps: [848.0])

[Step 370] Training Debug Info:
  Loss: 0.336970
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0623, std: 0.9219
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0630, std: 1.3594
  Model pred mean: 0.0640, std: 1.2188
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 370] Training Debug Info:
  Loss: 0.548621
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0066, std: 0.9336
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0081, std: 1.3672
  Model pred mean: -0.0073, std: 1.1484
  Sigmas: [0.61328125]... (timesteps: [612.0])

[Step 370] Training Debug Info:
  Loss: 0.491798
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0125, std: 0.8945
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0130, std: 1.3438
  Model pred mean: 0.0115, std: 1.1484
  Sigmas: [0.68359375]... (timesteps: [682.0])
Steps:   7%|▋         | 371/5000 [1:22:32<15:23:37, 11.97s/it, loss=1.0158, lr=7.40e-06]Steps:   7%|▋         | 371/5000 [1:22:32<15:23:37, 11.97s/it, loss=0.4918, lr=7.42e-06]Steps:   7%|▋         | 372/5000 [1:22:44<15:23:01, 11.97s/it, loss=0.4918, lr=7.42e-06]Steps:   7%|▋         | 372/5000 [1:22:44<15:23:01, 11.97s/it, loss=1.0549, lr=7.44e-06]Steps:   7%|▋         | 373/5000 [1:22:56<15:24:55, 11.99s/it, loss=1.0549, lr=7.44e-06]Steps:   7%|▋         | 373/5000 [1:22:56<15:24:55, 11.99s/it, loss=0.4993, lr=7.46e-06]Steps:   7%|▋         | 374/5000 [1:23:08<15:26:35, 12.02s/it, loss=0.4993, lr=7.46e-06]Steps:   7%|▋         | 374/5000 [1:23:08<15:26:35, 12.02s/it, loss=0.9700, lr=7.48e-06]Steps:   8%|▊         | 375/5000 [1:23:20<15:24:53, 12.00s/it, loss=0.9700, lr=7.48e-06]Steps:   8%|▊         | 375/5000 [1:23:20<15:24:53, 12.00s/it, loss=0.6665, lr=7.50e-06]Steps:   8%|▊         | 376/5000 [1:23:32<15:23:40, 11.99s/it, loss=0.6665, lr=7.50e-06]Steps:   8%|▊         | 376/5000 [1:23:32<15:23:40, 11.99s/it, loss=0.6901, lr=7.52e-06]Steps:   8%|▊         | 377/5000 [1:23:44<15:22:20, 11.97s/it, loss=0.6901, lr=7.52e-06]Steps:   8%|▊         | 377/5000 [1:23:44<15:22:20, 11.97s/it, loss=1.0003, lr=7.54e-06]Steps:   8%|▊         | 378/5000 [1:23:56<15:21:28, 11.96s/it, loss=1.0003, lr=7.54e-06]Steps:   8%|▊         | 378/5000 [1:23:56<15:21:28, 11.96s/it, loss=1.0810, lr=7.56e-06]Steps:   8%|▊         | 379/5000 [1:24:07<15:18:29, 11.93s/it, loss=1.0810, lr=7.56e-06]Steps:   8%|▊         | 379/5000 [1:24:07<15:18:29, 11.93s/it, loss=1.0633, lr=7.58e-06]Steps:   8%|▊         | 380/5000 [1:24:19<15:16:29, 11.90s/it, loss=1.0633, lr=7.58e-06]Steps:   8%|▊         | 380/5000 [1:24:19<15:16:29, 11.90s/it, loss=0.9951, lr=7.60e-06]
[Step 380] Training Debug Info:
  Loss: 1.001597
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0552, std: 0.9492
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0552, std: 1.3750
  Model pred mean: -0.0566, std: 0.9453
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 380] Training Debug Info:
  Loss: 1.035093
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0136, std: 0.9531
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0138, std: 1.3828
  Model pred mean: -0.0056, std: 0.9336
  Sigmas: [0.01397705078125]... (timesteps: [14.0])

[Step 380] Training Debug Info:
  Loss: 0.916851
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0164, std: 0.9883
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0145, std: 1.4062
  Model pred mean: -0.0167, std: 1.0469
  Sigmas: [0.38671875]... (timesteps: [387.0])

[Step 380] Training Debug Info:
  Loss: 0.457161
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0045, std: 0.9180
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0054, std: 1.3594
  Model pred mean: -0.0075, std: 1.1875
  Sigmas: [0.6875]... (timesteps: [686.0])
Steps:   8%|▊         | 381/5000 [1:24:31<15:20:51, 11.96s/it, loss=0.9951, lr=7.60e-06]Steps:   8%|▊         | 381/5000 [1:24:31<15:20:51, 11.96s/it, loss=0.4572, lr=7.62e-06]Steps:   8%|▊         | 382/5000 [1:24:44<15:24:12, 12.01s/it, loss=0.4572, lr=7.62e-06]Steps:   8%|▊         | 382/5000 [1:24:44<15:24:12, 12.01s/it, loss=0.5739, lr=7.64e-06]Steps:   8%|▊         | 383/5000 [1:24:55<15:20:22, 11.96s/it, loss=0.5739, lr=7.64e-06]Steps:   8%|▊         | 383/5000 [1:24:55<15:20:22, 11.96s/it, loss=0.6335, lr=7.66e-06]Steps:   8%|▊         | 384/5000 [1:25:07<15:19:10, 11.95s/it, loss=0.6335, lr=7.66e-06]Steps:   8%|▊         | 384/5000 [1:25:07<15:19:10, 11.95s/it, loss=0.5189, lr=7.68e-06]Steps:   8%|▊         | 385/5000 [1:25:19<15:19:46, 11.96s/it, loss=0.5189, lr=7.68e-06]Steps:   8%|▊         | 385/5000 [1:25:19<15:19:46, 11.96s/it, loss=1.0458, lr=7.70e-06]Steps:   8%|▊         | 386/5000 [1:25:31<15:17:42, 11.93s/it, loss=1.0458, lr=7.70e-06]Steps:   8%|▊         | 386/5000 [1:25:31<15:17:42, 11.93s/it, loss=0.8932, lr=7.72e-06]Steps:   8%|▊         | 387/5000 [1:25:43<15:16:44, 11.92s/it, loss=0.8932, lr=7.72e-06]Steps:   8%|▊         | 387/5000 [1:25:43<15:16:44, 11.92s/it, loss=0.3986, lr=7.74e-06]Steps:   8%|▊         | 388/5000 [1:25:55<15:21:10, 11.98s/it, loss=0.3986, lr=7.74e-06]Steps:   8%|▊         | 388/5000 [1:25:55<15:21:10, 11.98s/it, loss=1.1233, lr=7.76e-06]Steps:   8%|▊         | 389/5000 [1:26:07<15:24:22, 12.03s/it, loss=1.1233, lr=7.76e-06]Steps:   8%|▊         | 389/5000 [1:26:07<15:24:22, 12.03s/it, loss=0.3512, lr=7.78e-06]Steps:   8%|▊         | 390/5000 [1:26:19<15:22:36, 12.01s/it, loss=0.3512, lr=7.78e-06]Steps:   8%|▊         | 390/5000 [1:26:19<15:22:36, 12.01s/it, loss=1.0562, lr=7.80e-06]
[Step 390] Training Debug Info:
  Loss: 1.097766
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0238, std: 0.9297
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0225, std: 1.3672
  Model pred mean: -0.0242, std: 0.8789
  Sigmas: [0.06298828125]... (timesteps: [63.0])

[Step 390] Training Debug Info:
  Loss: 0.461130
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0238, std: 0.9180
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0232, std: 1.3594
  Model pred mean: -0.0188, std: 1.1797
  Sigmas: [0.66015625]... (timesteps: [659.0])

[Step 390] Training Debug Info:
  Loss: 0.718948
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0022, std: 0.9062
  Noise mean: 0.0045, std: 1.0000
  Target mean: 0.0067, std: 1.3516
  Model pred mean: 0.0012, std: 1.0547
  Sigmas: [0.5390625]... (timesteps: [540.0])

[Step 390] Training Debug Info:
  Loss: 0.468915
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0245, std: 0.9727
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0228, std: 1.3984
  Model pred mean: -0.0247, std: 1.2109
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   8%|▊         | 391/5000 [1:26:31<15:23:53, 12.03s/it, loss=1.0562, lr=7.80e-06]Steps:   8%|▊         | 391/5000 [1:26:31<15:23:53, 12.03s/it, loss=0.4689, lr=7.82e-06]Steps:   8%|▊         | 392/5000 [1:26:43<15:19:38, 11.97s/it, loss=0.4689, lr=7.82e-06]Steps:   8%|▊         | 392/5000 [1:26:43<15:19:38, 11.97s/it, loss=0.7615, lr=7.84e-06]Steps:   8%|▊         | 393/5000 [1:26:55<15:18:04, 11.96s/it, loss=0.7615, lr=7.84e-06]Steps:   8%|▊         | 393/5000 [1:26:55<15:18:04, 11.96s/it, loss=0.3827, lr=7.86e-06]Steps:   8%|▊         | 394/5000 [1:27:07<15:16:02, 11.93s/it, loss=0.3827, lr=7.86e-06]Steps:   8%|▊         | 394/5000 [1:27:07<15:16:02, 11.93s/it, loss=0.8487, lr=7.88e-06]Steps:   8%|▊         | 395/5000 [1:27:19<15:19:34, 11.98s/it, loss=0.8487, lr=7.88e-06]Steps:   8%|▊         | 395/5000 [1:27:19<15:19:34, 11.98s/it, loss=0.6680, lr=7.90e-06]Steps:   8%|▊         | 396/5000 [1:27:31<15:23:28, 12.03s/it, loss=0.6680, lr=7.90e-06]Steps:   8%|▊         | 396/5000 [1:27:31<15:23:28, 12.03s/it, loss=1.1668, lr=7.92e-06]Steps:   8%|▊         | 397/5000 [1:27:43<15:20:41, 12.00s/it, loss=1.1668, lr=7.92e-06]Steps:   8%|▊         | 397/5000 [1:27:43<15:20:41, 12.00s/it, loss=1.1606, lr=7.94e-06]Steps:   8%|▊         | 398/5000 [1:27:55<15:16:41, 11.95s/it, loss=1.1606, lr=7.94e-06]Steps:   8%|▊         | 398/5000 [1:27:55<15:16:41, 11.95s/it, loss=0.3943, lr=7.96e-06]Steps:   8%|▊         | 399/5000 [1:28:07<15:16:57, 11.96s/it, loss=0.3943, lr=7.96e-06]Steps:   8%|▊         | 399/5000 [1:28:07<15:16:57, 11.96s/it, loss=0.4014, lr=7.98e-06]Steps:   8%|▊         | 400/5000 [1:28:19<15:19:19, 11.99s/it, loss=0.4014, lr=7.98e-06]Steps:   8%|▊         | 400/5000 [1:28:19<15:19:19, 11.99s/it, loss=1.0888, lr=8.00e-06]01/22/2026 09:14:06 - INFO - __main__ - 
[Step 400] ✅ Loss in normal range (1.0888)
01/22/2026 09:14:06 - INFO - __main__ -   Loss avg (last 100): 0.7827
01/22/2026 09:14:06 - INFO - __main__ -   Loss range: [0.3208, 1.2021]
01/22/2026 09:14:06 - INFO - __main__ - 
🔍 Running validation at step 400...
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 400 (parquet mode)...
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 400...
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 09:14:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 09:14:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 09:14:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 09:14:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 09:14:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.41it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 09:15:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 09:15:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 09:15:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 09:15:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 09:15:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 09:15:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 09:16:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 09:16:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 09:16:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 09:16:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 09:16:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 09:16:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 09:17:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 09:17:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 09:17:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 09:17:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 09:17:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 09:17:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 09:18:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400/step000400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 09:18:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 09:18:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 09:18:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000400
01/22/2026 09:18:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 400] Training Debug Info:
  Loss: 0.654937
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0188, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0187, std: 1.3594
  Model pred mean: -0.0298, std: 1.1094
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 400] Training Debug Info:
  Loss: 0.684350
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0093, std: 0.8555
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0071, std: 1.3203
  Model pred mean: 0.0036, std: 1.0391
  Sigmas: [0.5625]... (timesteps: [561.0])

[Step 400] Training Debug Info:
  Loss: 0.817296
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0021, std: 0.8711
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0004, std: 1.3281
  Model pred mean: -0.0078, std: 0.9648
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 400] Training Debug Info:
  Loss: 1.130749
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0197, std: 0.9023
  Noise mean: -0.0019, std: 0.9961
  Target mean: -0.0215, std: 1.3438
  Model pred mean: -0.0216, std: 0.8203
  Sigmas: [0.14453125]... (timesteps: [145.0])
Steps:   8%|▊         | 401/5000 [1:32:42<111:38:04, 87.39s/it, loss=1.0888, lr=8.00e-06]Steps:   8%|▊         | 401/5000 [1:32:42<111:38:04, 87.39s/it, loss=1.1307, lr=8.02e-06]Steps:   8%|▊         | 402/5000 [1:32:54<82:40:58, 64.74s/it, loss=1.1307, lr=8.02e-06] Steps:   8%|▊         | 402/5000 [1:32:54<82:40:58, 64.74s/it, loss=1.1462, lr=8.04e-06]Steps:   8%|▊         | 403/5000 [1:33:06<62:26:10, 48.90s/it, loss=1.1462, lr=8.04e-06]Steps:   8%|▊         | 403/5000 [1:33:06<62:26:10, 48.90s/it, loss=0.3711, lr=8.06e-06]Steps:   8%|▊         | 404/5000 [1:33:18<48:16:39, 37.82s/it, loss=0.3711, lr=8.06e-06]Steps:   8%|▊         | 404/5000 [1:33:18<48:16:39, 37.82s/it, loss=0.5363, lr=8.08e-06]Steps:   8%|▊         | 405/5000 [1:33:30<38:21:54, 30.06s/it, loss=0.5363, lr=8.08e-06]Steps:   8%|▊         | 405/5000 [1:33:30<38:21:54, 30.06s/it, loss=0.5324, lr=8.10e-06]Steps:   8%|▊         | 406/5000 [1:33:42<31:23:39, 24.60s/it, loss=0.5324, lr=8.10e-06]Steps:   8%|▊         | 406/5000 [1:33:42<31:23:39, 24.60s/it, loss=0.6158, lr=8.12e-06]Steps:   8%|▊         | 407/5000 [1:33:54<26:32:39, 20.81s/it, loss=0.6158, lr=8.12e-06]Steps:   8%|▊         | 407/5000 [1:33:54<26:32:39, 20.81s/it, loss=1.1345, lr=8.14e-06]Steps:   8%|▊         | 408/5000 [1:34:06<23:11:59, 18.19s/it, loss=1.1345, lr=8.14e-06]Steps:   8%|▊         | 408/5000 [1:34:06<23:11:59, 18.19s/it, loss=0.9614, lr=8.16e-06]Steps:   8%|▊         | 409/5000 [1:34:18<20:53:00, 16.38s/it, loss=0.9614, lr=8.16e-06]Steps:   8%|▊         | 409/5000 [1:34:18<20:53:00, 16.38s/it, loss=0.8413, lr=8.18e-06]Steps:   8%|▊         | 410/5000 [1:34:30<19:07:40, 15.00s/it, loss=0.8413, lr=8.18e-06]Steps:   8%|▊         | 410/5000 [1:34:30<19:07:40, 15.00s/it, loss=0.9994, lr=8.20e-06]
[Step 410] Training Debug Info:
  Loss: 0.373597
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0001, std: 0.8555
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0021, std: 1.3125
  Model pred mean: -0.0036, std: 1.1641
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 410] Training Debug Info:
  Loss: 0.687147
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0427, std: 0.9258
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0442, std: 1.3672
  Model pred mean: -0.0435, std: 1.0859
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 410] Training Debug Info:
  Loss: 0.508050
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0166, std: 0.9219
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0171, std: 1.3594
  Model pred mean: -0.0134, std: 1.1719
  Sigmas: [0.625]... (timesteps: [625.0])

[Step 410] Training Debug Info:
  Loss: 0.418569
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0166, std: 0.8984
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0164, std: 1.3438
  Model pred mean: 0.0178, std: 1.1797
  Sigmas: [0.74609375]... (timesteps: [748.0])
Steps:   8%|▊         | 411/5000 [1:34:42<17:57:48, 14.09s/it, loss=0.9994, lr=8.20e-06]Steps:   8%|▊         | 411/5000 [1:34:42<17:57:48, 14.09s/it, loss=0.4186, lr=8.22e-06]Steps:   8%|▊         | 412/5000 [1:34:54<17:07:51, 13.44s/it, loss=0.4186, lr=8.22e-06]Steps:   8%|▊         | 412/5000 [1:34:54<17:07:51, 13.44s/it, loss=0.4645, lr=8.24e-06]Steps:   8%|▊         | 413/5000 [1:35:06<16:33:41, 13.00s/it, loss=0.4645, lr=8.24e-06]Steps:   8%|▊         | 413/5000 [1:35:06<16:33:41, 13.00s/it, loss=0.4828, lr=8.26e-06]Steps:   8%|▊         | 414/5000 [1:35:18<16:09:41, 12.69s/it, loss=0.4828, lr=8.26e-06]Steps:   8%|▊         | 414/5000 [1:35:18<16:09:41, 12.69s/it, loss=0.3673, lr=8.28e-06]Steps:   8%|▊         | 415/5000 [1:35:30<15:55:59, 12.51s/it, loss=0.3673, lr=8.28e-06]Steps:   8%|▊         | 415/5000 [1:35:30<15:55:59, 12.51s/it, loss=0.6186, lr=8.30e-06]Steps:   8%|▊         | 416/5000 [1:35:42<15:43:09, 12.35s/it, loss=0.6186, lr=8.30e-06]Steps:   8%|▊         | 416/5000 [1:35:42<15:43:09, 12.35s/it, loss=0.8503, lr=8.32e-06]Steps:   8%|▊         | 417/5000 [1:35:54<15:31:25, 12.19s/it, loss=0.8503, lr=8.32e-06]Steps:   8%|▊         | 417/5000 [1:35:54<15:31:25, 12.19s/it, loss=0.5523, lr=8.34e-06]Steps:   8%|▊         | 418/5000 [1:36:06<15:26:45, 12.14s/it, loss=0.5523, lr=8.34e-06]Steps:   8%|▊         | 418/5000 [1:36:06<15:26:45, 12.14s/it, loss=1.1131, lr=8.36e-06]Steps:   8%|▊         | 419/5000 [1:36:18<15:21:39, 12.07s/it, loss=1.1131, lr=8.36e-06]Steps:   8%|▊         | 419/5000 [1:36:18<15:21:39, 12.07s/it, loss=0.5971, lr=8.38e-06]Steps:   8%|▊         | 420/5000 [1:36:29<15:16:57, 12.01s/it, loss=0.5971, lr=8.38e-06]Steps:   8%|▊         | 420/5000 [1:36:29<15:16:57, 12.01s/it, loss=0.6385, lr=8.40e-06]
[Step 420] Training Debug Info:
  Loss: 1.125110
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0031, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0019, std: 1.3672
  Model pred mean: -0.0070, std: 0.8555
  Sigmas: [0.134765625]... (timesteps: [135.0])

[Step 420] Training Debug Info:
  Loss: 1.130498
  Latent shape: torch.Size([1, 32, 150, 60]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0309, std: 0.8945
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0300, std: 1.3438
  Model pred mean: -0.0302, std: 0.8203
  Sigmas: [0.1162109375]... (timesteps: [116.0])

[Step 420] Training Debug Info:
  Loss: 0.803427
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0251, std: 0.9531
  Noise mean: -0.0038, std: 1.0000
  Target mean: -0.0289, std: 1.3750
  Model pred mean: -0.0278, std: 1.0547
  Sigmas: [0.423828125]... (timesteps: [423.0])

[Step 420] Training Debug Info:
  Loss: 1.015192
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0349, std: 0.9141
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0376, std: 1.3516
  Model pred mean: -0.0334, std: 0.9102
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:   8%|▊         | 421/5000 [1:36:41<15:13:30, 11.97s/it, loss=0.6385, lr=8.40e-06]Steps:   8%|▊         | 421/5000 [1:36:41<15:13:30, 11.97s/it, loss=1.0152, lr=8.42e-06]Steps:   8%|▊         | 422/5000 [1:36:53<15:16:33, 12.01s/it, loss=1.0152, lr=8.42e-06]Steps:   8%|▊         | 422/5000 [1:36:53<15:16:33, 12.01s/it, loss=1.0566, lr=8.44e-06]Steps:   8%|▊         | 423/5000 [1:37:05<15:15:13, 12.00s/it, loss=1.0566, lr=8.44e-06]Steps:   8%|▊         | 423/5000 [1:37:05<15:15:13, 12.00s/it, loss=1.0475, lr=8.46e-06]Steps:   8%|▊         | 424/5000 [1:37:17<15:15:29, 12.00s/it, loss=1.0475, lr=8.46e-06]Steps:   8%|▊         | 424/5000 [1:37:17<15:15:29, 12.00s/it, loss=1.0241, lr=8.48e-06]Steps:   8%|▊         | 425/5000 [1:37:29<15:13:14, 11.98s/it, loss=1.0241, lr=8.48e-06]Steps:   8%|▊         | 425/5000 [1:37:29<15:13:14, 11.98s/it, loss=1.0631, lr=8.50e-06]Steps:   9%|▊         | 426/5000 [1:37:41<15:11:31, 11.96s/it, loss=1.0631, lr=8.50e-06]Steps:   9%|▊         | 426/5000 [1:37:41<15:11:31, 11.96s/it, loss=0.9442, lr=8.52e-06]Steps:   9%|▊         | 427/5000 [1:37:53<15:13:21, 11.98s/it, loss=0.9442, lr=8.52e-06]Steps:   9%|▊         | 427/5000 [1:37:53<15:13:21, 11.98s/it, loss=1.1010, lr=8.54e-06]Steps:   9%|▊         | 428/5000 [1:38:05<15:14:57, 12.01s/it, loss=1.1010, lr=8.54e-06]Steps:   9%|▊         | 428/5000 [1:38:05<15:14:57, 12.01s/it, loss=1.0823, lr=8.56e-06]Steps:   9%|▊         | 429/5000 [1:38:17<15:11:17, 11.96s/it, loss=1.0823, lr=8.56e-06]Steps:   9%|▊         | 429/5000 [1:38:17<15:11:17, 11.96s/it, loss=0.5768, lr=8.58e-06]Steps:   9%|▊         | 430/5000 [1:38:29<15:08:26, 11.93s/it, loss=0.5768, lr=8.58e-06]Steps:   9%|▊         | 430/5000 [1:38:29<15:08:26, 11.93s/it, loss=1.1857, lr=8.60e-06]
[Step 430] Training Debug Info:
  Loss: 0.583425
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0002, std: 0.8828
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0022, std: 1.3359
  Model pred mean: -0.0104, std: 1.0938
  Sigmas: [0.9609375]... (timesteps: [959.0])

[Step 430] Training Debug Info:
  Loss: 0.455380
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0073, std: 0.8867
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0062, std: 1.3359
  Model pred mean: -0.0095, std: 1.1562
  Sigmas: [0.921875]... (timesteps: [923.0])

[Step 430] Training Debug Info:
  Loss: 0.399181
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0115, std: 0.9258
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0107, std: 1.3672
  Model pred mean: -0.0134, std: 1.2109
  Sigmas: [0.7578125]... (timesteps: [757.0])

[Step 430] Training Debug Info:
  Loss: 1.144644
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0122, std: 0.9023
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0136, std: 1.3438
  Model pred mean: 0.0116, std: 0.8203
  Sigmas: [0.1796875]... (timesteps: [180.0])
Steps:   9%|▊         | 431/5000 [1:38:41<15:07:11, 11.91s/it, loss=1.1857, lr=8.60e-06]Steps:   9%|▊         | 431/5000 [1:38:41<15:07:11, 11.91s/it, loss=1.1446, lr=8.62e-06]Steps:   9%|▊         | 432/5000 [1:38:53<15:04:36, 11.88s/it, loss=1.1446, lr=8.62e-06]Steps:   9%|▊         | 432/5000 [1:38:53<15:04:36, 11.88s/it, loss=0.4780, lr=8.64e-06]Steps:   9%|▊         | 433/5000 [1:39:05<15:08:50, 11.94s/it, loss=0.4780, lr=8.64e-06]Steps:   9%|▊         | 433/5000 [1:39:05<15:08:50, 11.94s/it, loss=0.5443, lr=8.66e-06]Steps:   9%|▊         | 434/5000 [1:39:17<15:07:18, 11.92s/it, loss=0.5443, lr=8.66e-06]Steps:   9%|▊         | 434/5000 [1:39:17<15:07:18, 11.92s/it, loss=0.4488, lr=8.68e-06]Steps:   9%|▊         | 435/5000 [1:39:29<15:11:32, 11.98s/it, loss=0.4488, lr=8.68e-06]Steps:   9%|▊         | 435/5000 [1:39:29<15:11:32, 11.98s/it, loss=1.1148, lr=8.70e-06]Steps:   9%|▊         | 436/5000 [1:39:41<15:13:03, 12.00s/it, loss=1.1148, lr=8.70e-06]Steps:   9%|▊         | 436/5000 [1:39:41<15:13:03, 12.00s/it, loss=1.1125, lr=8.72e-06]Steps:   9%|▊         | 437/5000 [1:39:53<15:10:17, 11.97s/it, loss=1.1125, lr=8.72e-06]Steps:   9%|▊         | 437/5000 [1:39:53<15:10:17, 11.97s/it, loss=0.8408, lr=8.74e-06]Steps:   9%|▉         | 438/5000 [1:40:05<15:07:41, 11.94s/it, loss=0.8408, lr=8.74e-06]Steps:   9%|▉         | 438/5000 [1:40:05<15:07:41, 11.94s/it, loss=1.0968, lr=8.76e-06]Steps:   9%|▉         | 439/5000 [1:40:16<15:04:28, 11.90s/it, loss=1.0968, lr=8.76e-06]Steps:   9%|▉         | 439/5000 [1:40:16<15:04:28, 11.90s/it, loss=0.4297, lr=8.78e-06]Steps:   9%|▉         | 440/5000 [1:40:28<15:03:08, 11.88s/it, loss=0.4297, lr=8.78e-06]Steps:   9%|▉         | 440/5000 [1:40:28<15:03:08, 11.88s/it, loss=0.3548, lr=8.80e-06]
[Step 440] Training Debug Info:
  Loss: 0.712118
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0195, std: 0.9414
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0193, std: 1.3750
  Model pred mean: 0.0107, std: 1.0703
  Sigmas: [0.99609375]... (timesteps: [996.0])

[Step 440] Training Debug Info:
  Loss: 0.639884
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0040, std: 0.8438
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0040, std: 1.3047
  Model pred mean: -0.0114, std: 1.0547
  Sigmas: [0.58984375]... (timesteps: [590.0])

[Step 440] Training Debug Info:
  Loss: 0.603338
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0259, std: 0.9023
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0284, std: 1.3438
  Model pred mean: -0.0025, std: 1.0938
  Sigmas: [0.953125]... (timesteps: [955.0])

[Step 440] Training Debug Info:
  Loss: 0.538148
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0082, std: 1.0078
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0087, std: 1.4219
  Model pred mean: -0.0047, std: 1.2188
  Sigmas: [0.66796875]... (timesteps: [668.0])
Steps:   9%|▉         | 441/5000 [1:40:40<15:04:03, 11.90s/it, loss=0.3548, lr=8.80e-06]Steps:   9%|▉         | 441/5000 [1:40:40<15:04:03, 11.90s/it, loss=0.5381, lr=8.82e-06]Steps:   9%|▉         | 442/5000 [1:40:52<15:09:45, 11.98s/it, loss=0.5381, lr=8.82e-06]Steps:   9%|▉         | 442/5000 [1:40:52<15:09:45, 11.98s/it, loss=1.1438, lr=8.84e-06]Steps:   9%|▉         | 443/5000 [1:41:04<15:06:05, 11.93s/it, loss=1.1438, lr=8.84e-06]Steps:   9%|▉         | 443/5000 [1:41:04<15:06:05, 11.93s/it, loss=0.6881, lr=8.86e-06]Steps:   9%|▉         | 444/5000 [1:41:16<15:04:09, 11.91s/it, loss=0.6881, lr=8.86e-06]Steps:   9%|▉         | 444/5000 [1:41:16<15:04:09, 11.91s/it, loss=0.4124, lr=8.88e-06]Steps:   9%|▉         | 445/5000 [1:41:28<15:07:29, 11.95s/it, loss=0.4124, lr=8.88e-06]Steps:   9%|▉         | 445/5000 [1:41:28<15:07:29, 11.95s/it, loss=0.5971, lr=8.90e-06]Steps:   9%|▉         | 446/5000 [1:41:40<15:05:18, 11.93s/it, loss=0.5971, lr=8.90e-06]Steps:   9%|▉         | 446/5000 [1:41:40<15:05:18, 11.93s/it, loss=0.6483, lr=8.92e-06]Steps:   9%|▉         | 447/5000 [1:41:52<15:05:16, 11.93s/it, loss=0.6483, lr=8.92e-06]Steps:   9%|▉         | 447/5000 [1:41:52<15:05:16, 11.93s/it, loss=0.4316, lr=8.94e-06]Steps:   9%|▉         | 448/5000 [1:42:04<15:04:06, 11.92s/it, loss=0.4316, lr=8.94e-06]Steps:   9%|▉         | 448/5000 [1:42:04<15:04:06, 11.92s/it, loss=1.0791, lr=8.96e-06]Steps:   9%|▉         | 449/5000 [1:42:16<15:08:28, 11.98s/it, loss=1.0791, lr=8.96e-06]Steps:   9%|▉         | 449/5000 [1:42:16<15:08:28, 11.98s/it, loss=0.3418, lr=8.98e-06]Steps:   9%|▉         | 450/5000 [1:42:28<15:05:58, 11.95s/it, loss=0.3418, lr=8.98e-06]Steps:   9%|▉         | 450/5000 [1:42:28<15:05:58, 11.95s/it, loss=0.3697, lr=9.00e-06]
[Step 450] Training Debug Info:
  Loss: 1.179401
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0518, std: 0.8828
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0491, std: 1.3359
  Model pred mean: 0.0474, std: 0.7852
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 450] Training Debug Info:
  Loss: 0.560429
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0009, std: 0.9297
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0034, std: 1.3672
  Model pred mean: -0.0006, std: 1.1562
  Sigmas: [0.5703125]... (timesteps: [570.0])

[Step 450] Training Debug Info:
  Loss: 0.632095
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: 0.0079, std: 0.9141
  Noise mean: 0.0023, std: 0.9961
  Target mean: -0.0056, std: 1.3516
  Model pred mean: -0.0052, std: 1.1094
  Sigmas: [0.5546875]... (timesteps: [553.0])

[Step 450] Training Debug Info:
  Loss: 0.547629
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0042, std: 0.8789
  Noise mean: 0.0029, std: 1.0000
  Target mean: -0.0013, std: 1.3281
  Model pred mean: -0.0029, std: 1.1094
  Sigmas: [0.6328125]... (timesteps: [631.0])
Steps:   9%|▉         | 451/5000 [1:42:40<15:06:59, 11.96s/it, loss=0.3697, lr=9.00e-06]Steps:   9%|▉         | 451/5000 [1:42:40<15:06:59, 11.96s/it, loss=0.5476, lr=9.02e-06]Steps:   9%|▉         | 452/5000 [1:42:52<15:06:35, 11.96s/it, loss=0.5476, lr=9.02e-06]Steps:   9%|▉         | 452/5000 [1:42:52<15:06:35, 11.96s/it, loss=0.3555, lr=9.04e-06]Steps:   9%|▉         | 453/5000 [1:43:04<15:04:59, 11.94s/it, loss=0.3555, lr=9.04e-06]Steps:   9%|▉         | 453/5000 [1:43:04<15:04:59, 11.94s/it, loss=1.1096, lr=9.06e-06]Steps:   9%|▉         | 454/5000 [1:43:16<15:03:52, 11.93s/it, loss=1.1096, lr=9.06e-06]Steps:   9%|▉         | 454/5000 [1:43:16<15:03:52, 11.93s/it, loss=0.4166, lr=9.08e-06]Steps:   9%|▉         | 455/5000 [1:43:28<15:07:36, 11.98s/it, loss=0.4166, lr=9.08e-06]Steps:   9%|▉         | 455/5000 [1:43:28<15:07:36, 11.98s/it, loss=1.0654, lr=9.10e-06]Steps:   9%|▉         | 456/5000 [1:43:40<15:05:09, 11.95s/it, loss=1.0654, lr=9.10e-06]Steps:   9%|▉         | 456/5000 [1:43:40<15:05:09, 11.95s/it, loss=0.5587, lr=9.12e-06]Steps:   9%|▉         | 457/5000 [1:43:51<15:04:39, 11.95s/it, loss=0.5587, lr=9.12e-06]Steps:   9%|▉         | 457/5000 [1:43:51<15:04:39, 11.95s/it, loss=1.0054, lr=9.14e-06]Steps:   9%|▉         | 458/5000 [1:44:03<15:03:32, 11.94s/it, loss=1.0054, lr=9.14e-06]Steps:   9%|▉         | 458/5000 [1:44:03<15:03:32, 11.94s/it, loss=0.4583, lr=9.16e-06]Steps:   9%|▉         | 459/5000 [1:44:15<15:03:11, 11.93s/it, loss=0.4583, lr=9.16e-06]Steps:   9%|▉         | 459/5000 [1:44:15<15:03:11, 11.93s/it, loss=0.8703, lr=9.18e-06]Steps:   9%|▉         | 460/5000 [1:44:27<15:04:43, 11.96s/it, loss=0.8703, lr=9.18e-06]Steps:   9%|▉         | 460/5000 [1:44:27<15:04:43, 11.96s/it, loss=1.1224, lr=9.20e-06]
[Step 460] Training Debug Info:
  Loss: 1.130444
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0141, std: 0.9023
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0134, std: 1.3438
  Model pred mean: -0.0121, std: 0.8203
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 460] Training Debug Info:
  Loss: 0.388848
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0183, std: 0.9258
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0209, std: 1.3594
  Model pred mean: 0.0154, std: 1.1953
  Sigmas: [0.74609375]... (timesteps: [746.0])

[Step 460] Training Debug Info:
  Loss: 0.585523
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0116, std: 0.8672
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0116, std: 1.3203
  Model pred mean: 0.0248, std: 1.0781
  Sigmas: [0.99609375]... (timesteps: [995.0])

[Step 460] Training Debug Info:
  Loss: 0.970008
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0117, std: 0.8203
  Noise mean: 0.0042, std: 1.0000
  Target mean: 0.0160, std: 1.2891
  Model pred mean: 0.0091, std: 0.8242
  Sigmas: [0.408203125]... (timesteps: [408.0])
Steps:   9%|▉         | 461/5000 [1:44:39<15:02:31, 11.93s/it, loss=1.1224, lr=9.20e-06]Steps:   9%|▉         | 461/5000 [1:44:39<15:02:31, 11.93s/it, loss=0.9700, lr=9.22e-06]Steps:   9%|▉         | 462/5000 [1:44:51<15:04:46, 11.96s/it, loss=0.9700, lr=9.22e-06]Steps:   9%|▉         | 462/5000 [1:44:51<15:04:46, 11.96s/it, loss=0.4097, lr=9.24e-06]Steps:   9%|▉         | 463/5000 [1:45:03<15:06:57, 11.99s/it, loss=0.4097, lr=9.24e-06]Steps:   9%|▉         | 463/5000 [1:45:03<15:06:57, 11.99s/it, loss=1.1238, lr=9.26e-06]Steps:   9%|▉         | 464/5000 [1:45:15<15:05:13, 11.97s/it, loss=1.1238, lr=9.26e-06]Steps:   9%|▉         | 464/5000 [1:45:15<15:05:13, 11.97s/it, loss=0.6931, lr=9.28e-06]Steps:   9%|▉         | 465/5000 [1:45:27<15:04:54, 11.97s/it, loss=0.6931, lr=9.28e-06]Steps:   9%|▉         | 465/5000 [1:45:27<15:04:54, 11.97s/it, loss=0.3913, lr=9.30e-06]Steps:   9%|▉         | 466/5000 [1:45:39<15:03:07, 11.95s/it, loss=0.3913, lr=9.30e-06]Steps:   9%|▉         | 466/5000 [1:45:39<15:03:07, 11.95s/it, loss=1.1030, lr=9.32e-06]Steps:   9%|▉         | 467/5000 [1:45:51<15:02:58, 11.95s/it, loss=1.1030, lr=9.32e-06]Steps:   9%|▉         | 467/5000 [1:45:51<15:02:58, 11.95s/it, loss=1.0893, lr=9.34e-06]Steps:   9%|▉         | 468/5000 [1:46:03<15:02:02, 11.94s/it, loss=1.0893, lr=9.34e-06]Steps:   9%|▉         | 468/5000 [1:46:03<15:02:02, 11.94s/it, loss=0.7155, lr=9.36e-06]Steps:   9%|▉         | 469/5000 [1:46:15<15:06:49, 12.01s/it, loss=0.7155, lr=9.36e-06]Steps:   9%|▉         | 469/5000 [1:46:15<15:06:49, 12.01s/it, loss=0.9995, lr=9.38e-06]Steps:   9%|▉         | 470/5000 [1:46:27<15:04:40, 11.98s/it, loss=0.9995, lr=9.38e-06]Steps:   9%|▉         | 470/5000 [1:46:27<15:04:40, 11.98s/it, loss=0.3900, lr=9.40e-06]
[Step 470] Training Debug Info:
  Loss: 1.139276
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0079, std: 0.9258
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0082, std: 1.3594
  Model pred mean: -0.0095, std: 0.8398
  Sigmas: [0.130859375]... (timesteps: [131.0])

[Step 470] Training Debug Info:
  Loss: 0.996755
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0471, std: 0.9258
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0449, std: 1.3594
  Model pred mean: -0.0454, std: 0.9141
  Sigmas: [0.2578125]... (timesteps: [257.0])

[Step 470] Training Debug Info:
  Loss: 1.171274
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0018, std: 0.8906
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0046, std: 1.3359
  Model pred mean: -0.0008, std: 0.7891
  Sigmas: [0.2373046875]... (timesteps: [237.0])

[Step 470] Training Debug Info:
  Loss: 0.522355
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0022, std: 0.9180
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0041, std: 1.3594
  Model pred mean: 0.0006, std: 1.1328
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   9%|▉         | 471/5000 [1:46:39<15:02:35, 11.96s/it, loss=0.3900, lr=9.40e-06]Steps:   9%|▉         | 471/5000 [1:46:39<15:02:35, 11.96s/it, loss=0.5224, lr=9.42e-06]Steps:   9%|▉         | 472/5000 [1:46:51<15:05:24, 12.00s/it, loss=0.5224, lr=9.42e-06]Steps:   9%|▉         | 472/5000 [1:46:51<15:05:24, 12.00s/it, loss=0.4057, lr=9.44e-06]Steps:   9%|▉         | 473/5000 [1:47:03<15:03:12, 11.97s/it, loss=0.4057, lr=9.44e-06]Steps:   9%|▉         | 473/5000 [1:47:03<15:03:12, 11.97s/it, loss=0.6797, lr=9.46e-06]Steps:   9%|▉         | 474/5000 [1:47:15<14:59:15, 11.92s/it, loss=0.6797, lr=9.46e-06]Steps:   9%|▉         | 474/5000 [1:47:15<14:59:15, 11.92s/it, loss=0.5143, lr=9.48e-06]Steps:  10%|▉         | 475/5000 [1:47:27<14:58:10, 11.91s/it, loss=0.5143, lr=9.48e-06]Steps:  10%|▉         | 475/5000 [1:47:27<14:58:10, 11.91s/it, loss=0.4023, lr=9.50e-06]Steps:  10%|▉         | 476/5000 [1:47:39<14:59:51, 11.93s/it, loss=0.4023, lr=9.50e-06]Steps:  10%|▉         | 476/5000 [1:47:39<14:59:51, 11.93s/it, loss=1.1706, lr=9.52e-06]Steps:  10%|▉         | 477/5000 [1:47:51<15:00:11, 11.94s/it, loss=1.1706, lr=9.52e-06]Steps:  10%|▉         | 477/5000 [1:47:51<15:00:11, 11.94s/it, loss=0.7827, lr=9.54e-06]Steps:  10%|▉         | 478/5000 [1:48:03<15:02:10, 11.97s/it, loss=0.7827, lr=9.54e-06]Steps:  10%|▉         | 478/5000 [1:48:03<15:02:10, 11.97s/it, loss=0.6397, lr=9.56e-06]Steps:  10%|▉         | 479/5000 [1:48:14<14:59:46, 11.94s/it, loss=0.6397, lr=9.56e-06]Steps:  10%|▉         | 479/5000 [1:48:14<14:59:46, 11.94s/it, loss=0.6031, lr=9.58e-06]Steps:  10%|▉         | 480/5000 [1:48:26<14:58:59, 11.93s/it, loss=0.6031, lr=9.58e-06]Steps:  10%|▉         | 480/5000 [1:48:26<14:58:59, 11.93s/it, loss=0.5067, lr=9.60e-06]
[Step 480] Training Debug Info:
  Loss: 0.530214
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0140, std: 0.9883
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0120, std: 1.4062
  Model pred mean: -0.0156, std: 1.1953
  Sigmas: [0.59375]... (timesteps: [594.0])

[Step 480] Training Debug Info:
  Loss: 0.564513
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0094, std: 0.8828
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0085, std: 1.3359
  Model pred mean: -0.0091, std: 1.1016
  Sigmas: [0.62890625]... (timesteps: [628.0])

[Step 480] Training Debug Info:
  Loss: 1.174832
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0122, std: 0.9219
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0119, std: 1.3594
  Model pred mean: 0.0134, std: 0.8281
  Sigmas: [0.19140625]... (timesteps: [191.0])

[Step 480] Training Debug Info:
  Loss: 0.696201
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0109, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0112, std: 1.3438
  Model pred mean: -0.0104, std: 1.0547
  Sigmas: [0.52734375]... (timesteps: [529.0])
Steps:  10%|▉         | 481/5000 [1:48:39<15:02:55, 11.99s/it, loss=0.5067, lr=9.60e-06]Steps:  10%|▉         | 481/5000 [1:48:39<15:02:55, 11.99s/it, loss=0.6962, lr=9.62e-06]Steps:  10%|▉         | 482/5000 [1:48:51<15:02:26, 11.98s/it, loss=0.6962, lr=9.62e-06]Steps:  10%|▉         | 482/5000 [1:48:51<15:02:26, 11.98s/it, loss=1.0799, lr=9.64e-06]Steps:  10%|▉         | 483/5000 [1:49:02<15:00:46, 11.97s/it, loss=1.0799, lr=9.64e-06]Steps:  10%|▉         | 483/5000 [1:49:02<15:00:46, 11.97s/it, loss=1.1423, lr=9.66e-06]Steps:  10%|▉         | 484/5000 [1:49:14<14:59:54, 11.96s/it, loss=1.1423, lr=9.66e-06]Steps:  10%|▉         | 484/5000 [1:49:14<14:59:54, 11.96s/it, loss=0.7723, lr=9.68e-06]Steps:  10%|▉         | 485/5000 [1:49:26<14:57:41, 11.93s/it, loss=0.7723, lr=9.68e-06]Steps:  10%|▉         | 485/5000 [1:49:26<14:57:41, 11.93s/it, loss=0.4145, lr=9.70e-06]Steps:  10%|▉         | 486/5000 [1:49:38<14:57:46, 11.93s/it, loss=0.4145, lr=9.70e-06]Steps:  10%|▉         | 486/5000 [1:49:38<14:57:46, 11.93s/it, loss=1.1241, lr=9.72e-06]Steps:  10%|▉         | 487/5000 [1:49:50<15:01:08, 11.98s/it, loss=1.1241, lr=9.72e-06]Steps:  10%|▉         | 487/5000 [1:49:50<15:01:08, 11.98s/it, loss=0.4153, lr=9.74e-06]Steps:  10%|▉         | 488/5000 [1:50:02<14:58:57, 11.95s/it, loss=0.4153, lr=9.74e-06]Steps:  10%|▉         | 488/5000 [1:50:02<14:58:57, 11.95s/it, loss=0.5170, lr=9.76e-06]Steps:  10%|▉         | 489/5000 [1:50:14<15:00:45, 11.98s/it, loss=0.5170, lr=9.76e-06]Steps:  10%|▉         | 489/5000 [1:50:14<15:00:45, 11.98s/it, loss=0.7262, lr=9.78e-06]Steps:  10%|▉         | 490/5000 [1:50:26<15:02:43, 12.01s/it, loss=0.7262, lr=9.78e-06]Steps:  10%|▉         | 490/5000 [1:50:26<15:02:43, 12.01s/it, loss=0.8549, lr=9.80e-06]
[Step 490] Training Debug Info:
  Loss: 0.551623
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0106, std: 0.8438
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0104, std: 1.3125
  Model pred mean: 0.0087, std: 1.0703
  Sigmas: [0.6484375]... (timesteps: [647.0])

[Step 490] Training Debug Info:
  Loss: 0.602877
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0278, std: 0.9219
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0264, std: 1.3594
  Model pred mean: -0.0299, std: 1.1094
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 490] Training Debug Info:
  Loss: 0.447639
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0136, std: 0.9102
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0150, std: 1.3516
  Model pred mean: -0.0150, std: 1.1719
  Sigmas: [0.7109375]... (timesteps: [711.0])

[Step 490] Training Debug Info:
  Loss: 0.437040
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0325, std: 0.8906
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0317, std: 1.3438
  Model pred mean: -0.0258, std: 1.1719
  Sigmas: [0.83984375]... (timesteps: [838.0])
Steps:  10%|▉         | 491/5000 [1:50:38<15:00:55, 11.99s/it, loss=0.8549, lr=9.80e-06]Steps:  10%|▉         | 491/5000 [1:50:38<15:00:55, 11.99s/it, loss=0.4370, lr=9.82e-06]Steps:  10%|▉         | 492/5000 [1:50:50<14:57:02, 11.94s/it, loss=0.4370, lr=9.82e-06]Steps:  10%|▉         | 492/5000 [1:50:50<14:57:02, 11.94s/it, loss=0.9124, lr=9.84e-06]Steps:  10%|▉         | 493/5000 [1:51:02<14:54:25, 11.91s/it, loss=0.9124, lr=9.84e-06]Steps:  10%|▉         | 493/5000 [1:51:02<14:54:25, 11.91s/it, loss=0.3708, lr=9.86e-06]Steps:  10%|▉         | 494/5000 [1:51:14<14:53:52, 11.90s/it, loss=0.3708, lr=9.86e-06]Steps:  10%|▉         | 494/5000 [1:51:14<14:53:52, 11.90s/it, loss=0.6239, lr=9.88e-06]Steps:  10%|▉         | 495/5000 [1:51:26<14:52:22, 11.89s/it, loss=0.6239, lr=9.88e-06]Steps:  10%|▉         | 495/5000 [1:51:26<14:52:22, 11.89s/it, loss=0.8353, lr=9.90e-06]Steps:  10%|▉         | 496/5000 [1:51:38<14:59:03, 11.98s/it, loss=0.8353, lr=9.90e-06]Steps:  10%|▉         | 496/5000 [1:51:38<14:59:03, 11.98s/it, loss=0.5262, lr=9.92e-06]Steps:  10%|▉         | 497/5000 [1:51:50<14:56:57, 11.95s/it, loss=0.5262, lr=9.92e-06]Steps:  10%|▉         | 497/5000 [1:51:50<14:56:57, 11.95s/it, loss=0.8408, lr=9.94e-06]Steps:  10%|▉         | 498/5000 [1:52:02<14:54:21, 11.92s/it, loss=0.8408, lr=9.94e-06]Steps:  10%|▉         | 498/5000 [1:52:02<14:54:21, 11.92s/it, loss=0.4512, lr=9.96e-06]Steps:  10%|▉         | 499/5000 [1:52:14<14:56:05, 11.95s/it, loss=0.4512, lr=9.96e-06]Steps:  10%|▉         | 499/5000 [1:52:14<14:56:05, 11.95s/it, loss=1.1784, lr=9.98e-06]Steps:  10%|█         | 500/5000 [1:52:25<14:53:43, 11.92s/it, loss=1.1784, lr=9.98e-06]Steps:  10%|█         | 500/5000 [1:52:25<14:53:43, 11.92s/it, loss=0.3898, lr=1.00e-05]01/22/2026 09:38:12 - INFO - __main__ - 
[Step 500] ✅ Loss in normal range (0.3898)
01/22/2026 09:38:12 - INFO - __main__ -   Loss avg (last 100): 0.7421
01/22/2026 09:38:12 - INFO - __main__ -   Loss range: [0.3418, 1.1857]

[Step 500] Training Debug Info:
  Loss: 1.140533
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0011, std: 0.8711
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0008, std: 1.3281
  Model pred mean: -0.0049, std: 0.7930
  Sigmas: [0.2734375]... (timesteps: [274.0])

[Step 500] Training Debug Info:
  Loss: 0.407032
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0151, std: 0.9414
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0182, std: 1.3672
  Model pred mean: -0.0198, std: 1.2266
  Sigmas: [0.7109375]... (timesteps: [709.0])

[Step 500] Training Debug Info:
  Loss: 0.619984
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0122, std: 0.9336
  Noise mean: -0.0013, std: 0.9961
  Target mean: 0.0109, std: 1.3672
  Model pred mean: 0.0107, std: 1.1250
  Sigmas: [0.52734375]... (timesteps: [526.0])

[Step 500] Training Debug Info:
  Loss: 0.341787
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0026, std: 0.9180
  Noise mean: 0.0006, std: 0.9961
  Target mean: 0.0032, std: 1.3516
  Model pred mean: 0.0005, std: 1.2266
  Sigmas: [0.8515625]... (timesteps: [852.0])
Steps:  10%|█         | 501/5000 [1:52:37<14:52:49, 11.91s/it, loss=0.3898, lr=1.00e-05]Steps:  10%|█         | 501/5000 [1:52:37<14:52:49, 11.91s/it, loss=0.3418, lr=1.00e-05]Steps:  10%|█         | 502/5000 [1:52:49<14:52:04, 11.90s/it, loss=0.3418, lr=1.00e-05]Steps:  10%|█         | 502/5000 [1:52:49<14:52:04, 11.90s/it, loss=0.4954, lr=1.00e-05]Steps:  10%|█         | 503/5000 [1:53:01<14:54:48, 11.94s/it, loss=0.4954, lr=1.00e-05]Steps:  10%|█         | 503/5000 [1:53:01<14:54:48, 11.94s/it, loss=0.3457, lr=1.00e-05]Steps:  10%|█         | 504/5000 [1:53:13<14:53:34, 11.93s/it, loss=0.3457, lr=1.00e-05]Steps:  10%|█         | 504/5000 [1:53:13<14:53:34, 11.93s/it, loss=0.4062, lr=1.00e-05]Steps:  10%|█         | 505/5000 [1:53:25<14:56:19, 11.96s/it, loss=0.4062, lr=1.00e-05]Steps:  10%|█         | 505/5000 [1:53:25<14:56:19, 11.96s/it, loss=0.6357, lr=1.00e-05]Steps:  10%|█         | 506/5000 [1:53:37<14:55:52, 11.96s/it, loss=0.6357, lr=1.00e-05]Steps:  10%|█         | 506/5000 [1:53:37<14:55:52, 11.96s/it, loss=0.7181, lr=1.00e-05]Steps:  10%|█         | 507/5000 [1:53:49<14:55:26, 11.96s/it, loss=0.7181, lr=1.00e-05]Steps:  10%|█         | 507/5000 [1:53:49<14:55:26, 11.96s/it, loss=0.8629, lr=1.00e-05]Steps:  10%|█         | 508/5000 [1:54:01<14:58:00, 11.99s/it, loss=0.8629, lr=1.00e-05]Steps:  10%|█         | 508/5000 [1:54:01<14:58:00, 11.99s/it, loss=0.4529, lr=1.00e-05]Steps:  10%|█         | 509/5000 [1:54:13<14:58:29, 12.00s/it, loss=0.4529, lr=1.00e-05]Steps:  10%|█         | 509/5000 [1:54:13<14:58:29, 12.00s/it, loss=0.5625, lr=1.00e-05]Steps:  10%|█         | 510/5000 [1:54:25<14:56:05, 11.97s/it, loss=0.5625, lr=1.00e-05]Steps:  10%|█         | 510/5000 [1:54:25<14:56:05, 11.97s/it, loss=0.3824, lr=1.00e-05]
[Step 510] Training Debug Info:
  Loss: 0.404185
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0016, std: 0.9570
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0025, std: 1.3828
  Model pred mean: 0.0007, std: 1.2188
  Sigmas: [0.87890625]... (timesteps: [879.0])

[Step 510] Training Debug Info:
  Loss: 0.489748
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0007, std: 0.9258
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0016, std: 1.3594
  Model pred mean: 0.0043, std: 1.1641
  Sigmas: [0.6953125]... (timesteps: [695.0])

[Step 510] Training Debug Info:
  Loss: 0.987052
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0010, std: 0.9023
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0016, std: 1.3438
  Model pred mean: 0.0030, std: 0.8906
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 510] Training Debug Info:
  Loss: 0.739848
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0006, std: 0.8984
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0025, std: 1.3438
  Model pred mean: -0.0018, std: 1.0078
  Sigmas: [0.48828125]... (timesteps: [488.0])
Steps:  10%|█         | 511/5000 [1:54:37<14:54:46, 11.96s/it, loss=0.3824, lr=1.00e-05]Steps:  10%|█         | 511/5000 [1:54:37<14:54:46, 11.96s/it, loss=0.7398, lr=1.00e-05]Steps:  10%|█         | 512/5000 [1:54:49<14:54:14, 11.96s/it, loss=0.7398, lr=1.00e-05]Steps:  10%|█         | 512/5000 [1:54:49<14:54:14, 11.96s/it, loss=0.9229, lr=1.00e-05]Steps:  10%|█         | 513/5000 [1:55:01<14:52:49, 11.94s/it, loss=0.9229, lr=1.00e-05]Steps:  10%|█         | 513/5000 [1:55:01<14:52:49, 11.94s/it, loss=0.5174, lr=1.00e-05]Steps:  10%|█         | 514/5000 [1:55:13<14:54:41, 11.97s/it, loss=0.5174, lr=1.00e-05]Steps:  10%|█         | 514/5000 [1:55:13<14:54:41, 11.97s/it, loss=1.1211, lr=1.00e-05]Steps:  10%|█         | 515/5000 [1:55:25<14:53:15, 11.95s/it, loss=1.1211, lr=1.00e-05]Steps:  10%|█         | 515/5000 [1:55:25<14:53:15, 11.95s/it, loss=0.5735, lr=1.00e-05]Steps:  10%|█         | 516/5000 [1:55:37<14:54:47, 11.97s/it, loss=0.5735, lr=1.00e-05]Steps:  10%|█         | 516/5000 [1:55:37<14:54:47, 11.97s/it, loss=0.7977, lr=1.00e-05]Steps:  10%|█         | 517/5000 [1:55:49<14:56:54, 12.00s/it, loss=0.7977, lr=1.00e-05]Steps:  10%|█         | 517/5000 [1:55:49<14:56:54, 12.00s/it, loss=0.8028, lr=1.00e-05]Steps:  10%|█         | 518/5000 [1:56:01<14:56:02, 12.00s/it, loss=0.8028, lr=1.00e-05]Steps:  10%|█         | 518/5000 [1:56:01<14:56:02, 12.00s/it, loss=1.1178, lr=1.00e-05]Steps:  10%|█         | 519/5000 [1:56:13<14:52:02, 11.94s/it, loss=1.1178, lr=1.00e-05]Steps:  10%|█         | 519/5000 [1:56:13<14:52:02, 11.94s/it, loss=0.7914, lr=1.00e-05]Steps:  10%|█         | 520/5000 [1:56:25<14:51:22, 11.94s/it, loss=0.7914, lr=1.00e-05]Steps:  10%|█         | 520/5000 [1:56:25<14:51:22, 11.94s/it, loss=1.1774, lr=1.00e-05]
[Step 520] Training Debug Info:
  Loss: 0.612757
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0067, std: 0.9023
  Noise mean: -0.0032, std: 1.0000
  Target mean: -0.0099, std: 1.3438
  Model pred mean: -0.0074, std: 1.0781
  Sigmas: [0.57421875]... (timesteps: [575.0])

[Step 520] Training Debug Info:
  Loss: 0.485494
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0126, std: 0.9727
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0131, std: 1.3906
  Model pred mean: -0.0137, std: 1.2109
  Sigmas: [0.6171875]... (timesteps: [617.0])

[Step 520] Training Debug Info:
  Loss: 0.693031
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0566, std: 0.9336
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0554, std: 1.3672
  Model pred mean: -0.0559, std: 1.0781
  Sigmas: [0.400390625]... (timesteps: [400.0])

[Step 520] Training Debug Info:
  Loss: 1.137018
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0041, std: 0.9219
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0052, std: 1.3594
  Model pred mean: -0.0030, std: 0.8359
  Sigmas: [0.10888671875]... (timesteps: [109.0])
Steps:  10%|█         | 521/5000 [1:56:36<14:49:14, 11.91s/it, loss=1.1774, lr=1.00e-05]Steps:  10%|█         | 521/5000 [1:56:36<14:49:14, 11.91s/it, loss=1.1370, lr=1.00e-05]Steps:  10%|█         | 522/5000 [1:56:48<14:49:14, 11.91s/it, loss=1.1370, lr=1.00e-05]Steps:  10%|█         | 522/5000 [1:56:48<14:49:14, 11.91s/it, loss=0.4676, lr=1.00e-05]Steps:  10%|█         | 523/5000 [1:57:01<14:58:06, 12.04s/it, loss=0.4676, lr=1.00e-05]Steps:  10%|█         | 523/5000 [1:57:01<14:58:06, 12.04s/it, loss=1.1539, lr=1.00e-05]Steps:  10%|█         | 524/5000 [1:57:13<14:56:24, 12.02s/it, loss=1.1539, lr=1.00e-05]Steps:  10%|█         | 524/5000 [1:57:13<14:56:24, 12.02s/it, loss=0.8010, lr=1.00e-05]Steps:  10%|█         | 525/5000 [1:57:25<14:55:08, 12.00s/it, loss=0.8010, lr=1.00e-05]Steps:  10%|█         | 525/5000 [1:57:25<14:55:08, 12.00s/it, loss=0.6428, lr=1.00e-05]Steps:  11%|█         | 526/5000 [1:57:37<14:56:55, 12.03s/it, loss=0.6428, lr=1.00e-05]Steps:  11%|█         | 526/5000 [1:57:37<14:56:55, 12.03s/it, loss=1.0849, lr=1.00e-05]Steps:  11%|█         | 527/5000 [1:57:49<14:54:26, 12.00s/it, loss=1.0849, lr=1.00e-05]Steps:  11%|█         | 527/5000 [1:57:49<14:54:26, 12.00s/it, loss=0.5843, lr=1.00e-05]Steps:  11%|█         | 528/5000 [1:58:01<14:52:13, 11.97s/it, loss=0.5843, lr=1.00e-05]Steps:  11%|█         | 528/5000 [1:58:01<14:52:13, 11.97s/it, loss=1.0130, lr=1.00e-05]Steps:  11%|█         | 529/5000 [1:58:12<14:49:47, 11.94s/it, loss=1.0130, lr=1.00e-05]Steps:  11%|█         | 529/5000 [1:58:12<14:49:47, 11.94s/it, loss=1.1469, lr=1.00e-05]Steps:  11%|█         | 530/5000 [1:58:25<14:53:03, 11.99s/it, loss=1.1469, lr=1.00e-05]Steps:  11%|█         | 530/5000 [1:58:25<14:53:03, 11.99s/it, loss=0.8819, lr=1.00e-05]
[Step 530] Training Debug Info:
  Loss: 1.080769
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 0.9492
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0361, std: 1.3750
  Model pred mean: -0.0356, std: 0.9023
  Sigmas: [0.0751953125]... (timesteps: [75.0])

[Step 530] Training Debug Info:
  Loss: 1.072528
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0009, std: 0.8477
  Noise mean: 0.0027, std: 0.9961
  Target mean: 0.0036, std: 1.3047
  Model pred mean: 0.0060, std: 0.7852
  Sigmas: [0.0390625]... (timesteps: [39.0])

[Step 530] Training Debug Info:
  Loss: 1.060256
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0001, std: 0.9062
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0033, std: 1.3516
  Model pred mean: 0.0036, std: 0.8750
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 530] Training Debug Info:
  Loss: 0.748145
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0306, std: 0.8242
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0306, std: 1.2969
  Model pred mean: 0.0339, std: 0.9727
  Sigmas: [0.5234375]... (timesteps: [525.0])
Steps:  11%|█         | 531/5000 [1:58:36<14:49:21, 11.94s/it, loss=0.8819, lr=1.00e-05]Steps:  11%|█         | 531/5000 [1:58:36<14:49:21, 11.94s/it, loss=0.7481, lr=1.00e-05]Steps:  11%|█         | 532/5000 [1:58:48<14:50:49, 11.96s/it, loss=0.7481, lr=1.00e-05]Steps:  11%|█         | 532/5000 [1:58:48<14:50:49, 11.96s/it, loss=1.1726, lr=1.00e-05]Steps:  11%|█         | 533/5000 [1:59:00<14:48:48, 11.94s/it, loss=1.1726, lr=1.00e-05]Steps:  11%|█         | 533/5000 [1:59:00<14:48:48, 11.94s/it, loss=1.1069, lr=1.00e-05]Steps:  11%|█         | 534/5000 [1:59:12<14:47:39, 11.93s/it, loss=1.1069, lr=1.00e-05]Steps:  11%|█         | 534/5000 [1:59:12<14:47:39, 11.93s/it, loss=0.9160, lr=1.00e-05]Steps:  11%|█         | 535/5000 [1:59:24<14:49:16, 11.95s/it, loss=0.9160, lr=1.00e-05]Steps:  11%|█         | 535/5000 [1:59:24<14:49:16, 11.95s/it, loss=0.5163, lr=1.00e-05]Steps:  11%|█         | 536/5000 [1:59:36<14:50:38, 11.97s/it, loss=0.5163, lr=1.00e-05]Steps:  11%|█         | 536/5000 [1:59:36<14:50:38, 11.97s/it, loss=1.0426, lr=1.00e-05]Steps:  11%|█         | 537/5000 [1:59:48<14:47:28, 11.93s/it, loss=1.0426, lr=1.00e-05]Steps:  11%|█         | 537/5000 [1:59:48<14:47:28, 11.93s/it, loss=0.6600, lr=1.00e-05]Steps:  11%|█         | 538/5000 [2:00:00<14:46:56, 11.93s/it, loss=0.6600, lr=1.00e-05]Steps:  11%|█         | 538/5000 [2:00:00<14:46:56, 11.93s/it, loss=0.4363, lr=1.00e-05]Steps:  11%|█         | 539/5000 [2:00:12<14:46:00, 11.92s/it, loss=0.4363, lr=1.00e-05]Steps:  11%|█         | 539/5000 [2:00:12<14:46:00, 11.92s/it, loss=1.1362, lr=1.00e-05]Steps:  11%|█         | 540/5000 [2:00:24<14:46:42, 11.93s/it, loss=1.1362, lr=1.00e-05]Steps:  11%|█         | 540/5000 [2:00:24<14:46:42, 11.93s/it, loss=0.4682, lr=1.00e-05]
[Step 540] Training Debug Info:
  Loss: 1.092956
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0165, std: 0.9180
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0167, std: 1.3594
  Model pred mean: -0.0156, std: 0.8633
  Sigmas: [0.11083984375]... (timesteps: [111.0])

[Step 540] Training Debug Info:
  Loss: 1.068168
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0273, std: 0.9688
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0276, std: 1.3984
  Model pred mean: 0.0247, std: 0.9336
  Sigmas: [0.330078125]... (timesteps: [331.0])

[Step 540] Training Debug Info:
  Loss: 1.087388
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0581, std: 0.9414
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0579, std: 1.3750
  Model pred mean: -0.0574, std: 0.8945
  Sigmas: [0.10009765625]... (timesteps: [100.0])

[Step 540] Training Debug Info:
  Loss: 0.652391
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.9141
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0000, std: 1.3594
  Model pred mean: -0.0010, std: 1.0859
  Sigmas: [0.5234375]... (timesteps: [524.0])
Steps:  11%|█         | 541/5000 [2:00:36<14:49:09, 11.96s/it, loss=0.4682, lr=1.00e-05]Steps:  11%|█         | 541/5000 [2:00:36<14:49:09, 11.96s/it, loss=0.6524, lr=1.00e-05]Steps:  11%|█         | 542/5000 [2:00:48<14:48:14, 11.95s/it, loss=0.6524, lr=1.00e-05]Steps:  11%|█         | 542/5000 [2:00:48<14:48:14, 11.95s/it, loss=1.1773, lr=1.00e-05]Steps:  11%|█         | 543/5000 [2:01:00<14:50:30, 11.99s/it, loss=1.1773, lr=1.00e-05]Steps:  11%|█         | 543/5000 [2:01:00<14:50:30, 11.99s/it, loss=0.3908, lr=1.00e-05]Steps:  11%|█         | 544/5000 [2:01:12<14:51:02, 12.00s/it, loss=0.3908, lr=1.00e-05]Steps:  11%|█         | 544/5000 [2:01:12<14:51:02, 12.00s/it, loss=1.0531, lr=1.00e-05]Steps:  11%|█         | 545/5000 [2:01:24<14:50:31, 11.99s/it, loss=1.0531, lr=1.00e-05]Steps:  11%|█         | 545/5000 [2:01:24<14:50:31, 11.99s/it, loss=0.6864, lr=1.00e-05]Steps:  11%|█         | 546/5000 [2:01:36<14:48:44, 11.97s/it, loss=0.6864, lr=1.00e-05]Steps:  11%|█         | 546/5000 [2:01:36<14:48:44, 11.97s/it, loss=0.9651, lr=1.00e-05]Steps:  11%|█         | 547/5000 [2:01:48<14:48:05, 11.97s/it, loss=0.9651, lr=1.00e-05]Steps:  11%|█         | 547/5000 [2:01:48<14:48:05, 11.97s/it, loss=0.7081, lr=1.00e-05]Steps:  11%|█         | 548/5000 [2:02:00<14:46:09, 11.94s/it, loss=0.7081, lr=1.00e-05]Steps:  11%|█         | 548/5000 [2:02:00<14:46:09, 11.94s/it, loss=0.5496, lr=1.00e-05]Steps:  11%|█         | 549/5000 [2:02:12<14:47:40, 11.97s/it, loss=0.5496, lr=1.00e-05]Steps:  11%|█         | 549/5000 [2:02:12<14:47:40, 11.97s/it, loss=0.6444, lr=1.00e-05]Steps:  11%|█         | 550/5000 [2:02:24<14:54:34, 12.06s/it, loss=0.6444, lr=1.00e-05]Steps:  11%|█         | 550/5000 [2:02:24<14:54:34, 12.06s/it, loss=0.4080, lr=1.00e-05]
[Step 550] Training Debug Info:
  Loss: 0.365417
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0262, std: 0.9102
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0281, std: 1.3516
  Model pred mean: 0.0265, std: 1.2109
  Sigmas: [0.91015625]... (timesteps: [910.0])

[Step 550] Training Debug Info:
  Loss: 0.533061
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0025, std: 0.9453
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0042, std: 1.3750
  Model pred mean: 0.0025, std: 1.1641
  Sigmas: [0.62109375]... (timesteps: [622.0])

[Step 550] Training Debug Info:
  Loss: 0.353133
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0762, std: 0.9336
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0757, std: 1.3672
  Model pred mean: -0.0762, std: 1.2344
  Sigmas: [0.75]... (timesteps: [751.0])

[Step 550] Training Debug Info:
  Loss: 1.054652
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0199, std: 0.8867
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0203, std: 1.3359
  Model pred mean: -0.0167, std: 0.8516
  Sigmas: [0.326171875]... (timesteps: [326.0])
Steps:  11%|█         | 551/5000 [2:02:36<14:52:26, 12.04s/it, loss=0.4080, lr=1.00e-05]Steps:  11%|█         | 551/5000 [2:02:36<14:52:26, 12.04s/it, loss=1.0547, lr=1.00e-05]Steps:  11%|█         | 552/5000 [2:02:48<14:49:30, 12.00s/it, loss=1.0547, lr=1.00e-05]Steps:  11%|█         | 552/5000 [2:02:48<14:49:30, 12.00s/it, loss=0.5380, lr=1.00e-05]Steps:  11%|█         | 553/5000 [2:03:00<14:49:46, 12.00s/it, loss=0.5380, lr=1.00e-05]Steps:  11%|█         | 553/5000 [2:03:00<14:49:46, 12.00s/it, loss=1.1081, lr=1.00e-05]Steps:  11%|█         | 554/5000 [2:03:12<14:47:38, 11.98s/it, loss=1.1081, lr=1.00e-05]Steps:  11%|█         | 554/5000 [2:03:12<14:47:38, 11.98s/it, loss=0.5941, lr=1.00e-05]Steps:  11%|█         | 555/5000 [2:03:24<14:45:31, 11.95s/it, loss=0.5941, lr=1.00e-05]Steps:  11%|█         | 555/5000 [2:03:24<14:45:31, 11.95s/it, loss=0.9915, lr=1.00e-05]Steps:  11%|█         | 556/5000 [2:03:36<14:44:40, 11.94s/it, loss=0.9915, lr=1.00e-05]Steps:  11%|█         | 556/5000 [2:03:36<14:44:40, 11.94s/it, loss=0.5930, lr=1.00e-05]Steps:  11%|█         | 557/5000 [2:03:48<14:46:09, 11.97s/it, loss=0.5930, lr=1.00e-05]Steps:  11%|█         | 557/5000 [2:03:48<14:46:09, 11.97s/it, loss=0.4721, lr=1.00e-05]Steps:  11%|█         | 558/5000 [2:03:59<14:44:22, 11.95s/it, loss=0.4721, lr=1.00e-05]Steps:  11%|█         | 558/5000 [2:03:59<14:44:22, 11.95s/it, loss=0.4482, lr=1.00e-05]Steps:  11%|█         | 559/5000 [2:04:11<14:46:02, 11.97s/it, loss=0.4482, lr=1.00e-05]Steps:  11%|█         | 559/5000 [2:04:11<14:46:02, 11.97s/it, loss=1.1429, lr=1.00e-05]Steps:  11%|█         | 560/5000 [2:04:23<14:45:04, 11.96s/it, loss=1.1429, lr=1.00e-05]Steps:  11%|█         | 560/5000 [2:04:23<14:45:04, 11.96s/it, loss=0.5101, lr=1.00e-05]
[Step 560] Training Debug Info:
  Loss: 1.033029
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0091, std: 0.8750
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0096, std: 1.3281
  Model pred mean: -0.0130, std: 0.8438
  Sigmas: [0.353515625]... (timesteps: [354.0])

[Step 560] Training Debug Info:
  Loss: 0.353696
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0120, std: 0.9414
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0122, std: 1.3750
  Model pred mean: -0.0177, std: 1.2422
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 560] Training Debug Info:
  Loss: 0.961059
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0069, std: 0.9570
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0071, std: 1.3828
  Model pred mean: -0.0107, std: 0.9883
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 560] Training Debug Info:
  Loss: 0.489768
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0079, std: 0.9023
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0099, std: 1.3516
  Model pred mean: -0.0078, std: 1.1641
  Sigmas: [0.93359375]... (timesteps: [932.0])
Steps:  11%|█         | 561/5000 [2:04:35<14:44:34, 11.96s/it, loss=0.5101, lr=1.00e-05]Steps:  11%|█         | 561/5000 [2:04:35<14:44:34, 11.96s/it, loss=0.4898, lr=1.00e-05]Steps:  11%|█         | 562/5000 [2:04:47<14:46:53, 11.99s/it, loss=0.4898, lr=1.00e-05]Steps:  11%|█         | 562/5000 [2:04:47<14:46:53, 11.99s/it, loss=0.6354, lr=1.00e-05]Steps:  11%|█▏        | 563/5000 [2:04:59<14:47:45, 12.00s/it, loss=0.6354, lr=1.00e-05]Steps:  11%|█▏        | 563/5000 [2:04:59<14:47:45, 12.00s/it, loss=0.7558, lr=1.00e-05]Steps:  11%|█▏        | 564/5000 [2:05:11<14:44:36, 11.97s/it, loss=0.7558, lr=1.00e-05]Steps:  11%|█▏        | 564/5000 [2:05:11<14:44:36, 11.97s/it, loss=0.4768, lr=1.00e-05]Steps:  11%|█▏        | 565/5000 [2:05:23<14:43:47, 11.96s/it, loss=0.4768, lr=1.00e-05]Steps:  11%|█▏        | 565/5000 [2:05:23<14:43:47, 11.96s/it, loss=0.6457, lr=9.99e-06]Steps:  11%|█▏        | 566/5000 [2:05:35<14:42:22, 11.94s/it, loss=0.6457, lr=9.99e-06]Steps:  11%|█▏        | 566/5000 [2:05:35<14:42:22, 11.94s/it, loss=0.4638, lr=9.99e-06]Steps:  11%|█▏        | 567/5000 [2:05:47<14:41:00, 11.92s/it, loss=0.4638, lr=9.99e-06]Steps:  11%|█▏        | 567/5000 [2:05:47<14:41:00, 11.92s/it, loss=1.0395, lr=9.99e-06]Steps:  11%|█▏        | 568/5000 [2:05:59<14:44:45, 11.98s/it, loss=1.0395, lr=9.99e-06]Steps:  11%|█▏        | 568/5000 [2:05:59<14:44:45, 11.98s/it, loss=0.9743, lr=9.99e-06]Steps:  11%|█▏        | 569/5000 [2:06:11<14:42:38, 11.95s/it, loss=0.9743, lr=9.99e-06]Steps:  11%|█▏        | 569/5000 [2:06:11<14:42:38, 11.95s/it, loss=0.4433, lr=9.99e-06]Steps:  11%|█▏        | 570/5000 [2:06:23<14:44:21, 11.98s/it, loss=0.4433, lr=9.99e-06]Steps:  11%|█▏        | 570/5000 [2:06:23<14:44:21, 11.98s/it, loss=0.4401, lr=9.99e-06]
[Step 570] Training Debug Info:
  Loss: 0.725572
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0223, std: 0.9375
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0236, std: 1.3672
  Model pred mean: -0.0251, std: 1.0625
  Sigmas: [0.9609375]... (timesteps: [961.0])

[Step 570] Training Debug Info:
  Loss: 0.727696
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0109, std: 0.9258
  Noise mean: -0.0016, std: 1.0078
  Target mean: -0.0125, std: 1.3672
  Model pred mean: -0.0088, std: 1.0625
  Sigmas: [0.5]... (timesteps: [500.0])

[Step 570] Training Debug Info:
  Loss: 0.694691
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0505, std: 0.9727
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0493, std: 1.3984
  Model pred mean: -0.0491, std: 1.1250
  Sigmas: [0.427734375]... (timesteps: [428.0])

[Step 570] Training Debug Info:
  Loss: 0.456237
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0309, std: 0.8828
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0317, std: 1.3359
  Model pred mean: -0.0305, std: 1.1484
  Sigmas: [0.79296875]... (timesteps: [793.0])
Steps:  11%|█▏        | 571/5000 [2:06:35<14:45:55, 12.00s/it, loss=0.4401, lr=9.99e-06]Steps:  11%|█▏        | 571/5000 [2:06:35<14:45:55, 12.00s/it, loss=0.4562, lr=9.99e-06]Steps:  11%|█▏        | 572/5000 [2:06:47<14:42:06, 11.95s/it, loss=0.4562, lr=9.99e-06]Steps:  11%|█▏        | 572/5000 [2:06:47<14:42:06, 11.95s/it, loss=1.1568, lr=9.99e-06]Steps:  11%|█▏        | 573/5000 [2:06:59<14:39:49, 11.92s/it, loss=1.1568, lr=9.99e-06]Steps:  11%|█▏        | 573/5000 [2:06:59<14:39:49, 11.92s/it, loss=0.4605, lr=9.99e-06]Steps:  11%|█▏        | 574/5000 [2:07:11<14:40:40, 11.94s/it, loss=0.4605, lr=9.99e-06]Steps:  11%|█▏        | 574/5000 [2:07:11<14:40:40, 11.94s/it, loss=0.4627, lr=9.99e-06]Steps:  12%|█▏        | 575/5000 [2:07:23<14:37:54, 11.90s/it, loss=0.4627, lr=9.99e-06]Steps:  12%|█▏        | 575/5000 [2:07:23<14:37:54, 11.90s/it, loss=0.7070, lr=9.99e-06]Steps:  12%|█▏        | 576/5000 [2:07:35<14:38:31, 11.91s/it, loss=0.7070, lr=9.99e-06]Steps:  12%|█▏        | 576/5000 [2:07:35<14:38:31, 11.91s/it, loss=0.4765, lr=9.99e-06]Steps:  12%|█▏        | 577/5000 [2:07:47<14:43:55, 11.99s/it, loss=0.4765, lr=9.99e-06]Steps:  12%|█▏        | 577/5000 [2:07:47<14:43:55, 11.99s/it, loss=1.0913, lr=9.99e-06]Steps:  12%|█▏        | 578/5000 [2:07:59<14:40:39, 11.95s/it, loss=1.0913, lr=9.99e-06]Steps:  12%|█▏        | 578/5000 [2:07:59<14:40:39, 11.95s/it, loss=0.8909, lr=9.99e-06]Steps:  12%|█▏        | 579/5000 [2:08:11<14:39:28, 11.94s/it, loss=0.8909, lr=9.99e-06]Steps:  12%|█▏        | 579/5000 [2:08:11<14:39:28, 11.94s/it, loss=0.3885, lr=9.99e-06]Steps:  12%|█▏        | 580/5000 [2:08:23<14:41:33, 11.97s/it, loss=0.3885, lr=9.99e-06]Steps:  12%|█▏        | 580/5000 [2:08:23<14:41:33, 11.97s/it, loss=0.4651, lr=9.99e-06]
[Step 580] Training Debug Info:
  Loss: 1.031343
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0053, std: 0.9297
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0058, std: 1.3672
  Model pred mean: -0.0071, std: 0.9062
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 580] Training Debug Info:
  Loss: 1.123532
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0092, std: 0.9141
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0104, std: 1.3594
  Model pred mean: -0.0132, std: 0.8320
  Sigmas: [0.09423828125]... (timesteps: [94.0])

[Step 580] Training Debug Info:
  Loss: 1.215412
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0025, std: 0.8711
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0029, std: 1.3281
  Model pred mean: -0.0050, std: 0.7266
  Sigmas: [0.2099609375]... (timesteps: [210.0])

[Step 580] Training Debug Info:
  Loss: 0.752956
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0033, std: 0.9219
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0022, std: 1.3594
  Model pred mean: 0.0003, std: 1.0547
  Sigmas: [0.47265625]... (timesteps: [472.0])
Steps:  12%|█▏        | 581/5000 [2:08:34<14:40:49, 11.96s/it, loss=0.4651, lr=9.99e-06]Steps:  12%|█▏        | 581/5000 [2:08:34<14:40:49, 11.96s/it, loss=0.7530, lr=9.99e-06]Steps:  12%|█▏        | 582/5000 [2:08:47<14:45:37, 12.03s/it, loss=0.7530, lr=9.99e-06]Steps:  12%|█▏        | 582/5000 [2:08:47<14:45:37, 12.03s/it, loss=0.4710, lr=9.99e-06]Steps:  12%|█▏        | 583/5000 [2:08:59<14:45:49, 12.03s/it, loss=0.4710, lr=9.99e-06]Steps:  12%|█▏        | 583/5000 [2:08:59<14:45:49, 12.03s/it, loss=1.1049, lr=9.99e-06]Steps:  12%|█▏        | 584/5000 [2:09:11<14:49:44, 12.09s/it, loss=1.1049, lr=9.99e-06]Steps:  12%|█▏        | 584/5000 [2:09:11<14:49:44, 12.09s/it, loss=0.6794, lr=9.99e-06]Steps:  12%|█▏        | 585/5000 [2:09:23<14:48:02, 12.07s/it, loss=0.6794, lr=9.99e-06]Steps:  12%|█▏        | 585/5000 [2:09:23<14:48:02, 12.07s/it, loss=0.9187, lr=9.99e-06]Steps:  12%|█▏        | 586/5000 [2:09:35<14:48:01, 12.07s/it, loss=0.9187, lr=9.99e-06]Steps:  12%|█▏        | 586/5000 [2:09:35<14:48:01, 12.07s/it, loss=0.9850, lr=9.99e-06]Steps:  12%|█▏        | 587/5000 [2:09:47<14:44:25, 12.02s/it, loss=0.9850, lr=9.99e-06]Steps:  12%|█▏        | 587/5000 [2:09:47<14:44:25, 12.02s/it, loss=0.5220, lr=9.99e-06]Steps:  12%|█▏        | 588/5000 [2:09:59<14:41:38, 11.99s/it, loss=0.5220, lr=9.99e-06]Steps:  12%|█▏        | 588/5000 [2:09:59<14:41:38, 11.99s/it, loss=1.1882, lr=9.99e-06]Steps:  12%|█▏        | 589/5000 [2:10:11<14:42:21, 12.00s/it, loss=1.1882, lr=9.99e-06]Steps:  12%|█▏        | 589/5000 [2:10:11<14:42:21, 12.00s/it, loss=1.1444, lr=9.99e-06]Steps:  12%|█▏        | 590/5000 [2:10:23<14:46:12, 12.06s/it, loss=1.1444, lr=9.99e-06]Steps:  12%|█▏        | 590/5000 [2:10:23<14:46:12, 12.06s/it, loss=0.5040, lr=9.99e-06]
[Step 590] Training Debug Info:
  Loss: 0.783712
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0074, std: 0.8906
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0093, std: 1.3438
  Model pred mean: 0.0111, std: 0.9922
  Sigmas: [0.48046875]... (timesteps: [481.0])

[Step 590] Training Debug Info:
  Loss: 0.561942
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0173, std: 0.9102
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0168, std: 1.3516
  Model pred mean: -0.0188, std: 1.1172
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 590] Training Debug Info:
  Loss: 1.085638
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0074, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0069, std: 1.3438
  Model pred mean: 0.0179, std: 0.8516
  Sigmas: [0.049072265625]... (timesteps: [49.0])

[Step 590] Training Debug Info:
  Loss: 1.092858
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0211, std: 0.8750
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0201, std: 1.3281
  Model pred mean: 0.0306, std: 0.8164
  Sigmas: [0.049072265625]... (timesteps: [49.0])
Steps:  12%|█▏        | 591/5000 [2:10:35<14:43:08, 12.02s/it, loss=0.5040, lr=9.99e-06]Steps:  12%|█▏        | 591/5000 [2:10:35<14:43:08, 12.02s/it, loss=1.0929, lr=9.99e-06]Steps:  12%|█▏        | 592/5000 [2:10:47<14:41:29, 12.00s/it, loss=1.0929, lr=9.99e-06]Steps:  12%|█▏        | 592/5000 [2:10:47<14:41:29, 12.00s/it, loss=1.1064, lr=9.99e-06]Steps:  12%|█▏        | 593/5000 [2:10:59<14:39:04, 11.97s/it, loss=1.1064, lr=9.99e-06]Steps:  12%|█▏        | 593/5000 [2:10:59<14:39:04, 11.97s/it, loss=0.4481, lr=9.99e-06]Steps:  12%|█▏        | 594/5000 [2:11:11<14:36:58, 11.94s/it, loss=0.4481, lr=9.99e-06]Steps:  12%|█▏        | 594/5000 [2:11:11<14:36:58, 11.94s/it, loss=0.8925, lr=9.99e-06]Steps:  12%|█▏        | 595/5000 [2:11:23<14:36:20, 11.94s/it, loss=0.8925, lr=9.99e-06]Steps:  12%|█▏        | 595/5000 [2:11:23<14:36:20, 11.94s/it, loss=0.6027, lr=9.99e-06]Steps:  12%|█▏        | 596/5000 [2:11:34<14:33:43, 11.90s/it, loss=0.6027, lr=9.99e-06]Steps:  12%|█▏        | 596/5000 [2:11:34<14:33:43, 11.90s/it, loss=1.2050, lr=9.99e-06]Steps:  12%|█▏        | 597/5000 [2:11:47<14:38:30, 11.97s/it, loss=1.2050, lr=9.99e-06]Steps:  12%|█▏        | 597/5000 [2:11:47<14:38:30, 11.97s/it, loss=0.3868, lr=9.99e-06]Steps:  12%|█▏        | 598/5000 [2:11:59<14:40:45, 12.00s/it, loss=0.3868, lr=9.99e-06]Steps:  12%|█▏        | 598/5000 [2:11:59<14:40:45, 12.00s/it, loss=0.4730, lr=9.99e-06]Steps:  12%|█▏        | 599/5000 [2:12:11<14:39:53, 12.00s/it, loss=0.4730, lr=9.99e-06]Steps:  12%|█▏        | 599/5000 [2:12:11<14:39:53, 12.00s/it, loss=1.1386, lr=9.99e-06]Steps:  12%|█▏        | 600/5000 [2:12:23<14:39:39, 12.00s/it, loss=1.1386, lr=9.99e-06]Steps:  12%|█▏        | 600/5000 [2:12:23<14:39:39, 12.00s/it, loss=0.4017, lr=9.99e-06]01/22/2026 09:58:09 - INFO - __main__ - 
[Step 600] ✅ Loss in normal range (0.4017)
01/22/2026 09:58:09 - INFO - __main__ -   Loss avg (last 100): 0.7451
01/22/2026 09:58:09 - INFO - __main__ -   Loss range: [0.3418, 1.2050]
01/22/2026 09:58:09 - INFO - __main__ - 
🔍 Running validation at step 600...
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 600 (parquet mode)...
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 600...
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 09:58:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 09:58:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 09:58:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.44it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.43it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.43it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.43it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 09:58:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 09:58:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 09:59:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 09:59:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 09:59:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 09:59:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 09:59:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 09:59:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:00:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 10:00:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:00:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 10:00:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:00:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 10:00:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:01:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 10:01:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 10:01:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 10:01:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 10:01:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 10:01:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 10:02:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600/step000600_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 10:02:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 10:02:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 10:02:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000600
01/22/2026 10:02:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 600] Training Debug Info:
  Loss: 0.390555
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0347, std: 0.9297
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0337, std: 1.3672
  Model pred mean: -0.0320, std: 1.2266
  Sigmas: [0.70703125]... (timesteps: [706.0])

[Step 600] Training Debug Info:
  Loss: 1.181221
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0128, std: 0.8672
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0145, std: 1.3203
  Model pred mean: -0.0043, std: 0.7500
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 600] Training Debug Info:
  Loss: 0.977829
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0110, std: 0.9180
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0101, std: 1.3594
  Model pred mean: 0.0176, std: 0.9414
  Sigmas: [0.337890625]... (timesteps: [337.0])

[Step 600] Training Debug Info:
  Loss: 0.459529
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0204, std: 0.8945
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0203, std: 1.3438
  Model pred mean: 0.0243, std: 1.1719
  Sigmas: [0.69140625]... (timesteps: [693.0])
Steps:  12%|█▏        | 601/5000 [2:16:47<106:59:25, 87.56s/it, loss=0.4017, lr=9.99e-06]Steps:  12%|█▏        | 601/5000 [2:16:47<106:59:25, 87.56s/it, loss=0.4595, lr=9.99e-06]Steps:  12%|█▏        | 602/5000 [2:16:58<79:13:48, 64.85s/it, loss=0.4595, lr=9.99e-06] Steps:  12%|█▏        | 602/5000 [2:16:58<79:13:48, 64.85s/it, loss=0.8553, lr=9.99e-06]Steps:  12%|█▏        | 603/5000 [2:17:10<59:48:22, 48.97s/it, loss=0.8553, lr=9.99e-06]Steps:  12%|█▏        | 603/5000 [2:17:10<59:48:22, 48.97s/it, loss=0.4505, lr=9.99e-06]Steps:  12%|█▏        | 604/5000 [2:17:22<46:18:21, 37.92s/it, loss=0.4505, lr=9.99e-06]Steps:  12%|█▏        | 604/5000 [2:17:22<46:18:21, 37.92s/it, loss=1.1033, lr=9.99e-06]Steps:  12%|█▏        | 605/5000 [2:17:34<36:45:54, 30.11s/it, loss=1.1033, lr=9.99e-06]Steps:  12%|█▏        | 605/5000 [2:17:34<36:45:54, 30.11s/it, loss=0.3812, lr=9.99e-06]Steps:  12%|█▏        | 606/5000 [2:17:46<30:06:12, 24.66s/it, loss=0.3812, lr=9.99e-06]Steps:  12%|█▏        | 606/5000 [2:17:46<30:06:12, 24.66s/it, loss=1.1130, lr=9.99e-06]Steps:  12%|█▏        | 607/5000 [2:17:58<25:27:33, 20.86s/it, loss=1.1130, lr=9.99e-06]Steps:  12%|█▏        | 607/5000 [2:17:58<25:27:33, 20.86s/it, loss=0.5451, lr=9.99e-06]Steps:  12%|█▏        | 608/5000 [2:18:10<22:11:38, 18.19s/it, loss=0.5451, lr=9.99e-06]Steps:  12%|█▏        | 608/5000 [2:18:10<22:11:38, 18.19s/it, loss=1.1643, lr=9.99e-06]Steps:  12%|█▏        | 609/5000 [2:18:22<19:55:45, 16.34s/it, loss=1.1643, lr=9.99e-06]Steps:  12%|█▏        | 609/5000 [2:18:22<19:55:45, 16.34s/it, loss=0.9033, lr=9.99e-06]Steps:  12%|█▏        | 610/5000 [2:18:34<18:17:56, 15.01s/it, loss=0.9033, lr=9.99e-06]Steps:  12%|█▏        | 610/5000 [2:18:34<18:17:56, 15.01s/it, loss=0.8638, lr=9.99e-06]
[Step 610] Training Debug Info:
  Loss: 0.962349
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0027, std: 0.9336
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0012, std: 1.3672
  Model pred mean: -0.0027, std: 0.9648
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 610] Training Debug Info:
  Loss: 0.743964
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0092, std: 0.9375
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0101, std: 1.3750
  Model pred mean: -0.0189, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [987.0])

[Step 610] Training Debug Info:
  Loss: 1.047584
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0007, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0013, std: 1.3438
  Model pred mean: 0.0001, std: 0.8867
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 610] Training Debug Info:
  Loss: 0.385704
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0098, std: 0.8789
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0107, std: 1.3359
  Model pred mean: 0.0099, std: 1.1797
  Sigmas: [0.796875]... (timesteps: [795.0])
Steps:  12%|█▏        | 611/5000 [2:18:46<17:17:12, 14.18s/it, loss=0.8638, lr=9.99e-06]Steps:  12%|█▏        | 611/5000 [2:18:46<17:17:12, 14.18s/it, loss=0.3857, lr=9.98e-06]Steps:  12%|█▏        | 612/5000 [2:18:58<16:26:26, 13.49s/it, loss=0.3857, lr=9.98e-06]Steps:  12%|█▏        | 612/5000 [2:18:58<16:26:26, 13.49s/it, loss=0.7547, lr=9.98e-06]Steps:  12%|█▏        | 613/5000 [2:19:10<15:50:45, 13.00s/it, loss=0.7547, lr=9.98e-06]Steps:  12%|█▏        | 613/5000 [2:19:10<15:50:45, 13.00s/it, loss=0.7511, lr=9.98e-06]Steps:  12%|█▏        | 614/5000 [2:19:22<15:29:31, 12.72s/it, loss=0.7511, lr=9.98e-06]Steps:  12%|█▏        | 614/5000 [2:19:22<15:29:31, 12.72s/it, loss=1.1098, lr=9.98e-06]Steps:  12%|█▏        | 615/5000 [2:19:34<15:11:37, 12.47s/it, loss=1.1098, lr=9.98e-06]Steps:  12%|█▏        | 615/5000 [2:19:34<15:11:37, 12.47s/it, loss=0.5902, lr=9.98e-06]Steps:  12%|█▏        | 616/5000 [2:19:46<15:03:07, 12.36s/it, loss=0.5902, lr=9.98e-06]Steps:  12%|█▏        | 616/5000 [2:19:46<15:03:07, 12.36s/it, loss=0.4863, lr=9.98e-06]Steps:  12%|█▏        | 617/5000 [2:19:58<14:56:32, 12.27s/it, loss=0.4863, lr=9.98e-06]Steps:  12%|█▏        | 617/5000 [2:19:58<14:56:32, 12.27s/it, loss=0.7367, lr=9.98e-06]Steps:  12%|█▏        | 618/5000 [2:20:10<14:48:18, 12.16s/it, loss=0.7367, lr=9.98e-06]Steps:  12%|█▏        | 618/5000 [2:20:10<14:48:18, 12.16s/it, loss=1.0470, lr=9.98e-06]Steps:  12%|█▏        | 619/5000 [2:20:22<14:43:19, 12.10s/it, loss=1.0470, lr=9.98e-06]Steps:  12%|█▏        | 619/5000 [2:20:22<14:43:19, 12.10s/it, loss=1.1076, lr=9.98e-06]Steps:  12%|█▏        | 620/5000 [2:20:34<14:39:06, 12.04s/it, loss=1.1076, lr=9.98e-06]Steps:  12%|█▏        | 620/5000 [2:20:34<14:39:06, 12.04s/it, loss=0.4893, lr=9.98e-06]
[Step 620] Training Debug Info:
  Loss: 1.113594
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0170, std: 0.9258
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0150, std: 1.3672
  Model pred mean: -0.0193, std: 0.8672
  Sigmas: [0.1923828125]... (timesteps: [192.0])

[Step 620] Training Debug Info:
  Loss: 0.508906
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0182, std: 0.9297
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0189, std: 1.3672
  Model pred mean: -0.0161, std: 1.1719
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 620] Training Debug Info:
  Loss: 0.419517
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0583, std: 0.9414
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0579, std: 1.3750
  Model pred mean: -0.0557, std: 1.2188
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 620] Training Debug Info:
  Loss: 0.436119
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0130, std: 0.8984
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0151, std: 1.3438
  Model pred mean: -0.0101, std: 1.1719
  Sigmas: [0.85546875]... (timesteps: [855.0])
Steps:  12%|█▏        | 621/5000 [2:20:46<14:37:50, 12.03s/it, loss=0.4893, lr=9.98e-06]Steps:  12%|█▏        | 621/5000 [2:20:46<14:37:50, 12.03s/it, loss=0.4361, lr=9.98e-06]Steps:  12%|█▏        | 622/5000 [2:20:58<14:35:59, 12.01s/it, loss=0.4361, lr=9.98e-06]Steps:  12%|█▏        | 622/5000 [2:20:58<14:35:59, 12.01s/it, loss=0.8333, lr=9.98e-06]Steps:  12%|█▏        | 623/5000 [2:21:10<14:34:44, 11.99s/it, loss=0.8333, lr=9.98e-06]Steps:  12%|█▏        | 623/5000 [2:21:10<14:34:44, 11.99s/it, loss=0.4637, lr=9.98e-06]Steps:  12%|█▏        | 624/5000 [2:21:22<14:35:02, 12.00s/it, loss=0.4637, lr=9.98e-06]Steps:  12%|█▏        | 624/5000 [2:21:22<14:35:02, 12.00s/it, loss=0.9787, lr=9.98e-06]Steps:  12%|█▎        | 625/5000 [2:21:34<14:36:24, 12.02s/it, loss=0.9787, lr=9.98e-06]Steps:  12%|█▎        | 625/5000 [2:21:34<14:36:24, 12.02s/it, loss=0.4723, lr=9.98e-06]Steps:  13%|█▎        | 626/5000 [2:21:46<14:36:26, 12.02s/it, loss=0.4723, lr=9.98e-06]Steps:  13%|█▎        | 626/5000 [2:21:46<14:36:26, 12.02s/it, loss=0.4278, lr=9.98e-06]Steps:  13%|█▎        | 627/5000 [2:21:58<14:35:18, 12.01s/it, loss=0.4278, lr=9.98e-06]Steps:  13%|█▎        | 627/5000 [2:21:58<14:35:18, 12.01s/it, loss=0.5301, lr=9.98e-06]Steps:  13%|█▎        | 628/5000 [2:22:10<14:32:41, 11.98s/it, loss=0.5301, lr=9.98e-06]Steps:  13%|█▎        | 628/5000 [2:22:10<14:32:41, 11.98s/it, loss=1.0445, lr=9.98e-06]Steps:  13%|█▎        | 629/5000 [2:22:22<14:33:44, 11.99s/it, loss=1.0445, lr=9.98e-06]Steps:  13%|█▎        | 629/5000 [2:22:22<14:33:44, 11.99s/it, loss=1.1325, lr=9.98e-06]Steps:  13%|█▎        | 630/5000 [2:22:34<14:33:45, 12.00s/it, loss=1.1325, lr=9.98e-06]Steps:  13%|█▎        | 630/5000 [2:22:34<14:33:45, 12.00s/it, loss=0.4517, lr=9.98e-06]
[Step 630] Training Debug Info:
  Loss: 0.472396
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0461, std: 0.9727
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0459, std: 1.3984
  Model pred mean: -0.0493, std: 1.2188
  Sigmas: [0.82421875]... (timesteps: [825.0])

[Step 630] Training Debug Info:
  Loss: 1.101271
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0075, std: 0.9375
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0080, std: 1.3750
  Model pred mean: 0.0061, std: 0.8828
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 630] Training Debug Info:
  Loss: 0.604633
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0234, std: 0.9688
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0238, std: 1.3906
  Model pred mean: -0.0253, std: 1.1641
  Sigmas: [0.546875]... (timesteps: [548.0])

[Step 630] Training Debug Info:
  Loss: 1.022991
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0250, std: 0.9219
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0271, std: 1.3594
  Model pred mean: -0.0298, std: 0.9141
  Sigmas: [0.006988525390625]... (timesteps: [7.0])
Steps:  13%|█▎        | 631/5000 [2:22:46<14:37:03, 12.04s/it, loss=0.4517, lr=9.98e-06]Steps:  13%|█▎        | 631/5000 [2:22:46<14:37:03, 12.04s/it, loss=1.0230, lr=9.98e-06]Steps:  13%|█▎        | 632/5000 [2:22:58<14:36:47, 12.04s/it, loss=1.0230, lr=9.98e-06]Steps:  13%|█▎        | 632/5000 [2:22:58<14:36:47, 12.04s/it, loss=1.0839, lr=9.98e-06]Steps:  13%|█▎        | 633/5000 [2:23:10<14:38:50, 12.07s/it, loss=1.0839, lr=9.98e-06]Steps:  13%|█▎        | 633/5000 [2:23:10<14:38:50, 12.07s/it, loss=0.4000, lr=9.98e-06]Steps:  13%|█▎        | 634/5000 [2:23:22<14:39:57, 12.09s/it, loss=0.4000, lr=9.98e-06]Steps:  13%|█▎        | 634/5000 [2:23:22<14:39:57, 12.09s/it, loss=1.1878, lr=9.98e-06]Steps:  13%|█▎        | 635/5000 [2:23:34<14:36:45, 12.05s/it, loss=1.1878, lr=9.98e-06]Steps:  13%|█▎        | 635/5000 [2:23:34<14:36:45, 12.05s/it, loss=1.0929, lr=9.98e-06]Steps:  13%|█▎        | 636/5000 [2:23:46<14:35:55, 12.04s/it, loss=1.0929, lr=9.98e-06]Steps:  13%|█▎        | 636/5000 [2:23:46<14:35:55, 12.04s/it, loss=0.6426, lr=9.98e-06]Steps:  13%|█▎        | 637/5000 [2:23:58<14:34:52, 12.03s/it, loss=0.6426, lr=9.98e-06]Steps:  13%|█▎        | 637/5000 [2:23:58<14:34:52, 12.03s/it, loss=1.0828, lr=9.98e-06]Steps:  13%|█▎        | 638/5000 [2:24:11<14:36:54, 12.06s/it, loss=1.0828, lr=9.98e-06]Steps:  13%|█▎        | 638/5000 [2:24:11<14:36:54, 12.06s/it, loss=0.4887, lr=9.98e-06]Steps:  13%|█▎        | 639/5000 [2:24:23<14:36:23, 12.06s/it, loss=0.4887, lr=9.98e-06]Steps:  13%|█▎        | 639/5000 [2:24:23<14:36:23, 12.06s/it, loss=1.0821, lr=9.98e-06]Steps:  13%|█▎        | 640/5000 [2:24:35<14:35:28, 12.05s/it, loss=1.0821, lr=9.98e-06]Steps:  13%|█▎        | 640/5000 [2:24:35<14:35:28, 12.05s/it, loss=1.1774, lr=9.98e-06]
[Step 640] Training Debug Info:
  Loss: 1.167055
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0109, std: 0.9844
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0108, std: 1.4062
  Model pred mean: -0.0135, std: 0.8984
  Sigmas: [0.1689453125]... (timesteps: [169.0])

[Step 640] Training Debug Info:
  Loss: 0.738407
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0298, std: 0.9062
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0295, std: 1.3516
  Model pred mean: -0.0264, std: 1.0312
  Sigmas: [0.419921875]... (timesteps: [420.0])

[Step 640] Training Debug Info:
  Loss: 0.447779
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0240, std: 0.8945
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0237, std: 1.3438
  Model pred mean: 0.0258, std: 1.1562
  Sigmas: [0.73046875]... (timesteps: [730.0])

[Step 640] Training Debug Info:
  Loss: 0.949833
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0020, std: 0.8906
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0045, std: 1.3438
  Model pred mean: 0.0044, std: 0.9219
  Sigmas: [0.39453125]... (timesteps: [394.0])
Steps:  13%|█▎        | 641/5000 [2:24:47<14:32:56, 12.02s/it, loss=1.1774, lr=9.98e-06]Steps:  13%|█▎        | 641/5000 [2:24:47<14:32:56, 12.02s/it, loss=0.9498, lr=9.98e-06]Steps:  13%|█▎        | 642/5000 [2:24:59<14:35:33, 12.05s/it, loss=0.9498, lr=9.98e-06]Steps:  13%|█▎        | 642/5000 [2:24:59<14:35:33, 12.05s/it, loss=0.7776, lr=9.98e-06]Steps:  13%|█▎        | 643/5000 [2:25:11<14:36:27, 12.07s/it, loss=0.7776, lr=9.98e-06]Steps:  13%|█▎        | 643/5000 [2:25:11<14:36:27, 12.07s/it, loss=1.0960, lr=9.98e-06]Steps:  13%|█▎        | 644/5000 [2:25:23<14:37:52, 12.09s/it, loss=1.0960, lr=9.98e-06]Steps:  13%|█▎        | 644/5000 [2:25:23<14:37:52, 12.09s/it, loss=0.7364, lr=9.97e-06]Steps:  13%|█▎        | 645/5000 [2:25:35<14:37:21, 12.09s/it, loss=0.7364, lr=9.97e-06]Steps:  13%|█▎        | 645/5000 [2:25:35<14:37:21, 12.09s/it, loss=0.5928, lr=9.97e-06]Steps:  13%|█▎        | 646/5000 [2:25:47<14:36:03, 12.07s/it, loss=0.5928, lr=9.97e-06]Steps:  13%|█▎        | 646/5000 [2:25:47<14:36:03, 12.07s/it, loss=0.6027, lr=9.97e-06]Steps:  13%|█▎        | 647/5000 [2:25:59<14:34:24, 12.05s/it, loss=0.6027, lr=9.97e-06]Steps:  13%|█▎        | 647/5000 [2:25:59<14:34:24, 12.05s/it, loss=0.3932, lr=9.97e-06]Steps:  13%|█▎        | 648/5000 [2:26:11<14:34:44, 12.06s/it, loss=0.3932, lr=9.97e-06]Steps:  13%|█▎        | 648/5000 [2:26:11<14:34:44, 12.06s/it, loss=0.9084, lr=9.97e-06]Steps:  13%|█▎        | 649/5000 [2:26:23<14:34:18, 12.06s/it, loss=0.9084, lr=9.97e-06]Steps:  13%|█▎        | 649/5000 [2:26:23<14:34:18, 12.06s/it, loss=1.1816, lr=9.97e-06]Steps:  13%|█▎        | 650/5000 [2:26:35<14:36:29, 12.09s/it, loss=1.1816, lr=9.97e-06]Steps:  13%|█▎        | 650/5000 [2:26:35<14:36:29, 12.09s/it, loss=0.4449, lr=9.97e-06]
[Step 650] Training Debug Info:
  Loss: 0.885960
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0493, std: 0.9336
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0466, std: 1.3672
  Model pred mean: -0.0486, std: 0.9883
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 650] Training Debug Info:
  Loss: 1.140170
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0170, std: 0.9023
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0186, std: 1.3516
  Model pred mean: -0.0181, std: 0.8203
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 650] Training Debug Info:
  Loss: 0.491302
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0131, std: 0.9336
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0136, std: 1.3672
  Model pred mean: -0.0181, std: 1.1641
  Sigmas: [0.6953125]... (timesteps: [696.0])

[Step 650] Training Debug Info:
  Loss: 1.136557
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0055, std: 0.8828
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0029, std: 1.3359
  Model pred mean: -0.0071, std: 0.8047
  Sigmas: [0.0869140625]... (timesteps: [87.0])
Steps:  13%|█▎        | 651/5000 [2:26:48<14:38:47, 12.12s/it, loss=0.4449, lr=9.97e-06]Steps:  13%|█▎        | 651/5000 [2:26:48<14:38:47, 12.12s/it, loss=1.1366, lr=9.97e-06]Steps:  13%|█▎        | 652/5000 [2:27:00<14:38:24, 12.12s/it, loss=1.1366, lr=9.97e-06]Steps:  13%|█▎        | 652/5000 [2:27:00<14:38:24, 12.12s/it, loss=0.5232, lr=9.97e-06]Steps:  13%|█▎        | 653/5000 [2:27:12<14:35:30, 12.08s/it, loss=0.5232, lr=9.97e-06]Steps:  13%|█▎        | 653/5000 [2:27:12<14:35:30, 12.08s/it, loss=0.4515, lr=9.97e-06]Steps:  13%|█▎        | 654/5000 [2:27:24<14:35:18, 12.08s/it, loss=0.4515, lr=9.97e-06]Steps:  13%|█▎        | 654/5000 [2:27:24<14:35:18, 12.08s/it, loss=0.9503, lr=9.97e-06]Steps:  13%|█▎        | 655/5000 [2:27:36<14:32:36, 12.05s/it, loss=0.9503, lr=9.97e-06]Steps:  13%|█▎        | 655/5000 [2:27:36<14:32:36, 12.05s/it, loss=0.4459, lr=9.97e-06]Steps:  13%|█▎        | 656/5000 [2:27:48<14:30:26, 12.02s/it, loss=0.4459, lr=9.97e-06]Steps:  13%|█▎        | 656/5000 [2:27:48<14:30:26, 12.02s/it, loss=1.0790, lr=9.97e-06]Steps:  13%|█▎        | 657/5000 [2:28:00<14:30:02, 12.02s/it, loss=1.0790, lr=9.97e-06]Steps:  13%|█▎        | 657/5000 [2:28:00<14:30:02, 12.02s/it, loss=0.3421, lr=9.97e-06]Steps:  13%|█▎        | 658/5000 [2:28:12<14:32:27, 12.06s/it, loss=0.3421, lr=9.97e-06]Steps:  13%|█▎        | 658/5000 [2:28:12<14:32:27, 12.06s/it, loss=1.0408, lr=9.97e-06]Steps:  13%|█▎        | 659/5000 [2:28:24<14:39:39, 12.16s/it, loss=1.0408, lr=9.97e-06]Steps:  13%|█▎        | 659/5000 [2:28:24<14:39:39, 12.16s/it, loss=0.7312, lr=9.97e-06]Steps:  13%|█▎        | 660/5000 [2:28:36<14:40:36, 12.17s/it, loss=0.7312, lr=9.97e-06]Steps:  13%|█▎        | 660/5000 [2:28:36<14:40:36, 12.17s/it, loss=0.6980, lr=9.97e-06]
[Step 660] Training Debug Info:
  Loss: 1.221984
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0214, std: 0.8398
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0199, std: 1.3047
  Model pred mean: 0.0214, std: 0.7031
  Sigmas: [0.1572265625]... (timesteps: [157.0])

[Step 660] Training Debug Info:
  Loss: 1.088725
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0057, std: 0.8984
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0066, std: 1.3438
  Model pred mean: -0.0069, std: 0.8438
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 660] Training Debug Info:
  Loss: 0.398495
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0073, std: 0.9062
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0075, std: 1.3516
  Model pred mean: -0.0039, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [824.0])

[Step 660] Training Debug Info:
  Loss: 0.761672
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0435, std: 0.9062
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0439, std: 1.3516
  Model pred mean: -0.0461, std: 1.0234
  Sigmas: [0.37109375]... (timesteps: [371.0])
Steps:  13%|█▎        | 661/5000 [2:28:49<14:46:07, 12.25s/it, loss=0.6980, lr=9.97e-06]Steps:  13%|█▎        | 661/5000 [2:28:49<14:46:07, 12.25s/it, loss=0.7617, lr=9.97e-06]Steps:  13%|█▎        | 662/5000 [2:29:01<14:45:45, 12.25s/it, loss=0.7617, lr=9.97e-06]Steps:  13%|█▎        | 662/5000 [2:29:01<14:45:45, 12.25s/it, loss=0.4639, lr=9.97e-06]Steps:  13%|█▎        | 663/5000 [2:29:13<14:46:03, 12.26s/it, loss=0.4639, lr=9.97e-06]Steps:  13%|█▎        | 663/5000 [2:29:13<14:46:03, 12.26s/it, loss=0.4713, lr=9.97e-06]Steps:  13%|█▎        | 664/5000 [2:29:26<14:45:43, 12.26s/it, loss=0.4713, lr=9.97e-06]Steps:  13%|█▎        | 664/5000 [2:29:26<14:45:43, 12.26s/it, loss=0.3742, lr=9.97e-06]Steps:  13%|█▎        | 665/5000 [2:29:38<14:50:14, 12.32s/it, loss=0.3742, lr=9.97e-06]Steps:  13%|█▎        | 665/5000 [2:29:38<14:50:14, 12.32s/it, loss=0.5156, lr=9.97e-06]Steps:  13%|█▎        | 666/5000 [2:29:51<14:52:21, 12.35s/it, loss=0.5156, lr=9.97e-06]Steps:  13%|█▎        | 666/5000 [2:29:51<14:52:21, 12.35s/it, loss=0.6212, lr=9.97e-06]Steps:  13%|█▎        | 667/5000 [2:30:03<14:52:53, 12.36s/it, loss=0.6212, lr=9.97e-06]Steps:  13%|█▎        | 667/5000 [2:30:03<14:52:53, 12.36s/it, loss=0.4384, lr=9.97e-06]Steps:  13%|█▎        | 668/5000 [2:30:15<14:51:23, 12.35s/it, loss=0.4384, lr=9.97e-06]Steps:  13%|█▎        | 668/5000 [2:30:15<14:51:23, 12.35s/it, loss=0.3707, lr=9.97e-06]Steps:  13%|█▎        | 669/5000 [2:30:28<14:52:01, 12.36s/it, loss=0.3707, lr=9.97e-06]Steps:  13%|█▎        | 669/5000 [2:30:28<14:52:01, 12.36s/it, loss=0.5129, lr=9.97e-06]Steps:  13%|█▎        | 670/5000 [2:30:40<14:54:21, 12.39s/it, loss=0.5129, lr=9.97e-06]Steps:  13%|█▎        | 670/5000 [2:30:40<14:54:21, 12.39s/it, loss=0.3503, lr=9.96e-06]
[Step 670] Training Debug Info:
  Loss: 0.553462
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0150, std: 0.9141
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0171, std: 1.3516
  Model pred mean: 0.0190, std: 1.1250
  Sigmas: [0.5703125]... (timesteps: [569.0])

[Step 670] Training Debug Info:
  Loss: 0.971066
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0105, std: 0.9531
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0121, std: 1.3750
  Model pred mean: -0.0095, std: 0.9688
  Sigmas: [0.40625]... (timesteps: [407.0])

[Step 670] Training Debug Info:
  Loss: 0.437720
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0236, std: 0.9023
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0234, std: 1.3438
  Model pred mean: -0.0190, std: 1.1641
  Sigmas: [0.72265625]... (timesteps: [723.0])

[Step 670] Training Debug Info:
  Loss: 1.066113
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0130, std: 0.9609
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0146, std: 1.3906
  Model pred mean: 0.0148, std: 0.9414
  Sigmas: [0.041015625]... (timesteps: [41.0])
Steps:  13%|█▎        | 671/5000 [2:30:53<14:55:18, 12.41s/it, loss=0.3503, lr=9.96e-06]Steps:  13%|█▎        | 671/5000 [2:30:53<14:55:18, 12.41s/it, loss=1.0661, lr=9.96e-06]Steps:  13%|█▎        | 672/5000 [2:31:05<14:51:55, 12.36s/it, loss=1.0661, lr=9.96e-06]Steps:  13%|█▎        | 672/5000 [2:31:05<14:51:55, 12.36s/it, loss=0.9978, lr=9.96e-06]Steps:  13%|█▎        | 673/5000 [2:31:17<14:51:42, 12.36s/it, loss=0.9978, lr=9.96e-06]Steps:  13%|█▎        | 673/5000 [2:31:17<14:51:42, 12.36s/it, loss=0.4164, lr=9.96e-06]Steps:  13%|█▎        | 674/5000 [2:31:30<14:50:02, 12.34s/it, loss=0.4164, lr=9.96e-06]Steps:  13%|█▎        | 674/5000 [2:31:30<14:50:02, 12.34s/it, loss=0.4768, lr=9.96e-06]Steps:  14%|█▎        | 675/5000 [2:31:42<14:47:28, 12.31s/it, loss=0.4768, lr=9.96e-06]Steps:  14%|█▎        | 675/5000 [2:31:42<14:47:28, 12.31s/it, loss=0.7713, lr=9.96e-06]Steps:  14%|█▎        | 676/5000 [2:31:54<14:48:17, 12.33s/it, loss=0.7713, lr=9.96e-06]Steps:  14%|█▎        | 676/5000 [2:31:54<14:48:17, 12.33s/it, loss=0.7975, lr=9.96e-06]Steps:  14%|█▎        | 677/5000 [2:32:06<14:48:06, 12.33s/it, loss=0.7975, lr=9.96e-06]Steps:  14%|█▎        | 677/5000 [2:32:06<14:48:06, 12.33s/it, loss=0.4214, lr=9.96e-06]Steps:  14%|█▎        | 678/5000 [2:32:19<14:52:18, 12.39s/it, loss=0.4214, lr=9.96e-06]Steps:  14%|█▎        | 678/5000 [2:32:19<14:52:18, 12.39s/it, loss=1.0180, lr=9.96e-06]Steps:  14%|█▎        | 679/5000 [2:32:31<14:53:31, 12.41s/it, loss=1.0180, lr=9.96e-06]Steps:  14%|█▎        | 679/5000 [2:32:31<14:53:31, 12.41s/it, loss=1.0252, lr=9.96e-06]Steps:  14%|█▎        | 680/5000 [2:32:44<14:56:07, 12.45s/it, loss=1.0252, lr=9.96e-06]Steps:  14%|█▎        | 680/5000 [2:32:44<14:56:07, 12.45s/it, loss=1.0829, lr=9.96e-06]
[Step 680] Training Debug Info:
  Loss: 1.111267
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0052, std: 0.9297
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0058, std: 1.3672
  Model pred mean: -0.0029, std: 0.8672
  Sigmas: [0.07080078125]... (timesteps: [71.0])

[Step 680] Training Debug Info:
  Loss: 0.416999
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0240, std: 0.9219
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0276, std: 1.3594
  Model pred mean: 0.0233, std: 1.1875
  Sigmas: [0.734375]... (timesteps: [736.0])

[Step 680] Training Debug Info:
  Loss: 0.743045
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0072, std: 0.8672
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0069, std: 1.3203
  Model pred mean: -0.0073, std: 0.9961
  Sigmas: [0.51953125]... (timesteps: [521.0])

[Step 680] Training Debug Info:
  Loss: 0.395252
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0091, std: 0.9336
  Noise mean: -0.0019, std: 1.0000
  Target mean: 0.0072, std: 1.3672
  Model pred mean: 0.0093, std: 1.2109
  Sigmas: [0.75390625]... (timesteps: [752.0])
Steps:  14%|█▎        | 681/5000 [2:32:56<14:53:28, 12.41s/it, loss=1.0829, lr=9.96e-06]Steps:  14%|█▎        | 681/5000 [2:32:56<14:53:28, 12.41s/it, loss=0.3953, lr=9.96e-06]Steps:  14%|█▎        | 682/5000 [2:33:09<14:48:53, 12.35s/it, loss=0.3953, lr=9.96e-06]Steps:  14%|█▎        | 682/5000 [2:33:09<14:48:53, 12.35s/it, loss=0.5508, lr=9.96e-06]Steps:  14%|█▎        | 683/5000 [2:33:21<14:47:52, 12.34s/it, loss=0.5508, lr=9.96e-06]Steps:  14%|█▎        | 683/5000 [2:33:21<14:47:52, 12.34s/it, loss=1.1191, lr=9.96e-06]Steps:  14%|█▎        | 684/5000 [2:33:33<14:43:35, 12.28s/it, loss=1.1191, lr=9.96e-06]Steps:  14%|█▎        | 684/5000 [2:33:33<14:43:35, 12.28s/it, loss=1.1067, lr=9.96e-06]Steps:  14%|█▎        | 685/5000 [2:33:45<14:45:57, 12.32s/it, loss=1.1067, lr=9.96e-06]Steps:  14%|█▎        | 685/5000 [2:33:45<14:45:57, 12.32s/it, loss=0.4193, lr=9.96e-06]Steps:  14%|█▎        | 686/5000 [2:33:58<14:44:49, 12.31s/it, loss=0.4193, lr=9.96e-06]Steps:  14%|█▎        | 686/5000 [2:33:58<14:44:49, 12.31s/it, loss=0.8744, lr=9.96e-06]Steps:  14%|█▎        | 687/5000 [2:34:10<14:50:07, 12.38s/it, loss=0.8744, lr=9.96e-06]Steps:  14%|█▎        | 687/5000 [2:34:10<14:50:07, 12.38s/it, loss=1.1041, lr=9.96e-06]Steps:  14%|█▍        | 688/5000 [2:34:23<14:48:56, 12.37s/it, loss=1.1041, lr=9.96e-06]Steps:  14%|█▍        | 688/5000 [2:34:23<14:48:56, 12.37s/it, loss=1.0459, lr=9.96e-06]Steps:  14%|█▍        | 689/5000 [2:34:35<14:47:27, 12.35s/it, loss=1.0459, lr=9.96e-06]Steps:  14%|█▍        | 689/5000 [2:34:35<14:47:27, 12.35s/it, loss=0.8577, lr=9.96e-06]Steps:  14%|█▍        | 690/5000 [2:34:47<14:44:34, 12.31s/it, loss=0.8577, lr=9.96e-06]Steps:  14%|█▍        | 690/5000 [2:34:47<14:44:34, 12.31s/it, loss=1.0850, lr=9.96e-06]
[Step 690] Training Debug Info:
  Loss: 0.542232
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0542, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0547, std: 1.3438
  Model pred mean: -0.0586, std: 1.1250
  Sigmas: [0.8828125]... (timesteps: [884.0])

[Step 690] Training Debug Info:
  Loss: 1.115701
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0557, std: 0.9414
  Noise mean: 0.0041, std: 1.0000
  Target mean: -0.0518, std: 1.3750
  Model pred mean: -0.0527, std: 0.8711
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 690] Training Debug Info:
  Loss: 0.369645
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0117, std: 0.8750
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0104, std: 1.3281
  Model pred mean: 0.0094, std: 1.1797
  Sigmas: [0.83203125]... (timesteps: [831.0])

[Step 690] Training Debug Info:
  Loss: 0.425639
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0603, std: 0.9570
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0615, std: 1.3828
  Model pred mean: -0.0605, std: 1.2188
  Sigmas: [0.84375]... (timesteps: [845.0])
Steps:  14%|█▍        | 691/5000 [2:34:59<14:39:47, 12.25s/it, loss=1.0850, lr=9.96e-06]Steps:  14%|█▍        | 691/5000 [2:34:59<14:39:47, 12.25s/it, loss=0.4256, lr=9.96e-06]Steps:  14%|█▍        | 692/5000 [2:35:12<14:41:14, 12.27s/it, loss=0.4256, lr=9.96e-06]Steps:  14%|█▍        | 692/5000 [2:35:12<14:41:14, 12.27s/it, loss=0.4891, lr=9.96e-06]Steps:  14%|█▍        | 693/5000 [2:35:24<14:40:28, 12.27s/it, loss=0.4891, lr=9.96e-06]Steps:  14%|█▍        | 693/5000 [2:35:24<14:40:28, 12.27s/it, loss=0.4644, lr=9.95e-06]Steps:  14%|█▍        | 694/5000 [2:35:36<14:39:06, 12.25s/it, loss=0.4644, lr=9.95e-06]Steps:  14%|█▍        | 694/5000 [2:35:36<14:39:06, 12.25s/it, loss=0.7173, lr=9.95e-06]Steps:  14%|█▍        | 695/5000 [2:35:48<14:38:11, 12.24s/it, loss=0.7173, lr=9.95e-06]Steps:  14%|█▍        | 695/5000 [2:35:48<14:38:11, 12.24s/it, loss=0.3917, lr=9.95e-06]Steps:  14%|█▍        | 696/5000 [2:36:00<14:39:09, 12.26s/it, loss=0.3917, lr=9.95e-06]Steps:  14%|█▍        | 696/5000 [2:36:00<14:39:09, 12.26s/it, loss=1.1000, lr=9.95e-06]Steps:  14%|█▍        | 697/5000 [2:36:13<14:41:24, 12.29s/it, loss=1.1000, lr=9.95e-06]Steps:  14%|█▍        | 697/5000 [2:36:13<14:41:24, 12.29s/it, loss=0.5054, lr=9.95e-06]Steps:  14%|█▍        | 698/5000 [2:36:25<14:42:28, 12.31s/it, loss=0.5054, lr=9.95e-06]Steps:  14%|█▍        | 698/5000 [2:36:25<14:42:28, 12.31s/it, loss=0.7009, lr=9.95e-06]Steps:  14%|█▍        | 699/5000 [2:36:37<14:41:26, 12.30s/it, loss=0.7009, lr=9.95e-06]Steps:  14%|█▍        | 699/5000 [2:36:37<14:41:26, 12.30s/it, loss=1.1636, lr=9.95e-06]Steps:  14%|█▍        | 700/5000 [2:36:50<14:40:22, 12.28s/it, loss=1.1636, lr=9.95e-06]Steps:  14%|█▍        | 700/5000 [2:36:50<14:40:22, 12.28s/it, loss=1.0661, lr=9.95e-06]01/22/2026 10:22:36 - INFO - __main__ - 
[Step 700] ✅ Loss in normal range (1.0661)
01/22/2026 10:22:36 - INFO - __main__ -   Loss avg (last 100): 0.7495
01/22/2026 10:22:36 - INFO - __main__ -   Loss range: [0.3421, 1.1878]

[Step 700] Training Debug Info:
  Loss: 1.139267
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0347, std: 0.9141
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0344, std: 1.3516
  Model pred mean: 0.0287, std: 0.8242
  Sigmas: [0.08984375]... (timesteps: [90.0])

[Step 700] Training Debug Info:
  Loss: 0.376016
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0398, std: 0.9453
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0393, std: 1.3750
  Model pred mean: 0.0403, std: 1.2344
  Sigmas: [0.88671875]... (timesteps: [885.0])

[Step 700] Training Debug Info:
  Loss: 0.511017
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0178, std: 0.9375
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0140, std: 1.3750
  Model pred mean: -0.0221, std: 1.1719
  Sigmas: [0.61328125]... (timesteps: [613.0])

[Step 700] Training Debug Info:
  Loss: 0.756248
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0220, std: 0.9336
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0195, std: 1.3672
  Model pred mean: -0.0004, std: 1.0703
  Sigmas: [0.984375]... (timesteps: [983.0])
Steps:  14%|█▍        | 701/5000 [2:37:02<14:39:08, 12.27s/it, loss=1.0661, lr=9.95e-06]Steps:  14%|█▍        | 701/5000 [2:37:02<14:39:08, 12.27s/it, loss=0.7562, lr=9.95e-06]Steps:  14%|█▍        | 702/5000 [2:37:14<14:40:50, 12.30s/it, loss=0.7562, lr=9.95e-06]Steps:  14%|█▍        | 702/5000 [2:37:14<14:40:50, 12.30s/it, loss=0.9201, lr=9.95e-06]Steps:  14%|█▍        | 703/5000 [2:37:27<14:44:09, 12.35s/it, loss=0.9201, lr=9.95e-06]Steps:  14%|█▍        | 703/5000 [2:37:27<14:44:09, 12.35s/it, loss=0.7860, lr=9.95e-06]Steps:  14%|█▍        | 704/5000 [2:37:39<14:42:38, 12.33s/it, loss=0.7860, lr=9.95e-06]Steps:  14%|█▍        | 704/5000 [2:37:39<14:42:38, 12.33s/it, loss=0.3858, lr=9.95e-06]Steps:  14%|█▍        | 705/5000 [2:37:52<14:44:57, 12.36s/it, loss=0.3858, lr=9.95e-06]Steps:  14%|█▍        | 705/5000 [2:37:52<14:44:57, 12.36s/it, loss=0.4215, lr=9.95e-06]Steps:  14%|█▍        | 706/5000 [2:38:04<14:46:34, 12.39s/it, loss=0.4215, lr=9.95e-06]Steps:  14%|█▍        | 706/5000 [2:38:04<14:46:34, 12.39s/it, loss=0.9390, lr=9.95e-06]Steps:  14%|█▍        | 707/5000 [2:38:16<14:44:32, 12.36s/it, loss=0.9390, lr=9.95e-06]Steps:  14%|█▍        | 707/5000 [2:38:16<14:44:32, 12.36s/it, loss=0.4253, lr=9.95e-06]Steps:  14%|█▍        | 708/5000 [2:38:29<14:43:39, 12.35s/it, loss=0.4253, lr=9.95e-06]Steps:  14%|█▍        | 708/5000 [2:38:29<14:43:39, 12.35s/it, loss=1.1528, lr=9.95e-06]Steps:  14%|█▍        | 709/5000 [2:38:41<14:43:07, 12.35s/it, loss=1.1528, lr=9.95e-06]Steps:  14%|█▍        | 709/5000 [2:38:41<14:43:07, 12.35s/it, loss=0.4623, lr=9.95e-06]Steps:  14%|█▍        | 710/5000 [2:38:53<14:40:50, 12.32s/it, loss=0.4623, lr=9.95e-06]Steps:  14%|█▍        | 710/5000 [2:38:53<14:40:50, 12.32s/it, loss=0.6291, lr=9.95e-06]
[Step 710] Training Debug Info:
  Loss: 1.138759
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0084, std: 0.9375
  Noise mean: 0.0009, std: 0.9961
  Target mean: 0.0093, std: 1.3672
  Model pred mean: 0.0089, std: 0.8594
  Sigmas: [0.1484375]... (timesteps: [148.0])

[Step 710] Training Debug Info:
  Loss: 1.015605
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0067, std: 0.8945
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0060, std: 1.3438
  Model pred mean: -0.0063, std: 0.8828
  Sigmas: [0.32421875]... (timesteps: [325.0])

[Step 710] Training Debug Info:
  Loss: 0.854465
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0369, std: 0.9258
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0354, std: 1.3672
  Model pred mean: -0.0352, std: 1.0000
  Sigmas: [0.357421875]... (timesteps: [358.0])

[Step 710] Training Debug Info:
  Loss: 0.417413
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0020, std: 0.9062
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0011, std: 1.3516
  Model pred mean: -0.0035, std: 1.1875
  Sigmas: [0.8203125]... (timesteps: [819.0])
Steps:  14%|█▍        | 711/5000 [2:39:06<14:41:36, 12.33s/it, loss=0.6291, lr=9.95e-06]Steps:  14%|█▍        | 711/5000 [2:39:06<14:41:36, 12.33s/it, loss=0.4174, lr=9.95e-06]Steps:  14%|█▍        | 712/5000 [2:39:18<14:44:35, 12.38s/it, loss=0.4174, lr=9.95e-06]Steps:  14%|█▍        | 712/5000 [2:39:18<14:44:35, 12.38s/it, loss=1.1271, lr=9.95e-06]Steps:  14%|█▍        | 713/5000 [2:39:30<14:43:11, 12.36s/it, loss=1.1271, lr=9.95e-06]Steps:  14%|█▍        | 713/5000 [2:39:30<14:43:11, 12.36s/it, loss=0.6119, lr=9.94e-06]Steps:  14%|█▍        | 714/5000 [2:39:43<14:42:54, 12.36s/it, loss=0.6119, lr=9.94e-06]Steps:  14%|█▍        | 714/5000 [2:39:43<14:42:54, 12.36s/it, loss=0.4796, lr=9.94e-06]Steps:  14%|█▍        | 715/5000 [2:39:55<14:44:50, 12.39s/it, loss=0.4796, lr=9.94e-06]Steps:  14%|█▍        | 715/5000 [2:39:55<14:44:50, 12.39s/it, loss=0.4178, lr=9.94e-06]Steps:  14%|█▍        | 716/5000 [2:40:07<14:41:50, 12.35s/it, loss=0.4178, lr=9.94e-06]Steps:  14%|█▍        | 716/5000 [2:40:07<14:41:50, 12.35s/it, loss=1.1394, lr=9.94e-06]Steps:  14%|█▍        | 717/5000 [2:40:20<14:39:36, 12.32s/it, loss=1.1394, lr=9.94e-06]Steps:  14%|█▍        | 717/5000 [2:40:20<14:39:36, 12.32s/it, loss=0.4270, lr=9.94e-06]Steps:  14%|█▍        | 718/5000 [2:40:32<14:40:24, 12.34s/it, loss=0.4270, lr=9.94e-06]Steps:  14%|█▍        | 718/5000 [2:40:32<14:40:24, 12.34s/it, loss=1.0383, lr=9.94e-06]Steps:  14%|█▍        | 719/5000 [2:40:44<14:41:01, 12.35s/it, loss=1.0383, lr=9.94e-06]Steps:  14%|█▍        | 719/5000 [2:40:44<14:41:01, 12.35s/it, loss=0.7859, lr=9.94e-06]Steps:  14%|█▍        | 720/5000 [2:40:57<14:40:39, 12.35s/it, loss=0.7859, lr=9.94e-06]Steps:  14%|█▍        | 720/5000 [2:40:57<14:40:39, 12.35s/it, loss=0.3943, lr=9.94e-06]
[Step 720] Training Debug Info:
  Loss: 0.549833
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0049, std: 0.8633
  Noise mean: 0.0006, std: 0.9961
  Target mean: -0.0043, std: 1.3203
  Model pred mean: 0.0127, std: 1.0859
  Sigmas: [0.9609375]... (timesteps: [962.0])

[Step 720] Training Debug Info:
  Loss: 0.459835
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0206, std: 0.9062
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0232, std: 1.3516
  Model pred mean: 0.0265, std: 1.1641
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 720] Training Debug Info:
  Loss: 0.399294
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0025, std: 0.9727
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0032, std: 1.3984
  Model pred mean: 0.0020, std: 1.2500
  Sigmas: [0.8125]... (timesteps: [814.0])

[Step 720] Training Debug Info:
  Loss: 1.049614
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.9102
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0031, std: 1.3516
  Model pred mean: 0.0087, std: 0.9023
  Sigmas: [0.02294921875]... (timesteps: [23.0])
Steps:  14%|█▍        | 721/5000 [2:41:09<14:42:55, 12.38s/it, loss=0.3943, lr=9.94e-06]Steps:  14%|█▍        | 721/5000 [2:41:09<14:42:55, 12.38s/it, loss=1.0496, lr=9.94e-06]Steps:  14%|█▍        | 722/5000 [2:41:22<14:41:46, 12.37s/it, loss=1.0496, lr=9.94e-06]Steps:  14%|█▍        | 722/5000 [2:41:22<14:41:46, 12.37s/it, loss=0.9437, lr=9.94e-06]Steps:  14%|█▍        | 723/5000 [2:41:34<14:39:39, 12.34s/it, loss=0.9437, lr=9.94e-06]Steps:  14%|█▍        | 723/5000 [2:41:34<14:39:39, 12.34s/it, loss=0.5341, lr=9.94e-06]Steps:  14%|█▍        | 724/5000 [2:41:46<14:42:49, 12.39s/it, loss=0.5341, lr=9.94e-06]Steps:  14%|█▍        | 724/5000 [2:41:46<14:42:49, 12.39s/it, loss=1.1277, lr=9.94e-06]Steps:  14%|█▍        | 725/5000 [2:41:59<14:45:15, 12.42s/it, loss=1.1277, lr=9.94e-06]Steps:  14%|█▍        | 725/5000 [2:41:59<14:45:15, 12.42s/it, loss=0.7763, lr=9.94e-06]Steps:  15%|█▍        | 726/5000 [2:42:11<14:43:09, 12.40s/it, loss=0.7763, lr=9.94e-06]Steps:  15%|█▍        | 726/5000 [2:42:11<14:43:09, 12.40s/it, loss=0.5160, lr=9.94e-06]Steps:  15%|█▍        | 727/5000 [2:42:24<14:42:18, 12.39s/it, loss=0.5160, lr=9.94e-06]Steps:  15%|█▍        | 727/5000 [2:42:24<14:42:18, 12.39s/it, loss=1.0720, lr=9.94e-06]Steps:  15%|█▍        | 728/5000 [2:42:36<14:41:38, 12.38s/it, loss=1.0720, lr=9.94e-06]Steps:  15%|█▍        | 728/5000 [2:42:36<14:41:38, 12.38s/it, loss=0.4384, lr=9.94e-06]Steps:  15%|█▍        | 729/5000 [2:42:48<14:42:52, 12.40s/it, loss=0.4384, lr=9.94e-06]Steps:  15%|█▍        | 729/5000 [2:42:48<14:42:52, 12.40s/it, loss=1.1427, lr=9.94e-06]Steps:  15%|█▍        | 730/5000 [2:43:01<14:44:37, 12.43s/it, loss=1.1427, lr=9.94e-06]Steps:  15%|█▍        | 730/5000 [2:43:01<14:44:37, 12.43s/it, loss=1.1705, lr=9.94e-06]
[Step 730] Training Debug Info:
  Loss: 1.079652
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0052, std: 0.9102
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0049, std: 1.3516
  Model pred mean: -0.0043, std: 0.8633
  Sigmas: [0.28515625]... (timesteps: [285.0])

[Step 730] Training Debug Info:
  Loss: 1.090615
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0216, std: 0.9219
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0232, std: 1.3594
  Model pred mean: -0.0184, std: 0.8633
  Sigmas: [0.2412109375]... (timesteps: [241.0])

[Step 730] Training Debug Info:
  Loss: 0.477962
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0104, std: 0.8945
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0121, std: 1.3438
  Model pred mean: 0.0162, std: 1.1406
  Sigmas: [0.71484375]... (timesteps: [713.0])

[Step 730] Training Debug Info:
  Loss: 0.386902
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0250, std: 0.9023
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0244, std: 1.3438
  Model pred mean: -0.0211, std: 1.1875
  Sigmas: [0.765625]... (timesteps: [766.0])
Steps:  15%|█▍        | 731/5000 [2:43:13<14:45:17, 12.44s/it, loss=1.1705, lr=9.94e-06]Steps:  15%|█▍        | 731/5000 [2:43:13<14:45:17, 12.44s/it, loss=0.3869, lr=9.94e-06]Steps:  15%|█▍        | 732/5000 [2:43:26<14:48:46, 12.49s/it, loss=0.3869, lr=9.94e-06]Steps:  15%|█▍        | 732/5000 [2:43:26<14:48:46, 12.49s/it, loss=1.1355, lr=9.93e-06]Steps:  15%|█▍        | 733/5000 [2:43:38<14:46:00, 12.46s/it, loss=1.1355, lr=9.93e-06]Steps:  15%|█▍        | 733/5000 [2:43:38<14:46:00, 12.46s/it, loss=1.2279, lr=9.93e-06]Steps:  15%|█▍        | 734/5000 [2:43:51<14:43:14, 12.42s/it, loss=1.2279, lr=9.93e-06]Steps:  15%|█▍        | 734/5000 [2:43:51<14:43:14, 12.42s/it, loss=1.0098, lr=9.93e-06]Steps:  15%|█▍        | 735/5000 [2:44:03<14:41:21, 12.40s/it, loss=1.0098, lr=9.93e-06]Steps:  15%|█▍        | 735/5000 [2:44:03<14:41:21, 12.40s/it, loss=1.1513, lr=9.93e-06]Steps:  15%|█▍        | 736/5000 [2:44:15<14:41:40, 12.41s/it, loss=1.1513, lr=9.93e-06]Steps:  15%|█▍        | 736/5000 [2:44:15<14:41:40, 12.41s/it, loss=0.7708, lr=9.93e-06]Steps:  15%|█▍        | 737/5000 [2:44:28<14:40:37, 12.39s/it, loss=0.7708, lr=9.93e-06]Steps:  15%|█▍        | 737/5000 [2:44:28<14:40:37, 12.39s/it, loss=1.0563, lr=9.93e-06]Steps:  15%|█▍        | 738/5000 [2:44:40<14:39:08, 12.38s/it, loss=1.0563, lr=9.93e-06]Steps:  15%|█▍        | 738/5000 [2:44:40<14:39:08, 12.38s/it, loss=1.0596, lr=9.93e-06]Steps:  15%|█▍        | 739/5000 [2:44:53<14:43:16, 12.44s/it, loss=1.0596, lr=9.93e-06]Steps:  15%|█▍        | 739/5000 [2:44:53<14:43:16, 12.44s/it, loss=0.3164, lr=9.93e-06]Steps:  15%|█▍        | 740/5000 [2:45:05<14:40:26, 12.40s/it, loss=0.3164, lr=9.93e-06]Steps:  15%|█▍        | 740/5000 [2:45:05<14:40:26, 12.40s/it, loss=0.3675, lr=9.93e-06]
[Step 740] Training Debug Info:
  Loss: 1.168079
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0120, std: 0.9336
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0142, std: 1.3750
  Model pred mean: -0.0041, std: 0.8398
  Sigmas: [0.2265625]... (timesteps: [227.0])

[Step 740] Training Debug Info:
  Loss: 1.007672
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0114, std: 0.8867
  Noise mean: 0.0028, std: 0.9961
  Target mean: 0.0143, std: 1.3359
  Model pred mean: 0.0217, std: 0.8594
  Sigmas: [0.0019989013671875]... (timesteps: [2.0])

[Step 740] Training Debug Info:
  Loss: 0.530941
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0371, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0386, std: 1.3516
  Model pred mean: -0.0352, std: 1.1328
  Sigmas: [0.609375]... (timesteps: [611.0])

[Step 740] Training Debug Info:
  Loss: 0.408360
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0031, std: 0.9023
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0025, std: 1.3516
  Model pred mean: 0.0040, std: 1.1875
  Sigmas: [0.8359375]... (timesteps: [837.0])
Steps:  15%|█▍        | 741/5000 [2:45:17<14:37:49, 12.37s/it, loss=0.3675, lr=9.93e-06]Steps:  15%|█▍        | 741/5000 [2:45:17<14:37:49, 12.37s/it, loss=0.4084, lr=9.93e-06]Steps:  15%|█▍        | 742/5000 [2:45:30<14:36:42, 12.35s/it, loss=0.4084, lr=9.93e-06]Steps:  15%|█▍        | 742/5000 [2:45:30<14:36:42, 12.35s/it, loss=0.4481, lr=9.93e-06]Steps:  15%|█▍        | 743/5000 [2:45:42<14:29:22, 12.25s/it, loss=0.4481, lr=9.93e-06]Steps:  15%|█▍        | 743/5000 [2:45:42<14:29:22, 12.25s/it, loss=0.4050, lr=9.93e-06]Steps:  15%|█▍        | 744/5000 [2:45:54<14:25:07, 12.20s/it, loss=0.4050, lr=9.93e-06]Steps:  15%|█▍        | 744/5000 [2:45:54<14:25:07, 12.20s/it, loss=0.4930, lr=9.93e-06]Steps:  15%|█▍        | 745/5000 [2:46:06<14:21:26, 12.15s/it, loss=0.4930, lr=9.93e-06]Steps:  15%|█▍        | 745/5000 [2:46:06<14:21:26, 12.15s/it, loss=0.9745, lr=9.93e-06]Steps:  15%|█▍        | 746/5000 [2:46:18<14:20:59, 12.14s/it, loss=0.9745, lr=9.93e-06]Steps:  15%|█▍        | 746/5000 [2:46:18<14:20:59, 12.14s/it, loss=1.1761, lr=9.93e-06]Steps:  15%|█▍        | 747/5000 [2:46:30<14:18:53, 12.12s/it, loss=1.1761, lr=9.93e-06]Steps:  15%|█▍        | 747/5000 [2:46:30<14:18:53, 12.12s/it, loss=0.4787, lr=9.93e-06]Steps:  15%|█▍        | 748/5000 [2:46:42<14:19:49, 12.13s/it, loss=0.4787, lr=9.93e-06]Steps:  15%|█▍        | 748/5000 [2:46:42<14:19:49, 12.13s/it, loss=0.5306, lr=9.93e-06]Steps:  15%|█▍        | 749/5000 [2:46:54<14:17:52, 12.11s/it, loss=0.5306, lr=9.93e-06]Steps:  15%|█▍        | 749/5000 [2:46:54<14:17:52, 12.11s/it, loss=1.1587, lr=9.92e-06]Steps:  15%|█▌        | 750/5000 [2:47:06<14:14:07, 12.06s/it, loss=1.1587, lr=9.92e-06]Steps:  15%|█▌        | 750/5000 [2:47:06<14:14:07, 12.06s/it, loss=1.1676, lr=9.92e-06]
[Step 750] Training Debug Info:
  Loss: 1.000379
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0078, std: 0.9297
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0063, std: 1.3672
  Model pred mean: -0.0105, std: 0.9375
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 750] Training Debug Info:
  Loss: 0.723833
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0227, std: 0.9648
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0215, std: 1.3906
  Model pred mean: -0.0120, std: 1.0859
  Sigmas: [0.95703125]... (timesteps: [956.0])

[Step 750] Training Debug Info:
  Loss: 0.721129
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0374, std: 0.9141
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0371, std: 1.3516
  Model pred mean: -0.0383, std: 1.0703
  Sigmas: [0.435546875]... (timesteps: [436.0])

[Step 750] Training Debug Info:
  Loss: 0.495000
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0018, std: 0.9219
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0015, std: 1.3594
  Model pred mean: -0.0000, std: 1.1641
  Sigmas: [0.67578125]... (timesteps: [676.0])
Steps:  15%|█▌        | 751/5000 [2:47:18<14:15:41, 12.08s/it, loss=1.1676, lr=9.92e-06]Steps:  15%|█▌        | 751/5000 [2:47:18<14:15:41, 12.08s/it, loss=0.4950, lr=9.92e-06]Steps:  15%|█▌        | 752/5000 [2:47:30<14:17:07, 12.11s/it, loss=0.4950, lr=9.92e-06]Steps:  15%|█▌        | 752/5000 [2:47:30<14:17:07, 12.11s/it, loss=0.3940, lr=9.92e-06]Steps:  15%|█▌        | 753/5000 [2:47:42<14:13:20, 12.06s/it, loss=0.3940, lr=9.92e-06]Steps:  15%|█▌        | 753/5000 [2:47:42<14:13:20, 12.06s/it, loss=1.0174, lr=9.92e-06]Steps:  15%|█▌        | 754/5000 [2:47:54<14:13:45, 12.06s/it, loss=1.0174, lr=9.92e-06]Steps:  15%|█▌        | 754/5000 [2:47:54<14:13:45, 12.06s/it, loss=1.0661, lr=9.92e-06]Steps:  15%|█▌        | 755/5000 [2:48:06<14:12:51, 12.05s/it, loss=1.0661, lr=9.92e-06]Steps:  15%|█▌        | 755/5000 [2:48:06<14:12:51, 12.05s/it, loss=0.4001, lr=9.92e-06]Steps:  15%|█▌        | 756/5000 [2:48:19<14:11:58, 12.04s/it, loss=0.4001, lr=9.92e-06]Steps:  15%|█▌        | 756/5000 [2:48:19<14:11:58, 12.04s/it, loss=0.6812, lr=9.92e-06]Steps:  15%|█▌        | 757/5000 [2:48:31<14:15:30, 12.10s/it, loss=0.6812, lr=9.92e-06]Steps:  15%|█▌        | 757/5000 [2:48:31<14:15:30, 12.10s/it, loss=0.4882, lr=9.92e-06]Steps:  15%|█▌        | 758/5000 [2:48:43<14:14:13, 12.08s/it, loss=0.4882, lr=9.92e-06]Steps:  15%|█▌        | 758/5000 [2:48:43<14:14:13, 12.08s/it, loss=0.3930, lr=9.92e-06]Steps:  15%|█▌        | 759/5000 [2:48:55<14:15:33, 12.10s/it, loss=0.3930, lr=9.92e-06]Steps:  15%|█▌        | 759/5000 [2:48:55<14:15:33, 12.10s/it, loss=0.9974, lr=9.92e-06]Steps:  15%|█▌        | 760/5000 [2:49:07<14:17:00, 12.13s/it, loss=0.9974, lr=9.92e-06]Steps:  15%|█▌        | 760/5000 [2:49:07<14:17:00, 12.13s/it, loss=0.5773, lr=9.92e-06]
[Step 760] Training Debug Info:
  Loss: 0.414090
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0312, std: 0.9414
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0337, std: 1.3750
  Model pred mean: -0.0249, std: 1.2188
  Sigmas: [0.78515625]... (timesteps: [785.0])

[Step 760] Training Debug Info:
  Loss: 1.018528
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0135, std: 0.9141
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0136, std: 1.3516
  Model pred mean: 0.0067, std: 0.8984
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 760] Training Debug Info:
  Loss: 0.643940
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0090, std: 0.9141
  Noise mean: 0.0027, std: 0.9961
  Target mean: -0.0063, std: 1.3516
  Model pred mean: -0.0019, std: 1.0938
  Sigmas: [0.984375]... (timesteps: [985.0])

[Step 760] Training Debug Info:
  Loss: 1.188291
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0053, std: 0.8906
  Noise mean: 0.0002, std: 0.9961
  Target mean: 0.0056, std: 1.3359
  Model pred mean: 0.0013, std: 0.7734
  Sigmas: [0.1943359375]... (timesteps: [194.0])
Steps:  15%|█▌        | 761/5000 [2:49:19<14:14:31, 12.10s/it, loss=0.5773, lr=9.92e-06]Steps:  15%|█▌        | 761/5000 [2:49:19<14:14:31, 12.10s/it, loss=1.1883, lr=9.92e-06]Steps:  15%|█▌        | 762/5000 [2:49:31<14:13:00, 12.08s/it, loss=1.1883, lr=9.92e-06]Steps:  15%|█▌        | 762/5000 [2:49:31<14:13:00, 12.08s/it, loss=0.6544, lr=9.92e-06]Steps:  15%|█▌        | 763/5000 [2:49:43<14:12:38, 12.07s/it, loss=0.6544, lr=9.92e-06]Steps:  15%|█▌        | 763/5000 [2:49:43<14:12:38, 12.07s/it, loss=0.7464, lr=9.92e-06]Steps:  15%|█▌        | 764/5000 [2:49:55<14:12:44, 12.08s/it, loss=0.7464, lr=9.92e-06]Steps:  15%|█▌        | 764/5000 [2:49:55<14:12:44, 12.08s/it, loss=0.4100, lr=9.92e-06]Steps:  15%|█▌        | 765/5000 [2:50:07<14:10:59, 12.06s/it, loss=0.4100, lr=9.92e-06]Steps:  15%|█▌        | 765/5000 [2:50:07<14:10:59, 12.06s/it, loss=1.1000, lr=9.91e-06]Steps:  15%|█▌        | 766/5000 [2:50:20<14:16:51, 12.14s/it, loss=1.1000, lr=9.91e-06]Steps:  15%|█▌        | 766/5000 [2:50:20<14:16:51, 12.14s/it, loss=0.5079, lr=9.91e-06]Steps:  15%|█▌        | 767/5000 [2:50:32<14:14:00, 12.10s/it, loss=0.5079, lr=9.91e-06]Steps:  15%|█▌        | 767/5000 [2:50:32<14:14:00, 12.10s/it, loss=1.1036, lr=9.91e-06]Steps:  15%|█▌        | 768/5000 [2:50:44<14:12:05, 12.08s/it, loss=1.1036, lr=9.91e-06]Steps:  15%|█▌        | 768/5000 [2:50:44<14:12:05, 12.08s/it, loss=0.7909, lr=9.91e-06]Steps:  15%|█▌        | 769/5000 [2:50:56<14:16:14, 12.14s/it, loss=0.7909, lr=9.91e-06]Steps:  15%|█▌        | 769/5000 [2:50:56<14:16:14, 12.14s/it, loss=1.0918, lr=9.91e-06]Steps:  15%|█▌        | 770/5000 [2:51:08<14:20:09, 12.20s/it, loss=1.0918, lr=9.91e-06]Steps:  15%|█▌        | 770/5000 [2:51:08<14:20:09, 12.20s/it, loss=0.8527, lr=9.91e-06]
[Step 770] Training Debug Info:
  Loss: 0.496196
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0062, std: 0.9297
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0085, std: 1.3594
  Model pred mean: -0.0039, std: 1.1641
  Sigmas: [0.640625]... (timesteps: [640.0])

[Step 770] Training Debug Info:
  Loss: 0.430407
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0576, std: 0.9297
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0574, std: 1.3594
  Model pred mean: -0.0540, std: 1.2031
  Sigmas: [0.88671875]... (timesteps: [888.0])

[Step 770] Training Debug Info:
  Loss: 0.456605
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0496, std: 0.9219
  Noise mean: -0.0039, std: 1.0000
  Target mean: -0.0535, std: 1.3594
  Model pred mean: -0.0483, std: 1.1797
  Sigmas: [0.76953125]... (timesteps: [769.0])

[Step 770] Training Debug Info:
  Loss: 0.587526
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0081, std: 0.9180
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0046, std: 1.3594
  Model pred mean: -0.0044, std: 1.1094
  Sigmas: [0.58203125]... (timesteps: [582.0])
Steps:  15%|█▌        | 771/5000 [2:51:21<14:22:23, 12.24s/it, loss=0.8527, lr=9.91e-06]Steps:  15%|█▌        | 771/5000 [2:51:21<14:22:23, 12.24s/it, loss=0.5875, lr=9.91e-06]Steps:  15%|█▌        | 772/5000 [2:51:33<14:24:28, 12.27s/it, loss=0.5875, lr=9.91e-06]Steps:  15%|█▌        | 772/5000 [2:51:33<14:24:28, 12.27s/it, loss=1.0032, lr=9.91e-06]Steps:  15%|█▌        | 773/5000 [2:51:45<14:27:08, 12.31s/it, loss=1.0032, lr=9.91e-06]Steps:  15%|█▌        | 773/5000 [2:51:45<14:27:08, 12.31s/it, loss=1.1495, lr=9.91e-06]Steps:  15%|█▌        | 774/5000 [2:51:58<14:26:44, 12.31s/it, loss=1.1495, lr=9.91e-06]Steps:  15%|█▌        | 774/5000 [2:51:58<14:26:44, 12.31s/it, loss=1.1399, lr=9.91e-06]Steps:  16%|█▌        | 775/5000 [2:52:10<14:29:45, 12.35s/it, loss=1.1399, lr=9.91e-06]Steps:  16%|█▌        | 775/5000 [2:52:10<14:29:45, 12.35s/it, loss=1.0416, lr=9.91e-06]Steps:  16%|█▌        | 776/5000 [2:52:22<14:27:56, 12.33s/it, loss=1.0416, lr=9.91e-06]Steps:  16%|█▌        | 776/5000 [2:52:22<14:27:56, 12.33s/it, loss=1.1366, lr=9.91e-06]Steps:  16%|█▌        | 777/5000 [2:52:35<14:28:40, 12.34s/it, loss=1.1366, lr=9.91e-06]Steps:  16%|█▌        | 777/5000 [2:52:35<14:28:40, 12.34s/it, loss=0.4048, lr=9.91e-06]Steps:  16%|█▌        | 778/5000 [2:52:47<14:30:36, 12.37s/it, loss=0.4048, lr=9.91e-06]Steps:  16%|█▌        | 778/5000 [2:52:47<14:30:36, 12.37s/it, loss=1.1636, lr=9.91e-06]Steps:  16%|█▌        | 779/5000 [2:53:00<14:30:23, 12.37s/it, loss=1.1636, lr=9.91e-06]Steps:  16%|█▌        | 779/5000 [2:53:00<14:30:23, 12.37s/it, loss=1.1255, lr=9.91e-06]Steps:  16%|█▌        | 780/5000 [2:53:12<14:28:50, 12.35s/it, loss=1.1255, lr=9.91e-06]Steps:  16%|█▌        | 780/5000 [2:53:12<14:28:50, 12.35s/it, loss=0.6981, lr=9.90e-06]
[Step 780] Training Debug Info:
  Loss: 0.910500
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0250, std: 0.9414
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0232, std: 1.3750
  Model pred mean: -0.0259, std: 0.9922
  Sigmas: [0.361328125]... (timesteps: [362.0])

[Step 780] Training Debug Info:
  Loss: 0.656359
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0136, std: 0.9062
  Noise mean: -0.0029, std: 1.0000
  Target mean: 0.0107, std: 1.3516
  Model pred mean: 0.0142, std: 1.0859
  Sigmas: [0.5546875]... (timesteps: [555.0])

[Step 780] Training Debug Info:
  Loss: 1.146718
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0022, std: 0.9297
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0029, std: 1.3672
  Model pred mean: 0.0006, std: 0.8438
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 780] Training Debug Info:
  Loss: 0.503049
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0096, std: 1.3359
  Model pred mean: -0.0090, std: 1.1328
  Sigmas: [0.671875]... (timesteps: [673.0])
Steps:  16%|█▌        | 781/5000 [2:53:24<14:28:58, 12.36s/it, loss=0.6981, lr=9.90e-06]Steps:  16%|█▌        | 781/5000 [2:53:24<14:28:58, 12.36s/it, loss=0.5030, lr=9.90e-06]Steps:  16%|█▌        | 782/5000 [2:53:37<14:29:34, 12.37s/it, loss=0.5030, lr=9.90e-06]Steps:  16%|█▌        | 782/5000 [2:53:37<14:29:34, 12.37s/it, loss=1.0442, lr=9.90e-06]Steps:  16%|█▌        | 783/5000 [2:53:49<14:28:43, 12.36s/it, loss=1.0442, lr=9.90e-06]Steps:  16%|█▌        | 783/5000 [2:53:49<14:28:43, 12.36s/it, loss=0.4373, lr=9.90e-06]Steps:  16%|█▌        | 784/5000 [2:54:01<14:29:51, 12.38s/it, loss=0.4373, lr=9.90e-06]Steps:  16%|█▌        | 784/5000 [2:54:01<14:29:51, 12.38s/it, loss=0.4753, lr=9.90e-06]Steps:  16%|█▌        | 785/5000 [2:54:14<14:26:18, 12.33s/it, loss=0.4753, lr=9.90e-06]Steps:  16%|█▌        | 785/5000 [2:54:14<14:26:18, 12.33s/it, loss=0.4107, lr=9.90e-06]Steps:  16%|█▌        | 786/5000 [2:54:26<14:29:26, 12.38s/it, loss=0.4107, lr=9.90e-06]Steps:  16%|█▌        | 786/5000 [2:54:26<14:29:26, 12.38s/it, loss=0.8253, lr=9.90e-06]Steps:  16%|█▌        | 787/5000 [2:54:39<14:29:51, 12.39s/it, loss=0.8253, lr=9.90e-06]Steps:  16%|█▌        | 787/5000 [2:54:39<14:29:51, 12.39s/it, loss=0.6423, lr=9.90e-06]Steps:  16%|█▌        | 788/5000 [2:54:51<14:28:51, 12.38s/it, loss=0.6423, lr=9.90e-06]Steps:  16%|█▌        | 788/5000 [2:54:51<14:28:51, 12.38s/it, loss=1.1174, lr=9.90e-06]Steps:  16%|█▌        | 789/5000 [2:55:03<14:26:19, 12.34s/it, loss=1.1174, lr=9.90e-06]Steps:  16%|█▌        | 789/5000 [2:55:03<14:26:19, 12.34s/it, loss=1.0289, lr=9.90e-06]Steps:  16%|█▌        | 790/5000 [2:55:16<14:26:37, 12.35s/it, loss=1.0289, lr=9.90e-06]Steps:  16%|█▌        | 790/5000 [2:55:16<14:26:37, 12.35s/it, loss=1.2159, lr=9.90e-06]
[Step 790] Training Debug Info:
  Loss: 0.395951
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0092, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0097, std: 1.3516
  Model pred mean: 0.0125, std: 1.2109
  Sigmas: [0.9296875]... (timesteps: [929.0])

[Step 790] Training Debug Info:
  Loss: 1.139401
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0095, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0098, std: 1.3594
  Model pred mean: -0.0081, std: 0.8398
  Sigmas: [0.205078125]... (timesteps: [205.0])

[Step 790] Training Debug Info:
  Loss: 0.409943
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0084, std: 0.8750
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0077, std: 1.3281
  Model pred mean: 0.0092, std: 1.1719
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 790] Training Debug Info:
  Loss: 1.060830
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0013, std: 0.9336
  Noise mean: -0.0038, std: 1.0000
  Target mean: -0.0050, std: 1.3672
  Model pred mean: -0.0053, std: 0.8945
  Sigmas: [0.035888671875]... (timesteps: [36.0])
Steps:  16%|█▌        | 791/5000 [2:55:28<14:26:32, 12.35s/it, loss=1.2159, lr=9.90e-06]Steps:  16%|█▌        | 791/5000 [2:55:28<14:26:32, 12.35s/it, loss=1.0608, lr=9.90e-06]Steps:  16%|█▌        | 792/5000 [2:55:40<14:25:52, 12.35s/it, loss=1.0608, lr=9.90e-06]Steps:  16%|█▌        | 792/5000 [2:55:40<14:25:52, 12.35s/it, loss=0.4644, lr=9.90e-06]Steps:  16%|█▌        | 793/5000 [2:55:53<14:29:48, 12.41s/it, loss=0.4644, lr=9.90e-06]Steps:  16%|█▌        | 793/5000 [2:55:53<14:29:48, 12.41s/it, loss=0.6156, lr=9.90e-06]Steps:  16%|█▌        | 794/5000 [2:56:05<14:28:09, 12.38s/it, loss=0.6156, lr=9.90e-06]Steps:  16%|█▌        | 794/5000 [2:56:05<14:28:09, 12.38s/it, loss=0.3922, lr=9.90e-06]Steps:  16%|█▌        | 795/5000 [2:56:17<14:25:59, 12.36s/it, loss=0.3922, lr=9.90e-06]Steps:  16%|█▌        | 795/5000 [2:56:17<14:25:59, 12.36s/it, loss=0.6442, lr=9.89e-06]Steps:  16%|█▌        | 796/5000 [2:56:30<14:28:28, 12.40s/it, loss=0.6442, lr=9.89e-06]Steps:  16%|█▌        | 796/5000 [2:56:30<14:28:28, 12.40s/it, loss=0.8286, lr=9.89e-06]Steps:  16%|█▌        | 797/5000 [2:56:42<14:20:31, 12.28s/it, loss=0.8286, lr=9.89e-06]Steps:  16%|█▌        | 797/5000 [2:56:42<14:20:31, 12.28s/it, loss=0.4679, lr=9.89e-06]Steps:  16%|█▌        | 798/5000 [2:56:54<14:13:56, 12.19s/it, loss=0.4679, lr=9.89e-06]Steps:  16%|█▌        | 798/5000 [2:56:54<14:13:56, 12.19s/it, loss=1.1406, lr=9.89e-06]Steps:  16%|█▌        | 799/5000 [2:57:06<14:07:14, 12.10s/it, loss=1.1406, lr=9.89e-06]Steps:  16%|█▌        | 799/5000 [2:57:06<14:07:14, 12.10s/it, loss=0.3468, lr=9.89e-06]Steps:  16%|█▌        | 800/5000 [2:57:18<14:06:14, 12.09s/it, loss=0.3468, lr=9.89e-06]Steps:  16%|█▌        | 800/5000 [2:57:18<14:06:14, 12.09s/it, loss=0.9669, lr=9.89e-06]01/22/2026 10:43:05 - INFO - __main__ - 
[Step 800] ✅ Loss in normal range (0.9669)
01/22/2026 10:43:05 - INFO - __main__ -   Loss avg (last 100): 0.7724
01/22/2026 10:43:05 - INFO - __main__ -   Loss range: [0.3164, 1.2279]
01/22/2026 10:43:05 - INFO - __main__ - 
🔍 Running validation at step 800...
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 800 (parquet mode)...
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 800...
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 10:43:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 10:43:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 10:43:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 10:43:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 10:43:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 10:44:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 10:44:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 10:44:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 10:44:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 10:44:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 10:44:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 10:45:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 10:45:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:45:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 10:45:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:45:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 10:45:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 10:46:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 10:46:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 10:46:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 10:46:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 10:46:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 10:46:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.44it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 10:47:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800/step000800_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 10:47:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 10:47:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 10:47:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_000800
01/22/2026 10:47:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 800] Training Debug Info:
  Loss: 1.104484
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0085, std: 0.9688
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0107, std: 1.3906
  Model pred mean: -0.0095, std: 0.9180
  Sigmas: [0.216796875]... (timesteps: [217.0])

[Step 800] Training Debug Info:
  Loss: 1.081667
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0398, std: 0.9258
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0425, std: 1.3594
  Model pred mean: -0.0339, std: 0.8867
  Sigmas: [0.06005859375]... (timesteps: [60.0])

[Step 800] Training Debug Info:
  Loss: 0.779523
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0166, std: 1.0000
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0188, std: 1.4141
  Model pred mean: -0.0197, std: 1.0859
  Sigmas: [0.9765625]... (timesteps: [976.0])

[Step 800] Training Debug Info:
  Loss: 1.075674
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0311, std: 0.9570
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0325, std: 1.3828
  Model pred mean: -0.0281, std: 0.9141
  Sigmas: [0.049072265625]... (timesteps: [49.0])
Steps:  16%|█▌        | 801/5000 [3:01:41<102:01:54, 87.48s/it, loss=0.9669, lr=9.89e-06]Steps:  16%|█▌        | 801/5000 [3:01:41<102:01:54, 87.48s/it, loss=1.0757, lr=9.89e-06]Steps:  16%|█▌        | 802/5000 [3:01:53<75:34:11, 64.80s/it, loss=1.0757, lr=9.89e-06] Steps:  16%|█▌        | 802/5000 [3:01:53<75:34:11, 64.80s/it, loss=0.4485, lr=9.89e-06]Steps:  16%|█▌        | 803/5000 [3:02:05<57:03:12, 48.94s/it, loss=0.4485, lr=9.89e-06]Steps:  16%|█▌        | 803/5000 [3:02:05<57:03:12, 48.94s/it, loss=0.6399, lr=9.89e-06]Steps:  16%|█▌        | 804/5000 [3:02:17<44:06:26, 37.84s/it, loss=0.6399, lr=9.89e-06]Steps:  16%|█▌        | 804/5000 [3:02:17<44:06:26, 37.84s/it, loss=1.1242, lr=9.89e-06]Steps:  16%|█▌        | 805/5000 [3:02:29<35:04:42, 30.10s/it, loss=1.1242, lr=9.89e-06]Steps:  16%|█▌        | 805/5000 [3:02:29<35:04:42, 30.10s/it, loss=1.1716, lr=9.89e-06]Steps:  16%|█▌        | 806/5000 [3:02:41<28:46:26, 24.70s/it, loss=1.1716, lr=9.89e-06]Steps:  16%|█▌        | 806/5000 [3:02:41<28:46:26, 24.70s/it, loss=0.3918, lr=9.89e-06]Steps:  16%|█▌        | 807/5000 [3:02:53<24:18:03, 20.86s/it, loss=0.3918, lr=9.89e-06]Steps:  16%|█▌        | 807/5000 [3:02:53<24:18:03, 20.86s/it, loss=1.1399, lr=9.89e-06]Steps:  16%|█▌        | 808/5000 [3:03:05<21:10:10, 18.18s/it, loss=1.1399, lr=9.89e-06]Steps:  16%|█▌        | 808/5000 [3:03:05<21:10:10, 18.18s/it, loss=1.1542, lr=9.88e-06]Steps:  16%|█▌        | 809/5000 [3:03:17<18:59:20, 16.31s/it, loss=1.1542, lr=9.88e-06]Steps:  16%|█▌        | 809/5000 [3:03:17<18:59:20, 16.31s/it, loss=1.1708, lr=9.88e-06]Steps:  16%|█▌        | 810/5000 [3:03:29<17:27:43, 15.00s/it, loss=1.1708, lr=9.88e-06]Steps:  16%|█▌        | 810/5000 [3:03:29<17:27:43, 15.00s/it, loss=0.6041, lr=9.88e-06]
[Step 810] Training Debug Info:
  Loss: 0.584094
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.8828
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0010, std: 1.3359
  Model pred mean: 0.0033, std: 1.0859
  Sigmas: [0.60546875]... (timesteps: [604.0])

[Step 810] Training Debug Info:
  Loss: 0.873715
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0027, std: 0.9688
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0018, std: 1.3984
  Model pred mean: -0.0038, std: 1.0234
  Sigmas: [0.3984375]... (timesteps: [399.0])

[Step 810] Training Debug Info:
  Loss: 1.069304
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0009, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0005, std: 1.3672
  Model pred mean: 0.0006, std: 0.9062
  Sigmas: [0.052978515625]... (timesteps: [53.0])

[Step 810] Training Debug Info:
  Loss: 1.087356
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0173, std: 0.8945
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0199, std: 1.3359
  Model pred mean: 0.0182, std: 0.8438
  Sigmas: [0.275390625]... (timesteps: [276.0])
Steps:  16%|█▌        | 811/5000 [3:03:41<16:22:12, 14.07s/it, loss=0.6041, lr=9.88e-06]Steps:  16%|█▌        | 811/5000 [3:03:41<16:22:12, 14.07s/it, loss=1.0874, lr=9.88e-06]Steps:  16%|█▌        | 812/5000 [3:03:53<15:35:03, 13.40s/it, loss=1.0874, lr=9.88e-06]Steps:  16%|█▌        | 812/5000 [3:03:53<15:35:03, 13.40s/it, loss=0.7538, lr=9.88e-06]Steps:  16%|█▋        | 813/5000 [3:04:05<15:04:12, 12.96s/it, loss=0.7538, lr=9.88e-06]Steps:  16%|█▋        | 813/5000 [3:04:05<15:04:12, 12.96s/it, loss=0.8894, lr=9.88e-06]Steps:  16%|█▋        | 814/5000 [3:04:17<14:44:54, 12.68s/it, loss=0.8894, lr=9.88e-06]Steps:  16%|█▋        | 814/5000 [3:04:17<14:44:54, 12.68s/it, loss=0.3956, lr=9.88e-06]Steps:  16%|█▋        | 815/5000 [3:04:28<14:28:35, 12.45s/it, loss=0.3956, lr=9.88e-06]Steps:  16%|█▋        | 815/5000 [3:04:28<14:28:35, 12.45s/it, loss=0.4610, lr=9.88e-06]Steps:  16%|█▋        | 816/5000 [3:04:40<14:17:24, 12.30s/it, loss=0.4610, lr=9.88e-06]Steps:  16%|█▋        | 816/5000 [3:04:40<14:17:24, 12.30s/it, loss=0.3755, lr=9.88e-06]Steps:  16%|█▋        | 817/5000 [3:04:52<14:08:10, 12.17s/it, loss=0.3755, lr=9.88e-06]Steps:  16%|█▋        | 817/5000 [3:04:52<14:08:10, 12.17s/it, loss=1.1160, lr=9.88e-06]Steps:  16%|█▋        | 818/5000 [3:05:04<14:02:21, 12.09s/it, loss=1.1160, lr=9.88e-06]Steps:  16%|█▋        | 818/5000 [3:05:04<14:02:21, 12.09s/it, loss=0.5773, lr=9.88e-06]Steps:  16%|█▋        | 819/5000 [3:05:16<13:58:47, 12.04s/it, loss=0.5773, lr=9.88e-06]Steps:  16%|█▋        | 819/5000 [3:05:16<13:58:47, 12.04s/it, loss=1.1116, lr=9.88e-06]Steps:  16%|█▋        | 820/5000 [3:05:28<13:57:24, 12.02s/it, loss=1.1116, lr=9.88e-06]Steps:  16%|█▋        | 820/5000 [3:05:28<13:57:24, 12.02s/it, loss=0.5417, lr=9.88e-06]
[Step 820] Training Debug Info:
  Loss: 0.818500
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0056, std: 0.9219
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0058, std: 1.3594
  Model pred mean: 0.0024, std: 1.0000
  Sigmas: [0.439453125]... (timesteps: [440.0])

[Step 820] Training Debug Info:
  Loss: 1.081231
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0167, std: 0.9453
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0194, std: 1.3750
  Model pred mean: -0.0145, std: 0.8828
  Sigmas: [0.08203125]... (timesteps: [82.0])

[Step 820] Training Debug Info:
  Loss: 0.460966
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0337, std: 0.9102
  Noise mean: 0.0007, std: 1.0078
  Target mean: -0.0332, std: 1.3594
  Model pred mean: -0.0303, std: 1.1641
  Sigmas: [0.63671875]... (timesteps: [635.0])

[Step 820] Training Debug Info:
  Loss: 1.176672
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0077, std: 0.8945
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0045, std: 1.3438
  Model pred mean: -0.0079, std: 0.7812
  Sigmas: [0.2109375]... (timesteps: [211.0])
Steps:  16%|█▋        | 821/5000 [3:05:40<13:54:08, 11.98s/it, loss=0.5417, lr=9.88e-06]Steps:  16%|█▋        | 821/5000 [3:05:40<13:54:08, 11.98s/it, loss=1.1767, lr=9.87e-06]Steps:  16%|█▋        | 822/5000 [3:05:52<13:51:02, 11.93s/it, loss=1.1767, lr=9.87e-06]Steps:  16%|█▋        | 822/5000 [3:05:52<13:51:02, 11.93s/it, loss=0.9503, lr=9.87e-06]Steps:  16%|█▋        | 823/5000 [3:06:04<13:52:01, 11.95s/it, loss=0.9503, lr=9.87e-06]Steps:  16%|█▋        | 823/5000 [3:06:04<13:52:01, 11.95s/it, loss=1.1810, lr=9.87e-06]Steps:  16%|█▋        | 824/5000 [3:06:16<13:52:03, 11.95s/it, loss=1.1810, lr=9.87e-06]Steps:  16%|█▋        | 824/5000 [3:06:16<13:52:03, 11.95s/it, loss=1.1660, lr=9.87e-06]Steps:  16%|█▋        | 825/5000 [3:06:28<13:51:41, 11.95s/it, loss=1.1660, lr=9.87e-06]Steps:  16%|█▋        | 825/5000 [3:06:28<13:51:41, 11.95s/it, loss=0.3740, lr=9.87e-06]Steps:  17%|█▋        | 826/5000 [3:06:40<13:50:37, 11.94s/it, loss=0.3740, lr=9.87e-06]Steps:  17%|█▋        | 826/5000 [3:06:40<13:50:37, 11.94s/it, loss=0.6024, lr=9.87e-06]Steps:  17%|█▋        | 827/5000 [3:06:52<13:50:44, 11.94s/it, loss=0.6024, lr=9.87e-06]Steps:  17%|█▋        | 827/5000 [3:06:52<13:50:44, 11.94s/it, loss=1.0570, lr=9.87e-06]Steps:  17%|█▋        | 828/5000 [3:07:03<13:50:21, 11.94s/it, loss=1.0570, lr=9.87e-06]Steps:  17%|█▋        | 828/5000 [3:07:03<13:50:21, 11.94s/it, loss=0.6614, lr=9.87e-06]Steps:  17%|█▋        | 829/5000 [3:07:15<13:48:11, 11.91s/it, loss=0.6614, lr=9.87e-06]Steps:  17%|█▋        | 829/5000 [3:07:15<13:48:11, 11.91s/it, loss=0.7692, lr=9.87e-06]Steps:  17%|█▋        | 830/5000 [3:07:27<13:47:18, 11.90s/it, loss=0.7692, lr=9.87e-06]Steps:  17%|█▋        | 830/5000 [3:07:27<13:47:18, 11.90s/it, loss=0.8490, lr=9.87e-06]
[Step 830] Training Debug Info:
  Loss: 0.647415
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0071, std: 0.9141
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0054, std: 1.3516
  Model pred mean: -0.0287, std: 1.0703
  Sigmas: [0.98828125]... (timesteps: [987.0])

[Step 830] Training Debug Info:
  Loss: 0.516166
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0261, std: 0.9961
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0262, std: 1.4141
  Model pred mean: -0.0221, std: 1.2109
  Sigmas: [0.58984375]... (timesteps: [589.0])

[Step 830] Training Debug Info:
  Loss: 0.522783
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0063, std: 0.9062
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0052, std: 1.3516
  Model pred mean: 0.0064, std: 1.1328
  Sigmas: [0.63671875]... (timesteps: [636.0])

[Step 830] Training Debug Info:
  Loss: 0.489868
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0194, std: 0.8828
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0176, std: 1.3359
  Model pred mean: -0.0240, std: 1.1328
  Sigmas: [0.71484375]... (timesteps: [714.0])
Steps:  17%|█▋        | 831/5000 [3:07:39<13:47:49, 11.91s/it, loss=0.8490, lr=9.87e-06]Steps:  17%|█▋        | 831/5000 [3:07:39<13:47:49, 11.91s/it, loss=0.4899, lr=9.87e-06]Steps:  17%|█▋        | 832/5000 [3:07:51<13:49:24, 11.94s/it, loss=0.4899, lr=9.87e-06]Steps:  17%|█▋        | 832/5000 [3:07:51<13:49:24, 11.94s/it, loss=0.6310, lr=9.87e-06]Steps:  17%|█▋        | 833/5000 [3:08:03<13:53:18, 12.00s/it, loss=0.6310, lr=9.87e-06]Steps:  17%|█▋        | 833/5000 [3:08:03<13:53:18, 12.00s/it, loss=0.4677, lr=9.87e-06]Steps:  17%|█▋        | 834/5000 [3:08:15<13:51:54, 11.98s/it, loss=0.4677, lr=9.87e-06]Steps:  17%|█▋        | 834/5000 [3:08:15<13:51:54, 11.98s/it, loss=0.3775, lr=9.86e-06]Steps:  17%|█▋        | 835/5000 [3:08:27<13:50:07, 11.96s/it, loss=0.3775, lr=9.86e-06]Steps:  17%|█▋        | 835/5000 [3:08:27<13:50:07, 11.96s/it, loss=0.9635, lr=9.86e-06]Steps:  17%|█▋        | 836/5000 [3:08:39<13:48:45, 11.94s/it, loss=0.9635, lr=9.86e-06]Steps:  17%|█▋        | 836/5000 [3:08:39<13:48:45, 11.94s/it, loss=1.0949, lr=9.86e-06]Steps:  17%|█▋        | 837/5000 [3:08:51<13:48:45, 11.94s/it, loss=1.0949, lr=9.86e-06]Steps:  17%|█▋        | 837/5000 [3:08:51<13:48:45, 11.94s/it, loss=0.4295, lr=9.86e-06]Steps:  17%|█▋        | 838/5000 [3:09:03<13:47:26, 11.93s/it, loss=0.4295, lr=9.86e-06]Steps:  17%|█▋        | 838/5000 [3:09:03<13:47:26, 11.93s/it, loss=0.8150, lr=9.86e-06]Steps:  17%|█▋        | 839/5000 [3:09:15<13:47:07, 11.93s/it, loss=0.8150, lr=9.86e-06]Steps:  17%|█▋        | 839/5000 [3:09:15<13:47:07, 11.93s/it, loss=0.5118, lr=9.86e-06]Steps:  17%|█▋        | 840/5000 [3:09:27<13:48:30, 11.95s/it, loss=0.5118, lr=9.86e-06]Steps:  17%|█▋        | 840/5000 [3:09:27<13:48:30, 11.95s/it, loss=0.5031, lr=9.86e-06]
[Step 840] Training Debug Info:
  Loss: 1.028816
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0286, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0284, std: 1.3594
  Model pred mean: -0.0293, std: 0.8984
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 840] Training Debug Info:
  Loss: 1.109889
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0425, std: 0.9102
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0435, std: 1.3516
  Model pred mean: 0.0361, std: 0.8398
  Sigmas: [0.302734375]... (timesteps: [302.0])

[Step 840] Training Debug Info:
  Loss: 0.443992
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0219, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0209, std: 1.3594
  Model pred mean: 0.0156, std: 1.1797
  Sigmas: [0.91015625]... (timesteps: [912.0])

[Step 840] Training Debug Info:
  Loss: 1.089659
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0149, std: 0.8906
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0145, std: 1.3359
  Model pred mean: -0.0198, std: 0.8359
  Sigmas: [0.220703125]... (timesteps: [221.0])
Steps:  17%|█▋        | 841/5000 [3:09:39<13:49:48, 11.97s/it, loss=0.5031, lr=9.86e-06]Steps:  17%|█▋        | 841/5000 [3:09:39<13:49:48, 11.97s/it, loss=1.0897, lr=9.86e-06]Steps:  17%|█▋        | 842/5000 [3:09:51<13:51:23, 12.00s/it, loss=1.0897, lr=9.86e-06]Steps:  17%|█▋        | 842/5000 [3:09:51<13:51:23, 12.00s/it, loss=1.0949, lr=9.86e-06]Steps:  17%|█▋        | 843/5000 [3:10:03<13:49:25, 11.97s/it, loss=1.0949, lr=9.86e-06]Steps:  17%|█▋        | 843/5000 [3:10:03<13:49:25, 11.97s/it, loss=0.4584, lr=9.86e-06]Steps:  17%|█▋        | 844/5000 [3:10:15<13:47:53, 11.95s/it, loss=0.4584, lr=9.86e-06]Steps:  17%|█▋        | 844/5000 [3:10:15<13:47:53, 11.95s/it, loss=1.0813, lr=9.86e-06]Steps:  17%|█▋        | 845/5000 [3:10:27<13:46:35, 11.94s/it, loss=1.0813, lr=9.86e-06]Steps:  17%|█▋        | 845/5000 [3:10:27<13:46:35, 11.94s/it, loss=0.4127, lr=9.86e-06]Steps:  17%|█▋        | 846/5000 [3:10:39<13:45:34, 11.92s/it, loss=0.4127, lr=9.86e-06]Steps:  17%|█▋        | 846/5000 [3:10:39<13:45:34, 11.92s/it, loss=0.4299, lr=9.85e-06]Steps:  17%|█▋        | 847/5000 [3:10:51<13:47:36, 11.96s/it, loss=0.4299, lr=9.85e-06]Steps:  17%|█▋        | 847/5000 [3:10:51<13:47:36, 11.96s/it, loss=0.3808, lr=9.85e-06]Steps:  17%|█▋        | 848/5000 [3:11:02<13:46:51, 11.95s/it, loss=0.3808, lr=9.85e-06]Steps:  17%|█▋        | 848/5000 [3:11:02<13:46:51, 11.95s/it, loss=0.7941, lr=9.85e-06]Steps:  17%|█▋        | 849/5000 [3:11:14<13:46:29, 11.95s/it, loss=0.7941, lr=9.85e-06]Steps:  17%|█▋        | 849/5000 [3:11:14<13:46:29, 11.95s/it, loss=0.6349, lr=9.85e-06]Steps:  17%|█▋        | 850/5000 [3:11:26<13:48:25, 11.98s/it, loss=0.6349, lr=9.85e-06]Steps:  17%|█▋        | 850/5000 [3:11:26<13:48:25, 11.98s/it, loss=0.4281, lr=9.85e-06]
[Step 850] Training Debug Info:
  Loss: 1.046981
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0032, std: 1.0000
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0012, std: 1.4141
  Model pred mean: -0.0067, std: 0.9805
  Sigmas: [0.28125]... (timesteps: [281.0])

[Step 850] Training Debug Info:
  Loss: 0.339758
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0320, std: 0.9180
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0344, std: 1.3594
  Model pred mean: 0.0259, std: 1.2266
  Sigmas: [0.86328125]... (timesteps: [862.0])

[Step 850] Training Debug Info:
  Loss: 1.142352
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0332, std: 0.9531
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0354, std: 1.3828
  Model pred mean: 0.0327, std: 0.8828
  Sigmas: [0.17578125]... (timesteps: [176.0])

[Step 850] Training Debug Info:
  Loss: 1.140599
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0151, std: 0.8867
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0129, std: 1.3359
  Model pred mean: -0.0148, std: 0.8125
  Sigmas: [0.26953125]... (timesteps: [270.0])
Steps:  17%|█▋        | 851/5000 [3:11:39<13:50:02, 12.00s/it, loss=0.4281, lr=9.85e-06]Steps:  17%|█▋        | 851/5000 [3:11:39<13:50:02, 12.00s/it, loss=1.1406, lr=9.85e-06]Steps:  17%|█▋        | 852/5000 [3:11:50<13:47:07, 11.96s/it, loss=1.1406, lr=9.85e-06]Steps:  17%|█▋        | 852/5000 [3:11:50<13:47:07, 11.96s/it, loss=0.4752, lr=9.85e-06]Steps:  17%|█▋        | 853/5000 [3:12:02<13:45:05, 11.94s/it, loss=0.4752, lr=9.85e-06]Steps:  17%|█▋        | 853/5000 [3:12:02<13:45:05, 11.94s/it, loss=0.5247, lr=9.85e-06]Steps:  17%|█▋        | 854/5000 [3:12:14<13:48:27, 11.99s/it, loss=0.5247, lr=9.85e-06]Steps:  17%|█▋        | 854/5000 [3:12:14<13:48:27, 11.99s/it, loss=0.4193, lr=9.85e-06]Steps:  17%|█▋        | 855/5000 [3:12:26<13:47:10, 11.97s/it, loss=0.4193, lr=9.85e-06]Steps:  17%|█▋        | 855/5000 [3:12:26<13:47:10, 11.97s/it, loss=1.1111, lr=9.85e-06]Steps:  17%|█▋        | 856/5000 [3:12:38<13:45:42, 11.96s/it, loss=1.1111, lr=9.85e-06]Steps:  17%|█▋        | 856/5000 [3:12:38<13:45:42, 11.96s/it, loss=0.4564, lr=9.85e-06]Steps:  17%|█▋        | 857/5000 [3:12:50<13:45:31, 11.96s/it, loss=0.4564, lr=9.85e-06]Steps:  17%|█▋        | 857/5000 [3:12:50<13:45:31, 11.96s/it, loss=0.4335, lr=9.85e-06]Steps:  17%|█▋        | 858/5000 [3:13:02<13:44:20, 11.94s/it, loss=0.4335, lr=9.85e-06]Steps:  17%|█▋        | 858/5000 [3:13:02<13:44:20, 11.94s/it, loss=0.8388, lr=9.84e-06]Steps:  17%|█▋        | 859/5000 [3:13:14<13:45:05, 11.95s/it, loss=0.8388, lr=9.84e-06]Steps:  17%|█▋        | 859/5000 [3:13:14<13:45:05, 11.95s/it, loss=0.3844, lr=9.84e-06]Steps:  17%|█▋        | 860/5000 [3:13:26<13:48:42, 12.01s/it, loss=0.3844, lr=9.84e-06]Steps:  17%|█▋        | 860/5000 [3:13:26<13:48:42, 12.01s/it, loss=0.6582, lr=9.84e-06]
[Step 860] Training Debug Info:
  Loss: 0.426391
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0132, std: 0.8789
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0128, std: 1.3281
  Model pred mean: -0.0060, std: 1.1719
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 860] Training Debug Info:
  Loss: 0.612157
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0060, std: 0.8633
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0067, std: 1.3203
  Model pred mean: 0.0065, std: 1.0625
  Sigmas: [0.62890625]... (timesteps: [630.0])

[Step 860] Training Debug Info:
  Loss: 0.924603
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0042, std: 0.9141
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0033, std: 1.3594
  Model pred mean: -0.0064, std: 0.9492
  Sigmas: [0.361328125]... (timesteps: [362.0])

[Step 860] Training Debug Info:
  Loss: 1.094444
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0081, std: 0.9219
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0071, std: 1.3594
  Model pred mean: -0.0092, std: 0.8672
  Sigmas: [0.06103515625]... (timesteps: [61.0])
Steps:  17%|█▋        | 861/5000 [3:13:38<13:45:30, 11.97s/it, loss=0.6582, lr=9.84e-06]Steps:  17%|█▋        | 861/5000 [3:13:38<13:45:30, 11.97s/it, loss=1.0944, lr=9.84e-06]Steps:  17%|█▋        | 862/5000 [3:13:50<13:44:05, 11.95s/it, loss=1.0944, lr=9.84e-06]Steps:  17%|█▋        | 862/5000 [3:13:50<13:44:05, 11.95s/it, loss=0.4255, lr=9.84e-06]Steps:  17%|█▋        | 863/5000 [3:14:02<13:42:41, 11.93s/it, loss=0.4255, lr=9.84e-06]Steps:  17%|█▋        | 863/5000 [3:14:02<13:42:41, 11.93s/it, loss=0.4688, lr=9.84e-06]Steps:  17%|█▋        | 864/5000 [3:14:14<13:42:06, 11.93s/it, loss=0.4688, lr=9.84e-06]Steps:  17%|█▋        | 864/5000 [3:14:14<13:42:06, 11.93s/it, loss=0.7098, lr=9.84e-06]Steps:  17%|█▋        | 865/5000 [3:14:26<13:40:39, 11.91s/it, loss=0.7098, lr=9.84e-06]Steps:  17%|█▋        | 865/5000 [3:14:26<13:40:39, 11.91s/it, loss=0.7034, lr=9.84e-06]Steps:  17%|█▋        | 866/5000 [3:14:38<13:39:32, 11.89s/it, loss=0.7034, lr=9.84e-06]Steps:  17%|█▋        | 866/5000 [3:14:38<13:39:32, 11.89s/it, loss=0.4021, lr=9.84e-06]Steps:  17%|█▋        | 867/5000 [3:14:50<13:42:25, 11.94s/it, loss=0.4021, lr=9.84e-06]Steps:  17%|█▋        | 867/5000 [3:14:50<13:42:25, 11.94s/it, loss=1.1821, lr=9.84e-06]Steps:  17%|█▋        | 868/5000 [3:15:02<13:46:00, 11.99s/it, loss=1.1821, lr=9.84e-06]Steps:  17%|█▋        | 868/5000 [3:15:02<13:46:00, 11.99s/it, loss=0.6141, lr=9.84e-06]Steps:  17%|█▋        | 869/5000 [3:15:14<13:45:06, 11.98s/it, loss=0.6141, lr=9.84e-06]Steps:  17%|█▋        | 869/5000 [3:15:14<13:45:06, 11.98s/it, loss=0.8324, lr=9.84e-06]Steps:  17%|█▋        | 870/5000 [3:15:26<13:43:26, 11.96s/it, loss=0.8324, lr=9.84e-06]Steps:  17%|█▋        | 870/5000 [3:15:26<13:43:26, 11.96s/it, loss=0.4980, lr=9.83e-06]
[Step 870] Training Debug Info:
  Loss: 1.198358
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0045, std: 0.9258
  Noise mean: -0.0036, std: 1.0000
  Target mean: 0.0010, std: 1.3672
  Model pred mean: 0.0080, std: 0.8125
  Sigmas: [0.1953125]... (timesteps: [195.0])

[Step 870] Training Debug Info:
  Loss: 0.390355
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0413, std: 0.9492
  Noise mean: -0.0003, std: 0.9961
  Target mean: -0.0415, std: 1.3750
  Model pred mean: -0.0396, std: 1.2188
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 870] Training Debug Info:
  Loss: 1.105256
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0066, std: 0.8633
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0054, std: 1.3203
  Model pred mean: -0.0042, std: 0.7969
  Sigmas: [0.05810546875]... (timesteps: [58.0])

[Step 870] Training Debug Info:
  Loss: 1.025996
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0302, std: 0.9375
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0289, std: 1.3672
  Model pred mean: -0.0272, std: 0.9258
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:  17%|█▋        | 871/5000 [3:15:37<13:41:09, 11.93s/it, loss=0.4980, lr=9.83e-06]Steps:  17%|█▋        | 871/5000 [3:15:37<13:41:09, 11.93s/it, loss=1.0260, lr=9.83e-06]Steps:  17%|█▋        | 872/5000 [3:15:49<13:41:12, 11.94s/it, loss=1.0260, lr=9.83e-06]Steps:  17%|█▋        | 872/5000 [3:15:49<13:41:12, 11.94s/it, loss=0.4090, lr=9.83e-06]Steps:  17%|█▋        | 873/5000 [3:16:01<13:38:29, 11.90s/it, loss=0.4090, lr=9.83e-06]Steps:  17%|█▋        | 873/5000 [3:16:01<13:38:29, 11.90s/it, loss=0.4203, lr=9.83e-06]Steps:  17%|█▋        | 874/5000 [3:16:13<13:43:09, 11.97s/it, loss=0.4203, lr=9.83e-06]Steps:  17%|█▋        | 874/5000 [3:16:13<13:43:09, 11.97s/it, loss=0.4946, lr=9.83e-06]Steps:  18%|█▊        | 875/5000 [3:16:25<13:41:50, 11.95s/it, loss=0.4946, lr=9.83e-06]Steps:  18%|█▊        | 875/5000 [3:16:25<13:41:50, 11.95s/it, loss=0.6605, lr=9.83e-06]Steps:  18%|█▊        | 876/5000 [3:16:37<13:41:44, 11.96s/it, loss=0.6605, lr=9.83e-06]Steps:  18%|█▊        | 876/5000 [3:16:37<13:41:44, 11.96s/it, loss=0.9006, lr=9.83e-06]Steps:  18%|█▊        | 877/5000 [3:16:49<13:44:21, 12.00s/it, loss=0.9006, lr=9.83e-06]Steps:  18%|█▊        | 877/5000 [3:16:49<13:44:21, 12.00s/it, loss=1.1029, lr=9.83e-06]Steps:  18%|█▊        | 878/5000 [3:17:01<13:47:08, 12.04s/it, loss=1.1029, lr=9.83e-06]Steps:  18%|█▊        | 878/5000 [3:17:01<13:47:08, 12.04s/it, loss=1.1087, lr=9.83e-06]Steps:  18%|█▊        | 879/5000 [3:17:13<13:44:19, 12.00s/it, loss=1.1087, lr=9.83e-06]Steps:  18%|█▊        | 879/5000 [3:17:13<13:44:19, 12.00s/it, loss=0.8065, lr=9.83e-06]Steps:  18%|█▊        | 880/5000 [3:17:25<13:41:36, 11.97s/it, loss=0.8065, lr=9.83e-06]Steps:  18%|█▊        | 880/5000 [3:17:25<13:41:36, 11.97s/it, loss=1.1567, lr=9.83e-06]
[Step 880] Training Debug Info:
  Loss: 0.442087
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0102, std: 0.9258
  Noise mean: 0.0014, std: 0.9961
  Target mean: -0.0089, std: 1.3594
  Model pred mean: -0.0112, std: 1.1797
  Sigmas: [0.84375]... (timesteps: [845.0])

[Step 880] Training Debug Info:
  Loss: 0.442765
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0052, std: 0.9258
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0068, std: 1.3594
  Model pred mean: -0.0064, std: 1.1797
  Sigmas: [0.8984375]... (timesteps: [900.0])

[Step 880] Training Debug Info:
  Loss: 0.621385
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0503, std: 0.9492
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0488, std: 1.3750
  Model pred mean: -0.0422, std: 1.1328
  Sigmas: [0.890625]... (timesteps: [891.0])

[Step 880] Training Debug Info:
  Loss: 0.366878
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0062, std: 0.9258
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0064, std: 1.3594
  Model pred mean: -0.0057, std: 1.2109
  Sigmas: [0.796875]... (timesteps: [796.0])
Steps:  18%|█▊        | 881/5000 [3:17:37<13:44:11, 12.01s/it, loss=1.1567, lr=9.83e-06]Steps:  18%|█▊        | 881/5000 [3:17:37<13:44:11, 12.01s/it, loss=0.3669, lr=9.82e-06]Steps:  18%|█▊        | 882/5000 [3:17:49<13:42:21, 11.98s/it, loss=0.3669, lr=9.82e-06]Steps:  18%|█▊        | 882/5000 [3:17:49<13:42:21, 11.98s/it, loss=0.5370, lr=9.82e-06]Steps:  18%|█▊        | 883/5000 [3:18:01<13:40:23, 11.96s/it, loss=0.5370, lr=9.82e-06]Steps:  18%|█▊        | 883/5000 [3:18:01<13:40:23, 11.96s/it, loss=1.1980, lr=9.82e-06]Steps:  18%|█▊        | 884/5000 [3:18:13<13:38:09, 11.93s/it, loss=1.1980, lr=9.82e-06]Steps:  18%|█▊        | 884/5000 [3:18:13<13:38:09, 11.93s/it, loss=0.3807, lr=9.82e-06]Steps:  18%|█▊        | 885/5000 [3:18:25<13:38:37, 11.94s/it, loss=0.3807, lr=9.82e-06]Steps:  18%|█▊        | 885/5000 [3:18:25<13:38:37, 11.94s/it, loss=0.5849, lr=9.82e-06]Steps:  18%|█▊        | 886/5000 [3:18:37<13:40:11, 11.96s/it, loss=0.5849, lr=9.82e-06]Steps:  18%|█▊        | 886/5000 [3:18:37<13:40:11, 11.96s/it, loss=0.6070, lr=9.82e-06]Steps:  18%|█▊        | 887/5000 [3:18:49<13:44:19, 12.03s/it, loss=0.6070, lr=9.82e-06]Steps:  18%|█▊        | 887/5000 [3:18:49<13:44:19, 12.03s/it, loss=0.8988, lr=9.82e-06]Steps:  18%|█▊        | 888/5000 [3:19:01<13:41:31, 11.99s/it, loss=0.8988, lr=9.82e-06]Steps:  18%|█▊        | 888/5000 [3:19:01<13:41:31, 11.99s/it, loss=0.6247, lr=9.82e-06]Steps:  18%|█▊        | 889/5000 [3:19:13<13:39:47, 11.96s/it, loss=0.6247, lr=9.82e-06]Steps:  18%|█▊        | 889/5000 [3:19:13<13:39:47, 11.96s/it, loss=0.6769, lr=9.82e-06]Steps:  18%|█▊        | 890/5000 [3:19:25<13:39:29, 11.96s/it, loss=0.6769, lr=9.82e-06]Steps:  18%|█▊        | 890/5000 [3:19:25<13:39:29, 11.96s/it, loss=1.1030, lr=9.82e-06]
[Step 890] Training Debug Info:
  Loss: 1.149117
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0071, std: 0.9102
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0046, std: 1.3516
  Model pred mean: -0.0119, std: 0.8203
  Sigmas: [0.1494140625]... (timesteps: [149.0])

[Step 890] Training Debug Info:
  Loss: 1.048290
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0172, std: 0.8945
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0166, std: 1.3438
  Model pred mean: -0.0303, std: 0.8594
  Sigmas: [0.02099609375]... (timesteps: [21.0])

[Step 890] Training Debug Info:
  Loss: 0.367218
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0086, std: 0.9141
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0082, std: 1.3516
  Model pred mean: -0.0047, std: 1.2109
  Sigmas: [0.86328125]... (timesteps: [862.0])

[Step 890] Training Debug Info:
  Loss: 0.415577
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0315, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0312, std: 1.3516
  Model pred mean: 0.0299, std: 1.1875
  Sigmas: [0.765625]... (timesteps: [767.0])
Steps:  18%|█▊        | 891/5000 [3:19:37<13:37:06, 11.93s/it, loss=1.1030, lr=9.82e-06]Steps:  18%|█▊        | 891/5000 [3:19:37<13:37:06, 11.93s/it, loss=0.4156, lr=9.81e-06]Steps:  18%|█▊        | 892/5000 [3:19:49<13:35:20, 11.91s/it, loss=0.4156, lr=9.81e-06]Steps:  18%|█▊        | 892/5000 [3:19:49<13:35:20, 11.91s/it, loss=1.1189, lr=9.81e-06]Steps:  18%|█▊        | 893/5000 [3:20:01<13:35:38, 11.92s/it, loss=1.1189, lr=9.81e-06]Steps:  18%|█▊        | 893/5000 [3:20:01<13:35:38, 11.92s/it, loss=0.4346, lr=9.81e-06]Steps:  18%|█▊        | 894/5000 [3:20:13<13:38:23, 11.96s/it, loss=0.4346, lr=9.81e-06]Steps:  18%|█▊        | 894/5000 [3:20:13<13:38:23, 11.96s/it, loss=0.5166, lr=9.81e-06]Steps:  18%|█▊        | 895/5000 [3:20:25<13:40:27, 11.99s/it, loss=0.5166, lr=9.81e-06]Steps:  18%|█▊        | 895/5000 [3:20:25<13:40:27, 11.99s/it, loss=0.5793, lr=9.81e-06]Steps:  18%|█▊        | 896/5000 [3:20:37<13:37:51, 11.96s/it, loss=0.5793, lr=9.81e-06]Steps:  18%|█▊        | 896/5000 [3:20:37<13:37:51, 11.96s/it, loss=0.7153, lr=9.81e-06]Steps:  18%|█▊        | 897/5000 [3:20:48<13:35:21, 11.92s/it, loss=0.7153, lr=9.81e-06]Steps:  18%|█▊        | 897/5000 [3:20:48<13:35:21, 11.92s/it, loss=1.1538, lr=9.81e-06]Steps:  18%|█▊        | 898/5000 [3:21:00<13:34:47, 11.92s/it, loss=1.1538, lr=9.81e-06]Steps:  18%|█▊        | 898/5000 [3:21:00<13:34:47, 11.92s/it, loss=1.0903, lr=9.81e-06]Steps:  18%|█▊        | 899/5000 [3:21:12<13:33:46, 11.91s/it, loss=1.0903, lr=9.81e-06]Steps:  18%|█▊        | 899/5000 [3:21:12<13:33:46, 11.91s/it, loss=1.0520, lr=9.81e-06]Steps:  18%|█▊        | 900/5000 [3:21:24<13:33:54, 11.91s/it, loss=1.0520, lr=9.81e-06]Steps:  18%|█▊        | 900/5000 [3:21:24<13:33:54, 11.91s/it, loss=0.3916, lr=9.81e-06]01/22/2026 11:07:11 - INFO - __main__ - 
[Step 900] ✅ Loss in normal range (0.3916)
01/22/2026 11:07:11 - INFO - __main__ -   Loss avg (last 100): 0.7401
01/22/2026 11:07:11 - INFO - __main__ -   Loss range: [0.3669, 1.1980]

[Step 900] Training Debug Info:
  Loss: 1.106395
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0160, std: 0.9258
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0162, std: 1.3594
  Model pred mean: -0.0182, std: 0.8594
  Sigmas: [0.1982421875]... (timesteps: [198.0])

[Step 900] Training Debug Info:
  Loss: 0.348771
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0270, std: 0.9219
  Noise mean: -0.0025, std: 0.9961
  Target mean: -0.0294, std: 1.3594
  Model pred mean: -0.0294, std: 1.2188
  Sigmas: [0.77734375]... (timesteps: [776.0])

[Step 900] Training Debug Info:
  Loss: 0.650951
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0104, std: 0.9102
  Noise mean: 0.0019, std: 0.9961
  Target mean: -0.0085, std: 1.3516
  Model pred mean: -0.0159, std: 1.0781
  Sigmas: [0.56640625]... (timesteps: [568.0])

[Step 900] Training Debug Info:
  Loss: 0.440835
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0023, std: 0.8867
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0018, std: 1.3359
  Model pred mean: -0.0083, std: 1.1641
  Sigmas: [0.7421875]... (timesteps: [742.0])
Steps:  18%|█▊        | 901/5000 [3:21:36<13:37:10, 11.96s/it, loss=0.3916, lr=9.81e-06]Steps:  18%|█▊        | 901/5000 [3:21:36<13:37:10, 11.96s/it, loss=0.4408, lr=9.81e-06]Steps:  18%|█▊        | 902/5000 [3:21:48<13:35:30, 11.94s/it, loss=0.4408, lr=9.81e-06]Steps:  18%|█▊        | 902/5000 [3:21:48<13:35:30, 11.94s/it, loss=0.7234, lr=9.80e-06]Steps:  18%|█▊        | 903/5000 [3:22:00<13:36:31, 11.96s/it, loss=0.7234, lr=9.80e-06]Steps:  18%|█▊        | 903/5000 [3:22:00<13:36:31, 11.96s/it, loss=1.0711, lr=9.80e-06]Steps:  18%|█▊        | 904/5000 [3:22:12<13:37:53, 11.98s/it, loss=1.0711, lr=9.80e-06]Steps:  18%|█▊        | 904/5000 [3:22:12<13:37:53, 11.98s/it, loss=0.7448, lr=9.80e-06]Steps:  18%|█▊        | 905/5000 [3:22:24<13:34:56, 11.94s/it, loss=0.7448, lr=9.80e-06]Steps:  18%|█▊        | 905/5000 [3:22:24<13:34:56, 11.94s/it, loss=0.9882, lr=9.80e-06]Steps:  18%|█▊        | 906/5000 [3:22:36<13:34:09, 11.93s/it, loss=0.9882, lr=9.80e-06]Steps:  18%|█▊        | 906/5000 [3:22:36<13:34:09, 11.93s/it, loss=0.9303, lr=9.80e-06]Steps:  18%|█▊        | 907/5000 [3:22:48<13:33:31, 11.93s/it, loss=0.9303, lr=9.80e-06]Steps:  18%|█▊        | 907/5000 [3:22:48<13:33:31, 11.93s/it, loss=1.0628, lr=9.80e-06]Steps:  18%|█▊        | 908/5000 [3:23:00<13:36:07, 11.97s/it, loss=1.0628, lr=9.80e-06]Steps:  18%|█▊        | 908/5000 [3:23:00<13:36:07, 11.97s/it, loss=0.5058, lr=9.80e-06]Steps:  18%|█▊        | 909/5000 [3:23:12<13:35:37, 11.96s/it, loss=0.5058, lr=9.80e-06]Steps:  18%|█▊        | 909/5000 [3:23:12<13:35:37, 11.96s/it, loss=1.1753, lr=9.80e-06]Steps:  18%|█▊        | 910/5000 [3:23:24<13:37:08, 11.99s/it, loss=1.1753, lr=9.80e-06]Steps:  18%|█▊        | 910/5000 [3:23:24<13:37:08, 11.99s/it, loss=0.9396, lr=9.80e-06]
[Step 910] Training Debug Info:
  Loss: 0.461598
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0117, std: 0.9414
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0123, std: 1.3750
  Model pred mean: 0.0064, std: 1.1797
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 910] Training Debug Info:
  Loss: 0.589537
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0165, std: 0.9766
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0160, std: 1.3984
  Model pred mean: 0.0148, std: 1.1719
  Sigmas: [0.61328125]... (timesteps: [615.0])

[Step 910] Training Debug Info:
  Loss: 0.575945
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0549, std: 0.9062
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0569, std: 1.3516
  Model pred mean: -0.0549, std: 1.1172
  Sigmas: [0.55859375]... (timesteps: [557.0])

[Step 910] Training Debug Info:
  Loss: 1.182483
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0049, std: 0.8633
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0054, std: 1.3203
  Model pred mean: -0.0062, std: 0.7500
  Sigmas: [0.2578125]... (timesteps: [258.0])
Steps:  18%|█▊        | 911/5000 [3:23:36<13:36:28, 11.98s/it, loss=0.9396, lr=9.80e-06]Steps:  18%|█▊        | 911/5000 [3:23:36<13:36:28, 11.98s/it, loss=1.1825, lr=9.80e-06]Steps:  18%|█▊        | 912/5000 [3:23:48<13:35:56, 11.98s/it, loss=1.1825, lr=9.80e-06]Steps:  18%|█▊        | 912/5000 [3:23:48<13:35:56, 11.98s/it, loss=1.0736, lr=9.79e-06]Steps:  18%|█▊        | 913/5000 [3:24:00<13:36:38, 11.99s/it, loss=1.0736, lr=9.79e-06]Steps:  18%|█▊        | 913/5000 [3:24:00<13:36:38, 11.99s/it, loss=0.4994, lr=9.79e-06]Steps:  18%|█▊        | 914/5000 [3:24:12<13:35:37, 11.98s/it, loss=0.4994, lr=9.79e-06]Steps:  18%|█▊        | 914/5000 [3:24:12<13:35:37, 11.98s/it, loss=0.4704, lr=9.79e-06]Steps:  18%|█▊        | 915/5000 [3:24:24<13:32:56, 11.94s/it, loss=0.4704, lr=9.79e-06]Steps:  18%|█▊        | 915/5000 [3:24:24<13:32:56, 11.94s/it, loss=0.3610, lr=9.79e-06]Steps:  18%|█▊        | 916/5000 [3:24:35<13:31:31, 11.92s/it, loss=0.3610, lr=9.79e-06]Steps:  18%|█▊        | 916/5000 [3:24:35<13:31:31, 11.92s/it, loss=0.8396, lr=9.79e-06]Steps:  18%|█▊        | 917/5000 [3:24:48<13:36:07, 11.99s/it, loss=0.8396, lr=9.79e-06]Steps:  18%|█▊        | 917/5000 [3:24:48<13:36:07, 11.99s/it, loss=1.1790, lr=9.79e-06]Steps:  18%|█▊        | 918/5000 [3:25:00<13:34:16, 11.97s/it, loss=1.1790, lr=9.79e-06]Steps:  18%|█▊        | 918/5000 [3:25:00<13:34:16, 11.97s/it, loss=0.3804, lr=9.79e-06]Steps:  18%|█▊        | 919/5000 [3:25:11<13:32:02, 11.94s/it, loss=0.3804, lr=9.79e-06]Steps:  18%|█▊        | 919/5000 [3:25:11<13:32:02, 11.94s/it, loss=0.4487, lr=9.79e-06]Steps:  18%|█▊        | 920/5000 [3:25:23<13:30:41, 11.92s/it, loss=0.4487, lr=9.79e-06]Steps:  18%|█▊        | 920/5000 [3:25:23<13:30:41, 11.92s/it, loss=0.3988, lr=9.79e-06]
[Step 920] Training Debug Info:
  Loss: 0.948783
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0053, std: 0.9180
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0060, std: 1.3594
  Model pred mean: 0.0029, std: 0.9453
  Sigmas: [0.388671875]... (timesteps: [389.0])

[Step 920] Training Debug Info:
  Loss: 1.109721
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0234, std: 0.9023
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0243, std: 1.3438
  Model pred mean: -0.0243, std: 0.8438
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 920] Training Debug Info:
  Loss: 0.682832
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0134, std: 0.9023
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0123, std: 1.3438
  Model pred mean: 0.0109, std: 1.0625
  Sigmas: [0.51171875]... (timesteps: [513.0])

[Step 920] Training Debug Info:
  Loss: 0.686934
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0033, std: 0.9219
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0039, std: 1.3594
  Model pred mean: -0.0044, std: 1.0781
  Sigmas: [0.50390625]... (timesteps: [505.0])
Steps:  18%|█▊        | 921/5000 [3:25:35<13:31:37, 11.94s/it, loss=0.3988, lr=9.79e-06]Steps:  18%|█▊        | 921/5000 [3:25:35<13:31:37, 11.94s/it, loss=0.6869, lr=9.79e-06]Steps:  18%|█▊        | 922/5000 [3:25:47<13:33:43, 11.97s/it, loss=0.6869, lr=9.79e-06]Steps:  18%|█▊        | 922/5000 [3:25:47<13:33:43, 11.97s/it, loss=0.4754, lr=9.78e-06]Steps:  18%|█▊        | 923/5000 [3:25:59<13:33:04, 11.97s/it, loss=0.4754, lr=9.78e-06]Steps:  18%|█▊        | 923/5000 [3:25:59<13:33:04, 11.97s/it, loss=0.6048, lr=9.78e-06]Steps:  18%|█▊        | 924/5000 [3:26:12<13:38:24, 12.05s/it, loss=0.6048, lr=9.78e-06]Steps:  18%|█▊        | 924/5000 [3:26:12<13:38:24, 12.05s/it, loss=0.4476, lr=9.78e-06]Steps:  18%|█▊        | 925/5000 [3:26:23<13:35:34, 12.01s/it, loss=0.4476, lr=9.78e-06]Steps:  18%|█▊        | 925/5000 [3:26:23<13:35:34, 12.01s/it, loss=1.1671, lr=9.78e-06]Steps:  19%|█▊        | 926/5000 [3:26:35<13:33:52, 11.99s/it, loss=1.1671, lr=9.78e-06]Steps:  19%|█▊        | 926/5000 [3:26:35<13:33:52, 11.99s/it, loss=0.4305, lr=9.78e-06]Steps:  19%|█▊        | 927/5000 [3:26:47<13:32:57, 11.98s/it, loss=0.4305, lr=9.78e-06]Steps:  19%|█▊        | 927/5000 [3:26:47<13:32:57, 11.98s/it, loss=0.4504, lr=9.78e-06]Steps:  19%|█▊        | 928/5000 [3:26:59<13:33:59, 11.99s/it, loss=0.4504, lr=9.78e-06]Steps:  19%|█▊        | 928/5000 [3:26:59<13:33:59, 11.99s/it, loss=0.6949, lr=9.78e-06]Steps:  19%|█▊        | 929/5000 [3:27:11<13:33:01, 11.98s/it, loss=0.6949, lr=9.78e-06]Steps:  19%|█▊        | 929/5000 [3:27:11<13:33:01, 11.98s/it, loss=0.7308, lr=9.78e-06]Steps:  19%|█▊        | 930/5000 [3:27:23<13:31:27, 11.96s/it, loss=0.7308, lr=9.78e-06]Steps:  19%|█▊        | 930/5000 [3:27:23<13:31:27, 11.96s/it, loss=0.4238, lr=9.78e-06]
[Step 930] Training Debug Info:
  Loss: 1.051393
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0096, std: 0.8828
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0072, std: 1.3359
  Model pred mean: 0.0143, std: 0.8711
  Sigmas: [0.02294921875]... (timesteps: [23.0])

[Step 930] Training Debug Info:
  Loss: 1.183336
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0124, std: 0.8867
  Noise mean: 0.0040, std: 1.0000
  Target mean: 0.0164, std: 1.3359
  Model pred mean: 0.0128, std: 0.7773
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 930] Training Debug Info:
  Loss: 0.632410
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0193, std: 0.8789
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0181, std: 1.3281
  Model pred mean: 0.0249, std: 1.0703
  Sigmas: [0.578125]... (timesteps: [579.0])

[Step 930] Training Debug Info:
  Loss: 1.083853
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0093, std: 1.3750
  Model pred mean: -0.0089, std: 0.9023
  Sigmas: [0.06494140625]... (timesteps: [65.0])
Steps:  19%|█▊        | 931/5000 [3:27:35<13:34:04, 12.00s/it, loss=0.4238, lr=9.78e-06]Steps:  19%|█▊        | 931/5000 [3:27:35<13:34:04, 12.00s/it, loss=1.0839, lr=9.78e-06]Steps:  19%|█▊        | 932/5000 [3:27:47<13:31:46, 11.97s/it, loss=1.0839, lr=9.78e-06]Steps:  19%|█▊        | 932/5000 [3:27:47<13:31:46, 11.97s/it, loss=1.0778, lr=9.77e-06]Steps:  19%|█▊        | 933/5000 [3:27:59<13:29:34, 11.94s/it, loss=1.0778, lr=9.77e-06]Steps:  19%|█▊        | 933/5000 [3:27:59<13:29:34, 11.94s/it, loss=0.5131, lr=9.77e-06]Steps:  19%|█▊        | 934/5000 [3:28:11<13:26:58, 11.91s/it, loss=0.5131, lr=9.77e-06]Steps:  19%|█▊        | 934/5000 [3:28:11<13:26:58, 11.91s/it, loss=0.4850, lr=9.77e-06]Steps:  19%|█▊        | 935/5000 [3:28:23<13:30:19, 11.96s/it, loss=0.4850, lr=9.77e-06]Steps:  19%|█▊        | 935/5000 [3:28:23<13:30:19, 11.96s/it, loss=0.6027, lr=9.77e-06]Steps:  19%|█▊        | 936/5000 [3:28:35<13:27:48, 11.93s/it, loss=0.6027, lr=9.77e-06]Steps:  19%|█▊        | 936/5000 [3:28:35<13:27:48, 11.93s/it, loss=0.9220, lr=9.77e-06]Steps:  19%|█▊        | 937/5000 [3:28:47<13:28:19, 11.94s/it, loss=0.9220, lr=9.77e-06]Steps:  19%|█▊        | 937/5000 [3:28:47<13:28:19, 11.94s/it, loss=1.1554, lr=9.77e-06]Steps:  19%|█▉        | 938/5000 [3:28:59<13:28:16, 11.94s/it, loss=1.1554, lr=9.77e-06]Steps:  19%|█▉        | 938/5000 [3:28:59<13:28:16, 11.94s/it, loss=0.5048, lr=9.77e-06]Steps:  19%|█▉        | 939/5000 [3:29:11<13:28:22, 11.94s/it, loss=0.5048, lr=9.77e-06]Steps:  19%|█▉        | 939/5000 [3:29:11<13:28:22, 11.94s/it, loss=0.4222, lr=9.77e-06]Steps:  19%|█▉        | 940/5000 [3:29:23<13:30:11, 11.97s/it, loss=0.4222, lr=9.77e-06]Steps:  19%|█▉        | 940/5000 [3:29:23<13:30:11, 11.97s/it, loss=0.7562, lr=9.77e-06]
[Step 940] Training Debug Info:
  Loss: 0.750703
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0060, std: 0.9375
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0037, std: 1.3672
  Model pred mean: -0.0064, std: 1.0703
  Sigmas: [0.4296875]... (timesteps: [430.0])

[Step 940] Training Debug Info:
  Loss: 1.100015
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0066, std: 0.9258
  Noise mean: 0.0050, std: 1.0000
  Target mean: 0.0117, std: 1.3672
  Model pred mean: 0.0065, std: 0.8750
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 940] Training Debug Info:
  Loss: 1.134575
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0190, std: 0.9727
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0214, std: 1.3906
  Model pred mean: -0.0181, std: 0.9023
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 940] Training Debug Info:
  Loss: 0.767493
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0398, std: 0.9258
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0366, std: 1.3594
  Model pred mean: 0.0415, std: 1.0469
  Sigmas: [0.453125]... (timesteps: [453.0])
Steps:  19%|█▉        | 941/5000 [3:29:35<13:32:07, 12.00s/it, loss=0.7562, lr=9.77e-06]Steps:  19%|█▉        | 941/5000 [3:29:35<13:32:07, 12.00s/it, loss=0.7675, lr=9.76e-06]Steps:  19%|█▉        | 942/5000 [3:29:47<13:29:28, 11.97s/it, loss=0.7675, lr=9.76e-06]Steps:  19%|█▉        | 942/5000 [3:29:47<13:29:28, 11.97s/it, loss=0.3890, lr=9.76e-06]Steps:  19%|█▉        | 943/5000 [3:29:59<13:26:51, 11.93s/it, loss=0.3890, lr=9.76e-06]Steps:  19%|█▉        | 943/5000 [3:29:59<13:26:51, 11.93s/it, loss=1.2082, lr=9.76e-06]Steps:  19%|█▉        | 944/5000 [3:30:10<13:25:03, 11.91s/it, loss=1.2082, lr=9.76e-06]Steps:  19%|█▉        | 944/5000 [3:30:10<13:25:03, 11.91s/it, loss=0.9804, lr=9.76e-06]Steps:  19%|█▉        | 945/5000 [3:30:22<13:24:49, 11.91s/it, loss=0.9804, lr=9.76e-06]Steps:  19%|█▉        | 945/5000 [3:30:22<13:24:49, 11.91s/it, loss=1.0202, lr=9.76e-06]Steps:  19%|█▉        | 946/5000 [3:30:34<13:23:53, 11.90s/it, loss=1.0202, lr=9.76e-06]Steps:  19%|█▉        | 946/5000 [3:30:34<13:23:53, 11.90s/it, loss=0.5320, lr=9.76e-06]Steps:  19%|█▉        | 947/5000 [3:30:46<13:22:12, 11.88s/it, loss=0.5320, lr=9.76e-06]Steps:  19%|█▉        | 947/5000 [3:30:46<13:22:12, 11.88s/it, loss=0.7955, lr=9.76e-06]Steps:  19%|█▉        | 948/5000 [3:30:58<13:25:35, 11.93s/it, loss=0.7955, lr=9.76e-06]Steps:  19%|█▉        | 948/5000 [3:30:58<13:25:35, 11.93s/it, loss=0.6981, lr=9.76e-06]Steps:  19%|█▉        | 949/5000 [3:31:10<13:27:10, 11.96s/it, loss=0.6981, lr=9.76e-06]Steps:  19%|█▉        | 949/5000 [3:31:10<13:27:10, 11.96s/it, loss=0.4532, lr=9.76e-06]Steps:  19%|█▉        | 950/5000 [3:31:22<13:25:46, 11.94s/it, loss=0.4532, lr=9.76e-06]Steps:  19%|█▉        | 950/5000 [3:31:22<13:25:46, 11.94s/it, loss=0.3663, lr=9.76e-06]
[Step 950] Training Debug Info:
  Loss: 0.458600
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0173, std: 0.9375
  Noise mean: 0.0042, std: 0.9961
  Target mean: -0.0131, std: 1.3672
  Model pred mean: -0.0148, std: 1.2031
  Sigmas: [0.66015625]... (timesteps: [662.0])

[Step 950] Training Debug Info:
  Loss: 0.437381
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0166, std: 0.9023
  Noise mean: -0.0045, std: 1.0000
  Target mean: 0.0120, std: 1.3516
  Model pred mean: 0.0130, std: 1.1719
  Sigmas: [0.8984375]... (timesteps: [900.0])

[Step 950] Training Debug Info:
  Loss: 1.126146
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0067, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0066, std: 1.3516
  Model pred mean: -0.0031, std: 0.8398
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 950] Training Debug Info:
  Loss: 0.748052
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0654, std: 0.9375
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0664, std: 1.3672
  Model pred mean: -0.0304, std: 1.0547
  Sigmas: [0.96875]... (timesteps: [970.0])
Steps:  19%|█▉        | 951/5000 [3:31:34<13:25:12, 11.93s/it, loss=0.3663, lr=9.76e-06]Steps:  19%|█▉        | 951/5000 [3:31:34<13:25:12, 11.93s/it, loss=0.7481, lr=9.75e-06]Steps:  19%|█▉        | 952/5000 [3:31:46<13:25:05, 11.93s/it, loss=0.7481, lr=9.75e-06]Steps:  19%|█▉        | 952/5000 [3:31:46<13:25:05, 11.93s/it, loss=1.2177, lr=9.75e-06]Steps:  19%|█▉        | 953/5000 [3:31:58<13:24:31, 11.93s/it, loss=1.2177, lr=9.75e-06]Steps:  19%|█▉        | 953/5000 [3:31:58<13:24:31, 11.93s/it, loss=0.4175, lr=9.75e-06]Steps:  19%|█▉        | 954/5000 [3:32:10<13:23:55, 11.92s/it, loss=0.4175, lr=9.75e-06]Steps:  19%|█▉        | 954/5000 [3:32:10<13:23:55, 11.92s/it, loss=0.8779, lr=9.75e-06]Steps:  19%|█▉        | 955/5000 [3:32:22<13:27:01, 11.97s/it, loss=0.8779, lr=9.75e-06]Steps:  19%|█▉        | 955/5000 [3:32:22<13:27:01, 11.97s/it, loss=0.5645, lr=9.75e-06]Steps:  19%|█▉        | 956/5000 [3:32:34<13:25:11, 11.95s/it, loss=0.5645, lr=9.75e-06]Steps:  19%|█▉        | 956/5000 [3:32:34<13:25:11, 11.95s/it, loss=1.1227, lr=9.75e-06]Steps:  19%|█▉        | 957/5000 [3:32:46<13:24:32, 11.94s/it, loss=1.1227, lr=9.75e-06]Steps:  19%|█▉        | 957/5000 [3:32:46<13:24:32, 11.94s/it, loss=1.0422, lr=9.75e-06]Steps:  19%|█▉        | 958/5000 [3:32:58<13:25:41, 11.96s/it, loss=1.0422, lr=9.75e-06]Steps:  19%|█▉        | 958/5000 [3:32:58<13:25:41, 11.96s/it, loss=0.9865, lr=9.75e-06]Steps:  19%|█▉        | 959/5000 [3:33:10<13:24:47, 11.95s/it, loss=0.9865, lr=9.75e-06]Steps:  19%|█▉        | 959/5000 [3:33:10<13:24:47, 11.95s/it, loss=1.1346, lr=9.75e-06]Steps:  19%|█▉        | 960/5000 [3:33:21<13:23:51, 11.94s/it, loss=1.1346, lr=9.75e-06]Steps:  19%|█▉        | 960/5000 [3:33:21<13:23:51, 11.94s/it, loss=1.0102, lr=9.74e-06]
[Step 960] Training Debug Info:
  Loss: 1.125583
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0215, std: 0.9219
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0200, std: 1.3594
  Model pred mean: -0.0183, std: 0.8516
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 960] Training Debug Info:
  Loss: 0.623475
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0063, std: 0.9180
  Noise mean: 0.0016, std: 0.9961
  Target mean: 0.0079, std: 1.3516
  Model pred mean: 0.0087, std: 1.0938
  Sigmas: [0.55859375]... (timesteps: [558.0])

[Step 960] Training Debug Info:
  Loss: 0.817363
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0361, std: 0.9414
  Noise mean: 0.0010, std: 0.9961
  Target mean: -0.0352, std: 1.3750
  Model pred mean: -0.0339, std: 1.0312
  Sigmas: [0.38671875]... (timesteps: [386.0])

[Step 960] Training Debug Info:
  Loss: 1.111336
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0063, std: 0.8711
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0061, std: 1.3281
  Model pred mean: -0.0033, std: 0.8047
  Sigmas: [0.27734375]... (timesteps: [278.0])
Steps:  19%|█▉        | 961/5000 [3:33:33<13:23:46, 11.94s/it, loss=1.0102, lr=9.74e-06]Steps:  19%|█▉        | 961/5000 [3:33:33<13:23:46, 11.94s/it, loss=1.1113, lr=9.74e-06]Steps:  19%|█▉        | 962/5000 [3:33:45<13:26:42, 11.99s/it, loss=1.1113, lr=9.74e-06]Steps:  19%|█▉        | 962/5000 [3:33:45<13:26:42, 11.99s/it, loss=0.4381, lr=9.74e-06]Steps:  19%|█▉        | 963/5000 [3:33:57<13:24:36, 11.96s/it, loss=0.4381, lr=9.74e-06]Steps:  19%|█▉        | 963/5000 [3:33:57<13:24:36, 11.96s/it, loss=1.1108, lr=9.74e-06]Steps:  19%|█▉        | 964/5000 [3:34:09<13:22:41, 11.93s/it, loss=1.1108, lr=9.74e-06]Steps:  19%|█▉        | 964/5000 [3:34:09<13:22:41, 11.93s/it, loss=0.4052, lr=9.74e-06]Steps:  19%|█▉        | 965/5000 [3:34:21<13:24:17, 11.96s/it, loss=0.4052, lr=9.74e-06]Steps:  19%|█▉        | 965/5000 [3:34:21<13:24:17, 11.96s/it, loss=1.1085, lr=9.74e-06]Steps:  19%|█▉        | 966/5000 [3:34:33<13:21:53, 11.93s/it, loss=1.1085, lr=9.74e-06]Steps:  19%|█▉        | 966/5000 [3:34:33<13:21:53, 11.93s/it, loss=0.7794, lr=9.74e-06]Steps:  19%|█▉        | 967/5000 [3:34:45<13:25:36, 11.99s/it, loss=0.7794, lr=9.74e-06]Steps:  19%|█▉        | 967/5000 [3:34:45<13:25:36, 11.99s/it, loss=0.5476, lr=9.74e-06]Steps:  19%|█▉        | 968/5000 [3:34:57<13:26:30, 12.00s/it, loss=0.5476, lr=9.74e-06]Steps:  19%|█▉        | 968/5000 [3:34:57<13:26:30, 12.00s/it, loss=1.1312, lr=9.74e-06]Steps:  19%|█▉        | 969/5000 [3:35:09<13:23:54, 11.97s/it, loss=1.1312, lr=9.74e-06]Steps:  19%|█▉        | 969/5000 [3:35:09<13:23:54, 11.97s/it, loss=1.0847, lr=9.73e-06]Steps:  19%|█▉        | 970/5000 [3:35:21<13:23:29, 11.96s/it, loss=1.0847, lr=9.73e-06]Steps:  19%|█▉        | 970/5000 [3:35:21<13:23:29, 11.96s/it, loss=0.7018, lr=9.73e-06]
[Step 970] Training Debug Info:
  Loss: 0.765746
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0233, std: 0.9727
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0251, std: 1.3984
  Model pred mean: -0.0277, std: 1.0859
  Sigmas: [0.435546875]... (timesteps: [435.0])

[Step 970] Training Debug Info:
  Loss: 1.060020
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0654, std: 0.9531
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0649, std: 1.3828
  Model pred mean: -0.0659, std: 0.9180
  Sigmas: [0.0439453125]... (timesteps: [44.0])

[Step 970] Training Debug Info:
  Loss: 1.116030
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0214, std: 0.8945
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0219, std: 1.3438
  Model pred mean: 0.0199, std: 0.8242
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 970] Training Debug Info:
  Loss: 0.512095
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0153, std: 0.9102
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0138, std: 1.3516
  Model pred mean: -0.0156, std: 1.1406
  Sigmas: [0.6171875]... (timesteps: [616.0])
Steps:  19%|█▉        | 971/5000 [3:35:33<13:22:29, 11.95s/it, loss=0.7018, lr=9.73e-06]Steps:  19%|█▉        | 971/5000 [3:35:33<13:22:29, 11.95s/it, loss=0.5121, lr=9.73e-06]Steps:  19%|█▉        | 972/5000 [3:35:45<13:21:21, 11.94s/it, loss=0.5121, lr=9.73e-06]Steps:  19%|█▉        | 972/5000 [3:35:45<13:21:21, 11.94s/it, loss=0.4779, lr=9.73e-06]Steps:  19%|█▉        | 973/5000 [3:35:57<13:20:36, 11.93s/it, loss=0.4779, lr=9.73e-06]Steps:  19%|█▉        | 973/5000 [3:35:57<13:20:36, 11.93s/it, loss=0.9108, lr=9.73e-06]Steps:  19%|█▉        | 974/5000 [3:36:09<13:19:56, 11.92s/it, loss=0.9108, lr=9.73e-06]Steps:  19%|█▉        | 974/5000 [3:36:09<13:19:56, 11.92s/it, loss=0.4828, lr=9.73e-06]Steps:  20%|█▉        | 975/5000 [3:36:21<13:21:55, 11.95s/it, loss=0.4828, lr=9.73e-06]Steps:  20%|█▉        | 975/5000 [3:36:21<13:21:55, 11.95s/it, loss=0.3779, lr=9.73e-06]Steps:  20%|█▉        | 976/5000 [3:36:33<13:24:16, 11.99s/it, loss=0.3779, lr=9.73e-06]Steps:  20%|█▉        | 976/5000 [3:36:33<13:24:16, 11.99s/it, loss=0.3779, lr=9.73e-06]Steps:  20%|█▉        | 977/5000 [3:36:45<13:22:37, 11.97s/it, loss=0.3779, lr=9.73e-06]Steps:  20%|█▉        | 977/5000 [3:36:45<13:22:37, 11.97s/it, loss=1.1587, lr=9.73e-06]Steps:  20%|█▉        | 978/5000 [3:36:57<13:20:49, 11.95s/it, loss=1.1587, lr=9.73e-06]Steps:  20%|█▉        | 978/5000 [3:36:57<13:20:49, 11.95s/it, loss=0.5819, lr=9.72e-06]Steps:  20%|█▉        | 979/5000 [3:37:09<13:19:12, 11.93s/it, loss=0.5819, lr=9.72e-06]Steps:  20%|█▉        | 979/5000 [3:37:09<13:19:12, 11.93s/it, loss=0.6344, lr=9.72e-06]Steps:  20%|█▉        | 980/5000 [3:37:20<13:19:01, 11.93s/it, loss=0.6344, lr=9.72e-06]Steps:  20%|█▉        | 980/5000 [3:37:20<13:19:01, 11.93s/it, loss=0.8521, lr=9.72e-06]
[Step 980] Training Debug Info:
  Loss: 1.103697
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0025, std: 0.9219
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0032, std: 1.3594
  Model pred mean: 0.0011, std: 0.8633
  Sigmas: [0.06494140625]... (timesteps: [65.0])

[Step 980] Training Debug Info:
  Loss: 1.065331
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0242, std: 0.9453
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0260, std: 1.3750
  Model pred mean: -0.0244, std: 0.9141
  Sigmas: [0.271484375]... (timesteps: [272.0])

[Step 980] Training Debug Info:
  Loss: 1.026208
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0420, std: 0.9141
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0391, std: 1.3594
  Model pred mean: -0.0356, std: 0.9023
  Sigmas: [0.010986328125]... (timesteps: [11.0])

[Step 980] Training Debug Info:
  Loss: 0.462979
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0009, std: 0.9219
  Noise mean: -0.0046, std: 1.0000
  Target mean: -0.0055, std: 1.3594
  Model pred mean: -0.0015, std: 1.1797
  Sigmas: [0.7109375]... (timesteps: [712.0])
Steps:  20%|█▉        | 981/5000 [3:37:32<13:18:50, 11.93s/it, loss=0.8521, lr=9.72e-06]Steps:  20%|█▉        | 981/5000 [3:37:32<13:18:50, 11.93s/it, loss=0.4630, lr=9.72e-06]Steps:  20%|█▉        | 982/5000 [3:37:44<13:22:00, 11.98s/it, loss=0.4630, lr=9.72e-06]Steps:  20%|█▉        | 982/5000 [3:37:44<13:22:00, 11.98s/it, loss=0.4550, lr=9.72e-06]Steps:  20%|█▉        | 983/5000 [3:37:57<13:22:34, 11.99s/it, loss=0.4550, lr=9.72e-06]Steps:  20%|█▉        | 983/5000 [3:37:57<13:22:34, 11.99s/it, loss=1.1873, lr=9.72e-06]Steps:  20%|█▉        | 984/5000 [3:38:08<13:20:24, 11.96s/it, loss=1.1873, lr=9.72e-06]Steps:  20%|█▉        | 984/5000 [3:38:08<13:20:24, 11.96s/it, loss=0.4980, lr=9.72e-06]Steps:  20%|█▉        | 985/5000 [3:38:20<13:20:57, 11.97s/it, loss=0.4980, lr=9.72e-06]Steps:  20%|█▉        | 985/5000 [3:38:20<13:20:57, 11.97s/it, loss=1.0575, lr=9.72e-06]Steps:  20%|█▉        | 986/5000 [3:38:32<13:18:22, 11.93s/it, loss=1.0575, lr=9.72e-06]Steps:  20%|█▉        | 986/5000 [3:38:32<13:18:22, 11.93s/it, loss=0.9143, lr=9.71e-06]Steps:  20%|█▉        | 987/5000 [3:38:44<13:17:55, 11.93s/it, loss=0.9143, lr=9.71e-06]Steps:  20%|█▉        | 987/5000 [3:38:44<13:17:55, 11.93s/it, loss=0.5494, lr=9.71e-06]Steps:  20%|█▉        | 988/5000 [3:38:56<13:18:23, 11.94s/it, loss=0.5494, lr=9.71e-06]Steps:  20%|█▉        | 988/5000 [3:38:56<13:18:23, 11.94s/it, loss=0.4663, lr=9.71e-06]Steps:  20%|█▉        | 989/5000 [3:39:08<13:21:02, 11.98s/it, loss=0.4663, lr=9.71e-06]Steps:  20%|█▉        | 989/5000 [3:39:08<13:21:02, 11.98s/it, loss=0.6139, lr=9.71e-06]Steps:  20%|█▉        | 990/5000 [3:39:20<13:18:42, 11.95s/it, loss=0.6139, lr=9.71e-06]Steps:  20%|█▉        | 990/5000 [3:39:20<13:18:42, 11.95s/it, loss=0.4313, lr=9.71e-06]
[Step 990] Training Debug Info:
  Loss: 0.657958
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0079, std: 0.8984
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0061, std: 1.3438
  Model pred mean: -0.0066, std: 1.0703
  Sigmas: [0.5234375]... (timesteps: [524.0])

[Step 990] Training Debug Info:
  Loss: 0.530886
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0236, std: 0.9219
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0254, std: 1.3594
  Model pred mean: -0.0225, std: 1.1406
  Sigmas: [0.59375]... (timesteps: [594.0])

[Step 990] Training Debug Info:
  Loss: 0.491488
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0210, std: 0.8984
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0184, std: 1.3438
  Model pred mean: -0.0199, std: 1.1406
  Sigmas: [0.703125]... (timesteps: [705.0])

[Step 990] Training Debug Info:
  Loss: 1.065545
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0215, std: 0.9102
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0197, std: 1.3516
  Model pred mean: -0.0165, std: 0.8750
  Sigmas: [0.0380859375]... (timesteps: [38.0])
Steps:  20%|█▉        | 991/5000 [3:39:32<13:17:20, 11.93s/it, loss=0.4313, lr=9.71e-06]Steps:  20%|█▉        | 991/5000 [3:39:32<13:17:20, 11.93s/it, loss=1.0655, lr=9.71e-06]Steps:  20%|█▉        | 992/5000 [3:39:44<13:16:19, 11.92s/it, loss=1.0655, lr=9.71e-06]Steps:  20%|█▉        | 992/5000 [3:39:44<13:16:19, 11.92s/it, loss=0.6827, lr=9.71e-06]Steps:  20%|█▉        | 993/5000 [3:39:56<13:16:20, 11.92s/it, loss=0.6827, lr=9.71e-06]Steps:  20%|█▉        | 993/5000 [3:39:56<13:16:20, 11.92s/it, loss=0.5420, lr=9.71e-06]Steps:  20%|█▉        | 994/5000 [3:40:08<13:18:28, 11.96s/it, loss=0.5420, lr=9.71e-06]Steps:  20%|█▉        | 994/5000 [3:40:08<13:18:28, 11.96s/it, loss=1.1132, lr=9.71e-06]Steps:  20%|█▉        | 995/5000 [3:40:20<13:18:40, 11.97s/it, loss=1.1132, lr=9.71e-06]Steps:  20%|█▉        | 995/5000 [3:40:20<13:18:40, 11.97s/it, loss=0.9609, lr=9.70e-06]Steps:  20%|█▉        | 996/5000 [3:40:32<13:17:24, 11.95s/it, loss=0.9609, lr=9.70e-06]Steps:  20%|█▉        | 996/5000 [3:40:32<13:17:24, 11.95s/it, loss=0.9270, lr=9.70e-06]Steps:  20%|█▉        | 997/5000 [3:40:44<13:16:32, 11.94s/it, loss=0.9270, lr=9.70e-06]Steps:  20%|█▉        | 997/5000 [3:40:44<13:16:32, 11.94s/it, loss=0.3941, lr=9.70e-06]Steps:  20%|█▉        | 998/5000 [3:40:56<13:15:48, 11.93s/it, loss=0.3941, lr=9.70e-06]Steps:  20%|█▉        | 998/5000 [3:40:56<13:15:48, 11.93s/it, loss=0.6430, lr=9.70e-06]Steps:  20%|█▉        | 999/5000 [3:41:07<13:15:10, 11.92s/it, loss=0.6430, lr=9.70e-06]Steps:  20%|█▉        | 999/5000 [3:41:07<13:15:10, 11.92s/it, loss=0.5746, lr=9.70e-06]Steps:  20%|██        | 1000/5000 [3:41:19<13:13:53, 11.91s/it, loss=0.5746, lr=9.70e-06]Steps:  20%|██        | 1000/5000 [3:41:19<13:13:53, 11.91s/it, loss=0.9149, lr=9.70e-06]01/22/2026 11:27:06 - INFO - __main__ - 
[Step 1000] ✅ Loss in normal range (0.9149)
01/22/2026 11:27:06 - INFO - __main__ -   Loss avg (last 100): 0.7462
01/22/2026 11:27:06 - INFO - __main__ -   Loss range: [0.3610, 1.2177]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/transformer/diffusion_pytorch_model.safetensors
01/22/2026 11:27:57 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000
01/22/2026 11:27:57 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/accelerator
01/22/2026 11:27:57 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/22/2026 11:29:39 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/accelerator/pytorch_model
01/22/2026 11:29:39 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/accelerator/scheduler.bin
01/22/2026 11:29:39 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/accelerator/sampler.bin
01/22/2026 11:29:39 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-1000/accelerator/random_states_0.pkl
01/22/2026 11:29:39 - INFO - __main__ - 
🔍 Running validation at step 1000...
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1000 (parquet mode)...
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1000...
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 11:29:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.50it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.49it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 11:30:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 11:30:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 11:30:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 11:30:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.13it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 11:30:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 11:30:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 11:31:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 11:31:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 11:31:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 11:31:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 11:31:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 11:31:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 11:32:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 11:32:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 11:32:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 11:32:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 11:32:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 11:32:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 11:33:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 11:33:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 11:33:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 11:33:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 11:33:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000/step001000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 11:33:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 11:33:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 11:33:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001000
01/22/2026 11:33:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1000] Training Debug Info:
  Loss: 0.416283
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0369, std: 0.9219
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0386, std: 1.3594
  Model pred mean: 0.0396, std: 1.2031
  Sigmas: [0.7734375]... (timesteps: [774.0])

[Step 1000] Training Debug Info:
  Loss: 0.839105
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0026, std: 0.8945
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0013, std: 1.3438
  Model pred mean: -0.0003, std: 0.9883
  Sigmas: [0.443359375]... (timesteps: [444.0])

[Step 1000] Training Debug Info:
  Loss: 0.791087
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0208, std: 0.9531
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0227, std: 1.3828
  Model pred mean: -0.0063, std: 1.0859
  Sigmas: [1.0]... (timesteps: [999.0])

[Step 1000] Training Debug Info:
  Loss: 0.720680
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9102
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0234, std: 1.3516
  Model pred mean: -0.0226, std: 1.0625
  Sigmas: [0.49609375]... (timesteps: [496.0])
Steps:  20%|██        | 1001/5000 [3:48:16<148:14:19, 133.45s/it, loss=0.9149, lr=9.70e-06]Steps:  20%|██        | 1001/5000 [3:48:16<148:14:19, 133.45s/it, loss=0.7207, lr=9.70e-06]Steps:  20%|██        | 1002/5000 [3:48:28<107:42:18, 96.98s/it, loss=0.7207, lr=9.70e-06] Steps:  20%|██        | 1002/5000 [3:48:28<107:42:18, 96.98s/it, loss=0.5919, lr=9.70e-06]Steps:  20%|██        | 1003/5000 [3:48:41<79:27:48, 71.57s/it, loss=0.5919, lr=9.70e-06] Steps:  20%|██        | 1003/5000 [3:48:41<79:27:48, 71.57s/it, loss=0.4422, lr=9.69e-06]Steps:  20%|██        | 1004/5000 [3:48:52<59:34:07, 53.67s/it, loss=0.4422, lr=9.69e-06]Steps:  20%|██        | 1004/5000 [3:48:52<59:34:07, 53.67s/it, loss=0.5641, lr=9.69e-06]Steps:  20%|██        | 1005/5000 [3:49:04<45:39:56, 41.15s/it, loss=0.5641, lr=9.69e-06]Steps:  20%|██        | 1005/5000 [3:49:04<45:39:56, 41.15s/it, loss=1.1192, lr=9.69e-06]Steps:  20%|██        | 1006/5000 [3:49:16<35:56:31, 32.40s/it, loss=1.1192, lr=9.69e-06]Steps:  20%|██        | 1006/5000 [3:49:16<35:56:31, 32.40s/it, loss=1.1270, lr=9.69e-06]Steps:  20%|██        | 1007/5000 [3:49:28<29:06:25, 26.24s/it, loss=1.1270, lr=9.69e-06]Steps:  20%|██        | 1007/5000 [3:49:28<29:06:25, 26.24s/it, loss=1.0513, lr=9.69e-06]Steps:  20%|██        | 1008/5000 [3:49:40<24:20:45, 21.96s/it, loss=1.0513, lr=9.69e-06]Steps:  20%|██        | 1008/5000 [3:49:40<24:20:45, 21.96s/it, loss=0.4086, lr=9.69e-06]Steps:  20%|██        | 1009/5000 [3:49:52<21:06:15, 19.04s/it, loss=0.4086, lr=9.69e-06]Steps:  20%|██        | 1009/5000 [3:49:52<21:06:15, 19.04s/it, loss=0.7748, lr=9.69e-06]Steps:  20%|██        | 1010/5000 [3:50:04<18:43:44, 16.90s/it, loss=0.7748, lr=9.69e-06]Steps:  20%|██        | 1010/5000 [3:50:04<18:43:44, 16.90s/it, loss=1.1338, lr=9.69e-06]
[Step 1010] Training Debug Info:
  Loss: 0.613094
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0322, std: 0.8750
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0344, std: 1.3281
  Model pred mean: 0.0295, std: 1.0703
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 1010] Training Debug Info:
  Loss: 1.174570
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0033, std: 0.8984
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0052, std: 1.3438
  Model pred mean: 0.0001, std: 0.7969
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 1010] Training Debug Info:
  Loss: 1.119157
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0378, std: 0.9023
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0391, std: 1.3438
  Model pred mean: -0.0425, std: 0.8320
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 1010] Training Debug Info:
  Loss: 1.080255
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0125, std: 0.9453
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0104, std: 1.3750
  Model pred mean: -0.0166, std: 0.8945
  Sigmas: [0.27734375]... (timesteps: [278.0])
Steps:  20%|██        | 1011/5000 [3:50:16<17:03:40, 15.40s/it, loss=1.1338, lr=9.69e-06]Steps:  20%|██        | 1011/5000 [3:50:16<17:03:40, 15.40s/it, loss=1.0803, lr=9.69e-06]Steps:  20%|██        | 1012/5000 [3:50:28<15:54:19, 14.36s/it, loss=1.0803, lr=9.69e-06]Steps:  20%|██        | 1012/5000 [3:50:28<15:54:19, 14.36s/it, loss=0.9144, lr=9.68e-06]Steps:  20%|██        | 1013/5000 [3:50:40<15:04:58, 13.62s/it, loss=0.9144, lr=9.68e-06]Steps:  20%|██        | 1013/5000 [3:50:40<15:04:58, 13.62s/it, loss=0.7961, lr=9.68e-06]Steps:  20%|██        | 1014/5000 [3:50:52<14:30:51, 13.11s/it, loss=0.7961, lr=9.68e-06]Steps:  20%|██        | 1014/5000 [3:50:52<14:30:51, 13.11s/it, loss=0.3822, lr=9.68e-06]Steps:  20%|██        | 1015/5000 [3:51:04<14:08:06, 12.77s/it, loss=0.3822, lr=9.68e-06]Steps:  20%|██        | 1015/5000 [3:51:04<14:08:06, 12.77s/it, loss=1.0920, lr=9.68e-06]Steps:  20%|██        | 1016/5000 [3:51:16<13:55:07, 12.58s/it, loss=1.0920, lr=9.68e-06]Steps:  20%|██        | 1016/5000 [3:51:16<13:55:07, 12.58s/it, loss=0.7458, lr=9.68e-06]Steps:  20%|██        | 1017/5000 [3:51:28<13:41:48, 12.38s/it, loss=0.7458, lr=9.68e-06]Steps:  20%|██        | 1017/5000 [3:51:28<13:41:48, 12.38s/it, loss=0.9057, lr=9.68e-06]Steps:  20%|██        | 1018/5000 [3:51:40<13:33:17, 12.25s/it, loss=0.9057, lr=9.68e-06]Steps:  20%|██        | 1018/5000 [3:51:40<13:33:17, 12.25s/it, loss=0.9919, lr=9.68e-06]Steps:  20%|██        | 1019/5000 [3:51:52<13:25:43, 12.14s/it, loss=0.9919, lr=9.68e-06]Steps:  20%|██        | 1019/5000 [3:51:52<13:25:43, 12.14s/it, loss=0.6352, lr=9.68e-06]Steps:  20%|██        | 1020/5000 [3:52:04<13:18:42, 12.04s/it, loss=0.6352, lr=9.68e-06]Steps:  20%|██        | 1020/5000 [3:52:04<13:18:42, 12.04s/it, loss=0.6013, lr=9.67e-06]
[Step 1020] Training Debug Info:
  Loss: 1.036997
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0322, std: 0.9023
  Noise mean: -0.0038, std: 1.0000
  Target mean: 0.0284, std: 1.3438
  Model pred mean: 0.0272, std: 0.8789
  Sigmas: [0.326171875]... (timesteps: [327.0])

[Step 1020] Training Debug Info:
  Loss: 0.697739
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0034, std: 0.9258
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0022, std: 1.3672
  Model pred mean: -0.0099, std: 1.0781
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 1020] Training Debug Info:
  Loss: 1.022292
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0282, std: 0.9023
  Noise mean: -0.0020, std: 0.9961
  Target mean: -0.0302, std: 1.3438
  Model pred mean: -0.0255, std: 0.8867
  Sigmas: [0.01202392578125]... (timesteps: [12.0])

[Step 1020] Training Debug Info:
  Loss: 0.595097
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0041, std: 0.8828
  Noise mean: -0.0028, std: 0.9961
  Target mean: 0.0013, std: 1.3281
  Model pred mean: 0.0032, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [988.0])
Steps:  20%|██        | 1021/5000 [3:52:15<13:14:26, 11.98s/it, loss=0.6013, lr=9.67e-06]Steps:  20%|██        | 1021/5000 [3:52:15<13:14:26, 11.98s/it, loss=0.5951, lr=9.67e-06]Steps:  20%|██        | 1022/5000 [3:52:27<13:13:28, 11.97s/it, loss=0.5951, lr=9.67e-06]Steps:  20%|██        | 1022/5000 [3:52:27<13:13:28, 11.97s/it, loss=0.5578, lr=9.67e-06]Steps:  20%|██        | 1023/5000 [3:52:40<13:16:28, 12.02s/it, loss=0.5578, lr=9.67e-06]Steps:  20%|██        | 1023/5000 [3:52:40<13:16:28, 12.02s/it, loss=1.0425, lr=9.67e-06]Steps:  20%|██        | 1024/5000 [3:52:52<13:15:48, 12.01s/it, loss=1.0425, lr=9.67e-06]Steps:  20%|██        | 1024/5000 [3:52:52<13:15:48, 12.01s/it, loss=1.1494, lr=9.67e-06]Steps:  20%|██        | 1025/5000 [3:53:03<13:14:08, 11.99s/it, loss=1.1494, lr=9.67e-06]Steps:  20%|██        | 1025/5000 [3:53:03<13:14:08, 11.99s/it, loss=1.2091, lr=9.67e-06]Steps:  21%|██        | 1026/5000 [3:53:15<13:12:23, 11.96s/it, loss=1.2091, lr=9.67e-06]Steps:  21%|██        | 1026/5000 [3:53:15<13:12:23, 11.96s/it, loss=0.4311, lr=9.67e-06]Steps:  21%|██        | 1027/5000 [3:53:27<13:10:35, 11.94s/it, loss=0.4311, lr=9.67e-06]Steps:  21%|██        | 1027/5000 [3:53:27<13:10:35, 11.94s/it, loss=0.4833, lr=9.67e-06]Steps:  21%|██        | 1028/5000 [3:53:39<13:12:50, 11.98s/it, loss=0.4833, lr=9.67e-06]Steps:  21%|██        | 1028/5000 [3:53:39<13:12:50, 11.98s/it, loss=1.0019, lr=9.66e-06]Steps:  21%|██        | 1029/5000 [3:53:51<13:09:42, 11.93s/it, loss=1.0019, lr=9.66e-06]Steps:  21%|██        | 1029/5000 [3:53:51<13:09:42, 11.93s/it, loss=1.0205, lr=9.66e-06]Steps:  21%|██        | 1030/5000 [3:54:03<13:13:22, 11.99s/it, loss=1.0205, lr=9.66e-06]Steps:  21%|██        | 1030/5000 [3:54:03<13:13:22, 11.99s/it, loss=0.7075, lr=9.66e-06]
[Step 1030] Training Debug Info:
  Loss: 0.399876
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0281, std: 0.8555
  Noise mean: 0.0031, std: 1.0000
  Target mean: 0.0312, std: 1.3203
  Model pred mean: 0.0342, std: 1.1562
  Sigmas: [0.80078125]... (timesteps: [800.0])

[Step 1030] Training Debug Info:
  Loss: 0.889670
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0442, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0437, std: 1.3516
  Model pred mean: -0.0396, std: 0.9766
  Sigmas: [0.345703125]... (timesteps: [345.0])

[Step 1030] Training Debug Info:
  Loss: 0.633759
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0223, std: 0.9023
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0233, std: 1.3438
  Model pred mean: -0.0184, std: 1.0859
  Sigmas: [0.5625]... (timesteps: [561.0])

[Step 1030] Training Debug Info:
  Loss: 0.468942
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0493, std: 0.9375
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0488, std: 1.3750
  Model pred mean: -0.0410, std: 1.1953
  Sigmas: [0.87109375]... (timesteps: [871.0])
Steps:  21%|██        | 1031/5000 [3:54:15<13:11:11, 11.96s/it, loss=0.7075, lr=9.66e-06]Steps:  21%|██        | 1031/5000 [3:54:15<13:11:11, 11.96s/it, loss=0.4689, lr=9.66e-06]Steps:  21%|██        | 1032/5000 [3:54:27<13:11:13, 11.96s/it, loss=0.4689, lr=9.66e-06]Steps:  21%|██        | 1032/5000 [3:54:27<13:11:13, 11.96s/it, loss=0.4062, lr=9.66e-06]Steps:  21%|██        | 1033/5000 [3:54:39<13:13:30, 12.00s/it, loss=0.4062, lr=9.66e-06]Steps:  21%|██        | 1033/5000 [3:54:39<13:13:30, 12.00s/it, loss=1.0269, lr=9.66e-06]Steps:  21%|██        | 1034/5000 [3:54:51<13:12:13, 11.99s/it, loss=1.0269, lr=9.66e-06]Steps:  21%|██        | 1034/5000 [3:54:51<13:12:13, 11.99s/it, loss=0.5977, lr=9.66e-06]Steps:  21%|██        | 1035/5000 [3:55:03<13:10:59, 11.97s/it, loss=0.5977, lr=9.66e-06]Steps:  21%|██        | 1035/5000 [3:55:03<13:10:59, 11.97s/it, loss=0.5731, lr=9.66e-06]Steps:  21%|██        | 1036/5000 [3:55:15<13:16:29, 12.06s/it, loss=0.5731, lr=9.66e-06]Steps:  21%|██        | 1036/5000 [3:55:15<13:16:29, 12.06s/it, loss=0.4974, lr=9.65e-06]Steps:  21%|██        | 1037/5000 [3:55:27<13:14:53, 12.03s/it, loss=0.4974, lr=9.65e-06]Steps:  21%|██        | 1037/5000 [3:55:27<13:14:53, 12.03s/it, loss=0.5685, lr=9.65e-06]Steps:  21%|██        | 1038/5000 [3:55:39<13:12:35, 12.00s/it, loss=0.5685, lr=9.65e-06]Steps:  21%|██        | 1038/5000 [3:55:39<13:12:35, 12.00s/it, loss=0.4839, lr=9.65e-06]Steps:  21%|██        | 1039/5000 [3:55:51<13:09:23, 11.96s/it, loss=0.4839, lr=9.65e-06]Steps:  21%|██        | 1039/5000 [3:55:51<13:09:23, 11.96s/it, loss=0.3844, lr=9.65e-06]Steps:  21%|██        | 1040/5000 [3:56:03<13:08:04, 11.94s/it, loss=0.3844, lr=9.65e-06]Steps:  21%|██        | 1040/5000 [3:56:03<13:08:04, 11.94s/it, loss=0.6325, lr=9.65e-06]
[Step 1040] Training Debug Info:
  Loss: 0.980407
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0293, std: 0.9219
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0291, std: 1.3594
  Model pred mean: -0.0300, std: 0.9375
  Sigmas: [0.30859375]... (timesteps: [308.0])

[Step 1040] Training Debug Info:
  Loss: 0.626125
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0025, std: 0.9570
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0002, std: 1.3828
  Model pred mean: -0.0058, std: 1.1250
  Sigmas: [0.8984375]... (timesteps: [898.0])

[Step 1040] Training Debug Info:
  Loss: 1.140776
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0037, std: 0.9180
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0028, std: 1.3594
  Model pred mean: 0.0024, std: 0.8438
  Sigmas: [0.234375]... (timesteps: [234.0])

[Step 1040] Training Debug Info:
  Loss: 1.046298
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0038, std: 0.9062
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: 0.0004, std: 0.8789
  Sigmas: [0.02294921875]... (timesteps: [23.0])
Steps:  21%|██        | 1041/5000 [3:56:15<13:05:33, 11.91s/it, loss=0.6325, lr=9.65e-06]Steps:  21%|██        | 1041/5000 [3:56:15<13:05:33, 11.91s/it, loss=1.0463, lr=9.65e-06]Steps:  21%|██        | 1042/5000 [3:56:27<13:08:42, 11.96s/it, loss=1.0463, lr=9.65e-06]Steps:  21%|██        | 1042/5000 [3:56:27<13:08:42, 11.96s/it, loss=0.6452, lr=9.65e-06]Steps:  21%|██        | 1043/5000 [3:56:39<13:12:08, 12.01s/it, loss=0.6452, lr=9.65e-06]Steps:  21%|██        | 1043/5000 [3:56:39<13:12:08, 12.01s/it, loss=0.4085, lr=9.65e-06]Steps:  21%|██        | 1044/5000 [3:56:51<13:09:34, 11.98s/it, loss=0.4085, lr=9.65e-06]Steps:  21%|██        | 1044/5000 [3:56:51<13:09:34, 11.98s/it, loss=1.0688, lr=9.64e-06]Steps:  21%|██        | 1045/5000 [3:57:03<13:07:39, 11.95s/it, loss=1.0688, lr=9.64e-06]Steps:  21%|██        | 1045/5000 [3:57:03<13:07:39, 11.95s/it, loss=1.1197, lr=9.64e-06]Steps:  21%|██        | 1046/5000 [3:57:15<13:05:53, 11.93s/it, loss=1.1197, lr=9.64e-06]Steps:  21%|██        | 1046/5000 [3:57:15<13:05:53, 11.93s/it, loss=1.1702, lr=9.64e-06]Steps:  21%|██        | 1047/5000 [3:57:27<13:05:54, 11.93s/it, loss=1.1702, lr=9.64e-06]Steps:  21%|██        | 1047/5000 [3:57:27<13:05:54, 11.93s/it, loss=0.4539, lr=9.64e-06]Steps:  21%|██        | 1048/5000 [3:57:39<13:05:08, 11.92s/it, loss=0.4539, lr=9.64e-06]Steps:  21%|██        | 1048/5000 [3:57:39<13:05:08, 11.92s/it, loss=1.0539, lr=9.64e-06]Steps:  21%|██        | 1049/5000 [3:57:50<13:04:19, 11.91s/it, loss=1.0539, lr=9.64e-06]Steps:  21%|██        | 1049/5000 [3:57:50<13:04:19, 11.91s/it, loss=0.7952, lr=9.64e-06]Steps:  21%|██        | 1050/5000 [3:58:03<13:09:23, 11.99s/it, loss=0.7952, lr=9.64e-06]Steps:  21%|██        | 1050/5000 [3:58:03<13:09:23, 11.99s/it, loss=0.8480, lr=9.64e-06]
[Step 1050] Training Debug Info:
  Loss: 0.553442
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0435, std: 0.9375
  Noise mean: 0.0030, std: 1.0000
  Target mean: -0.0403, std: 1.3672
  Model pred mean: -0.0396, std: 1.1484
  Sigmas: [0.546875]... (timesteps: [545.0])

[Step 1050] Training Debug Info:
  Loss: 0.387341
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0126, std: 0.8594
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0131, std: 1.3203
  Model pred mean: 0.0098, std: 1.1641
  Sigmas: [0.83203125]... (timesteps: [832.0])

[Step 1050] Training Debug Info:
  Loss: 0.593317
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0048, std: 0.9414
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0056, std: 1.3750
  Model pred mean: -0.0066, std: 1.1406
  Sigmas: [0.5625]... (timesteps: [564.0])

[Step 1050] Training Debug Info:
  Loss: 0.842734
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0016, std: 0.9414
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0008, std: 1.3750
  Model pred mean: 0.0047, std: 1.0234
  Sigmas: [0.4140625]... (timesteps: [414.0])
Steps:  21%|██        | 1051/5000 [3:58:15<13:09:48, 12.00s/it, loss=0.8480, lr=9.64e-06]Steps:  21%|██        | 1051/5000 [3:58:15<13:09:48, 12.00s/it, loss=0.8427, lr=9.63e-06]Steps:  21%|██        | 1052/5000 [3:58:27<13:07:51, 11.97s/it, loss=0.8427, lr=9.63e-06]Steps:  21%|██        | 1052/5000 [3:58:27<13:07:51, 11.97s/it, loss=0.8175, lr=9.63e-06]Steps:  21%|██        | 1053/5000 [3:58:39<13:07:13, 11.97s/it, loss=0.8175, lr=9.63e-06]Steps:  21%|██        | 1053/5000 [3:58:39<13:07:13, 11.97s/it, loss=1.0884, lr=9.63e-06]Steps:  21%|██        | 1054/5000 [3:58:50<13:06:22, 11.96s/it, loss=1.0884, lr=9.63e-06]Steps:  21%|██        | 1054/5000 [3:58:50<13:06:22, 11.96s/it, loss=0.4073, lr=9.63e-06]Steps:  21%|██        | 1055/5000 [3:59:02<13:04:32, 11.93s/it, loss=0.4073, lr=9.63e-06]Steps:  21%|██        | 1055/5000 [3:59:02<13:04:32, 11.93s/it, loss=0.3789, lr=9.63e-06]Steps:  21%|██        | 1056/5000 [3:59:14<13:03:11, 11.91s/it, loss=0.3789, lr=9.63e-06]Steps:  21%|██        | 1056/5000 [3:59:14<13:03:11, 11.91s/it, loss=0.3959, lr=9.63e-06]Steps:  21%|██        | 1057/5000 [3:59:26<13:07:09, 11.98s/it, loss=0.3959, lr=9.63e-06]Steps:  21%|██        | 1057/5000 [3:59:26<13:07:09, 11.98s/it, loss=0.6133, lr=9.63e-06]Steps:  21%|██        | 1058/5000 [3:59:38<13:06:17, 11.97s/it, loss=0.6133, lr=9.63e-06]Steps:  21%|██        | 1058/5000 [3:59:38<13:06:17, 11.97s/it, loss=0.6014, lr=9.63e-06]Steps:  21%|██        | 1059/5000 [3:59:50<13:04:20, 11.94s/it, loss=0.6014, lr=9.63e-06]Steps:  21%|██        | 1059/5000 [3:59:50<13:04:20, 11.94s/it, loss=0.5276, lr=9.62e-06]Steps:  21%|██        | 1060/5000 [4:00:02<13:06:45, 11.98s/it, loss=0.5276, lr=9.62e-06]Steps:  21%|██        | 1060/5000 [4:00:02<13:06:45, 11.98s/it, loss=0.5156, lr=9.62e-06]
[Step 1060] Training Debug Info:
  Loss: 0.487630
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0359, std: 0.9336
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0352, std: 1.3672
  Model pred mean: -0.0383, std: 1.1719
  Sigmas: [0.66796875]... (timesteps: [668.0])

[Step 1060] Training Debug Info:
  Loss: 1.097184
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0056, std: 0.9531
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0073, std: 1.3828
  Model pred mean: -0.0046, std: 0.9023
  Sigmas: [0.166015625]... (timesteps: [166.0])

[Step 1060] Training Debug Info:
  Loss: 0.858421
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0040, std: 0.9102
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0047, std: 1.3516
  Model pred mean: 0.0014, std: 0.9727
  Sigmas: [0.416015625]... (timesteps: [416.0])

[Step 1060] Training Debug Info:
  Loss: 0.615826
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0234, std: 0.9141
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0253, std: 1.3516
  Model pred mean: -0.0184, std: 1.0938
  Sigmas: [0.96484375]... (timesteps: [966.0])
Steps:  21%|██        | 1061/5000 [4:00:14<13:04:55, 11.96s/it, loss=0.5156, lr=9.62e-06]Steps:  21%|██        | 1061/5000 [4:00:14<13:04:55, 11.96s/it, loss=0.6158, lr=9.62e-06]Steps:  21%|██        | 1062/5000 [4:00:26<13:04:21, 11.95s/it, loss=0.6158, lr=9.62e-06]Steps:  21%|██        | 1062/5000 [4:00:26<13:04:21, 11.95s/it, loss=0.5216, lr=9.62e-06]Steps:  21%|██▏       | 1063/5000 [4:00:38<13:08:49, 12.02s/it, loss=0.5216, lr=9.62e-06]Steps:  21%|██▏       | 1063/5000 [4:00:38<13:08:49, 12.02s/it, loss=1.0284, lr=9.62e-06]Steps:  21%|██▏       | 1064/5000 [4:00:50<13:05:42, 11.98s/it, loss=1.0284, lr=9.62e-06]Steps:  21%|██▏       | 1064/5000 [4:00:50<13:05:42, 11.98s/it, loss=1.2028, lr=9.62e-06]Steps:  21%|██▏       | 1065/5000 [4:01:02<13:03:26, 11.95s/it, loss=1.2028, lr=9.62e-06]Steps:  21%|██▏       | 1065/5000 [4:01:02<13:03:26, 11.95s/it, loss=0.3910, lr=9.62e-06]Steps:  21%|██▏       | 1066/5000 [4:01:14<13:00:58, 11.91s/it, loss=0.3910, lr=9.62e-06]Steps:  21%|██▏       | 1066/5000 [4:01:14<13:00:58, 11.91s/it, loss=1.1583, lr=9.61e-06]Steps:  21%|██▏       | 1067/5000 [4:01:26<12:59:43, 11.90s/it, loss=1.1583, lr=9.61e-06]Steps:  21%|██▏       | 1067/5000 [4:01:26<12:59:43, 11.90s/it, loss=0.8675, lr=9.61e-06]Steps:  21%|██▏       | 1068/5000 [4:01:38<12:59:29, 11.89s/it, loss=0.8675, lr=9.61e-06]Steps:  21%|██▏       | 1068/5000 [4:01:38<12:59:29, 11.89s/it, loss=0.7174, lr=9.61e-06]Steps:  21%|██▏       | 1069/5000 [4:01:50<13:01:31, 11.93s/it, loss=0.7174, lr=9.61e-06]Steps:  21%|██▏       | 1069/5000 [4:01:50<13:01:31, 11.93s/it, loss=0.4131, lr=9.61e-06]Steps:  21%|██▏       | 1070/5000 [4:02:02<13:05:44, 12.00s/it, loss=0.4131, lr=9.61e-06]Steps:  21%|██▏       | 1070/5000 [4:02:02<13:05:44, 12.00s/it, loss=0.5997, lr=9.61e-06]
[Step 1070] Training Debug Info:
  Loss: 0.624973
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0320, std: 0.9102
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0302, std: 1.3516
  Model pred mean: 0.0304, std: 1.0938
  Sigmas: [0.55859375]... (timesteps: [557.0])

[Step 1070] Training Debug Info:
  Loss: 0.485200
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0245, std: 0.9023
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0254, std: 1.3438
  Model pred mean: -0.0291, std: 1.1484
  Sigmas: [0.6484375]... (timesteps: [649.0])

[Step 1070] Training Debug Info:
  Loss: 1.124176
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0115, std: 0.9297
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0105, std: 1.3672
  Model pred mean: -0.0143, std: 0.8594
  Sigmas: [0.177734375]... (timesteps: [178.0])

[Step 1070] Training Debug Info:
  Loss: 0.644854
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0095, std: 0.8945
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0073, std: 1.3438
  Model pred mean: -0.0114, std: 1.0703
  Sigmas: [0.546875]... (timesteps: [547.0])
Steps:  21%|██▏       | 1071/5000 [4:02:14<13:03:57, 11.97s/it, loss=0.5997, lr=9.61e-06]Steps:  21%|██▏       | 1071/5000 [4:02:14<13:03:57, 11.97s/it, loss=0.6449, lr=9.61e-06]Steps:  21%|██▏       | 1072/5000 [4:02:26<13:03:13, 11.96s/it, loss=0.6449, lr=9.61e-06]Steps:  21%|██▏       | 1072/5000 [4:02:26<13:03:13, 11.96s/it, loss=1.0904, lr=9.61e-06]Steps:  21%|██▏       | 1073/5000 [4:02:38<13:02:08, 11.95s/it, loss=1.0904, lr=9.61e-06]Steps:  21%|██▏       | 1073/5000 [4:02:38<13:02:08, 11.95s/it, loss=0.5381, lr=9.61e-06]Steps:  21%|██▏       | 1074/5000 [4:02:49<13:00:53, 11.93s/it, loss=0.5381, lr=9.61e-06]Steps:  21%|██▏       | 1074/5000 [4:02:49<13:00:53, 11.93s/it, loss=1.1232, lr=9.60e-06]Steps:  22%|██▏       | 1075/5000 [4:03:01<12:59:32, 11.92s/it, loss=1.1232, lr=9.60e-06]Steps:  22%|██▏       | 1075/5000 [4:03:01<12:59:32, 11.92s/it, loss=0.7425, lr=9.60e-06]Steps:  22%|██▏       | 1076/5000 [4:03:13<12:59:17, 11.92s/it, loss=0.7425, lr=9.60e-06]Steps:  22%|██▏       | 1076/5000 [4:03:13<12:59:17, 11.92s/it, loss=1.1321, lr=9.60e-06]Steps:  22%|██▏       | 1077/5000 [4:03:25<13:04:54, 12.00s/it, loss=1.1321, lr=9.60e-06]Steps:  22%|██▏       | 1077/5000 [4:03:25<13:04:54, 12.00s/it, loss=0.6453, lr=9.60e-06]Steps:  22%|██▏       | 1078/5000 [4:03:37<13:04:58, 12.01s/it, loss=0.6453, lr=9.60e-06]Steps:  22%|██▏       | 1078/5000 [4:03:37<13:04:58, 12.01s/it, loss=1.1337, lr=9.60e-06]Steps:  22%|██▏       | 1079/5000 [4:03:49<13:03:04, 11.98s/it, loss=1.1337, lr=9.60e-06]Steps:  22%|██▏       | 1079/5000 [4:03:49<13:03:04, 11.98s/it, loss=1.0705, lr=9.60e-06]Steps:  22%|██▏       | 1080/5000 [4:04:01<13:02:09, 11.97s/it, loss=1.0705, lr=9.60e-06]Steps:  22%|██▏       | 1080/5000 [4:04:01<13:02:09, 11.97s/it, loss=0.7594, lr=9.60e-06]
[Step 1080] Training Debug Info:
  Loss: 1.079245
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0008, std: 0.8750
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0014, std: 1.3281
  Model pred mean: 0.0006, std: 0.8281
  Sigmas: [0.04296875]... (timesteps: [43.0])

[Step 1080] Training Debug Info:
  Loss: 1.025242
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0654, std: 0.9219
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0640, std: 1.3594
  Model pred mean: -0.0640, std: 0.9102
  Sigmas: [0.224609375]... (timesteps: [225.0])

[Step 1080] Training Debug Info:
  Loss: 0.393098
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0021, std: 0.9180
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0020, std: 1.3594
  Model pred mean: 0.0044, std: 1.1953
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 1080] Training Debug Info:
  Loss: 1.099216
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0107, std: 0.8711
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0082, std: 1.3281
  Model pred mean: 0.0101, std: 0.8086
  Sigmas: [0.054931640625]... (timesteps: [55.0])
Steps:  22%|██▏       | 1081/5000 [4:04:13<13:01:49, 11.97s/it, loss=0.7594, lr=9.60e-06]Steps:  22%|██▏       | 1081/5000 [4:04:13<13:01:49, 11.97s/it, loss=1.0992, lr=9.59e-06]Steps:  22%|██▏       | 1082/5000 [4:04:25<12:59:27, 11.94s/it, loss=1.0992, lr=9.59e-06]Steps:  22%|██▏       | 1082/5000 [4:04:25<12:59:27, 11.94s/it, loss=1.0065, lr=9.59e-06]Steps:  22%|██▏       | 1083/5000 [4:04:37<12:57:13, 11.91s/it, loss=1.0065, lr=9.59e-06]Steps:  22%|██▏       | 1083/5000 [4:04:37<12:57:13, 11.91s/it, loss=1.0537, lr=9.59e-06]Steps:  22%|██▏       | 1084/5000 [4:04:49<13:01:32, 11.97s/it, loss=1.0537, lr=9.59e-06]Steps:  22%|██▏       | 1084/5000 [4:04:49<13:01:32, 11.97s/it, loss=0.3904, lr=9.59e-06]Steps:  22%|██▏       | 1085/5000 [4:05:01<13:01:08, 11.97s/it, loss=0.3904, lr=9.59e-06]Steps:  22%|██▏       | 1085/5000 [4:05:01<13:01:08, 11.97s/it, loss=1.0415, lr=9.59e-06]Steps:  22%|██▏       | 1086/5000 [4:05:13<13:00:16, 11.96s/it, loss=1.0415, lr=9.59e-06]Steps:  22%|██▏       | 1086/5000 [4:05:13<13:00:16, 11.96s/it, loss=1.1230, lr=9.59e-06]Steps:  22%|██▏       | 1087/5000 [4:05:25<13:02:57, 12.01s/it, loss=1.1230, lr=9.59e-06]Steps:  22%|██▏       | 1087/5000 [4:05:25<13:02:57, 12.01s/it, loss=1.1617, lr=9.59e-06]Steps:  22%|██▏       | 1088/5000 [4:05:37<13:02:19, 12.00s/it, loss=1.1617, lr=9.59e-06]Steps:  22%|██▏       | 1088/5000 [4:05:37<13:02:19, 12.00s/it, loss=1.1301, lr=9.58e-06]Steps:  22%|██▏       | 1089/5000 [4:05:49<12:59:15, 11.95s/it, loss=1.1301, lr=9.58e-06]Steps:  22%|██▏       | 1089/5000 [4:05:49<12:59:15, 11.95s/it, loss=1.1602, lr=9.58e-06]Steps:  22%|██▏       | 1090/5000 [4:06:01<13:04:07, 12.03s/it, loss=1.1602, lr=9.58e-06]Steps:  22%|██▏       | 1090/5000 [4:06:01<13:04:07, 12.03s/it, loss=0.4262, lr=9.58e-06]
[Step 1090] Training Debug Info:
  Loss: 0.638782
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0173, std: 0.9609
  Noise mean: -0.0014, std: 0.9961
  Target mean: -0.0188, std: 1.3906
  Model pred mean: -0.0151, std: 1.1328
  Sigmas: [0.5625]... (timesteps: [564.0])

[Step 1090] Training Debug Info:
  Loss: 0.796297
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0162, std: 0.9258
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0190, std: 1.3594
  Model pred mean: -0.0145, std: 1.0391
  Sigmas: [0.462890625]... (timesteps: [463.0])

[Step 1090] Training Debug Info:
  Loss: 0.756658
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0018, std: 0.8906
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0008, std: 1.3359
  Model pred mean: 0.0017, std: 1.0234
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 1090] Training Debug Info:
  Loss: 0.550828
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0060, std: 0.8828
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0046, std: 1.3359
  Model pred mean: 0.0084, std: 1.1172
  Sigmas: [0.6328125]... (timesteps: [633.0])
Steps:  22%|██▏       | 1091/5000 [4:06:13<13:02:35, 12.01s/it, loss=0.4262, lr=9.58e-06]Steps:  22%|██▏       | 1091/5000 [4:06:13<13:02:35, 12.01s/it, loss=0.5508, lr=9.58e-06]Steps:  22%|██▏       | 1092/5000 [4:06:25<13:01:50, 12.00s/it, loss=0.5508, lr=9.58e-06]Steps:  22%|██▏       | 1092/5000 [4:06:25<13:01:50, 12.00s/it, loss=0.5667, lr=9.58e-06]Steps:  22%|██▏       | 1093/5000 [4:06:37<13:00:43, 11.99s/it, loss=0.5667, lr=9.58e-06]Steps:  22%|██▏       | 1093/5000 [4:06:37<13:00:43, 11.99s/it, loss=0.8136, lr=9.58e-06]Steps:  22%|██▏       | 1094/5000 [4:06:49<13:00:11, 11.98s/it, loss=0.8136, lr=9.58e-06]Steps:  22%|██▏       | 1094/5000 [4:06:49<13:00:11, 11.98s/it, loss=0.3637, lr=9.58e-06]Steps:  22%|██▏       | 1095/5000 [4:07:01<12:58:28, 11.96s/it, loss=0.3637, lr=9.58e-06]Steps:  22%|██▏       | 1095/5000 [4:07:01<12:58:28, 11.96s/it, loss=0.8913, lr=9.57e-06]Steps:  22%|██▏       | 1096/5000 [4:07:13<12:59:10, 11.98s/it, loss=0.8913, lr=9.57e-06]Steps:  22%|██▏       | 1096/5000 [4:07:13<12:59:10, 11.98s/it, loss=0.7537, lr=9.57e-06]Steps:  22%|██▏       | 1097/5000 [4:07:25<13:04:27, 12.06s/it, loss=0.7537, lr=9.57e-06]Steps:  22%|██▏       | 1097/5000 [4:07:25<13:04:27, 12.06s/it, loss=1.1202, lr=9.57e-06]Steps:  22%|██▏       | 1098/5000 [4:07:37<13:02:15, 12.03s/it, loss=1.1202, lr=9.57e-06]Steps:  22%|██▏       | 1098/5000 [4:07:37<13:02:15, 12.03s/it, loss=0.4523, lr=9.57e-06]Steps:  22%|██▏       | 1099/5000 [4:07:49<12:59:13, 11.99s/it, loss=0.4523, lr=9.57e-06]Steps:  22%|██▏       | 1099/5000 [4:07:49<12:59:13, 11.99s/it, loss=1.0367, lr=9.57e-06]Steps:  22%|██▏       | 1100/5000 [4:08:01<12:57:49, 11.97s/it, loss=1.0367, lr=9.57e-06]Steps:  22%|██▏       | 1100/5000 [4:08:01<12:57:49, 11.97s/it, loss=0.5553, lr=9.57e-06]01/22/2026 11:53:48 - INFO - __main__ - 
[Step 1100] ✅ Loss in normal range (0.5553)
01/22/2026 11:53:48 - INFO - __main__ -   Loss avg (last 100): 0.7781
01/22/2026 11:53:48 - INFO - __main__ -   Loss range: [0.3637, 1.2091]

[Step 1100] Training Debug Info:
  Loss: 0.522130
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0052, std: 0.8906
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0057, std: 1.3438
  Model pred mean: -0.0063, std: 1.1328
  Sigmas: [0.65625]... (timesteps: [656.0])

[Step 1100] Training Debug Info:
  Loss: 0.802717
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9453
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0188, std: 1.3750
  Model pred mean: -0.0198, std: 1.0469
  Sigmas: [0.359375]... (timesteps: [359.0])

[Step 1100] Training Debug Info:
  Loss: 0.364828
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0131, std: 0.9141
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0132, std: 1.3594
  Model pred mean: 0.0154, std: 1.2109
  Sigmas: [0.828125]... (timesteps: [828.0])

[Step 1100] Training Debug Info:
  Loss: 0.903720
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0067, std: 0.8867
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0041, std: 1.3438
  Model pred mean: -0.0118, std: 0.9453
  Sigmas: [0.392578125]... (timesteps: [392.0])
Steps:  22%|██▏       | 1101/5000 [4:08:13<12:55:36, 11.94s/it, loss=0.5553, lr=9.57e-06]Steps:  22%|██▏       | 1101/5000 [4:08:13<12:55:36, 11.94s/it, loss=0.9037, lr=9.57e-06]Steps:  22%|██▏       | 1102/5000 [4:08:25<12:55:44, 11.94s/it, loss=0.9037, lr=9.57e-06]Steps:  22%|██▏       | 1102/5000 [4:08:25<12:55:44, 11.94s/it, loss=1.0659, lr=9.56e-06]Steps:  22%|██▏       | 1103/5000 [4:08:37<12:55:29, 11.94s/it, loss=1.0659, lr=9.56e-06]Steps:  22%|██▏       | 1103/5000 [4:08:37<12:55:29, 11.94s/it, loss=0.9119, lr=9.56e-06]Steps:  22%|██▏       | 1104/5000 [4:08:49<13:00:21, 12.02s/it, loss=0.9119, lr=9.56e-06]Steps:  22%|██▏       | 1104/5000 [4:08:49<13:00:21, 12.02s/it, loss=0.7336, lr=9.56e-06]Steps:  22%|██▏       | 1105/5000 [4:09:01<13:01:09, 12.03s/it, loss=0.7336, lr=9.56e-06]Steps:  22%|██▏       | 1105/5000 [4:09:01<13:01:09, 12.03s/it, loss=0.7108, lr=9.56e-06]Steps:  22%|██▏       | 1106/5000 [4:09:13<12:58:50, 12.00s/it, loss=0.7108, lr=9.56e-06]Steps:  22%|██▏       | 1106/5000 [4:09:13<12:58:50, 12.00s/it, loss=0.4575, lr=9.56e-06]Steps:  22%|██▏       | 1107/5000 [4:09:25<12:57:53, 11.99s/it, loss=0.4575, lr=9.56e-06]Steps:  22%|██▏       | 1107/5000 [4:09:25<12:57:53, 11.99s/it, loss=0.4172, lr=9.56e-06]Steps:  22%|██▏       | 1108/5000 [4:09:37<12:56:05, 11.96s/it, loss=0.4172, lr=9.56e-06]Steps:  22%|██▏       | 1108/5000 [4:09:37<12:56:05, 11.96s/it, loss=0.4828, lr=9.56e-06]Steps:  22%|██▏       | 1109/5000 [4:09:49<12:56:26, 11.97s/it, loss=0.4828, lr=9.56e-06]Steps:  22%|██▏       | 1109/5000 [4:09:49<12:56:26, 11.97s/it, loss=0.5005, lr=9.55e-06]Steps:  22%|██▏       | 1110/5000 [4:10:01<12:55:08, 11.96s/it, loss=0.5005, lr=9.55e-06]Steps:  22%|██▏       | 1110/5000 [4:10:01<12:55:08, 11.96s/it, loss=1.1642, lr=9.55e-06]
[Step 1110] Training Debug Info:
  Loss: 0.567234
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0089, std: 0.9844
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0092, std: 1.4062
  Model pred mean: -0.0070, std: 1.1953
  Sigmas: [0.58203125]... (timesteps: [582.0])

[Step 1110] Training Debug Info:
  Loss: 0.586676
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0554, std: 0.9609
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0537, std: 1.3906
  Model pred mean: -0.0549, std: 1.1641
  Sigmas: [0.50390625]... (timesteps: [505.0])

[Step 1110] Training Debug Info:
  Loss: 1.044579
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0273, std: 0.9023
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0277, std: 1.3438
  Model pred mean: -0.0238, std: 0.8789
  Sigmas: [0.287109375]... (timesteps: [288.0])

[Step 1110] Training Debug Info:
  Loss: 0.623101
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0209, std: 0.8867
  Noise mean: 0.0037, std: 1.0000
  Target mean: 0.0247, std: 1.3359
  Model pred mean: 0.0226, std: 1.0859
  Sigmas: [0.59375]... (timesteps: [592.0])
Steps:  22%|██▏       | 1111/5000 [4:10:13<12:58:02, 12.00s/it, loss=1.1642, lr=9.55e-06]Steps:  22%|██▏       | 1111/5000 [4:10:13<12:58:02, 12.00s/it, loss=0.6231, lr=9.55e-06]Steps:  22%|██▏       | 1112/5000 [4:10:25<12:55:26, 11.97s/it, loss=0.6231, lr=9.55e-06]Steps:  22%|██▏       | 1112/5000 [4:10:25<12:55:26, 11.97s/it, loss=0.3904, lr=9.55e-06]Steps:  22%|██▏       | 1113/5000 [4:10:37<12:52:41, 11.93s/it, loss=0.3904, lr=9.55e-06]Steps:  22%|██▏       | 1113/5000 [4:10:37<12:52:41, 11.93s/it, loss=0.4715, lr=9.55e-06]Steps:  22%|██▏       | 1114/5000 [4:10:49<12:53:53, 11.95s/it, loss=0.4715, lr=9.55e-06]Steps:  22%|██▏       | 1114/5000 [4:10:49<12:53:53, 11.95s/it, loss=1.0696, lr=9.55e-06]Steps:  22%|██▏       | 1115/5000 [4:11:00<12:53:17, 11.94s/it, loss=1.0696, lr=9.55e-06]Steps:  22%|██▏       | 1115/5000 [4:11:00<12:53:17, 11.94s/it, loss=0.4370, lr=9.55e-06]Steps:  22%|██▏       | 1116/5000 [4:11:12<12:51:17, 11.92s/it, loss=0.4370, lr=9.55e-06]Steps:  22%|██▏       | 1116/5000 [4:11:12<12:51:17, 11.92s/it, loss=0.7954, lr=9.54e-06]Steps:  22%|██▏       | 1117/5000 [4:11:25<12:57:34, 12.01s/it, loss=0.7954, lr=9.54e-06]Steps:  22%|██▏       | 1117/5000 [4:11:25<12:57:34, 12.01s/it, loss=0.9351, lr=9.54e-06]Steps:  22%|██▏       | 1118/5000 [4:11:37<12:56:39, 12.00s/it, loss=0.9351, lr=9.54e-06]Steps:  22%|██▏       | 1118/5000 [4:11:37<12:56:39, 12.00s/it, loss=0.3363, lr=9.54e-06]Steps:  22%|██▏       | 1119/5000 [4:11:48<12:52:43, 11.95s/it, loss=0.3363, lr=9.54e-06]Steps:  22%|██▏       | 1119/5000 [4:11:48<12:52:43, 11.95s/it, loss=0.6333, lr=9.54e-06]Steps:  22%|██▏       | 1120/5000 [4:12:00<12:52:22, 11.94s/it, loss=0.6333, lr=9.54e-06]Steps:  22%|██▏       | 1120/5000 [4:12:00<12:52:22, 11.94s/it, loss=0.7235, lr=9.54e-06]
[Step 1120] Training Debug Info:
  Loss: 1.116298
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0127, std: 0.9258
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0126, std: 1.3672
  Model pred mean: 0.0168, std: 0.8516
  Sigmas: [0.125]... (timesteps: [125.0])

[Step 1120] Training Debug Info:
  Loss: 1.189662
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0242, std: 0.8672
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0251, std: 1.3203
  Model pred mean: 0.0273, std: 0.7461
  Sigmas: [0.1298828125]... (timesteps: [130.0])

[Step 1120] Training Debug Info:
  Loss: 0.508606
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0214, std: 1.0078
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0198, std: 1.4219
  Model pred mean: -0.0189, std: 1.2266
  Sigmas: [0.80078125]... (timesteps: [802.0])

[Step 1120] Training Debug Info:
  Loss: 0.842132
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0084, std: 0.9062
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0071, std: 1.3516
  Model pred mean: 0.0039, std: 0.9883
  Sigmas: [0.44921875]... (timesteps: [450.0])
Steps:  22%|██▏       | 1121/5000 [4:12:12<12:51:59, 11.94s/it, loss=0.7235, lr=9.54e-06]Steps:  22%|██▏       | 1121/5000 [4:12:12<12:51:59, 11.94s/it, loss=0.8421, lr=9.54e-06]Steps:  22%|██▏       | 1122/5000 [4:12:24<12:50:59, 11.93s/it, loss=0.8421, lr=9.54e-06]Steps:  22%|██▏       | 1122/5000 [4:12:24<12:50:59, 11.93s/it, loss=1.1642, lr=9.54e-06]Steps:  22%|██▏       | 1123/5000 [4:12:36<12:52:16, 11.95s/it, loss=1.1642, lr=9.54e-06]Steps:  22%|██▏       | 1123/5000 [4:12:36<12:52:16, 11.95s/it, loss=0.6461, lr=9.53e-06]Steps:  22%|██▏       | 1124/5000 [4:12:48<12:56:21, 12.02s/it, loss=0.6461, lr=9.53e-06]Steps:  22%|██▏       | 1124/5000 [4:12:48<12:56:21, 12.02s/it, loss=0.6985, lr=9.53e-06]Steps:  22%|██▎       | 1125/5000 [4:13:00<12:54:11, 11.99s/it, loss=0.6985, lr=9.53e-06]Steps:  22%|██▎       | 1125/5000 [4:13:00<12:54:11, 11.99s/it, loss=0.6689, lr=9.53e-06]Steps:  23%|██▎       | 1126/5000 [4:13:12<12:52:31, 11.96s/it, loss=0.6689, lr=9.53e-06]Steps:  23%|██▎       | 1126/5000 [4:13:12<12:52:31, 11.96s/it, loss=0.4870, lr=9.53e-06]Steps:  23%|██▎       | 1127/5000 [4:13:24<12:51:21, 11.95s/it, loss=0.4870, lr=9.53e-06]Steps:  23%|██▎       | 1127/5000 [4:13:24<12:51:21, 11.95s/it, loss=1.1319, lr=9.53e-06]Steps:  23%|██▎       | 1128/5000 [4:13:36<12:50:01, 11.93s/it, loss=1.1319, lr=9.53e-06]Steps:  23%|██▎       | 1128/5000 [4:13:36<12:50:01, 11.93s/it, loss=1.1464, lr=9.53e-06]Steps:  23%|██▎       | 1129/5000 [4:13:48<12:49:56, 11.93s/it, loss=1.1464, lr=9.53e-06]Steps:  23%|██▎       | 1129/5000 [4:13:48<12:49:56, 11.93s/it, loss=0.3468, lr=9.53e-06]Steps:  23%|██▎       | 1130/5000 [4:14:00<12:50:02, 11.94s/it, loss=0.3468, lr=9.53e-06]Steps:  23%|██▎       | 1130/5000 [4:14:00<12:50:02, 11.94s/it, loss=0.4145, lr=9.52e-06]
[Step 1130] Training Debug Info:
  Loss: 0.339650
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0203, std: 0.8711
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0219, std: 1.3281
  Model pred mean: 0.0223, std: 1.1797
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 1130] Training Debug Info:
  Loss: 0.385347
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0073, std: 0.9336
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0076, std: 1.3672
  Model pred mean: 0.0030, std: 1.2188
  Sigmas: [0.75390625]... (timesteps: [752.0])

[Step 1130] Training Debug Info:
  Loss: 0.634439
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0275, std: 0.9023
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0320, std: 1.3438
  Model pred mean: -0.0264, std: 1.0781
  Sigmas: [0.515625]... (timesteps: [515.0])

[Step 1130] Training Debug Info:
  Loss: 0.363298
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0129, std: 0.9062
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0139, std: 1.3516
  Model pred mean: 0.0145, std: 1.2109
  Sigmas: [0.8046875]... (timesteps: [805.0])
Steps:  23%|██▎       | 1131/5000 [4:14:12<12:57:37, 12.06s/it, loss=0.4145, lr=9.52e-06]Steps:  23%|██▎       | 1131/5000 [4:14:12<12:57:37, 12.06s/it, loss=0.3633, lr=9.52e-06]Steps:  23%|██▎       | 1132/5000 [4:14:24<12:54:00, 12.01s/it, loss=0.3633, lr=9.52e-06]Steps:  23%|██▎       | 1132/5000 [4:14:24<12:54:00, 12.01s/it, loss=1.0568, lr=9.52e-06]Steps:  23%|██▎       | 1133/5000 [4:14:36<12:51:31, 11.97s/it, loss=1.0568, lr=9.52e-06]Steps:  23%|██▎       | 1133/5000 [4:14:36<12:51:31, 11.97s/it, loss=1.0918, lr=9.52e-06]Steps:  23%|██▎       | 1134/5000 [4:14:48<12:49:48, 11.95s/it, loss=1.0918, lr=9.52e-06]Steps:  23%|██▎       | 1134/5000 [4:14:48<12:49:48, 11.95s/it, loss=0.3702, lr=9.52e-06]Steps:  23%|██▎       | 1135/5000 [4:15:00<12:50:55, 11.97s/it, loss=0.3702, lr=9.52e-06]Steps:  23%|██▎       | 1135/5000 [4:15:00<12:50:55, 11.97s/it, loss=1.0779, lr=9.52e-06]Steps:  23%|██▎       | 1136/5000 [4:15:12<12:50:18, 11.96s/it, loss=1.0779, lr=9.52e-06]Steps:  23%|██▎       | 1136/5000 [4:15:12<12:50:18, 11.96s/it, loss=0.6708, lr=9.52e-06]Steps:  23%|██▎       | 1137/5000 [4:15:24<12:49:27, 11.95s/it, loss=0.6708, lr=9.52e-06]Steps:  23%|██▎       | 1137/5000 [4:15:24<12:49:27, 11.95s/it, loss=0.7369, lr=9.51e-06]Steps:  23%|██▎       | 1138/5000 [4:15:36<12:54:30, 12.03s/it, loss=0.7369, lr=9.51e-06]Steps:  23%|██▎       | 1138/5000 [4:15:36<12:54:30, 12.03s/it, loss=1.1779, lr=9.51e-06]Steps:  23%|██▎       | 1139/5000 [4:15:48<12:52:29, 12.00s/it, loss=1.1779, lr=9.51e-06]Steps:  23%|██▎       | 1139/5000 [4:15:48<12:52:29, 12.00s/it, loss=0.4022, lr=9.51e-06]Steps:  23%|██▎       | 1140/5000 [4:16:00<12:52:20, 12.01s/it, loss=0.4022, lr=9.51e-06]Steps:  23%|██▎       | 1140/5000 [4:16:00<12:52:20, 12.01s/it, loss=1.1521, lr=9.51e-06]
[Step 1140] Training Debug Info:
  Loss: 0.964747
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0249, std: 0.9180
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0251, std: 1.3594
  Model pred mean: 0.0261, std: 0.9375
  Sigmas: [0.365234375]... (timesteps: [366.0])

[Step 1140] Training Debug Info:
  Loss: 0.361068
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0254, std: 0.9531
  Noise mean: 0.0012, std: 0.9961
  Target mean: 0.0266, std: 1.3828
  Model pred mean: 0.0231, std: 1.2422
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 1140] Training Debug Info:
  Loss: 1.069506
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0062, std: 0.9062
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0068, std: 1.3516
  Model pred mean: 0.0046, std: 0.8594
  Sigmas: [0.0419921875]... (timesteps: [42.0])

[Step 1140] Training Debug Info:
  Loss: 0.944903
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0374, std: 0.9961
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0369, std: 1.4141
  Model pred mean: -0.0364, std: 1.0234
  Sigmas: [0.357421875]... (timesteps: [358.0])
Steps:  23%|██▎       | 1141/5000 [4:16:12<12:49:59, 11.97s/it, loss=1.1521, lr=9.51e-06]Steps:  23%|██▎       | 1141/5000 [4:16:12<12:49:59, 11.97s/it, loss=0.9449, lr=9.51e-06]Steps:  23%|██▎       | 1142/5000 [4:16:24<12:48:12, 11.95s/it, loss=0.9449, lr=9.51e-06]Steps:  23%|██▎       | 1142/5000 [4:16:24<12:48:12, 11.95s/it, loss=0.3833, lr=9.51e-06]Steps:  23%|██▎       | 1143/5000 [4:16:36<12:46:38, 11.93s/it, loss=0.3833, lr=9.51e-06]Steps:  23%|██▎       | 1143/5000 [4:16:36<12:46:38, 11.93s/it, loss=0.4488, lr=9.50e-06]Steps:  23%|██▎       | 1144/5000 [4:16:48<12:52:28, 12.02s/it, loss=0.4488, lr=9.50e-06]Steps:  23%|██▎       | 1144/5000 [4:16:48<12:52:28, 12.02s/it, loss=0.4683, lr=9.50e-06]Steps:  23%|██▎       | 1145/5000 [4:17:00<12:50:28, 11.99s/it, loss=0.4683, lr=9.50e-06]Steps:  23%|██▎       | 1145/5000 [4:17:00<12:50:28, 11.99s/it, loss=0.8518, lr=9.50e-06]Steps:  23%|██▎       | 1146/5000 [4:17:12<12:49:15, 11.98s/it, loss=0.8518, lr=9.50e-06]Steps:  23%|██▎       | 1146/5000 [4:17:12<12:49:15, 11.98s/it, loss=0.4080, lr=9.50e-06]Steps:  23%|██▎       | 1147/5000 [4:17:24<12:48:21, 11.97s/it, loss=0.4080, lr=9.50e-06]Steps:  23%|██▎       | 1147/5000 [4:17:24<12:48:21, 11.97s/it, loss=0.8903, lr=9.50e-06]Steps:  23%|██▎       | 1148/5000 [4:17:36<12:48:19, 11.97s/it, loss=0.8903, lr=9.50e-06]Steps:  23%|██▎       | 1148/5000 [4:17:36<12:48:19, 11.97s/it, loss=0.4704, lr=9.50e-06]Steps:  23%|██▎       | 1149/5000 [4:17:47<12:47:36, 11.96s/it, loss=0.4704, lr=9.50e-06]Steps:  23%|██▎       | 1149/5000 [4:17:48<12:47:36, 11.96s/it, loss=1.1093, lr=9.50e-06]Steps:  23%|██▎       | 1150/5000 [4:17:59<12:47:11, 11.96s/it, loss=1.1093, lr=9.50e-06]Steps:  23%|██▎       | 1150/5000 [4:17:59<12:47:11, 11.96s/it, loss=0.4338, lr=9.49e-06]
[Step 1150] Training Debug Info:
  Loss: 0.563201
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0452, std: 0.9609
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0447, std: 1.3828
  Model pred mean: -0.0466, std: 1.1719
  Sigmas: [0.5546875]... (timesteps: [556.0])

[Step 1150] Training Debug Info:
  Loss: 1.087819
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0064, std: 0.9414
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0043, std: 1.3750
  Model pred mean: -0.0016, std: 0.8906
  Sigmas: [0.06201171875]... (timesteps: [62.0])

[Step 1150] Training Debug Info:
  Loss: 0.421584
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0054, std: 0.8711
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0071, std: 1.3281
  Model pred mean: -0.0062, std: 1.1562
  Sigmas: [0.7578125]... (timesteps: [758.0])

[Step 1150] Training Debug Info:
  Loss: 0.804635
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0159, std: 0.9297
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0154, std: 1.3672
  Model pred mean: 0.0172, std: 1.0391
  Sigmas: [0.421875]... (timesteps: [421.0])
Steps:  23%|██▎       | 1151/5000 [4:18:12<12:52:45, 12.05s/it, loss=0.4338, lr=9.49e-06]Steps:  23%|██▎       | 1151/5000 [4:18:12<12:52:45, 12.05s/it, loss=0.8046, lr=9.49e-06]Steps:  23%|██▎       | 1152/5000 [4:18:24<12:50:44, 12.02s/it, loss=0.8046, lr=9.49e-06]Steps:  23%|██▎       | 1152/5000 [4:18:24<12:50:44, 12.02s/it, loss=0.3947, lr=9.49e-06]Steps:  23%|██▎       | 1153/5000 [4:18:36<12:48:16, 11.98s/it, loss=0.3947, lr=9.49e-06]Steps:  23%|██▎       | 1153/5000 [4:18:36<12:48:16, 11.98s/it, loss=1.2053, lr=9.49e-06]Steps:  23%|██▎       | 1154/5000 [4:18:47<12:45:10, 11.94s/it, loss=1.2053, lr=9.49e-06]Steps:  23%|██▎       | 1154/5000 [4:18:47<12:45:10, 11.94s/it, loss=0.5453, lr=9.49e-06]Steps:  23%|██▎       | 1155/5000 [4:18:59<12:44:05, 11.92s/it, loss=0.5453, lr=9.49e-06]Steps:  23%|██▎       | 1155/5000 [4:18:59<12:44:05, 11.92s/it, loss=0.3820, lr=9.49e-06]Steps:  23%|██▎       | 1156/5000 [4:19:11<12:44:18, 11.93s/it, loss=0.3820, lr=9.49e-06]Steps:  23%|██▎       | 1156/5000 [4:19:11<12:44:18, 11.93s/it, loss=1.0917, lr=9.48e-06]Steps:  23%|██▎       | 1157/5000 [4:19:23<12:43:26, 11.92s/it, loss=1.0917, lr=9.48e-06]Steps:  23%|██▎       | 1157/5000 [4:19:23<12:43:26, 11.92s/it, loss=0.5014, lr=9.48e-06]Steps:  23%|██▎       | 1158/5000 [4:19:35<12:48:55, 12.01s/it, loss=0.5014, lr=9.48e-06]Steps:  23%|██▎       | 1158/5000 [4:19:35<12:48:55, 12.01s/it, loss=0.4321, lr=9.48e-06]Steps:  23%|██▎       | 1159/5000 [4:19:47<12:45:13, 11.95s/it, loss=0.4321, lr=9.48e-06]Steps:  23%|██▎       | 1159/5000 [4:19:47<12:45:13, 11.95s/it, loss=1.1981, lr=9.48e-06]Steps:  23%|██▎       | 1160/5000 [4:19:59<12:45:13, 11.96s/it, loss=1.1981, lr=9.48e-06]Steps:  23%|██▎       | 1160/5000 [4:19:59<12:45:13, 11.96s/it, loss=1.1528, lr=9.48e-06]
[Step 1160] Training Debug Info:
  Loss: 1.074200
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0023, std: 0.9375
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0001, std: 1.3672
  Model pred mean: -0.0023, std: 0.8984
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 1160] Training Debug Info:
  Loss: 0.354557
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0004, std: 0.8984
  Noise mean: -0.0043, std: 1.0000
  Target mean: -0.0039, std: 1.3438
  Model pred mean: -0.0015, std: 1.2031
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 1160] Training Debug Info:
  Loss: 0.862115
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0630, std: 0.9375
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0630, std: 1.3750
  Model pred mean: 0.0613, std: 1.0078
  Sigmas: [0.376953125]... (timesteps: [377.0])

[Step 1160] Training Debug Info:
  Loss: 0.954079
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0155, std: 0.9297
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0149, std: 1.3672
  Model pred mean: -0.0175, std: 0.9570
  Sigmas: [0.30078125]... (timesteps: [301.0])
Steps:  23%|██▎       | 1161/5000 [4:20:11<12:42:49, 11.92s/it, loss=1.1528, lr=9.48e-06]Steps:  23%|██▎       | 1161/5000 [4:20:11<12:42:49, 11.92s/it, loss=0.9541, lr=9.48e-06]Steps:  23%|██▎       | 1162/5000 [4:20:23<12:45:18, 11.96s/it, loss=0.9541, lr=9.48e-06]Steps:  23%|██▎       | 1162/5000 [4:20:23<12:45:18, 11.96s/it, loss=1.1014, lr=9.48e-06]Steps:  23%|██▎       | 1163/5000 [4:20:35<12:43:32, 11.94s/it, loss=1.1014, lr=9.48e-06]Steps:  23%|██▎       | 1163/5000 [4:20:35<12:43:32, 11.94s/it, loss=0.9643, lr=9.47e-06]Steps:  23%|██▎       | 1164/5000 [4:20:47<12:42:23, 11.92s/it, loss=0.9643, lr=9.47e-06]Steps:  23%|██▎       | 1164/5000 [4:20:47<12:42:23, 11.92s/it, loss=0.8097, lr=9.47e-06]Steps:  23%|██▎       | 1165/5000 [4:20:59<12:48:00, 12.02s/it, loss=0.8097, lr=9.47e-06]Steps:  23%|██▎       | 1165/5000 [4:20:59<12:48:00, 12.02s/it, loss=0.5523, lr=9.47e-06]Steps:  23%|██▎       | 1166/5000 [4:21:11<12:46:10, 11.99s/it, loss=0.5523, lr=9.47e-06]Steps:  23%|██▎       | 1166/5000 [4:21:11<12:46:10, 11.99s/it, loss=0.4975, lr=9.47e-06]Steps:  23%|██▎       | 1167/5000 [4:21:23<12:45:37, 11.98s/it, loss=0.4975, lr=9.47e-06]Steps:  23%|██▎       | 1167/5000 [4:21:23<12:45:37, 11.98s/it, loss=0.4981, lr=9.47e-06]Steps:  23%|██▎       | 1168/5000 [4:21:35<12:44:56, 11.98s/it, loss=0.4981, lr=9.47e-06]Steps:  23%|██▎       | 1168/5000 [4:21:35<12:44:56, 11.98s/it, loss=0.9720, lr=9.47e-06]Steps:  23%|██▎       | 1169/5000 [4:21:47<12:45:57, 12.00s/it, loss=0.9720, lr=9.47e-06]Steps:  23%|██▎       | 1169/5000 [4:21:47<12:45:57, 12.00s/it, loss=1.0221, lr=9.46e-06]Steps:  23%|██▎       | 1170/5000 [4:21:59<12:44:42, 11.98s/it, loss=1.0221, lr=9.46e-06]Steps:  23%|██▎       | 1170/5000 [4:21:59<12:44:42, 11.98s/it, loss=0.7177, lr=9.46e-06]
[Step 1170] Training Debug Info:
  Loss: 0.391599
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0030, std: 0.9062
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0060, std: 1.3516
  Model pred mean: -0.0035, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [823.0])

[Step 1170] Training Debug Info:
  Loss: 0.755852
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0131, std: 0.9297
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0148, std: 1.3672
  Model pred mean: 0.0119, std: 1.0547
  Sigmas: [0.515625]... (timesteps: [515.0])

[Step 1170] Training Debug Info:
  Loss: 0.763027
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0199, std: 0.8984
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0225, std: 1.3438
  Model pred mean: -0.0187, std: 1.0078
  Sigmas: [0.474609375]... (timesteps: [474.0])

[Step 1170] Training Debug Info:
  Loss: 0.380308
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0354, std: 0.8984
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0349, std: 1.3438
  Model pred mean: 0.0330, std: 1.1953
  Sigmas: [0.8046875]... (timesteps: [804.0])
Steps:  23%|██▎       | 1171/5000 [4:22:11<12:47:36, 12.03s/it, loss=0.7177, lr=9.46e-06]Steps:  23%|██▎       | 1171/5000 [4:22:11<12:47:36, 12.03s/it, loss=0.3803, lr=9.46e-06]Steps:  23%|██▎       | 1172/5000 [4:22:23<12:45:48, 12.00s/it, loss=0.3803, lr=9.46e-06]Steps:  23%|██▎       | 1172/5000 [4:22:23<12:45:48, 12.00s/it, loss=0.9256, lr=9.46e-06]Steps:  23%|██▎       | 1173/5000 [4:22:35<12:45:13, 12.00s/it, loss=0.9256, lr=9.46e-06]Steps:  23%|██▎       | 1173/5000 [4:22:35<12:45:13, 12.00s/it, loss=0.6855, lr=9.46e-06]Steps:  23%|██▎       | 1174/5000 [4:22:47<12:44:19, 11.99s/it, loss=0.6855, lr=9.46e-06]Steps:  23%|██▎       | 1174/5000 [4:22:47<12:44:19, 11.99s/it, loss=0.3921, lr=9.46e-06]Steps:  24%|██▎       | 1175/5000 [4:22:59<12:43:14, 11.97s/it, loss=0.3921, lr=9.46e-06]Steps:  24%|██▎       | 1175/5000 [4:22:59<12:43:14, 11.97s/it, loss=0.6067, lr=9.46e-06]Steps:  24%|██▎       | 1176/5000 [4:23:11<12:47:22, 12.04s/it, loss=0.6067, lr=9.46e-06]Steps:  24%|██▎       | 1176/5000 [4:23:11<12:47:22, 12.04s/it, loss=0.7796, lr=9.45e-06]Steps:  24%|██▎       | 1177/5000 [4:23:23<12:43:29, 11.98s/it, loss=0.7796, lr=9.45e-06]Steps:  24%|██▎       | 1177/5000 [4:23:23<12:43:29, 11.98s/it, loss=0.4736, lr=9.45e-06]Steps:  24%|██▎       | 1178/5000 [4:23:35<12:47:47, 12.05s/it, loss=0.4736, lr=9.45e-06]Steps:  24%|██▎       | 1178/5000 [4:23:35<12:47:47, 12.05s/it, loss=1.0420, lr=9.45e-06]Steps:  24%|██▎       | 1179/5000 [4:23:47<12:42:25, 11.97s/it, loss=1.0420, lr=9.45e-06]Steps:  24%|██▎       | 1179/5000 [4:23:47<12:42:25, 11.97s/it, loss=1.2158, lr=9.45e-06]Steps:  24%|██▎       | 1180/5000 [4:23:59<12:40:02, 11.94s/it, loss=1.2158, lr=9.45e-06]Steps:  24%|██▎       | 1180/5000 [4:23:59<12:40:02, 11.94s/it, loss=1.1550, lr=9.45e-06]
[Step 1180] Training Debug Info:
  Loss: 0.631806
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0117, std: 0.9414
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0140, std: 1.3750
  Model pred mean: 0.0078, std: 1.1172
  Sigmas: [0.9609375]... (timesteps: [960.0])

[Step 1180] Training Debug Info:
  Loss: 0.512051
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0240, std: 0.8516
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0233, std: 1.3125
  Model pred mean: 0.0229, std: 1.1016
  Sigmas: [0.68359375]... (timesteps: [682.0])

[Step 1180] Training Debug Info:
  Loss: 0.657460
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0366, std: 0.9688
  Noise mean: -0.0047, std: 1.0000
  Target mean: -0.0413, std: 1.3906
  Model pred mean: -0.0413, std: 1.1328
  Sigmas: [0.470703125]... (timesteps: [470.0])

[Step 1180] Training Debug Info:
  Loss: 1.155198
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0388, std: 0.8398
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0420, std: 1.3047
  Model pred mean: 0.0381, std: 0.7422
  Sigmas: [0.09423828125]... (timesteps: [94.0])
Steps:  24%|██▎       | 1181/5000 [4:24:11<12:38:04, 11.91s/it, loss=1.1550, lr=9.45e-06]Steps:  24%|██▎       | 1181/5000 [4:24:11<12:38:04, 11.91s/it, loss=1.1552, lr=9.45e-06]Steps:  24%|██▎       | 1182/5000 [4:24:23<12:38:55, 11.93s/it, loss=1.1552, lr=9.45e-06]Steps:  24%|██▎       | 1182/5000 [4:24:23<12:38:55, 11.93s/it, loss=0.4215, lr=9.44e-06]Steps:  24%|██▎       | 1183/5000 [4:24:34<12:38:35, 11.92s/it, loss=0.4215, lr=9.44e-06]Steps:  24%|██▎       | 1183/5000 [4:24:34<12:38:35, 11.92s/it, loss=1.1314, lr=9.44e-06]Steps:  24%|██▎       | 1184/5000 [4:24:46<12:39:21, 11.94s/it, loss=1.1314, lr=9.44e-06]Steps:  24%|██▎       | 1184/5000 [4:24:46<12:39:21, 11.94s/it, loss=0.5849, lr=9.44e-06]Steps:  24%|██▎       | 1185/5000 [4:24:59<12:44:26, 12.02s/it, loss=0.5849, lr=9.44e-06]Steps:  24%|██▎       | 1185/5000 [4:24:59<12:44:26, 12.02s/it, loss=0.4509, lr=9.44e-06]Steps:  24%|██▎       | 1186/5000 [4:25:11<12:42:32, 12.00s/it, loss=0.4509, lr=9.44e-06]Steps:  24%|██▎       | 1186/5000 [4:25:11<12:42:32, 12.00s/it, loss=0.4390, lr=9.44e-06]Steps:  24%|██▎       | 1187/5000 [4:25:23<12:40:29, 11.97s/it, loss=0.4390, lr=9.44e-06]Steps:  24%|██▎       | 1187/5000 [4:25:23<12:40:29, 11.97s/it, loss=1.1575, lr=9.44e-06]Steps:  24%|██▍       | 1188/5000 [4:25:35<12:41:16, 11.98s/it, loss=1.1575, lr=9.44e-06]Steps:  24%|██▍       | 1188/5000 [4:25:35<12:41:16, 11.98s/it, loss=0.9753, lr=9.43e-06]Steps:  24%|██▍       | 1189/5000 [4:25:46<12:38:47, 11.95s/it, loss=0.9753, lr=9.43e-06]Steps:  24%|██▍       | 1189/5000 [4:25:46<12:38:47, 11.95s/it, loss=1.1064, lr=9.43e-06]Steps:  24%|██▍       | 1190/5000 [4:25:58<12:39:07, 11.95s/it, loss=1.1064, lr=9.43e-06]Steps:  24%|██▍       | 1190/5000 [4:25:58<12:39:07, 11.95s/it, loss=0.3933, lr=9.43e-06]
[Step 1190] Training Debug Info:
  Loss: 0.779996
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0154, std: 0.9180
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0142, std: 1.3594
  Model pred mean: -0.0122, std: 1.0312
  Sigmas: [0.46484375]... (timesteps: [465.0])

[Step 1190] Training Debug Info:
  Loss: 0.412549
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0315, std: 0.9180
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0295, std: 1.3594
  Model pred mean: -0.0308, std: 1.1953
  Sigmas: [0.70703125]... (timesteps: [708.0])

[Step 1190] Training Debug Info:
  Loss: 0.932048
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.9414
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0005, std: 1.3750
  Model pred mean: -0.0025, std: 0.9727
  Sigmas: [0.341796875]... (timesteps: [342.0])

[Step 1190] Training Debug Info:
  Loss: 0.534575
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0312, std: 0.9648
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0310, std: 1.3906
  Model pred mean: 0.0339, std: 1.1797
  Sigmas: [0.60546875]... (timesteps: [607.0])
Steps:  24%|██▍       | 1191/5000 [4:26:10<12:36:26, 11.92s/it, loss=0.3933, lr=9.43e-06]Steps:  24%|██▍       | 1191/5000 [4:26:10<12:36:26, 11.92s/it, loss=0.5346, lr=9.43e-06]Steps:  24%|██▍       | 1192/5000 [4:26:22<12:43:39, 12.03s/it, loss=0.5346, lr=9.43e-06]Steps:  24%|██▍       | 1192/5000 [4:26:22<12:43:39, 12.03s/it, loss=1.1435, lr=9.43e-06]Steps:  24%|██▍       | 1193/5000 [4:26:34<12:41:53, 12.01s/it, loss=1.1435, lr=9.43e-06]Steps:  24%|██▍       | 1193/5000 [4:26:34<12:41:53, 12.01s/it, loss=1.1292, lr=9.43e-06]Steps:  24%|██▍       | 1194/5000 [4:26:46<12:40:05, 11.98s/it, loss=1.1292, lr=9.43e-06]Steps:  24%|██▍       | 1194/5000 [4:26:46<12:40:05, 11.98s/it, loss=0.9069, lr=9.42e-06]Steps:  24%|██▍       | 1195/5000 [4:26:58<12:38:54, 11.97s/it, loss=0.9069, lr=9.42e-06]Steps:  24%|██▍       | 1195/5000 [4:26:58<12:38:54, 11.97s/it, loss=1.0195, lr=9.42e-06]Steps:  24%|██▍       | 1196/5000 [4:27:10<12:38:18, 11.96s/it, loss=1.0195, lr=9.42e-06]Steps:  24%|██▍       | 1196/5000 [4:27:10<12:38:18, 11.96s/it, loss=0.4922, lr=9.42e-06]Steps:  24%|██▍       | 1197/5000 [4:27:22<12:37:12, 11.95s/it, loss=0.4922, lr=9.42e-06]Steps:  24%|██▍       | 1197/5000 [4:27:22<12:37:12, 11.95s/it, loss=0.6343, lr=9.42e-06]Steps:  24%|██▍       | 1198/5000 [4:27:34<12:41:35, 12.02s/it, loss=0.6343, lr=9.42e-06]Steps:  24%|██▍       | 1198/5000 [4:27:34<12:41:35, 12.02s/it, loss=1.0409, lr=9.42e-06]Steps:  24%|██▍       | 1199/5000 [4:27:46<12:39:59, 12.00s/it, loss=1.0409, lr=9.42e-06]Steps:  24%|██▍       | 1199/5000 [4:27:46<12:39:59, 12.00s/it, loss=0.5149, lr=9.42e-06]Steps:  24%|██▍       | 1200/5000 [4:27:58<12:38:02, 11.97s/it, loss=0.5149, lr=9.42e-06]Steps:  24%|██▍       | 1200/5000 [4:27:58<12:38:02, 11.97s/it, loss=1.0691, lr=9.41e-06]01/22/2026 12:13:45 - INFO - __main__ - 
[Step 1200] ✅ Loss in normal range (1.0691)
01/22/2026 12:13:45 - INFO - __main__ -   Loss avg (last 100): 0.7557
01/22/2026 12:13:45 - INFO - __main__ -   Loss range: [0.3363, 1.2158]
01/22/2026 12:13:45 - INFO - __main__ - 
🔍 Running validation at step 1200...
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1200 (parquet mode)...
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1200...
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 12:13:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.23it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.50it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 12:14:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 12:14:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 12:14:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 12:14:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.13it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 12:14:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 12:14:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 12:15:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 12:15:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 12:15:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 12:15:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 12:15:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 12:15:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 12:16:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 12:16:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 12:16:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 12:16:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 12:16:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 12:16:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 12:17:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 12:17:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 12:17:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 12:17:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 12:17:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200/step001200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 12:17:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 12:17:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 12:17:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001200
01/22/2026 12:17:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1200] Training Debug Info:
  Loss: 0.498462
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0132, std: 0.9102
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0145, std: 1.3516
  Model pred mean: -0.0187, std: 1.1562
  Sigmas: [0.640625]... (timesteps: [642.0])

[Step 1200] Training Debug Info:
  Loss: 1.051322
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0204, std: 0.9258
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0194, std: 1.3672
  Model pred mean: 0.0195, std: 0.9023
  Sigmas: [0.3203125]... (timesteps: [320.0])

[Step 1200] Training Debug Info:
  Loss: 1.135631
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9336
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0004, std: 1.3672
  Model pred mean: 0.0048, std: 0.8633
  Sigmas: [0.1357421875]... (timesteps: [136.0])

[Step 1200] Training Debug Info:
  Loss: 0.668002
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0610, std: 0.9883
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0593, std: 1.4062
  Model pred mean: -0.0649, std: 1.1406
  Sigmas: [0.427734375]... (timesteps: [427.0])
Steps:  24%|██▍       | 1201/5000 [4:32:21<92:07:22, 87.30s/it, loss=1.0691, lr=9.41e-06]Steps:  24%|██▍       | 1201/5000 [4:32:21<92:07:22, 87.30s/it, loss=0.6680, lr=9.41e-06]Steps:  24%|██▍       | 1202/5000 [4:32:33<68:13:58, 64.68s/it, loss=0.6680, lr=9.41e-06]Steps:  24%|██▍       | 1202/5000 [4:32:33<68:13:58, 64.68s/it, loss=1.1376, lr=9.41e-06]Steps:  24%|██▍       | 1203/5000 [4:32:45<51:30:10, 48.83s/it, loss=1.1376, lr=9.41e-06]Steps:  24%|██▍       | 1203/5000 [4:32:45<51:30:10, 48.83s/it, loss=0.7053, lr=9.41e-06]Steps:  24%|██▍       | 1204/5000 [4:32:57<39:49:12, 37.76s/it, loss=0.7053, lr=9.41e-06]Steps:  24%|██▍       | 1204/5000 [4:32:57<39:49:12, 37.76s/it, loss=0.4535, lr=9.41e-06]Steps:  24%|██▍       | 1205/5000 [4:33:09<31:43:32, 30.10s/it, loss=0.4535, lr=9.41e-06]Steps:  24%|██▍       | 1205/5000 [4:33:09<31:43:32, 30.10s/it, loss=1.1817, lr=9.41e-06]Steps:  24%|██▍       | 1206/5000 [4:33:21<25:58:37, 24.65s/it, loss=1.1817, lr=9.41e-06]Steps:  24%|██▍       | 1206/5000 [4:33:21<25:58:37, 24.65s/it, loss=0.6964, lr=9.40e-06]Steps:  24%|██▍       | 1207/5000 [4:33:33<21:56:52, 20.83s/it, loss=0.6964, lr=9.40e-06]Steps:  24%|██▍       | 1207/5000 [4:33:33<21:56:52, 20.83s/it, loss=0.3673, lr=9.40e-06]Steps:  24%|██▍       | 1208/5000 [4:33:45<19:07:23, 18.15s/it, loss=0.3673, lr=9.40e-06]Steps:  24%|██▍       | 1208/5000 [4:33:45<19:07:23, 18.15s/it, loss=0.4234, lr=9.40e-06]Steps:  24%|██▍       | 1209/5000 [4:33:57<17:09:00, 16.29s/it, loss=0.4234, lr=9.40e-06]Steps:  24%|██▍       | 1209/5000 [4:33:57<17:09:00, 16.29s/it, loss=1.0613, lr=9.40e-06]Steps:  24%|██▍       | 1210/5000 [4:34:09<15:46:42, 14.99s/it, loss=1.0613, lr=9.40e-06]Steps:  24%|██▍       | 1210/5000 [4:34:09<15:46:42, 14.99s/it, loss=0.3858, lr=9.40e-06]
[Step 1210] Training Debug Info:
  Loss: 1.040870
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0280, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0271, std: 1.3594
  Model pred mean: -0.0271, std: 0.9062
  Sigmas: [0.02197265625]... (timesteps: [22.0])

[Step 1210] Training Debug Info:
  Loss: 0.387473
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0159, std: 0.8516
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0143, std: 1.3203
  Model pred mean: 0.0171, std: 1.1641
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 1210] Training Debug Info:
  Loss: 0.810377
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0474, std: 0.9492
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0486, std: 1.3750
  Model pred mean: -0.0503, std: 1.0469
  Sigmas: [0.41015625]... (timesteps: [410.0])

[Step 1210] Training Debug Info:
  Loss: 0.909918
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0322, std: 0.9297
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0349, std: 1.3672
  Model pred mean: 0.0320, std: 0.9844
  Sigmas: [0.353515625]... (timesteps: [353.0])
Steps:  24%|██▍       | 1211/5000 [4:34:21<14:48:45, 14.07s/it, loss=0.3858, lr=9.40e-06]Steps:  24%|██▍       | 1211/5000 [4:34:21<14:48:45, 14.07s/it, loss=0.9099, lr=9.40e-06]Steps:  24%|██▍       | 1212/5000 [4:34:33<14:13:01, 13.51s/it, loss=0.9099, lr=9.40e-06]Steps:  24%|██▍       | 1212/5000 [4:34:33<14:13:01, 13.51s/it, loss=0.4387, lr=9.39e-06]Steps:  24%|██▍       | 1213/5000 [4:34:45<13:42:47, 13.04s/it, loss=0.4387, lr=9.39e-06]Steps:  24%|██▍       | 1213/5000 [4:34:45<13:42:47, 13.04s/it, loss=1.1506, lr=9.39e-06]Steps:  24%|██▍       | 1214/5000 [4:34:57<13:20:35, 12.69s/it, loss=1.1506, lr=9.39e-06]Steps:  24%|██▍       | 1214/5000 [4:34:57<13:20:35, 12.69s/it, loss=0.4729, lr=9.39e-06]Steps:  24%|██▍       | 1215/5000 [4:35:09<13:05:36, 12.45s/it, loss=0.4729, lr=9.39e-06]Steps:  24%|██▍       | 1215/5000 [4:35:09<13:05:36, 12.45s/it, loss=1.0554, lr=9.39e-06]Steps:  24%|██▍       | 1216/5000 [4:35:21<12:55:38, 12.30s/it, loss=1.0554, lr=9.39e-06]Steps:  24%|██▍       | 1216/5000 [4:35:21<12:55:38, 12.30s/it, loss=0.8798, lr=9.39e-06]Steps:  24%|██▍       | 1217/5000 [4:35:32<12:46:56, 12.16s/it, loss=0.8798, lr=9.39e-06]Steps:  24%|██▍       | 1217/5000 [4:35:32<12:46:56, 12.16s/it, loss=1.0922, lr=9.39e-06]Steps:  24%|██▍       | 1218/5000 [4:35:44<12:42:13, 12.09s/it, loss=1.0922, lr=9.39e-06]Steps:  24%|██▍       | 1218/5000 [4:35:44<12:42:13, 12.09s/it, loss=0.6022, lr=9.38e-06]Steps:  24%|██▍       | 1219/5000 [4:35:57<12:44:22, 12.13s/it, loss=0.6022, lr=9.38e-06]Steps:  24%|██▍       | 1219/5000 [4:35:57<12:44:22, 12.13s/it, loss=1.1108, lr=9.38e-06]Steps:  24%|██▍       | 1220/5000 [4:36:09<12:41:32, 12.09s/it, loss=1.1108, lr=9.38e-06]Steps:  24%|██▍       | 1220/5000 [4:36:09<12:41:32, 12.09s/it, loss=0.4119, lr=9.38e-06]
[Step 1220] Training Debug Info:
  Loss: 0.927401
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0090, std: 0.9180
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0112, std: 1.3594
  Model pred mean: -0.0099, std: 0.9609
  Sigmas: [0.32421875]... (timesteps: [324.0])

[Step 1220] Training Debug Info:
  Loss: 0.374697
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0150, std: 0.9102
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0176, std: 1.3516
  Model pred mean: 0.0020, std: 1.1953
  Sigmas: [0.90625]... (timesteps: [906.0])

[Step 1220] Training Debug Info:
  Loss: 0.568327
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0111, std: 0.9375
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0125, std: 1.3672
  Model pred mean: -0.0028, std: 1.1172
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 1220] Training Debug Info:
  Loss: 0.448450
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0118, std: 0.9531
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0106, std: 1.3828
  Model pred mean: -0.0153, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [792.0])
Steps:  24%|██▍       | 1221/5000 [4:36:20<12:38:11, 12.04s/it, loss=0.4119, lr=9.38e-06]Steps:  24%|██▍       | 1221/5000 [4:36:20<12:38:11, 12.04s/it, loss=0.4485, lr=9.38e-06]Steps:  24%|██▍       | 1222/5000 [4:36:32<12:36:28, 12.01s/it, loss=0.4485, lr=9.38e-06]Steps:  24%|██▍       | 1222/5000 [4:36:32<12:36:28, 12.01s/it, loss=0.3585, lr=9.38e-06]Steps:  24%|██▍       | 1223/5000 [4:36:44<12:33:31, 11.97s/it, loss=0.3585, lr=9.38e-06]Steps:  24%|██▍       | 1223/5000 [4:36:44<12:33:31, 11.97s/it, loss=0.7574, lr=9.38e-06]Steps:  24%|██▍       | 1224/5000 [4:36:56<12:35:19, 12.00s/it, loss=0.7574, lr=9.38e-06]Steps:  24%|██▍       | 1224/5000 [4:36:56<12:35:19, 12.00s/it, loss=1.1065, lr=9.37e-06]Steps:  24%|██▍       | 1225/5000 [4:37:09<12:39:54, 12.08s/it, loss=1.1065, lr=9.37e-06]Steps:  24%|██▍       | 1225/5000 [4:37:09<12:39:54, 12.08s/it, loss=0.4070, lr=9.37e-06]Steps:  25%|██▍       | 1226/5000 [4:37:20<12:34:31, 12.00s/it, loss=0.4070, lr=9.37e-06]Steps:  25%|██▍       | 1226/5000 [4:37:20<12:34:31, 12.00s/it, loss=0.6301, lr=9.37e-06]Steps:  25%|██▍       | 1227/5000 [4:37:32<12:33:27, 11.98s/it, loss=0.6301, lr=9.37e-06]Steps:  25%|██▍       | 1227/5000 [4:37:32<12:33:27, 11.98s/it, loss=0.4140, lr=9.37e-06]Steps:  25%|██▍       | 1228/5000 [4:37:44<12:31:38, 11.96s/it, loss=0.4140, lr=9.37e-06]Steps:  25%|██▍       | 1228/5000 [4:37:44<12:31:38, 11.96s/it, loss=0.7883, lr=9.37e-06]Steps:  25%|██▍       | 1229/5000 [4:37:56<12:31:45, 11.96s/it, loss=0.7883, lr=9.37e-06]Steps:  25%|██▍       | 1229/5000 [4:37:56<12:31:45, 11.96s/it, loss=0.5438, lr=9.37e-06]Steps:  25%|██▍       | 1230/5000 [4:38:08<12:29:28, 11.93s/it, loss=0.5438, lr=9.37e-06]Steps:  25%|██▍       | 1230/5000 [4:38:08<12:29:28, 11.93s/it, loss=0.4536, lr=9.36e-06]
[Step 1230] Training Debug Info:
  Loss: 0.511923
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0189, std: 0.9023
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0187, std: 1.3438
  Model pred mean: -0.0188, std: 1.1406
  Sigmas: [0.640625]... (timesteps: [640.0])

[Step 1230] Training Debug Info:
  Loss: 1.100916
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0204, std: 0.8984
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0192, std: 1.3438
  Model pred mean: 0.0193, std: 0.8398
  Sigmas: [0.0751953125]... (timesteps: [75.0])

[Step 1230] Training Debug Info:
  Loss: 0.881390
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0060, std: 0.9258
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0078, std: 1.3672
  Model pred mean: -0.0040, std: 0.9844
  Sigmas: [0.408203125]... (timesteps: [409.0])

[Step 1230] Training Debug Info:
  Loss: 0.621266
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0020, std: 0.8750
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0016, std: 1.3281
  Model pred mean: 0.0015, std: 1.0703
  Sigmas: [0.58984375]... (timesteps: [590.0])
Steps:  25%|██▍       | 1231/5000 [4:38:20<12:28:53, 11.92s/it, loss=0.4536, lr=9.36e-06]Steps:  25%|██▍       | 1231/5000 [4:38:20<12:28:53, 11.92s/it, loss=0.6213, lr=9.36e-06]Steps:  25%|██▍       | 1232/5000 [4:38:32<12:35:35, 12.03s/it, loss=0.6213, lr=9.36e-06]Steps:  25%|██▍       | 1232/5000 [4:38:32<12:35:35, 12.03s/it, loss=0.3836, lr=9.36e-06]Steps:  25%|██▍       | 1233/5000 [4:38:44<12:32:46, 11.99s/it, loss=0.3836, lr=9.36e-06]Steps:  25%|██▍       | 1233/5000 [4:38:44<12:32:46, 11.99s/it, loss=1.1705, lr=9.36e-06]Steps:  25%|██▍       | 1234/5000 [4:38:56<12:31:42, 11.98s/it, loss=1.1705, lr=9.36e-06]Steps:  25%|██▍       | 1234/5000 [4:38:56<12:31:42, 11.98s/it, loss=1.0330, lr=9.36e-06]Steps:  25%|██▍       | 1235/5000 [4:39:08<12:30:29, 11.96s/it, loss=1.0330, lr=9.36e-06]Steps:  25%|██▍       | 1235/5000 [4:39:08<12:30:29, 11.96s/it, loss=1.1576, lr=9.36e-06]Steps:  25%|██▍       | 1236/5000 [4:39:20<12:28:47, 11.94s/it, loss=1.1576, lr=9.36e-06]Steps:  25%|██▍       | 1236/5000 [4:39:20<12:28:47, 11.94s/it, loss=0.4989, lr=9.35e-06]Steps:  25%|██▍       | 1237/5000 [4:39:32<12:28:55, 11.94s/it, loss=0.4989, lr=9.35e-06]Steps:  25%|██▍       | 1237/5000 [4:39:32<12:28:55, 11.94s/it, loss=0.5740, lr=9.35e-06]Steps:  25%|██▍       | 1238/5000 [4:39:44<12:27:53, 11.93s/it, loss=0.5740, lr=9.35e-06]Steps:  25%|██▍       | 1238/5000 [4:39:44<12:27:53, 11.93s/it, loss=1.0869, lr=9.35e-06]Steps:  25%|██▍       | 1239/5000 [4:39:56<12:33:21, 12.02s/it, loss=1.0869, lr=9.35e-06]Steps:  25%|██▍       | 1239/5000 [4:39:56<12:33:21, 12.02s/it, loss=1.1818, lr=9.35e-06]Steps:  25%|██▍       | 1240/5000 [4:40:08<12:33:08, 12.02s/it, loss=1.1818, lr=9.35e-06]Steps:  25%|██▍       | 1240/5000 [4:40:08<12:33:08, 12.02s/it, loss=0.7479, lr=9.35e-06]
[Step 1240] Training Debug Info:
  Loss: 0.734436
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0236, std: 0.9766
  Noise mean: -0.0007, std: 0.9961
  Target mean: -0.0242, std: 1.3906
  Model pred mean: -0.0236, std: 1.1016
  Sigmas: [0.46484375]... (timesteps: [465.0])

[Step 1240] Training Debug Info:
  Loss: 1.124921
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0559, std: 1.0078
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0571, std: 1.4219
  Model pred mean: -0.0540, std: 0.9492
  Sigmas: [0.177734375]... (timesteps: [178.0])

[Step 1240] Training Debug Info:
  Loss: 1.085217
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0160, std: 0.8789
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0164, std: 1.3281
  Model pred mean: 0.0179, std: 0.8281
  Sigmas: [0.326171875]... (timesteps: [326.0])

[Step 1240] Training Debug Info:
  Loss: 0.397813
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0134, std: 0.8867
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0138, std: 1.3359
  Model pred mean: 0.0145, std: 1.1797
  Sigmas: [0.78125]... (timesteps: [781.0])
Steps:  25%|██▍       | 1241/5000 [4:40:20<12:31:34, 12.00s/it, loss=0.7479, lr=9.35e-06]Steps:  25%|██▍       | 1241/5000 [4:40:20<12:31:34, 12.00s/it, loss=0.3978, lr=9.35e-06]Steps:  25%|██▍       | 1242/5000 [4:40:32<12:30:03, 11.98s/it, loss=0.3978, lr=9.35e-06]Steps:  25%|██▍       | 1242/5000 [4:40:32<12:30:03, 11.98s/it, loss=0.4937, lr=9.34e-06]Steps:  25%|██▍       | 1243/5000 [4:40:44<12:29:40, 11.97s/it, loss=0.4937, lr=9.34e-06]Steps:  25%|██▍       | 1243/5000 [4:40:44<12:29:40, 11.97s/it, loss=0.3686, lr=9.34e-06]Steps:  25%|██▍       | 1244/5000 [4:40:56<12:28:00, 11.95s/it, loss=0.3686, lr=9.34e-06]Steps:  25%|██▍       | 1244/5000 [4:40:56<12:28:00, 11.95s/it, loss=0.5330, lr=9.34e-06]Steps:  25%|██▍       | 1245/5000 [4:41:08<12:28:09, 11.95s/it, loss=0.5330, lr=9.34e-06]Steps:  25%|██▍       | 1245/5000 [4:41:08<12:28:09, 11.95s/it, loss=1.0830, lr=9.34e-06]Steps:  25%|██▍       | 1246/5000 [4:41:20<12:33:27, 12.04s/it, loss=1.0830, lr=9.34e-06]Steps:  25%|██▍       | 1246/5000 [4:41:20<12:33:27, 12.04s/it, loss=1.0710, lr=9.34e-06]Steps:  25%|██▍       | 1247/5000 [4:41:32<12:35:21, 12.08s/it, loss=1.0710, lr=9.34e-06]Steps:  25%|██▍       | 1247/5000 [4:41:32<12:35:21, 12.08s/it, loss=0.4193, lr=9.34e-06]Steps:  25%|██▍       | 1248/5000 [4:41:44<12:32:34, 12.03s/it, loss=0.4193, lr=9.34e-06]Steps:  25%|██▍       | 1248/5000 [4:41:44<12:32:34, 12.03s/it, loss=1.1985, lr=9.33e-06]Steps:  25%|██▍       | 1249/5000 [4:41:56<12:30:09, 12.00s/it, loss=1.1985, lr=9.33e-06]Steps:  25%|██▍       | 1249/5000 [4:41:56<12:30:09, 12.00s/it, loss=1.1552, lr=9.33e-06]Steps:  25%|██▌       | 1250/5000 [4:42:08<12:28:34, 11.98s/it, loss=1.1552, lr=9.33e-06]Steps:  25%|██▌       | 1250/5000 [4:42:08<12:28:34, 11.98s/it, loss=0.3751, lr=9.33e-06]
[Step 1250] Training Debug Info:
  Loss: 1.156213
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0120, std: 0.8789
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0142, std: 1.3281
  Model pred mean: 0.0087, std: 0.7812
  Sigmas: [0.28125]... (timesteps: [281.0])

[Step 1250] Training Debug Info:
  Loss: 0.539674
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.9219
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0107, std: 1.3594
  Model pred mean: -0.0117, std: 1.1406
  Sigmas: [0.6015625]... (timesteps: [600.0])

[Step 1250] Training Debug Info:
  Loss: 1.157055
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0199, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0210, std: 1.3594
  Model pred mean: -0.0210, std: 0.8320
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 1250] Training Debug Info:
  Loss: 0.642039
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0232, std: 0.9297
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0238, std: 1.3672
  Model pred mean: -0.0261, std: 1.1094
  Sigmas: [0.515625]... (timesteps: [514.0])
Steps:  25%|██▌       | 1251/5000 [4:42:20<12:27:00, 11.96s/it, loss=0.3751, lr=9.33e-06]Steps:  25%|██▌       | 1251/5000 [4:42:20<12:27:00, 11.96s/it, loss=0.6420, lr=9.33e-06]Steps:  25%|██▌       | 1252/5000 [4:42:32<12:31:43, 12.03s/it, loss=0.6420, lr=9.33e-06]Steps:  25%|██▌       | 1252/5000 [4:42:32<12:31:43, 12.03s/it, loss=0.6318, lr=9.33e-06]Steps:  25%|██▌       | 1253/5000 [4:42:44<12:29:44, 12.01s/it, loss=0.6318, lr=9.33e-06]Steps:  25%|██▌       | 1253/5000 [4:42:44<12:29:44, 12.01s/it, loss=1.0983, lr=9.32e-06]Steps:  25%|██▌       | 1254/5000 [4:42:56<12:31:52, 12.04s/it, loss=1.0983, lr=9.32e-06]Steps:  25%|██▌       | 1254/5000 [4:42:56<12:31:52, 12.04s/it, loss=0.5884, lr=9.32e-06]Steps:  25%|██▌       | 1255/5000 [4:43:08<12:28:41, 11.99s/it, loss=0.5884, lr=9.32e-06]Steps:  25%|██▌       | 1255/5000 [4:43:08<12:28:41, 11.99s/it, loss=1.1068, lr=9.32e-06]Steps:  25%|██▌       | 1256/5000 [4:43:20<12:27:10, 11.97s/it, loss=1.1068, lr=9.32e-06]Steps:  25%|██▌       | 1256/5000 [4:43:20<12:27:10, 11.97s/it, loss=1.1153, lr=9.32e-06]Steps:  25%|██▌       | 1257/5000 [4:43:32<12:26:33, 11.97s/it, loss=1.1153, lr=9.32e-06]Steps:  25%|██▌       | 1257/5000 [4:43:32<12:26:33, 11.97s/it, loss=0.6172, lr=9.32e-06]Steps:  25%|██▌       | 1258/5000 [4:43:44<12:24:09, 11.93s/it, loss=0.6172, lr=9.32e-06]Steps:  25%|██▌       | 1258/5000 [4:43:44<12:24:09, 11.93s/it, loss=0.4427, lr=9.32e-06]Steps:  25%|██▌       | 1259/5000 [4:43:56<12:29:44, 12.02s/it, loss=0.4427, lr=9.32e-06]Steps:  25%|██▌       | 1259/5000 [4:43:56<12:29:44, 12.02s/it, loss=1.1561, lr=9.31e-06]Steps:  25%|██▌       | 1260/5000 [4:44:08<12:26:51, 11.98s/it, loss=1.1561, lr=9.31e-06]Steps:  25%|██▌       | 1260/5000 [4:44:08<12:26:51, 11.98s/it, loss=1.0603, lr=9.31e-06]
[Step 1260] Training Debug Info:
  Loss: 0.634763
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0009, std: 0.9102
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0047, std: 1.3516
  Model pred mean: 0.0015, std: 1.0859
  Sigmas: [0.5859375]... (timesteps: [585.0])

[Step 1260] Training Debug Info:
  Loss: 1.108087
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0025, std: 0.9023
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0061, std: 1.3516
  Model pred mean: -0.0009, std: 0.8398
  Sigmas: [0.06884765625]... (timesteps: [69.0])

[Step 1260] Training Debug Info:
  Loss: 0.981354
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0053, std: 0.9023
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0054, std: 1.3516
  Model pred mean: -0.0029, std: 0.9102
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 1260] Training Debug Info:
  Loss: 1.030564
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0280, std: 0.8828
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0286, std: 1.3281
  Model pred mean: -0.0272, std: 0.8555
  Sigmas: [0.0159912109375]... (timesteps: [16.0])
Steps:  25%|██▌       | 1261/5000 [4:44:20<12:29:00, 12.02s/it, loss=1.0603, lr=9.31e-06]Steps:  25%|██▌       | 1261/5000 [4:44:20<12:29:00, 12.02s/it, loss=1.0306, lr=9.31e-06]Steps:  25%|██▌       | 1262/5000 [4:44:32<12:25:31, 11.97s/it, loss=1.0306, lr=9.31e-06]Steps:  25%|██▌       | 1262/5000 [4:44:32<12:25:31, 11.97s/it, loss=0.4992, lr=9.31e-06]Steps:  25%|██▌       | 1263/5000 [4:44:44<12:23:57, 11.94s/it, loss=0.4992, lr=9.31e-06]Steps:  25%|██▌       | 1263/5000 [4:44:44<12:23:57, 11.94s/it, loss=0.5017, lr=9.31e-06]Steps:  25%|██▌       | 1264/5000 [4:44:56<12:23:52, 11.95s/it, loss=0.5017, lr=9.31e-06]Steps:  25%|██▌       | 1264/5000 [4:44:56<12:23:52, 11.95s/it, loss=0.8225, lr=9.31e-06]Steps:  25%|██▌       | 1265/5000 [4:45:08<12:22:41, 11.93s/it, loss=0.8225, lr=9.31e-06]Steps:  25%|██▌       | 1265/5000 [4:45:08<12:22:41, 11.93s/it, loss=1.0308, lr=9.30e-06]Steps:  25%|██▌       | 1266/5000 [4:45:20<12:26:48, 12.00s/it, loss=1.0308, lr=9.30e-06]Steps:  25%|██▌       | 1266/5000 [4:45:20<12:26:48, 12.00s/it, loss=0.8160, lr=9.30e-06]Steps:  25%|██▌       | 1267/5000 [4:45:32<12:25:22, 11.98s/it, loss=0.8160, lr=9.30e-06]Steps:  25%|██▌       | 1267/5000 [4:45:32<12:25:22, 11.98s/it, loss=0.7360, lr=9.30e-06]Steps:  25%|██▌       | 1268/5000 [4:45:44<12:24:15, 11.97s/it, loss=0.7360, lr=9.30e-06]Steps:  25%|██▌       | 1268/5000 [4:45:44<12:24:15, 11.97s/it, loss=1.0292, lr=9.30e-06]Steps:  25%|██▌       | 1269/5000 [4:45:56<12:23:16, 11.95s/it, loss=1.0292, lr=9.30e-06]Steps:  25%|██▌       | 1269/5000 [4:45:56<12:23:16, 11.95s/it, loss=1.1491, lr=9.30e-06]Steps:  25%|██▌       | 1270/5000 [4:46:07<12:22:05, 11.94s/it, loss=1.1491, lr=9.30e-06]Steps:  25%|██▌       | 1270/5000 [4:46:07<12:22:05, 11.94s/it, loss=0.3733, lr=9.29e-06]
[Step 1270] Training Debug Info:
  Loss: 0.463634
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0109, std: 0.9727
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0104, std: 1.3906
  Model pred mean: -0.0184, std: 1.2109
  Sigmas: [0.875]... (timesteps: [875.0])

[Step 1270] Training Debug Info:
  Loss: 0.608199
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0182, std: 0.9062
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0178, std: 1.3516
  Model pred mean: 0.0167, std: 1.1016
  Sigmas: [0.58984375]... (timesteps: [588.0])

[Step 1270] Training Debug Info:
  Loss: 0.639171
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0248, std: 0.9297
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0244, std: 1.3672
  Model pred mean: -0.0293, std: 1.1016
  Sigmas: [0.4453125]... (timesteps: [445.0])

[Step 1270] Training Debug Info:
  Loss: 0.404536
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0017, std: 0.8750
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0003, std: 1.3281
  Model pred mean: 0.0009, std: 1.1641
  Sigmas: [0.79296875]... (timesteps: [792.0])
Steps:  25%|██▌       | 1271/5000 [4:46:19<12:22:10, 11.94s/it, loss=0.3733, lr=9.29e-06]Steps:  25%|██▌       | 1271/5000 [4:46:19<12:22:10, 11.94s/it, loss=0.4045, lr=9.29e-06]Steps:  25%|██▌       | 1272/5000 [4:46:31<12:22:02, 11.94s/it, loss=0.4045, lr=9.29e-06]Steps:  25%|██▌       | 1272/5000 [4:46:31<12:22:02, 11.94s/it, loss=0.3681, lr=9.29e-06]Steps:  25%|██▌       | 1273/5000 [4:46:44<12:27:06, 12.03s/it, loss=0.3681, lr=9.29e-06]Steps:  25%|██▌       | 1273/5000 [4:46:44<12:27:06, 12.03s/it, loss=1.1129, lr=9.29e-06]Steps:  25%|██▌       | 1274/5000 [4:46:55<12:24:56, 12.00s/it, loss=1.1129, lr=9.29e-06]Steps:  25%|██▌       | 1274/5000 [4:46:55<12:24:56, 12.00s/it, loss=0.3734, lr=9.29e-06]Steps:  26%|██▌       | 1275/5000 [4:47:07<12:22:34, 11.96s/it, loss=0.3734, lr=9.29e-06]Steps:  26%|██▌       | 1275/5000 [4:47:07<12:22:34, 11.96s/it, loss=0.8119, lr=9.29e-06]Steps:  26%|██▌       | 1276/5000 [4:47:19<12:22:19, 11.96s/it, loss=0.8119, lr=9.29e-06]Steps:  26%|██▌       | 1276/5000 [4:47:19<12:22:19, 11.96s/it, loss=1.0433, lr=9.28e-06]Steps:  26%|██▌       | 1277/5000 [4:47:31<12:23:55, 11.99s/it, loss=1.0433, lr=9.28e-06]Steps:  26%|██▌       | 1277/5000 [4:47:31<12:23:55, 11.99s/it, loss=0.7666, lr=9.28e-06]Steps:  26%|██▌       | 1278/5000 [4:47:43<12:23:20, 11.98s/it, loss=0.7666, lr=9.28e-06]Steps:  26%|██▌       | 1278/5000 [4:47:43<12:23:20, 11.98s/it, loss=0.6312, lr=9.28e-06]Steps:  26%|██▌       | 1279/5000 [4:47:55<12:25:56, 12.03s/it, loss=0.6312, lr=9.28e-06]Steps:  26%|██▌       | 1279/5000 [4:47:55<12:25:56, 12.03s/it, loss=1.1375, lr=9.28e-06]Steps:  26%|██▌       | 1280/5000 [4:48:07<12:22:36, 11.98s/it, loss=1.1375, lr=9.28e-06]Steps:  26%|██▌       | 1280/5000 [4:48:07<12:22:36, 11.98s/it, loss=0.7725, lr=9.28e-06]
[Step 1280] Training Debug Info:
  Loss: 0.599253
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0198, std: 0.8906
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0193, std: 1.3359
  Model pred mean: -0.0208, std: 1.0703
  Sigmas: [0.984375]... (timesteps: [986.0])

[Step 1280] Training Debug Info:
  Loss: 0.634650
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0009, std: 0.9062
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0017, std: 1.3516
  Model pred mean: 0.0036, std: 1.0859
  Sigmas: [0.56640625]... (timesteps: [566.0])

[Step 1280] Training Debug Info:
  Loss: 1.188699
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0129, std: 0.8555
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0131, std: 1.3203
  Model pred mean: 0.0112, std: 0.7344
  Sigmas: [0.142578125]... (timesteps: [143.0])

[Step 1280] Training Debug Info:
  Loss: 0.506806
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0405, std: 0.9766
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0398, std: 1.3984
  Model pred mean: -0.0280, std: 1.2109
  Sigmas: [0.828125]... (timesteps: [830.0])
Steps:  26%|██▌       | 1281/5000 [4:48:19<12:21:27, 11.96s/it, loss=0.7725, lr=9.28e-06]Steps:  26%|██▌       | 1281/5000 [4:48:19<12:21:27, 11.96s/it, loss=0.5068, lr=9.28e-06]Steps:  26%|██▌       | 1282/5000 [4:48:31<12:19:20, 11.93s/it, loss=0.5068, lr=9.28e-06]Steps:  26%|██▌       | 1282/5000 [4:48:31<12:19:20, 11.93s/it, loss=1.0844, lr=9.27e-06]Steps:  26%|██▌       | 1283/5000 [4:48:43<12:18:08, 11.92s/it, loss=1.0844, lr=9.27e-06]Steps:  26%|██▌       | 1283/5000 [4:48:43<12:18:08, 11.92s/it, loss=0.5032, lr=9.27e-06]Steps:  26%|██▌       | 1284/5000 [4:48:55<12:16:13, 11.89s/it, loss=0.5032, lr=9.27e-06]Steps:  26%|██▌       | 1284/5000 [4:48:55<12:16:13, 11.89s/it, loss=1.1409, lr=9.27e-06]Steps:  26%|██▌       | 1285/5000 [4:49:07<12:15:51, 11.88s/it, loss=1.1409, lr=9.27e-06]Steps:  26%|██▌       | 1285/5000 [4:49:07<12:15:51, 11.88s/it, loss=0.3798, lr=9.27e-06]Steps:  26%|██▌       | 1286/5000 [4:49:19<12:23:59, 12.02s/it, loss=0.3798, lr=9.27e-06]Steps:  26%|██▌       | 1286/5000 [4:49:19<12:23:59, 12.02s/it, loss=0.4766, lr=9.27e-06]Steps:  26%|██▌       | 1287/5000 [4:49:31<12:21:52, 11.99s/it, loss=0.4766, lr=9.27e-06]Steps:  26%|██▌       | 1287/5000 [4:49:31<12:21:52, 11.99s/it, loss=0.8538, lr=9.26e-06]Steps:  26%|██▌       | 1288/5000 [4:49:43<12:20:26, 11.97s/it, loss=0.8538, lr=9.26e-06]Steps:  26%|██▌       | 1288/5000 [4:49:43<12:20:26, 11.97s/it, loss=0.9804, lr=9.26e-06]Steps:  26%|██▌       | 1289/5000 [4:49:55<12:19:56, 11.96s/it, loss=0.9804, lr=9.26e-06]Steps:  26%|██▌       | 1289/5000 [4:49:55<12:19:56, 11.96s/it, loss=0.7701, lr=9.26e-06]Steps:  26%|██▌       | 1290/5000 [4:50:07<12:19:43, 11.96s/it, loss=0.7701, lr=9.26e-06]Steps:  26%|██▌       | 1290/5000 [4:50:07<12:19:43, 11.96s/it, loss=0.3965, lr=9.26e-06]
[Step 1290] Training Debug Info:
  Loss: 0.704926
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0080, std: 0.9531
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0061, std: 1.3828
  Model pred mean: -0.0064, std: 1.0938
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 1290] Training Debug Info:
  Loss: 0.516749
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 1.0391
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0374, std: 1.4453
  Model pred mean: -0.0325, std: 1.2578
  Sigmas: [0.734375]... (timesteps: [734.0])

[Step 1290] Training Debug Info:
  Loss: 1.216032
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0231, std: 0.8672
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0258, std: 1.3203
  Model pred mean: 0.0238, std: 0.7188
  Sigmas: [0.2109375]... (timesteps: [211.0])

[Step 1290] Training Debug Info:
  Loss: 1.097507
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0034, std: 0.9297
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0032, std: 1.3672
  Model pred mean: 0.0041, std: 0.8711
  Sigmas: [0.06591796875]... (timesteps: [66.0])
Steps:  26%|██▌       | 1291/5000 [4:50:19<12:18:05, 11.94s/it, loss=0.3965, lr=9.26e-06]Steps:  26%|██▌       | 1291/5000 [4:50:19<12:18:05, 11.94s/it, loss=1.0975, lr=9.26e-06]Steps:  26%|██▌       | 1292/5000 [4:50:31<12:17:42, 11.94s/it, loss=1.0975, lr=9.26e-06]Steps:  26%|██▌       | 1292/5000 [4:50:31<12:17:42, 11.94s/it, loss=0.4704, lr=9.25e-06]Steps:  26%|██▌       | 1293/5000 [4:50:43<12:22:45, 12.02s/it, loss=0.4704, lr=9.25e-06]Steps:  26%|██▌       | 1293/5000 [4:50:43<12:22:45, 12.02s/it, loss=0.4213, lr=9.25e-06]Steps:  26%|██▌       | 1294/5000 [4:50:55<12:20:56, 12.00s/it, loss=0.4213, lr=9.25e-06]Steps:  26%|██▌       | 1294/5000 [4:50:55<12:20:56, 12.00s/it, loss=0.7967, lr=9.25e-06]Steps:  26%|██▌       | 1295/5000 [4:51:07<12:20:35, 11.99s/it, loss=0.7967, lr=9.25e-06]Steps:  26%|██▌       | 1295/5000 [4:51:07<12:20:35, 11.99s/it, loss=0.9090, lr=9.25e-06]Steps:  26%|██▌       | 1296/5000 [4:51:19<12:18:59, 11.97s/it, loss=0.9090, lr=9.25e-06]Steps:  26%|██▌       | 1296/5000 [4:51:19<12:18:59, 11.97s/it, loss=0.3745, lr=9.25e-06]Steps:  26%|██▌       | 1297/5000 [4:51:30<12:16:14, 11.93s/it, loss=0.3745, lr=9.25e-06]Steps:  26%|██▌       | 1297/5000 [4:51:30<12:16:14, 11.93s/it, loss=1.1088, lr=9.25e-06]Steps:  26%|██▌       | 1298/5000 [4:51:42<12:16:09, 11.93s/it, loss=1.1088, lr=9.25e-06]Steps:  26%|██▌       | 1298/5000 [4:51:42<12:16:09, 11.93s/it, loss=1.0963, lr=9.24e-06]Steps:  26%|██▌       | 1299/5000 [4:51:54<12:16:25, 11.94s/it, loss=1.0963, lr=9.24e-06]Steps:  26%|██▌       | 1299/5000 [4:51:54<12:16:25, 11.94s/it, loss=1.1832, lr=9.24e-06]Steps:  26%|██▌       | 1300/5000 [4:52:07<12:20:45, 12.01s/it, loss=1.1832, lr=9.24e-06]Steps:  26%|██▌       | 1300/5000 [4:52:07<12:20:45, 12.01s/it, loss=0.9971, lr=9.24e-06]01/22/2026 12:37:53 - INFO - __main__ - 
[Step 1300] ✅ Loss in normal range (0.9971)
01/22/2026 12:37:53 - INFO - __main__ -   Loss avg (last 100): 0.7608
01/22/2026 12:37:53 - INFO - __main__ -   Loss range: [0.3585, 1.1985]

[Step 1300] Training Debug Info:
  Loss: 1.111062
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0020, std: 0.9258
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0032, std: 1.3672
  Model pred mean: -0.0081, std: 0.8789
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 1300] Training Debug Info:
  Loss: 0.798832
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0046, std: 0.8750
  Noise mean: -0.0029, std: 1.0000
  Target mean: 0.0017, std: 1.3281
  Model pred mean: 0.0065, std: 0.9805
  Sigmas: [0.484375]... (timesteps: [484.0])

[Step 1300] Training Debug Info:
  Loss: 0.776417
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0610, std: 0.9414
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0583, std: 1.3750
  Model pred mean: -0.0618, std: 1.0547
  Sigmas: [0.34765625]... (timesteps: [347.0])

[Step 1300] Training Debug Info:
  Loss: 0.609052
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0262, std: 0.9258
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0269, std: 1.3594
  Model pred mean: -0.0091, std: 1.1094
  Sigmas: [0.97265625]... (timesteps: [974.0])
Steps:  26%|██▌       | 1301/5000 [4:52:18<12:18:16, 11.98s/it, loss=0.9971, lr=9.24e-06]Steps:  26%|██▌       | 1301/5000 [4:52:18<12:18:16, 11.98s/it, loss=0.6091, lr=9.24e-06]Steps:  26%|██▌       | 1302/5000 [4:52:30<12:17:39, 11.97s/it, loss=0.6091, lr=9.24e-06]Steps:  26%|██▌       | 1302/5000 [4:52:30<12:17:39, 11.97s/it, loss=0.5118, lr=9.24e-06]Steps:  26%|██▌       | 1303/5000 [4:52:42<12:17:26, 11.97s/it, loss=0.5118, lr=9.24e-06]Steps:  26%|██▌       | 1303/5000 [4:52:42<12:17:26, 11.97s/it, loss=0.6190, lr=9.23e-06]Steps:  26%|██▌       | 1304/5000 [4:52:54<12:19:57, 12.01s/it, loss=0.6190, lr=9.23e-06]Steps:  26%|██▌       | 1304/5000 [4:52:54<12:19:57, 12.01s/it, loss=0.4773, lr=9.23e-06]Steps:  26%|██▌       | 1305/5000 [4:53:06<12:17:56, 11.98s/it, loss=0.4773, lr=9.23e-06]Steps:  26%|██▌       | 1305/5000 [4:53:06<12:17:56, 11.98s/it, loss=0.8460, lr=9.23e-06]Steps:  26%|██▌       | 1306/5000 [4:53:19<12:23:11, 12.07s/it, loss=0.8460, lr=9.23e-06]Steps:  26%|██▌       | 1306/5000 [4:53:19<12:23:11, 12.07s/it, loss=1.0254, lr=9.23e-06]Steps:  26%|██▌       | 1307/5000 [4:53:31<12:19:23, 12.01s/it, loss=1.0254, lr=9.23e-06]Steps:  26%|██▌       | 1307/5000 [4:53:31<12:19:23, 12.01s/it, loss=0.4309, lr=9.23e-06]Steps:  26%|██▌       | 1308/5000 [4:53:42<12:18:01, 11.99s/it, loss=0.4309, lr=9.23e-06]Steps:  26%|██▌       | 1308/5000 [4:53:42<12:18:01, 11.99s/it, loss=0.4461, lr=9.23e-06]Steps:  26%|██▌       | 1309/5000 [4:53:54<12:16:11, 11.97s/it, loss=0.4461, lr=9.23e-06]Steps:  26%|██▌       | 1309/5000 [4:53:54<12:16:11, 11.97s/it, loss=1.1412, lr=9.22e-06]Steps:  26%|██▌       | 1310/5000 [4:54:06<12:16:44, 11.98s/it, loss=1.1412, lr=9.22e-06]Steps:  26%|██▌       | 1310/5000 [4:54:06<12:16:44, 11.98s/it, loss=0.4188, lr=9.22e-06]
[Step 1310] Training Debug Info:
  Loss: 0.413768
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0405, std: 0.9375
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0378, std: 1.3672
  Model pred mean: -0.0417, std: 1.2109
  Sigmas: [0.6796875]... (timesteps: [681.0])

[Step 1310] Training Debug Info:
  Loss: 0.645345
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0072, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0073, std: 1.3516
  Model pred mean: -0.0090, std: 1.1094
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 1310] Training Debug Info:
  Loss: 0.646198
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0410, std: 0.9453
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0398, std: 1.3750
  Model pred mean: -0.0364, std: 1.1172
  Sigmas: [0.94140625]... (timesteps: [943.0])

[Step 1310] Training Debug Info:
  Loss: 0.523594
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0271, std: 0.9531
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0302, std: 1.3828
  Model pred mean: -0.0292, std: 1.1797
  Sigmas: [0.87109375]... (timesteps: [870.0])
Steps:  26%|██▌       | 1311/5000 [4:54:18<12:16:02, 11.97s/it, loss=0.4188, lr=9.22e-06]Steps:  26%|██▌       | 1311/5000 [4:54:18<12:16:02, 11.97s/it, loss=0.5236, lr=9.22e-06]Steps:  26%|██▌       | 1312/5000 [4:54:30<12:14:50, 11.96s/it, loss=0.5236, lr=9.22e-06]Steps:  26%|██▌       | 1312/5000 [4:54:30<12:14:50, 11.96s/it, loss=1.0799, lr=9.22e-06]Steps:  26%|██▋       | 1313/5000 [4:54:43<12:24:15, 12.11s/it, loss=1.0799, lr=9.22e-06]Steps:  26%|██▋       | 1313/5000 [4:54:43<12:24:15, 12.11s/it, loss=0.9800, lr=9.22e-06]Steps:  26%|██▋       | 1314/5000 [4:54:55<12:20:02, 12.05s/it, loss=0.9800, lr=9.22e-06]Steps:  26%|██▋       | 1314/5000 [4:54:55<12:20:02, 12.05s/it, loss=0.8129, lr=9.21e-06]Steps:  26%|██▋       | 1315/5000 [4:55:06<12:16:23, 11.99s/it, loss=0.8129, lr=9.21e-06]Steps:  26%|██▋       | 1315/5000 [4:55:06<12:16:23, 11.99s/it, loss=0.4061, lr=9.21e-06]Steps:  26%|██▋       | 1316/5000 [4:55:18<12:14:54, 11.97s/it, loss=0.4061, lr=9.21e-06]Steps:  26%|██▋       | 1316/5000 [4:55:18<12:14:54, 11.97s/it, loss=0.9195, lr=9.21e-06]Steps:  26%|██▋       | 1317/5000 [4:55:30<12:14:21, 11.96s/it, loss=0.9195, lr=9.21e-06]Steps:  26%|██▋       | 1317/5000 [4:55:30<12:14:21, 11.96s/it, loss=0.3474, lr=9.21e-06]Steps:  26%|██▋       | 1318/5000 [4:55:42<12:14:05, 11.96s/it, loss=0.3474, lr=9.21e-06]Steps:  26%|██▋       | 1318/5000 [4:55:42<12:14:05, 11.96s/it, loss=0.4802, lr=9.21e-06]Steps:  26%|██▋       | 1319/5000 [4:55:54<12:13:55, 11.96s/it, loss=0.4802, lr=9.21e-06]Steps:  26%|██▋       | 1319/5000 [4:55:54<12:13:55, 11.96s/it, loss=0.6661, lr=9.20e-06]Steps:  26%|██▋       | 1320/5000 [4:56:07<12:19:21, 12.05s/it, loss=0.6661, lr=9.20e-06]Steps:  26%|██▋       | 1320/5000 [4:56:07<12:19:21, 12.05s/it, loss=1.1773, lr=9.20e-06]
[Step 1320] Training Debug Info:
  Loss: 1.046525
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0547, std: 0.8984
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0540, std: 1.3438
  Model pred mean: -0.0579, std: 0.8867
  Sigmas: [0.0269775390625]... (timesteps: [27.0])

[Step 1320] Training Debug Info:
  Loss: 1.111181
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0172, std: 0.9180
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0187, std: 1.3594
  Model pred mean: 0.0157, std: 0.8555
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 1320] Training Debug Info:
  Loss: 0.501737
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0265, std: 0.9375
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0256, std: 1.3672
  Model pred mean: -0.0256, std: 1.1719
  Sigmas: [0.85546875]... (timesteps: [854.0])

[Step 1320] Training Debug Info:
  Loss: 0.544275
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0043, std: 0.9102
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0068, std: 1.3516
  Model pred mean: 0.0057, std: 1.1406
  Sigmas: [0.609375]... (timesteps: [610.0])
Steps:  26%|██▋       | 1321/5000 [4:56:19<12:17:25, 12.03s/it, loss=1.1773, lr=9.20e-06]Steps:  26%|██▋       | 1321/5000 [4:56:19<12:17:25, 12.03s/it, loss=0.5443, lr=9.20e-06]Steps:  26%|██▋       | 1322/5000 [4:56:31<12:20:46, 12.08s/it, loss=0.5443, lr=9.20e-06]Steps:  26%|██▋       | 1322/5000 [4:56:31<12:20:46, 12.08s/it, loss=1.0982, lr=9.20e-06]Steps:  26%|██▋       | 1323/5000 [4:56:43<12:16:39, 12.02s/it, loss=1.0982, lr=9.20e-06]Steps:  26%|██▋       | 1323/5000 [4:56:43<12:16:39, 12.02s/it, loss=0.7959, lr=9.20e-06]Steps:  26%|██▋       | 1324/5000 [4:56:54<12:13:53, 11.98s/it, loss=0.7959, lr=9.20e-06]Steps:  26%|██▋       | 1324/5000 [4:56:54<12:13:53, 11.98s/it, loss=1.1747, lr=9.20e-06]Steps:  26%|██▋       | 1325/5000 [4:57:06<12:13:02, 11.97s/it, loss=1.1747, lr=9.20e-06]Steps:  26%|██▋       | 1325/5000 [4:57:06<12:13:02, 11.97s/it, loss=0.5056, lr=9.19e-06]Steps:  27%|██▋       | 1326/5000 [4:57:18<12:10:18, 11.93s/it, loss=0.5056, lr=9.19e-06]Steps:  27%|██▋       | 1326/5000 [4:57:18<12:10:18, 11.93s/it, loss=1.1632, lr=9.19e-06]Steps:  27%|██▋       | 1327/5000 [4:57:30<12:15:39, 12.02s/it, loss=1.1632, lr=9.19e-06]Steps:  27%|██▋       | 1327/5000 [4:57:30<12:15:39, 12.02s/it, loss=0.8734, lr=9.19e-06]Steps:  27%|██▋       | 1328/5000 [4:57:42<12:12:59, 11.98s/it, loss=0.8734, lr=9.19e-06]Steps:  27%|██▋       | 1328/5000 [4:57:42<12:12:59, 11.98s/it, loss=0.6357, lr=9.19e-06]Steps:  27%|██▋       | 1329/5000 [4:57:54<12:10:54, 11.95s/it, loss=0.6357, lr=9.19e-06]Steps:  27%|██▋       | 1329/5000 [4:57:54<12:10:54, 11.95s/it, loss=0.5728, lr=9.19e-06]Steps:  27%|██▋       | 1330/5000 [4:58:06<12:10:40, 11.95s/it, loss=0.5728, lr=9.19e-06]Steps:  27%|██▋       | 1330/5000 [4:58:06<12:10:40, 11.95s/it, loss=0.7607, lr=9.18e-06]
[Step 1330] Training Debug Info:
  Loss: 0.487133
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0168, std: 0.9609
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0164, std: 1.3906
  Model pred mean: 0.0152, std: 1.1953
  Sigmas: [0.6796875]... (timesteps: [680.0])

[Step 1330] Training Debug Info:
  Loss: 1.137293
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0073, std: 0.9141
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0095, std: 1.3516
  Model pred mean: 0.0037, std: 0.8359
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 1330] Training Debug Info:
  Loss: 0.402342
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0192, std: 0.9258
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0225, std: 1.3672
  Model pred mean: -0.0183, std: 1.1953
  Sigmas: [0.76953125]... (timesteps: [771.0])

[Step 1330] Training Debug Info:
  Loss: 1.131868
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0118, std: 0.9102
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0108, std: 1.3516
  Model pred mean: -0.0140, std: 0.8242
  Sigmas: [0.1630859375]... (timesteps: [163.0])
Steps:  27%|██▋       | 1331/5000 [4:58:18<12:11:02, 11.95s/it, loss=0.7607, lr=9.18e-06]Steps:  27%|██▋       | 1331/5000 [4:58:18<12:11:02, 11.95s/it, loss=1.1319, lr=9.18e-06]Steps:  27%|██▋       | 1332/5000 [4:58:30<12:10:42, 11.95s/it, loss=1.1319, lr=9.18e-06]Steps:  27%|██▋       | 1332/5000 [4:58:30<12:10:42, 11.95s/it, loss=0.4831, lr=9.18e-06]Steps:  27%|██▋       | 1333/5000 [4:58:42<12:14:52, 12.02s/it, loss=0.4831, lr=9.18e-06]Steps:  27%|██▋       | 1333/5000 [4:58:42<12:14:52, 12.02s/it, loss=0.4532, lr=9.18e-06]Steps:  27%|██▋       | 1334/5000 [4:58:54<12:13:58, 12.01s/it, loss=0.4532, lr=9.18e-06]Steps:  27%|██▋       | 1334/5000 [4:58:54<12:13:58, 12.01s/it, loss=1.0077, lr=9.18e-06]Steps:  27%|██▋       | 1335/5000 [4:59:06<12:11:22, 11.97s/it, loss=1.0077, lr=9.18e-06]Steps:  27%|██▋       | 1335/5000 [4:59:06<12:11:22, 11.97s/it, loss=0.4934, lr=9.17e-06]Steps:  27%|██▋       | 1336/5000 [4:59:18<12:09:07, 11.94s/it, loss=0.4934, lr=9.17e-06]Steps:  27%|██▋       | 1336/5000 [4:59:18<12:09:07, 11.94s/it, loss=1.1099, lr=9.17e-06]Steps:  27%|██▋       | 1337/5000 [4:59:30<12:08:40, 11.94s/it, loss=1.1099, lr=9.17e-06]Steps:  27%|██▋       | 1337/5000 [4:59:30<12:08:40, 11.94s/it, loss=1.1377, lr=9.17e-06]Steps:  27%|██▋       | 1338/5000 [4:59:42<12:06:56, 11.91s/it, loss=1.1377, lr=9.17e-06]Steps:  27%|██▋       | 1338/5000 [4:59:42<12:06:56, 11.91s/it, loss=1.0297, lr=9.17e-06]Steps:  27%|██▋       | 1339/5000 [4:59:54<12:06:15, 11.90s/it, loss=1.0297, lr=9.17e-06]Steps:  27%|██▋       | 1339/5000 [4:59:54<12:06:15, 11.90s/it, loss=0.4248, lr=9.17e-06]Steps:  27%|██▋       | 1340/5000 [5:00:06<12:12:43, 12.01s/it, loss=0.4248, lr=9.17e-06]Steps:  27%|██▋       | 1340/5000 [5:00:06<12:12:43, 12.01s/it, loss=0.7964, lr=9.16e-06]
[Step 1340] Training Debug Info:
  Loss: 1.126148
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0005, std: 0.9297
  Noise mean: 0.0042, std: 1.0000
  Target mean: 0.0047, std: 1.3672
  Model pred mean: -0.0029, std: 0.8516
  Sigmas: [0.1181640625]... (timesteps: [118.0])

[Step 1340] Training Debug Info:
  Loss: 0.424419
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0108, std: 0.9180
  Noise mean: 0.0028, std: 1.0000
  Target mean: 0.0136, std: 1.3594
  Model pred mean: 0.0115, std: 1.1953
  Sigmas: [0.859375]... (timesteps: [861.0])

[Step 1340] Training Debug Info:
  Loss: 1.124086
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0035, std: 0.8867
  Noise mean: -0.0033, std: 0.9961
  Target mean: -0.0068, std: 1.3359
  Model pred mean: -0.0050, std: 0.8047
  Sigmas: [0.2392578125]... (timesteps: [239.0])

[Step 1340] Training Debug Info:
  Loss: 1.105126
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0137, std: 0.9219
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0140, std: 1.3594
  Model pred mean: -0.0179, std: 0.8594
  Sigmas: [0.0771484375]... (timesteps: [77.0])
Steps:  27%|██▋       | 1341/5000 [5:00:18<12:10:48, 11.98s/it, loss=0.7964, lr=9.16e-06]Steps:  27%|██▋       | 1341/5000 [5:00:18<12:10:48, 11.98s/it, loss=1.1051, lr=9.16e-06]Steps:  27%|██▋       | 1342/5000 [5:00:30<12:09:56, 11.97s/it, loss=1.1051, lr=9.16e-06]Steps:  27%|██▋       | 1342/5000 [5:00:30<12:09:56, 11.97s/it, loss=0.9366, lr=9.16e-06]Steps:  27%|██▋       | 1343/5000 [5:00:42<12:10:29, 11.99s/it, loss=0.9366, lr=9.16e-06]Steps:  27%|██▋       | 1343/5000 [5:00:42<12:10:29, 11.99s/it, loss=1.1137, lr=9.16e-06]Steps:  27%|██▋       | 1344/5000 [5:00:54<12:09:15, 11.97s/it, loss=1.1137, lr=9.16e-06]Steps:  27%|██▋       | 1344/5000 [5:00:54<12:09:15, 11.97s/it, loss=0.6912, lr=9.16e-06]Steps:  27%|██▋       | 1345/5000 [5:01:06<12:06:08, 11.92s/it, loss=0.6912, lr=9.16e-06]Steps:  27%|██▋       | 1345/5000 [5:01:06<12:06:08, 11.92s/it, loss=1.0715, lr=9.15e-06]Steps:  27%|██▋       | 1346/5000 [5:01:17<12:05:33, 11.91s/it, loss=1.0715, lr=9.15e-06]Steps:  27%|██▋       | 1346/5000 [5:01:17<12:05:33, 11.91s/it, loss=0.8291, lr=9.15e-06]Steps:  27%|██▋       | 1347/5000 [5:01:30<12:10:38, 12.00s/it, loss=0.8291, lr=9.15e-06]Steps:  27%|██▋       | 1347/5000 [5:01:30<12:10:38, 12.00s/it, loss=1.0028, lr=9.15e-06]Steps:  27%|██▋       | 1348/5000 [5:01:42<12:09:06, 11.98s/it, loss=1.0028, lr=9.15e-06]Steps:  27%|██▋       | 1348/5000 [5:01:42<12:09:06, 11.98s/it, loss=0.3804, lr=9.15e-06]Steps:  27%|██▋       | 1349/5000 [5:01:54<12:08:18, 11.97s/it, loss=0.3804, lr=9.15e-06]Steps:  27%|██▋       | 1349/5000 [5:01:54<12:08:18, 11.97s/it, loss=0.6265, lr=9.15e-06]Steps:  27%|██▋       | 1350/5000 [5:02:05<12:06:13, 11.94s/it, loss=0.6265, lr=9.15e-06]Steps:  27%|██▋       | 1350/5000 [5:02:05<12:06:13, 11.94s/it, loss=1.0048, lr=9.15e-06]
[Step 1350] Training Debug Info:
  Loss: 1.202281
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0432, std: 0.8477
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0425, std: 1.3125
  Model pred mean: 0.0422, std: 0.7188
  Sigmas: [0.140625]... (timesteps: [141.0])

[Step 1350] Training Debug Info:
  Loss: 0.557688
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0282, std: 0.9453
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0287, std: 1.3828
  Model pred mean: -0.0248, std: 1.1562
  Sigmas: [0.57421875]... (timesteps: [575.0])

[Step 1350] Training Debug Info:
  Loss: 0.450266
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0177, std: 0.9297
  Noise mean: -0.0040, std: 1.0000
  Target mean: -0.0217, std: 1.3672
  Model pred mean: -0.0123, std: 1.1875
  Sigmas: [0.859375]... (timesteps: [860.0])

[Step 1350] Training Debug Info:
  Loss: 0.403398
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0012, std: 0.9336
  Noise mean: 0.0027, std: 0.9961
  Target mean: 0.0039, std: 1.3672
  Model pred mean: 0.0029, std: 1.2109
  Sigmas: [0.7109375]... (timesteps: [710.0])
Steps:  27%|██▋       | 1351/5000 [5:02:17<12:05:43, 11.93s/it, loss=1.0048, lr=9.15e-06]Steps:  27%|██▋       | 1351/5000 [5:02:17<12:05:43, 11.93s/it, loss=0.4034, lr=9.14e-06]Steps:  27%|██▋       | 1352/5000 [5:02:29<12:05:20, 11.93s/it, loss=0.4034, lr=9.14e-06]Steps:  27%|██▋       | 1352/5000 [5:02:29<12:05:20, 11.93s/it, loss=1.0758, lr=9.14e-06]Steps:  27%|██▋       | 1353/5000 [5:02:41<12:04:50, 11.92s/it, loss=1.0758, lr=9.14e-06]Steps:  27%|██▋       | 1353/5000 [5:02:41<12:04:50, 11.92s/it, loss=0.6500, lr=9.14e-06]Steps:  27%|██▋       | 1354/5000 [5:02:53<12:10:17, 12.02s/it, loss=0.6500, lr=9.14e-06]Steps:  27%|██▋       | 1354/5000 [5:02:53<12:10:17, 12.02s/it, loss=0.6925, lr=9.14e-06]Steps:  27%|██▋       | 1355/5000 [5:03:05<12:08:24, 11.99s/it, loss=0.6925, lr=9.14e-06]Steps:  27%|██▋       | 1355/5000 [5:03:05<12:08:24, 11.99s/it, loss=0.3820, lr=9.14e-06]Steps:  27%|██▋       | 1356/5000 [5:03:17<12:07:34, 11.98s/it, loss=0.3820, lr=9.14e-06]Steps:  27%|██▋       | 1356/5000 [5:03:17<12:07:34, 11.98s/it, loss=0.4878, lr=9.13e-06]Steps:  27%|██▋       | 1357/5000 [5:03:29<12:07:14, 11.98s/it, loss=0.4878, lr=9.13e-06]Steps:  27%|██▋       | 1357/5000 [5:03:29<12:07:14, 11.98s/it, loss=0.5776, lr=9.13e-06]Steps:  27%|██▋       | 1358/5000 [5:03:41<12:08:22, 12.00s/it, loss=0.5776, lr=9.13e-06]Steps:  27%|██▋       | 1358/5000 [5:03:41<12:08:22, 12.00s/it, loss=0.5201, lr=9.13e-06]Steps:  27%|██▋       | 1359/5000 [5:03:53<12:08:16, 12.00s/it, loss=0.5201, lr=9.13e-06]Steps:  27%|██▋       | 1359/5000 [5:03:53<12:08:16, 12.00s/it, loss=1.0883, lr=9.13e-06]Steps:  27%|██▋       | 1360/5000 [5:04:06<12:13:29, 12.09s/it, loss=1.0883, lr=9.13e-06]Steps:  27%|██▋       | 1360/5000 [5:04:06<12:13:29, 12.09s/it, loss=0.6214, lr=9.13e-06]
[Step 1360] Training Debug Info:
  Loss: 0.720493
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0066, std: 0.9141
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0082, std: 1.3516
  Model pred mean: -0.0117, std: 1.0547
  Sigmas: [0.50390625]... (timesteps: [501.9999694824219])

[Step 1360] Training Debug Info:
  Loss: 0.379372
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0164, std: 0.9297
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0177, std: 1.3672
  Model pred mean: 0.0084, std: 1.2188
  Sigmas: [0.828125]... (timesteps: [827.0])

[Step 1360] Training Debug Info:
  Loss: 0.958238
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0361, std: 1.0000
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0366, std: 1.4141
  Model pred mean: -0.0396, std: 1.0234
  Sigmas: [0.2236328125]... (timesteps: [224.0])

[Step 1360] Training Debug Info:
  Loss: 0.757459
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0282, std: 0.9688
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0272, std: 1.3906
  Model pred mean: -0.0294, std: 1.0938
  Sigmas: [0.46875]... (timesteps: [468.0])
Steps:  27%|██▋       | 1361/5000 [5:04:18<12:11:00, 12.05s/it, loss=0.6214, lr=9.13e-06]Steps:  27%|██▋       | 1361/5000 [5:04:18<12:11:00, 12.05s/it, loss=0.7575, lr=9.12e-06]Steps:  27%|██▋       | 1362/5000 [5:04:29<12:07:37, 12.00s/it, loss=0.7575, lr=9.12e-06]Steps:  27%|██▋       | 1362/5000 [5:04:29<12:07:37, 12.00s/it, loss=1.0165, lr=9.12e-06]Steps:  27%|██▋       | 1363/5000 [5:04:41<12:05:49, 11.97s/it, loss=1.0165, lr=9.12e-06]Steps:  27%|██▋       | 1363/5000 [5:04:41<12:05:49, 11.97s/it, loss=1.2025, lr=9.12e-06]Steps:  27%|██▋       | 1364/5000 [5:04:53<12:04:09, 11.95s/it, loss=1.2025, lr=9.12e-06]Steps:  27%|██▋       | 1364/5000 [5:04:53<12:04:09, 11.95s/it, loss=0.6128, lr=9.12e-06]Steps:  27%|██▋       | 1365/5000 [5:05:05<12:04:31, 11.96s/it, loss=0.6128, lr=9.12e-06]Steps:  27%|██▋       | 1365/5000 [5:05:05<12:04:31, 11.96s/it, loss=0.4477, lr=9.12e-06]Steps:  27%|██▋       | 1366/5000 [5:05:17<12:03:50, 11.95s/it, loss=0.4477, lr=9.12e-06]Steps:  27%|██▋       | 1366/5000 [5:05:17<12:03:50, 11.95s/it, loss=0.6528, lr=9.11e-06]Steps:  27%|██▋       | 1367/5000 [5:05:30<12:10:30, 12.06s/it, loss=0.6528, lr=9.11e-06]Steps:  27%|██▋       | 1367/5000 [5:05:30<12:10:30, 12.06s/it, loss=0.4136, lr=9.11e-06]Steps:  27%|██▋       | 1368/5000 [5:05:41<12:07:27, 12.02s/it, loss=0.4136, lr=9.11e-06]Steps:  27%|██▋       | 1368/5000 [5:05:41<12:07:27, 12.02s/it, loss=0.8729, lr=9.11e-06]Steps:  27%|██▋       | 1369/5000 [5:05:53<12:05:38, 11.99s/it, loss=0.8729, lr=9.11e-06]Steps:  27%|██▋       | 1369/5000 [5:05:53<12:05:38, 11.99s/it, loss=1.0682, lr=9.11e-06]Steps:  27%|██▋       | 1370/5000 [5:06:05<12:03:44, 11.96s/it, loss=1.0682, lr=9.11e-06]Steps:  27%|██▋       | 1370/5000 [5:06:05<12:03:44, 11.96s/it, loss=0.5944, lr=9.11e-06]
[Step 1370] Training Debug Info:
  Loss: 1.103129
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0209, std: 0.9023
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0206, std: 1.3438
  Model pred mean: 0.0188, std: 0.8359
  Sigmas: [0.302734375]... (timesteps: [303.0])

[Step 1370] Training Debug Info:
  Loss: 1.043851
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: 0.0056, std: 1.0000
  Target mean: -0.0114, std: 1.3516
  Model pred mean: -0.0153, std: 0.8789
  Sigmas: [0.240234375]... (timesteps: [240.0])

[Step 1370] Training Debug Info:
  Loss: 0.401421
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0464, std: 0.8906
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0461, std: 1.3438
  Model pred mean: -0.0417, std: 1.1797
  Sigmas: [0.8671875]... (timesteps: [867.0])

[Step 1370] Training Debug Info:
  Loss: 0.899481
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0388, std: 0.9141
  Noise mean: 0.0051, std: 1.0000
  Target mean: -0.0337, std: 1.3516
  Model pred mean: -0.0386, std: 0.9648
  Sigmas: [0.34765625]... (timesteps: [348.0])
Steps:  27%|██▋       | 1371/5000 [5:06:17<12:02:22, 11.94s/it, loss=0.5944, lr=9.11e-06]Steps:  27%|██▋       | 1371/5000 [5:06:17<12:02:22, 11.94s/it, loss=0.8995, lr=9.10e-06]Steps:  27%|██▋       | 1372/5000 [5:06:29<12:02:53, 11.96s/it, loss=0.8995, lr=9.10e-06]Steps:  27%|██▋       | 1372/5000 [5:06:29<12:02:53, 11.96s/it, loss=1.0822, lr=9.10e-06]Steps:  27%|██▋       | 1373/5000 [5:06:41<12:02:03, 11.94s/it, loss=1.0822, lr=9.10e-06]Steps:  27%|██▋       | 1373/5000 [5:06:41<12:02:03, 11.94s/it, loss=0.9728, lr=9.10e-06]Steps:  27%|██▋       | 1374/5000 [5:06:53<12:05:36, 12.01s/it, loss=0.9728, lr=9.10e-06]Steps:  27%|██▋       | 1374/5000 [5:06:53<12:05:36, 12.01s/it, loss=1.0390, lr=9.10e-06]Steps:  28%|██▊       | 1375/5000 [5:07:05<12:03:19, 11.97s/it, loss=1.0390, lr=9.10e-06]Steps:  28%|██▊       | 1375/5000 [5:07:05<12:03:19, 11.97s/it, loss=1.0789, lr=9.10e-06]Steps:  28%|██▊       | 1376/5000 [5:07:17<12:03:57, 11.99s/it, loss=1.0789, lr=9.10e-06]Steps:  28%|██▊       | 1376/5000 [5:07:17<12:03:57, 11.99s/it, loss=0.4950, lr=9.09e-06]Steps:  28%|██▊       | 1377/5000 [5:07:29<12:03:07, 11.98s/it, loss=0.4950, lr=9.09e-06]Steps:  28%|██▊       | 1377/5000 [5:07:29<12:03:07, 11.98s/it, loss=0.5155, lr=9.09e-06]Steps:  28%|██▊       | 1378/5000 [5:07:41<12:02:11, 11.96s/it, loss=0.5155, lr=9.09e-06]Steps:  28%|██▊       | 1378/5000 [5:07:41<12:02:11, 11.96s/it, loss=1.0802, lr=9.09e-06]Steps:  28%|██▊       | 1379/5000 [5:07:53<12:00:22, 11.94s/it, loss=1.0802, lr=9.09e-06]Steps:  28%|██▊       | 1379/5000 [5:07:53<12:00:22, 11.94s/it, loss=0.9495, lr=9.09e-06]Steps:  28%|██▊       | 1380/5000 [5:08:05<12:00:07, 11.94s/it, loss=0.9495, lr=9.09e-06]Steps:  28%|██▊       | 1380/5000 [5:08:05<12:00:07, 11.94s/it, loss=0.3865, lr=9.09e-06]
[Step 1380] Training Debug Info:
  Loss: 0.613959
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0118, std: 0.8984
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0124, std: 1.3438
  Model pred mean: -0.0244, std: 1.0781
  Sigmas: [0.9921875]... (timesteps: [993.0])

[Step 1380] Training Debug Info:
  Loss: 0.457112
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0359, std: 0.9258
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0393, std: 1.3594
  Model pred mean: -0.0344, std: 1.1875
  Sigmas: [0.6875]... (timesteps: [689.0])

[Step 1380] Training Debug Info:
  Loss: 0.756634
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0327, std: 0.9414
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0332, std: 1.3750
  Model pred mean: -0.0337, std: 1.0625
  Sigmas: [0.484375]... (timesteps: [485.0])

[Step 1380] Training Debug Info:
  Loss: 1.079531
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0076, std: 0.9336
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0073, std: 1.3672
  Model pred mean: -0.0085, std: 0.8867
  Sigmas: [0.055908203125]... (timesteps: [56.0])
Steps:  28%|██▊       | 1381/5000 [5:08:17<12:04:06, 12.01s/it, loss=0.3865, lr=9.09e-06]Steps:  28%|██▊       | 1381/5000 [5:08:17<12:04:06, 12.01s/it, loss=1.0795, lr=9.08e-06]Steps:  28%|██▊       | 1382/5000 [5:08:29<12:02:47, 11.99s/it, loss=1.0795, lr=9.08e-06]Steps:  28%|██▊       | 1382/5000 [5:08:29<12:02:47, 11.99s/it, loss=0.5398, lr=9.08e-06]Steps:  28%|██▊       | 1383/5000 [5:08:41<12:00:43, 11.96s/it, loss=0.5398, lr=9.08e-06]Steps:  28%|██▊       | 1383/5000 [5:08:41<12:00:43, 11.96s/it, loss=1.1541, lr=9.08e-06]Steps:  28%|██▊       | 1384/5000 [5:08:53<12:00:14, 11.95s/it, loss=1.1541, lr=9.08e-06]Steps:  28%|██▊       | 1384/5000 [5:08:53<12:00:14, 11.95s/it, loss=1.0631, lr=9.08e-06]Steps:  28%|██▊       | 1385/5000 [5:09:05<12:01:41, 11.98s/it, loss=1.0631, lr=9.08e-06]Steps:  28%|██▊       | 1385/5000 [5:09:05<12:01:41, 11.98s/it, loss=1.0810, lr=9.08e-06]Steps:  28%|██▊       | 1386/5000 [5:09:17<12:00:05, 11.96s/it, loss=1.0810, lr=9.08e-06]Steps:  28%|██▊       | 1386/5000 [5:09:17<12:00:05, 11.96s/it, loss=1.0580, lr=9.07e-06]Steps:  28%|██▊       | 1387/5000 [5:09:29<12:05:01, 12.04s/it, loss=1.0580, lr=9.07e-06]Steps:  28%|██▊       | 1387/5000 [5:09:29<12:05:01, 12.04s/it, loss=0.4117, lr=9.07e-06]Steps:  28%|██▊       | 1388/5000 [5:09:41<12:03:22, 12.02s/it, loss=0.4117, lr=9.07e-06]Steps:  28%|██▊       | 1388/5000 [5:09:41<12:03:22, 12.02s/it, loss=0.8325, lr=9.07e-06]Steps:  28%|██▊       | 1389/5000 [5:09:53<11:59:31, 11.96s/it, loss=0.8325, lr=9.07e-06]Steps:  28%|██▊       | 1389/5000 [5:09:53<11:59:31, 11.96s/it, loss=0.4248, lr=9.07e-06]Steps:  28%|██▊       | 1390/5000 [5:10:05<11:59:31, 11.96s/it, loss=0.4248, lr=9.07e-06]Steps:  28%|██▊       | 1390/5000 [5:10:05<11:59:31, 11.96s/it, loss=0.8290, lr=9.07e-06]
[Step 1390] Training Debug Info:
  Loss: 1.050180
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0165, std: 0.9844
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0172, std: 1.3984
  Model pred mean: 0.0171, std: 0.9570
  Sigmas: [0.0260009765625]... (timesteps: [26.0])

[Step 1390] Training Debug Info:
  Loss: 0.568562
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0109, std: 0.8945
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0115, std: 1.3438
  Model pred mean: -0.0015, std: 1.1172
  Sigmas: [0.9296875]... (timesteps: [929.0])

[Step 1390] Training Debug Info:
  Loss: 0.395795
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0074, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0075, std: 1.3516
  Model pred mean: -0.0038, std: 1.1953
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 1390] Training Debug Info:
  Loss: 1.174572
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0223, std: 0.8281
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0197, std: 1.3047
  Model pred mean: 0.0226, std: 0.7227
  Sigmas: [0.28515625]... (timesteps: [285.0])
Steps:  28%|██▊       | 1391/5000 [5:10:17<11:59:06, 11.96s/it, loss=0.8290, lr=9.07e-06]Steps:  28%|██▊       | 1391/5000 [5:10:17<11:59:06, 11.96s/it, loss=1.1746, lr=9.06e-06]Steps:  28%|██▊       | 1392/5000 [5:10:28<11:57:30, 11.93s/it, loss=1.1746, lr=9.06e-06]Steps:  28%|██▊       | 1392/5000 [5:10:28<11:57:30, 11.93s/it, loss=0.4442, lr=9.06e-06]Steps:  28%|██▊       | 1393/5000 [5:10:40<11:55:23, 11.90s/it, loss=0.4442, lr=9.06e-06]Steps:  28%|██▊       | 1393/5000 [5:10:40<11:55:23, 11.90s/it, loss=1.1627, lr=9.06e-06]Steps:  28%|██▊       | 1394/5000 [5:10:53<12:02:32, 12.02s/it, loss=1.1627, lr=9.06e-06]Steps:  28%|██▊       | 1394/5000 [5:10:53<12:02:32, 12.02s/it, loss=0.7195, lr=9.06e-06]Steps:  28%|██▊       | 1395/5000 [5:11:04<11:58:58, 11.97s/it, loss=0.7195, lr=9.06e-06]Steps:  28%|██▊       | 1395/5000 [5:11:04<11:58:58, 11.97s/it, loss=1.0489, lr=9.06e-06]Steps:  28%|██▊       | 1396/5000 [5:11:16<11:56:23, 11.93s/it, loss=1.0489, lr=9.06e-06]Steps:  28%|██▊       | 1396/5000 [5:11:16<11:56:23, 11.93s/it, loss=0.3739, lr=9.05e-06]Steps:  28%|██▊       | 1397/5000 [5:11:28<11:55:43, 11.92s/it, loss=0.3739, lr=9.05e-06]Steps:  28%|██▊       | 1397/5000 [5:11:28<11:55:43, 11.92s/it, loss=0.5037, lr=9.05e-06]Steps:  28%|██▊       | 1398/5000 [5:11:40<11:54:36, 11.90s/it, loss=0.5037, lr=9.05e-06]Steps:  28%|██▊       | 1398/5000 [5:11:40<11:54:36, 11.90s/it, loss=0.9610, lr=9.05e-06]Steps:  28%|██▊       | 1399/5000 [5:11:52<11:54:33, 11.91s/it, loss=0.9610, lr=9.05e-06]Steps:  28%|██▊       | 1399/5000 [5:11:52<11:54:33, 11.91s/it, loss=0.7789, lr=9.05e-06]Steps:  28%|██▊       | 1400/5000 [5:12:04<11:53:40, 11.89s/it, loss=0.7789, lr=9.05e-06]Steps:  28%|██▊       | 1400/5000 [5:12:04<11:53:40, 11.89s/it, loss=0.5585, lr=9.05e-06]01/22/2026 12:57:51 - INFO - __main__ - 
[Step 1400] ✅ Loss in normal range (0.5585)
01/22/2026 12:57:51 - INFO - __main__ -   Loss avg (last 100): 0.7771
01/22/2026 12:57:51 - INFO - __main__ -   Loss range: [0.3474, 1.2025]
01/22/2026 12:57:51 - INFO - __main__ - 
🔍 Running validation at step 1400...
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1400 (parquet mode)...
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1400...
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 12:57:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 12:58:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 12:58:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 12:58:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 12:58:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 12:58:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 12:58:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 12:59:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 12:59:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 12:59:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 12:59:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 12:59:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 12:59:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 13:00:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 13:00:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 13:00:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 13:00:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 13:00:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 13:00:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 13:01:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 13:01:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 13:01:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 13:01:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 13:01:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400/step001400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 13:01:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 13:01:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 13:01:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001400
01/22/2026 13:01:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1400] Training Debug Info:
  Loss: 0.605658
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0130, std: 0.9102
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0125, std: 1.3516
  Model pred mean: 0.0190, std: 1.1094
  Sigmas: [0.578125]... (timesteps: [578.0])

[Step 1400] Training Debug Info:
  Loss: 1.104637
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0016, std: 0.9609
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0038, std: 1.3906
  Model pred mean: 0.0064, std: 0.9062
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 1400] Training Debug Info:
  Loss: 0.836553
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0068, std: 0.9297
  Noise mean: 0.0014, std: 0.9961
  Target mean: 0.0082, std: 1.3672
  Model pred mean: 0.0111, std: 1.0156
  Sigmas: [0.412109375]... (timesteps: [413.0])

[Step 1400] Training Debug Info:
  Loss: 1.156822
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0132, std: 0.8984
  Noise mean: 0.0008, std: 0.9961
  Target mean: 0.0140, std: 1.3438
  Model pred mean: 0.0168, std: 0.8047
  Sigmas: [0.2333984375]... (timesteps: [233.0])
Steps:  28%|██▊       | 1401/5000 [5:16:28<87:26:14, 87.46s/it, loss=0.5585, lr=9.05e-06]Steps:  28%|██▊       | 1401/5000 [5:16:28<87:26:14, 87.46s/it, loss=1.1568, lr=9.04e-06]Steps:  28%|██▊       | 1402/5000 [5:16:40<64:45:47, 64.80s/it, loss=1.1568, lr=9.04e-06]Steps:  28%|██▊       | 1402/5000 [5:16:40<64:45:47, 64.80s/it, loss=1.0906, lr=9.04e-06]Steps:  28%|██▊       | 1403/5000 [5:16:51<48:54:22, 48.95s/it, loss=1.0906, lr=9.04e-06]Steps:  28%|██▊       | 1403/5000 [5:16:51<48:54:22, 48.95s/it, loss=0.7960, lr=9.04e-06]Steps:  28%|██▊       | 1404/5000 [5:17:03<37:48:36, 37.85s/it, loss=0.7960, lr=9.04e-06]Steps:  28%|██▊       | 1404/5000 [5:17:03<37:48:36, 37.85s/it, loss=1.1006, lr=9.04e-06]Steps:  28%|██▊       | 1405/5000 [5:17:15<30:01:20, 30.06s/it, loss=1.1006, lr=9.04e-06]Steps:  28%|██▊       | 1405/5000 [5:17:15<30:01:20, 30.06s/it, loss=0.5680, lr=9.03e-06]Steps:  28%|██▊       | 1406/5000 [5:17:27<24:35:16, 24.63s/it, loss=0.5680, lr=9.03e-06]Steps:  28%|██▊       | 1406/5000 [5:17:27<24:35:16, 24.63s/it, loss=0.8498, lr=9.03e-06]Steps:  28%|██▊       | 1407/5000 [5:17:39<20:46:50, 20.82s/it, loss=0.8498, lr=9.03e-06]Steps:  28%|██▊       | 1407/5000 [5:17:39<20:46:50, 20.82s/it, loss=0.7133, lr=9.03e-06]Steps:  28%|██▊       | 1408/5000 [5:17:52<18:13:04, 18.26s/it, loss=0.7133, lr=9.03e-06]Steps:  28%|██▊       | 1408/5000 [5:17:52<18:13:04, 18.26s/it, loss=0.5491, lr=9.03e-06]Steps:  28%|██▊       | 1409/5000 [5:18:03<16:18:53, 16.36s/it, loss=0.5491, lr=9.03e-06]Steps:  28%|██▊       | 1409/5000 [5:18:03<16:18:53, 16.36s/it, loss=1.1182, lr=9.03e-06]Steps:  28%|██▊       | 1410/5000 [5:18:15<14:59:13, 15.03s/it, loss=1.1182, lr=9.03e-06]Steps:  28%|██▊       | 1410/5000 [5:18:15<14:59:13, 15.03s/it, loss=0.4250, lr=9.02e-06]
[Step 1410] Training Debug Info:
  Loss: 0.725124
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0106, std: 0.9336
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0099, std: 1.3672
  Model pred mean: -0.0092, std: 1.0625
  Sigmas: [0.458984375]... (timesteps: [459.0])

[Step 1410] Training Debug Info:
  Loss: 0.617562
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.8906
  Noise mean: -0.0048, std: 1.0000
  Target mean: 0.0031, std: 1.3438
  Model pred mean: 0.0033, std: 1.0938
  Sigmas: [0.984375]... (timesteps: [984.0])

[Step 1410] Training Debug Info:
  Loss: 0.574172
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0162, std: 0.9102
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0148, std: 1.3516
  Model pred mean: 0.0160, std: 1.1172
  Sigmas: [0.6015625]... (timesteps: [603.0])

[Step 1410] Training Debug Info:
  Loss: 1.073140
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0124, std: 0.9609
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0135, std: 1.3906
  Model pred mean: -0.0096, std: 0.9180
  Sigmas: [0.2099609375]... (timesteps: [210.0])
Steps:  28%|██▊       | 1411/5000 [5:18:27<14:02:42, 14.09s/it, loss=0.4250, lr=9.02e-06]Steps:  28%|██▊       | 1411/5000 [5:18:27<14:02:42, 14.09s/it, loss=1.0731, lr=9.02e-06]Steps:  28%|██▊       | 1412/5000 [5:18:39<13:23:34, 13.44s/it, loss=1.0731, lr=9.02e-06]Steps:  28%|██▊       | 1412/5000 [5:18:39<13:23:34, 13.44s/it, loss=0.7519, lr=9.02e-06]Steps:  28%|██▊       | 1413/5000 [5:18:51<12:56:29, 12.99s/it, loss=0.7519, lr=9.02e-06]Steps:  28%|██▊       | 1413/5000 [5:18:51<12:56:29, 12.99s/it, loss=1.1076, lr=9.02e-06]Steps:  28%|██▊       | 1414/5000 [5:19:03<12:41:27, 12.74s/it, loss=1.1076, lr=9.02e-06]Steps:  28%|██▊       | 1414/5000 [5:19:03<12:41:27, 12.74s/it, loss=1.1120, lr=9.02e-06]Steps:  28%|██▊       | 1415/5000 [5:19:15<12:24:54, 12.47s/it, loss=1.1120, lr=9.02e-06]Steps:  28%|██▊       | 1415/5000 [5:19:15<12:24:54, 12.47s/it, loss=0.6376, lr=9.01e-06]Steps:  28%|██▊       | 1416/5000 [5:19:27<12:14:10, 12.29s/it, loss=0.6376, lr=9.01e-06]Steps:  28%|██▊       | 1416/5000 [5:19:27<12:14:10, 12.29s/it, loss=1.1348, lr=9.01e-06]Steps:  28%|██▊       | 1417/5000 [5:19:39<12:06:16, 12.16s/it, loss=1.1348, lr=9.01e-06]Steps:  28%|██▊       | 1417/5000 [5:19:39<12:06:16, 12.16s/it, loss=0.7247, lr=9.01e-06]Steps:  28%|██▊       | 1418/5000 [5:19:51<12:02:10, 12.10s/it, loss=0.7247, lr=9.01e-06]Steps:  28%|██▊       | 1418/5000 [5:19:51<12:02:10, 12.10s/it, loss=0.8457, lr=9.01e-06]Steps:  28%|██▊       | 1419/5000 [5:20:03<11:58:10, 12.03s/it, loss=0.8457, lr=9.01e-06]Steps:  28%|██▊       | 1419/5000 [5:20:03<11:58:10, 12.03s/it, loss=0.4573, lr=9.01e-06]Steps:  28%|██▊       | 1420/5000 [5:20:15<11:55:43, 12.00s/it, loss=0.4573, lr=9.01e-06]Steps:  28%|██▊       | 1420/5000 [5:20:15<11:55:43, 12.00s/it, loss=0.4222, lr=9.00e-06]
[Step 1420] Training Debug Info:
  Loss: 0.476631
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0232, std: 0.9258
  Noise mean: 0.0020, std: 0.9961
  Target mean: -0.0212, std: 1.3594
  Model pred mean: -0.0308, std: 1.1719
  Sigmas: [0.91015625]... (timesteps: [909.0])

[Step 1420] Training Debug Info:
  Loss: 0.501788
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0106, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0123, std: 1.3438
  Model pred mean: -0.0091, std: 1.1406
  Sigmas: [0.6484375]... (timesteps: [650.0])

[Step 1420] Training Debug Info:
  Loss: 0.519960
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0177, std: 0.9766
  Noise mean: 0.0032, std: 1.0000
  Target mean: -0.0145, std: 1.3984
  Model pred mean: -0.0181, std: 1.1875
  Sigmas: [0.8828125]... (timesteps: [883.0])

[Step 1420] Training Debug Info:
  Loss: 1.113717
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0124, std: 0.9062
  Noise mean: -0.0040, std: 0.9961
  Target mean: -0.0165, std: 1.3438
  Model pred mean: -0.0125, std: 0.8320
  Sigmas: [0.228515625]... (timesteps: [229.0])
Steps:  28%|██▊       | 1421/5000 [5:20:27<11:59:30, 12.06s/it, loss=0.4222, lr=9.00e-06]Steps:  28%|██▊       | 1421/5000 [5:20:27<11:59:30, 12.06s/it, loss=1.1137, lr=9.00e-06]Steps:  28%|██▊       | 1422/5000 [5:20:39<11:59:19, 12.06s/it, loss=1.1137, lr=9.00e-06]Steps:  28%|██▊       | 1422/5000 [5:20:39<11:59:19, 12.06s/it, loss=0.7770, lr=9.00e-06]Steps:  28%|██▊       | 1423/5000 [5:20:51<11:57:08, 12.03s/it, loss=0.7770, lr=9.00e-06]Steps:  28%|██▊       | 1423/5000 [5:20:51<11:57:08, 12.03s/it, loss=0.4474, lr=9.00e-06]Steps:  28%|██▊       | 1424/5000 [5:21:03<11:55:10, 12.00s/it, loss=0.4474, lr=9.00e-06]Steps:  28%|██▊       | 1424/5000 [5:21:03<11:55:10, 12.00s/it, loss=1.0604, lr=9.00e-06]Steps:  28%|██▊       | 1425/5000 [5:21:15<11:52:34, 11.96s/it, loss=1.0604, lr=9.00e-06]Steps:  28%|██▊       | 1425/5000 [5:21:15<11:52:34, 11.96s/it, loss=1.1278, lr=8.99e-06]Steps:  29%|██▊       | 1426/5000 [5:21:27<11:52:25, 11.96s/it, loss=1.1278, lr=8.99e-06]Steps:  29%|██▊       | 1426/5000 [5:21:27<11:52:25, 11.96s/it, loss=0.7872, lr=8.99e-06]Steps:  29%|██▊       | 1427/5000 [5:21:38<11:51:11, 11.94s/it, loss=0.7872, lr=8.99e-06]Steps:  29%|██▊       | 1427/5000 [5:21:38<11:51:11, 11.94s/it, loss=0.5580, lr=8.99e-06]Steps:  29%|██▊       | 1428/5000 [5:21:51<11:55:43, 12.02s/it, loss=0.5580, lr=8.99e-06]Steps:  29%|██▊       | 1428/5000 [5:21:51<11:55:43, 12.02s/it, loss=0.6304, lr=8.99e-06]Steps:  29%|██▊       | 1429/5000 [5:22:03<11:58:18, 12.07s/it, loss=0.6304, lr=8.99e-06]Steps:  29%|██▊       | 1429/5000 [5:22:03<11:58:18, 12.07s/it, loss=1.1703, lr=8.98e-06]Steps:  29%|██▊       | 1430/5000 [5:22:15<11:54:46, 12.01s/it, loss=1.1703, lr=8.98e-06]Steps:  29%|██▊       | 1430/5000 [5:22:15<11:54:46, 12.01s/it, loss=1.0632, lr=8.98e-06]
[Step 1430] Training Debug Info:
  Loss: 0.418648
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0461, std: 0.9492
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0452, std: 1.3828
  Model pred mean: -0.0398, std: 1.2188
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 1430] Training Debug Info:
  Loss: 0.791516
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0084, std: 0.9297
  Noise mean: -0.0008, std: 0.9961
  Target mean: -0.0091, std: 1.3672
  Model pred mean: -0.0069, std: 1.0391
  Sigmas: [0.4296875]... (timesteps: [429.0])

[Step 1430] Training Debug Info:
  Loss: 0.483720
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0021, std: 0.9023
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0030, std: 1.3438
  Model pred mean: -0.0029, std: 1.1484
  Sigmas: [0.68359375]... (timesteps: [683.0])

[Step 1430] Training Debug Info:
  Loss: 0.597947
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0151, std: 0.9062
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0171, std: 1.3516
  Model pred mean: -0.0097, std: 1.1016
  Sigmas: [0.56640625]... (timesteps: [567.0])
Steps:  29%|██▊       | 1431/5000 [5:22:27<11:52:22, 11.98s/it, loss=1.0632, lr=8.98e-06]Steps:  29%|██▊       | 1431/5000 [5:22:27<11:52:22, 11.98s/it, loss=0.5979, lr=8.98e-06]Steps:  29%|██▊       | 1432/5000 [5:22:39<11:51:22, 11.96s/it, loss=0.5979, lr=8.98e-06]Steps:  29%|██▊       | 1432/5000 [5:22:39<11:51:22, 11.96s/it, loss=0.4367, lr=8.98e-06]Steps:  29%|██▊       | 1433/5000 [5:22:50<11:50:15, 11.95s/it, loss=0.4367, lr=8.98e-06]Steps:  29%|██▊       | 1433/5000 [5:22:50<11:50:15, 11.95s/it, loss=0.7880, lr=8.98e-06]Steps:  29%|██▊       | 1434/5000 [5:23:02<11:48:45, 11.93s/it, loss=0.7880, lr=8.98e-06]Steps:  29%|██▊       | 1434/5000 [5:23:02<11:48:45, 11.93s/it, loss=1.2185, lr=8.97e-06]Steps:  29%|██▊       | 1435/5000 [5:23:15<11:53:46, 12.01s/it, loss=1.2185, lr=8.97e-06]Steps:  29%|██▊       | 1435/5000 [5:23:15<11:53:46, 12.01s/it, loss=0.5707, lr=8.97e-06]Steps:  29%|██▊       | 1436/5000 [5:23:27<11:56:42, 12.07s/it, loss=0.5707, lr=8.97e-06]Steps:  29%|██▊       | 1436/5000 [5:23:27<11:56:42, 12.07s/it, loss=1.0242, lr=8.97e-06]Steps:  29%|██▊       | 1437/5000 [5:23:39<11:54:07, 12.03s/it, loss=1.0242, lr=8.97e-06]Steps:  29%|██▊       | 1437/5000 [5:23:39<11:54:07, 12.03s/it, loss=1.1787, lr=8.97e-06]Steps:  29%|██▉       | 1438/5000 [5:23:51<11:52:32, 12.00s/it, loss=1.1787, lr=8.97e-06]Steps:  29%|██▉       | 1438/5000 [5:23:51<11:52:32, 12.00s/it, loss=0.5896, lr=8.97e-06]Steps:  29%|██▉       | 1439/5000 [5:24:03<11:51:18, 11.98s/it, loss=0.5896, lr=8.97e-06]Steps:  29%|██▉       | 1439/5000 [5:24:03<11:51:18, 11.98s/it, loss=0.5248, lr=8.96e-06]Steps:  29%|██▉       | 1440/5000 [5:24:14<11:48:54, 11.95s/it, loss=0.5248, lr=8.96e-06]Steps:  29%|██▉       | 1440/5000 [5:24:14<11:48:54, 11.95s/it, loss=0.6972, lr=8.96e-06]
[Step 1440] Training Debug Info:
  Loss: 1.133540
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0085, std: 0.9141
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0082, std: 1.3516
  Model pred mean: -0.0055, std: 0.8438
  Sigmas: [0.11279296875]... (timesteps: [113.0])

[Step 1440] Training Debug Info:
  Loss: 0.517951
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0075, std: 0.9453
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0082, std: 1.3750
  Model pred mean: -0.0069, std: 1.1797
  Sigmas: [0.6015625]... (timesteps: [601.0])

[Step 1440] Training Debug Info:
  Loss: 0.525116
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0051, std: 0.8672
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0066, std: 1.3281
  Model pred mean: 0.0034, std: 1.1016
  Sigmas: [0.98828125]... (timesteps: [989.0])

[Step 1440] Training Debug Info:
  Loss: 1.143087
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0184, std: 0.9102
  Noise mean: -0.0019, std: 1.0000
  Target mean: 0.0166, std: 1.3516
  Model pred mean: 0.0215, std: 0.8359
  Sigmas: [0.173828125]... (timesteps: [174.0])
Steps:  29%|██▉       | 1441/5000 [5:24:27<11:53:44, 12.03s/it, loss=0.6972, lr=8.96e-06]Steps:  29%|██▉       | 1441/5000 [5:24:27<11:53:44, 12.03s/it, loss=1.1431, lr=8.96e-06]Steps:  29%|██▉       | 1442/5000 [5:24:39<11:50:05, 11.97s/it, loss=1.1431, lr=8.96e-06]Steps:  29%|██▉       | 1442/5000 [5:24:39<11:50:05, 11.97s/it, loss=0.8605, lr=8.96e-06]Steps:  29%|██▉       | 1443/5000 [5:24:51<11:50:39, 11.99s/it, loss=0.8605, lr=8.96e-06]Steps:  29%|██▉       | 1443/5000 [5:24:51<11:50:39, 11.99s/it, loss=1.0999, lr=8.96e-06]Steps:  29%|██▉       | 1444/5000 [5:25:03<11:50:38, 11.99s/it, loss=1.0999, lr=8.96e-06]Steps:  29%|██▉       | 1444/5000 [5:25:03<11:50:38, 11.99s/it, loss=0.9330, lr=8.95e-06]Steps:  29%|██▉       | 1445/5000 [5:25:14<11:49:43, 11.98s/it, loss=0.9330, lr=8.95e-06]Steps:  29%|██▉       | 1445/5000 [5:25:14<11:49:43, 11.98s/it, loss=0.4733, lr=8.95e-06]Steps:  29%|██▉       | 1446/5000 [5:25:26<11:48:58, 11.97s/it, loss=0.4733, lr=8.95e-06]Steps:  29%|██▉       | 1446/5000 [5:25:26<11:48:58, 11.97s/it, loss=0.4092, lr=8.95e-06]Steps:  29%|██▉       | 1447/5000 [5:25:38<11:48:55, 11.97s/it, loss=0.4092, lr=8.95e-06]Steps:  29%|██▉       | 1447/5000 [5:25:38<11:48:55, 11.97s/it, loss=0.8196, lr=8.95e-06]Steps:  29%|██▉       | 1448/5000 [5:25:50<11:50:17, 12.00s/it, loss=0.8196, lr=8.95e-06]Steps:  29%|██▉       | 1448/5000 [5:25:50<11:50:17, 12.00s/it, loss=0.9391, lr=8.94e-06]Steps:  29%|██▉       | 1449/5000 [5:26:02<11:48:05, 11.96s/it, loss=0.9391, lr=8.94e-06]Steps:  29%|██▉       | 1449/5000 [5:26:02<11:48:05, 11.96s/it, loss=0.5120, lr=8.94e-06]Steps:  29%|██▉       | 1450/5000 [5:26:14<11:45:51, 11.93s/it, loss=0.5120, lr=8.94e-06]Steps:  29%|██▉       | 1450/5000 [5:26:14<11:45:51, 11.93s/it, loss=1.0579, lr=8.94e-06]
[Step 1450] Training Debug Info:
  Loss: 1.039546
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0272, std: 0.8945
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0255, std: 1.3438
  Model pred mean: 0.0291, std: 0.8750
  Sigmas: [0.02099609375]... (timesteps: [21.0])

[Step 1450] Training Debug Info:
  Loss: 0.415093
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0034, std: 0.9141
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0027, std: 1.3516
  Model pred mean: -0.0056, std: 1.1953
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 1450] Training Debug Info:
  Loss: 0.606831
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0249, std: 0.8906
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0259, std: 1.3438
  Model pred mean: -0.0003, std: 1.0781
  Sigmas: [0.99609375]... (timesteps: [998.0])

[Step 1450] Training Debug Info:
  Loss: 0.384860
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0016, std: 0.9141
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0038, std: 1.3594
  Model pred mean: 0.0012, std: 1.2109
  Sigmas: [0.8515625]... (timesteps: [850.0])
Steps:  29%|██▉       | 1451/5000 [5:26:26<11:44:06, 11.90s/it, loss=1.0579, lr=8.94e-06]Steps:  29%|██▉       | 1451/5000 [5:26:26<11:44:06, 11.90s/it, loss=0.3849, lr=8.94e-06]Steps:  29%|██▉       | 1452/5000 [5:26:38<11:44:18, 11.91s/it, loss=0.3849, lr=8.94e-06]Steps:  29%|██▉       | 1452/5000 [5:26:38<11:44:18, 11.91s/it, loss=1.1084, lr=8.94e-06]Steps:  29%|██▉       | 1453/5000 [5:26:50<11:44:23, 11.92s/it, loss=1.1084, lr=8.94e-06]Steps:  29%|██▉       | 1453/5000 [5:26:50<11:44:23, 11.92s/it, loss=0.4681, lr=8.93e-06]Steps:  29%|██▉       | 1454/5000 [5:27:02<11:45:11, 11.93s/it, loss=0.4681, lr=8.93e-06]Steps:  29%|██▉       | 1454/5000 [5:27:02<11:45:11, 11.93s/it, loss=0.8404, lr=8.93e-06]Steps:  29%|██▉       | 1455/5000 [5:27:14<11:50:18, 12.02s/it, loss=0.8404, lr=8.93e-06]Steps:  29%|██▉       | 1455/5000 [5:27:14<11:50:18, 12.02s/it, loss=1.0320, lr=8.93e-06]Steps:  29%|██▉       | 1456/5000 [5:27:26<11:48:44, 12.00s/it, loss=1.0320, lr=8.93e-06]Steps:  29%|██▉       | 1456/5000 [5:27:26<11:48:44, 12.00s/it, loss=1.0910, lr=8.93e-06]Steps:  29%|██▉       | 1457/5000 [5:27:38<11:46:48, 11.97s/it, loss=1.0910, lr=8.93e-06]Steps:  29%|██▉       | 1457/5000 [5:27:38<11:46:48, 11.97s/it, loss=0.4914, lr=8.92e-06]Steps:  29%|██▉       | 1458/5000 [5:27:50<11:44:59, 11.94s/it, loss=0.4914, lr=8.92e-06]Steps:  29%|██▉       | 1458/5000 [5:27:50<11:44:59, 11.94s/it, loss=0.7446, lr=8.92e-06]Steps:  29%|██▉       | 1459/5000 [5:28:02<11:43:09, 11.91s/it, loss=0.7446, lr=8.92e-06]Steps:  29%|██▉       | 1459/5000 [5:28:02<11:43:09, 11.91s/it, loss=0.5275, lr=8.92e-06]Steps:  29%|██▉       | 1460/5000 [5:28:14<11:42:41, 11.91s/it, loss=0.5275, lr=8.92e-06]Steps:  29%|██▉       | 1460/5000 [5:28:14<11:42:41, 11.91s/it, loss=0.5399, lr=8.92e-06]
[Step 1460] Training Debug Info:
  Loss: 0.622902
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0043, std: 0.8984
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0051, std: 1.3438
  Model pred mean: -0.0076, std: 1.1016
  Sigmas: [0.5703125]... (timesteps: [569.0])

[Step 1460] Training Debug Info:
  Loss: 1.059574
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0393, std: 0.9570
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0405, std: 1.3828
  Model pred mean: -0.0403, std: 0.9297
  Sigmas: [0.279296875]... (timesteps: [280.0])

[Step 1460] Training Debug Info:
  Loss: 0.483809
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0262, std: 0.9180
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0282, std: 1.3594
  Model pred mean: -0.0164, std: 1.1797
  Sigmas: [0.90625]... (timesteps: [905.0])

[Step 1460] Training Debug Info:
  Loss: 0.615875
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0256, std: 0.9141
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0244, std: 1.3594
  Model pred mean: -0.0287, std: 1.1172
  Sigmas: [0.51171875]... (timesteps: [512.0])
Steps:  29%|██▉       | 1461/5000 [5:28:26<11:44:29, 11.94s/it, loss=0.5399, lr=8.92e-06]Steps:  29%|██▉       | 1461/5000 [5:28:26<11:44:29, 11.94s/it, loss=0.6159, lr=8.92e-06]Steps:  29%|██▉       | 1462/5000 [5:28:38<11:48:28, 12.01s/it, loss=0.6159, lr=8.92e-06]Steps:  29%|██▉       | 1462/5000 [5:28:38<11:48:28, 12.01s/it, loss=0.4345, lr=8.91e-06]Steps:  29%|██▉       | 1463/5000 [5:28:50<11:46:16, 11.98s/it, loss=0.4345, lr=8.91e-06]Steps:  29%|██▉       | 1463/5000 [5:28:50<11:46:16, 11.98s/it, loss=1.1066, lr=8.91e-06]Steps:  29%|██▉       | 1464/5000 [5:29:02<11:46:21, 11.99s/it, loss=1.1066, lr=8.91e-06]Steps:  29%|██▉       | 1464/5000 [5:29:02<11:46:21, 11.99s/it, loss=0.4105, lr=8.91e-06]Steps:  29%|██▉       | 1465/5000 [5:29:14<11:43:42, 11.94s/it, loss=0.4105, lr=8.91e-06]Steps:  29%|██▉       | 1465/5000 [5:29:14<11:43:42, 11.94s/it, loss=0.5022, lr=8.91e-06]Steps:  29%|██▉       | 1466/5000 [5:29:25<11:43:08, 11.94s/it, loss=0.5022, lr=8.91e-06]Steps:  29%|██▉       | 1466/5000 [5:29:25<11:43:08, 11.94s/it, loss=0.3491, lr=8.91e-06]Steps:  29%|██▉       | 1467/5000 [5:29:37<11:43:06, 11.94s/it, loss=0.3491, lr=8.91e-06]Steps:  29%|██▉       | 1467/5000 [5:29:37<11:43:06, 11.94s/it, loss=0.4527, lr=8.90e-06]Steps:  29%|██▉       | 1468/5000 [5:29:50<11:47:36, 12.02s/it, loss=0.4527, lr=8.90e-06]Steps:  29%|██▉       | 1468/5000 [5:29:50<11:47:36, 12.02s/it, loss=0.7396, lr=8.90e-06]Steps:  29%|██▉       | 1469/5000 [5:30:02<11:46:05, 12.00s/it, loss=0.7396, lr=8.90e-06]Steps:  29%|██▉       | 1469/5000 [5:30:02<11:46:05, 12.00s/it, loss=1.1419, lr=8.90e-06]Steps:  29%|██▉       | 1470/5000 [5:30:14<11:46:38, 12.01s/it, loss=1.1419, lr=8.90e-06]Steps:  29%|██▉       | 1470/5000 [5:30:14<11:46:38, 12.01s/it, loss=0.8748, lr=8.90e-06]
[Step 1470] Training Debug Info:
  Loss: 1.008923
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0130, std: 0.8828
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0117, std: 1.3359
  Model pred mean: 0.0171, std: 0.8711
  Sigmas: [0.0030059814453125]... (timesteps: [3.0])

[Step 1470] Training Debug Info:
  Loss: 1.014635
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0194, std: 0.9570
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0227, std: 1.3828
  Model pred mean: -0.0142, std: 0.9492
  Sigmas: [0.0030059814453125]... (timesteps: [3.0])

[Step 1470] Training Debug Info:
  Loss: 1.093185
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0234, std: 0.9375
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0238, std: 1.3672
  Model pred mean: -0.0222, std: 0.8750
  Sigmas: [0.0810546875]... (timesteps: [81.0])

[Step 1470] Training Debug Info:
  Loss: 1.163483
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0103, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0094, std: 1.3594
  Model pred mean: -0.0092, std: 0.8242
  Sigmas: [0.16796875]... (timesteps: [168.0])
Steps:  29%|██▉       | 1471/5000 [5:30:25<11:44:16, 11.97s/it, loss=0.8748, lr=8.90e-06]Steps:  29%|██▉       | 1471/5000 [5:30:25<11:44:16, 11.97s/it, loss=1.1635, lr=8.89e-06]Steps:  29%|██▉       | 1472/5000 [5:30:37<11:41:38, 11.93s/it, loss=1.1635, lr=8.89e-06]Steps:  29%|██▉       | 1472/5000 [5:30:37<11:41:38, 11.93s/it, loss=0.6091, lr=8.89e-06]Steps:  29%|██▉       | 1473/5000 [5:30:49<11:39:57, 11.91s/it, loss=0.6091, lr=8.89e-06]Steps:  29%|██▉       | 1473/5000 [5:30:49<11:39:57, 11.91s/it, loss=0.4993, lr=8.89e-06]Steps:  29%|██▉       | 1474/5000 [5:31:01<11:39:08, 11.90s/it, loss=0.4993, lr=8.89e-06]Steps:  29%|██▉       | 1474/5000 [5:31:01<11:39:08, 11.90s/it, loss=1.0993, lr=8.89e-06]Steps:  30%|██▉       | 1475/5000 [5:31:13<11:44:48, 12.00s/it, loss=1.0993, lr=8.89e-06]Steps:  30%|██▉       | 1475/5000 [5:31:13<11:44:48, 12.00s/it, loss=1.0952, lr=8.89e-06]Steps:  30%|██▉       | 1476/5000 [5:31:25<11:42:03, 11.95s/it, loss=1.0952, lr=8.89e-06]Steps:  30%|██▉       | 1476/5000 [5:31:25<11:42:03, 11.95s/it, loss=0.4241, lr=8.88e-06]Steps:  30%|██▉       | 1477/5000 [5:31:37<11:39:26, 11.91s/it, loss=0.4241, lr=8.88e-06]Steps:  30%|██▉       | 1477/5000 [5:31:37<11:39:26, 11.91s/it, loss=0.4447, lr=8.88e-06]Steps:  30%|██▉       | 1478/5000 [5:31:49<11:38:22, 11.90s/it, loss=0.4447, lr=8.88e-06]Steps:  30%|██▉       | 1478/5000 [5:31:49<11:38:22, 11.90s/it, loss=1.0656, lr=8.88e-06]Steps:  30%|██▉       | 1479/5000 [5:32:01<11:41:02, 11.95s/it, loss=1.0656, lr=8.88e-06]Steps:  30%|██▉       | 1479/5000 [5:32:01<11:41:02, 11.95s/it, loss=1.1013, lr=8.88e-06]Steps:  30%|██▉       | 1480/5000 [5:32:13<11:40:16, 11.94s/it, loss=1.1013, lr=8.88e-06]Steps:  30%|██▉       | 1480/5000 [5:32:13<11:40:16, 11.94s/it, loss=0.5905, lr=8.87e-06]
[Step 1480] Training Debug Info:
  Loss: 0.633243
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0115, std: 0.8516
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0120, std: 1.3125
  Model pred mean: 0.0135, std: 1.0391
  Sigmas: [0.59375]... (timesteps: [593.0])

[Step 1480] Training Debug Info:
  Loss: 0.937941
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0066, std: 0.8906
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0064, std: 1.3359
  Model pred mean: -0.0016, std: 0.9336
  Sigmas: [0.37109375]... (timesteps: [372.0])

[Step 1480] Training Debug Info:
  Loss: 1.130554
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0045, std: 0.8906
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0019, std: 1.3438
  Model pred mean: -0.0019, std: 0.8203
  Sigmas: [0.083984375]... (timesteps: [84.0])

[Step 1480] Training Debug Info:
  Loss: 0.450996
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0039, std: 0.8828
  Noise mean: 0.0004, std: 0.9961
  Target mean: -0.0035, std: 1.3281
  Model pred mean: -0.0020, std: 1.1328
  Sigmas: [0.72265625]... (timesteps: [723.0])
Steps:  30%|██▉       | 1481/5000 [5:32:25<11:41:06, 11.95s/it, loss=0.5905, lr=8.87e-06]Steps:  30%|██▉       | 1481/5000 [5:32:25<11:41:06, 11.95s/it, loss=0.4510, lr=8.87e-06]Steps:  30%|██▉       | 1482/5000 [5:32:37<11:46:16, 12.05s/it, loss=0.4510, lr=8.87e-06]Steps:  30%|██▉       | 1482/5000 [5:32:37<11:46:16, 12.05s/it, loss=0.6407, lr=8.87e-06]Steps:  30%|██▉       | 1483/5000 [5:32:49<11:43:53, 12.01s/it, loss=0.6407, lr=8.87e-06]Steps:  30%|██▉       | 1483/5000 [5:32:49<11:43:53, 12.01s/it, loss=1.1408, lr=8.87e-06]Steps:  30%|██▉       | 1484/5000 [5:33:01<11:42:22, 11.99s/it, loss=1.1408, lr=8.87e-06]Steps:  30%|██▉       | 1484/5000 [5:33:01<11:42:22, 11.99s/it, loss=0.9799, lr=8.87e-06]Steps:  30%|██▉       | 1485/5000 [5:33:13<11:42:02, 11.98s/it, loss=0.9799, lr=8.87e-06]Steps:  30%|██▉       | 1485/5000 [5:33:13<11:42:02, 11.98s/it, loss=0.7696, lr=8.86e-06]Steps:  30%|██▉       | 1486/5000 [5:33:25<11:41:10, 11.97s/it, loss=0.7696, lr=8.86e-06]Steps:  30%|██▉       | 1486/5000 [5:33:25<11:41:10, 11.97s/it, loss=0.4232, lr=8.86e-06]Steps:  30%|██▉       | 1487/5000 [5:33:37<11:40:44, 11.97s/it, loss=0.4232, lr=8.86e-06]Steps:  30%|██▉       | 1487/5000 [5:33:37<11:40:44, 11.97s/it, loss=0.4503, lr=8.86e-06]Steps:  30%|██▉       | 1488/5000 [5:33:49<11:42:26, 12.00s/it, loss=0.4503, lr=8.86e-06]Steps:  30%|██▉       | 1488/5000 [5:33:49<11:42:26, 12.00s/it, loss=1.1449, lr=8.86e-06]Steps:  30%|██▉       | 1489/5000 [5:34:01<11:46:34, 12.07s/it, loss=1.1449, lr=8.86e-06]Steps:  30%|██▉       | 1489/5000 [5:34:01<11:46:34, 12.07s/it, loss=1.0197, lr=8.85e-06]Steps:  30%|██▉       | 1490/5000 [5:34:13<11:43:06, 12.02s/it, loss=1.0197, lr=8.85e-06]Steps:  30%|██▉       | 1490/5000 [5:34:13<11:43:06, 12.02s/it, loss=1.0702, lr=8.85e-06]
[Step 1490] Training Debug Info:
  Loss: 0.373163
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0056, std: 0.9141
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0063, std: 1.3594
  Model pred mean: -0.0063, std: 1.2109
  Sigmas: [0.84765625]... (timesteps: [847.0])

[Step 1490] Training Debug Info:
  Loss: 0.526422
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0439, std: 0.9609
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0420, std: 1.3828
  Model pred mean: -0.0354, std: 1.1797
  Sigmas: [0.90234375]... (timesteps: [901.0])

[Step 1490] Training Debug Info:
  Loss: 0.658703
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0029, std: 0.9023
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0024, std: 1.3438
  Model pred mean: -0.0035, std: 1.0859
  Sigmas: [0.5546875]... (timesteps: [554.0])

[Step 1490] Training Debug Info:
  Loss: 0.461406
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0052, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0041, std: 1.3594
  Model pred mean: -0.0059, std: 1.1797
  Sigmas: [0.72265625]... (timesteps: [722.0])
Steps:  30%|██▉       | 1491/5000 [5:34:25<11:41:14, 11.99s/it, loss=1.0702, lr=8.85e-06]Steps:  30%|██▉       | 1491/5000 [5:34:25<11:41:14, 11.99s/it, loss=0.4614, lr=8.85e-06]Steps:  30%|██▉       | 1492/5000 [5:34:37<11:40:04, 11.97s/it, loss=0.4614, lr=8.85e-06]Steps:  30%|██▉       | 1492/5000 [5:34:37<11:40:04, 11.97s/it, loss=1.0197, lr=8.85e-06]Steps:  30%|██▉       | 1493/5000 [5:34:49<11:38:44, 11.95s/it, loss=1.0197, lr=8.85e-06]Steps:  30%|██▉       | 1493/5000 [5:34:49<11:38:44, 11.95s/it, loss=1.0444, lr=8.85e-06]Steps:  30%|██▉       | 1494/5000 [5:35:01<11:37:47, 11.94s/it, loss=1.0444, lr=8.85e-06]Steps:  30%|██▉       | 1494/5000 [5:35:01<11:37:47, 11.94s/it, loss=0.6662, lr=8.84e-06]Steps:  30%|██▉       | 1495/5000 [5:35:13<11:41:06, 12.00s/it, loss=0.6662, lr=8.84e-06]Steps:  30%|██▉       | 1495/5000 [5:35:13<11:41:06, 12.00s/it, loss=0.4209, lr=8.84e-06]Steps:  30%|██▉       | 1496/5000 [5:35:25<11:38:04, 11.95s/it, loss=0.4209, lr=8.84e-06]Steps:  30%|██▉       | 1496/5000 [5:35:25<11:38:04, 11.95s/it, loss=1.1148, lr=8.84e-06]Steps:  30%|██▉       | 1497/5000 [5:35:37<11:37:57, 11.95s/it, loss=1.1148, lr=8.84e-06]Steps:  30%|██▉       | 1497/5000 [5:35:37<11:37:57, 11.95s/it, loss=0.3836, lr=8.84e-06]Steps:  30%|██▉       | 1498/5000 [5:35:49<11:37:23, 11.95s/it, loss=0.3836, lr=8.84e-06]Steps:  30%|██▉       | 1498/5000 [5:35:49<11:37:23, 11.95s/it, loss=0.4762, lr=8.83e-06]Steps:  30%|██▉       | 1499/5000 [5:36:00<11:36:36, 11.94s/it, loss=0.4762, lr=8.83e-06]Steps:  30%|██▉       | 1499/5000 [5:36:00<11:36:36, 11.94s/it, loss=0.8260, lr=8.83e-06]Steps:  30%|███       | 1500/5000 [5:36:12<11:35:26, 11.92s/it, loss=0.8260, lr=8.83e-06]Steps:  30%|███       | 1500/5000 [5:36:12<11:35:26, 11.92s/it, loss=0.4892, lr=8.83e-06]01/22/2026 13:21:59 - INFO - __main__ - 
[Step 1500] ✅ Loss in normal range (0.4892)
01/22/2026 13:21:59 - INFO - __main__ -   Loss avg (last 100): 0.7818
01/22/2026 13:21:59 - INFO - __main__ -   Loss range: [0.3491, 1.2185]

[Step 1500] Training Debug Info:
  Loss: 1.089800
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0085, std: 0.8906
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0072, std: 1.3438
  Model pred mean: 0.0081, std: 0.8516
  Sigmas: [0.050048828125]... (timesteps: [50.0])

[Step 1500] Training Debug Info:
  Loss: 0.407224
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0231, std: 0.9570
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0206, std: 1.3828
  Model pred mean: 0.0262, std: 1.2344
  Sigmas: [0.8515625]... (timesteps: [852.0])

[Step 1500] Training Debug Info:
  Loss: 0.370593
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0244, std: 0.8477
  Noise mean: -0.0030, std: 1.0000
  Target mean: 0.0214, std: 1.3125
  Model pred mean: 0.0243, std: 1.1719
  Sigmas: [0.8828125]... (timesteps: [881.0])

[Step 1500] Training Debug Info:
  Loss: 0.417732
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0410, std: 0.9219
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0422, std: 1.3594
  Model pred mean: -0.0322, std: 1.2109
  Sigmas: [0.90625]... (timesteps: [908.0])
Steps:  30%|███       | 1501/5000 [5:36:24<11:34:29, 11.91s/it, loss=0.4892, lr=8.83e-06]Steps:  30%|███       | 1501/5000 [5:36:24<11:34:29, 11.91s/it, loss=0.4177, lr=8.83e-06]Steps:  30%|███       | 1502/5000 [5:36:36<11:39:37, 12.00s/it, loss=0.4177, lr=8.83e-06]Steps:  30%|███       | 1502/5000 [5:36:36<11:39:37, 12.00s/it, loss=1.0991, lr=8.83e-06]Steps:  30%|███       | 1503/5000 [5:36:48<11:38:10, 11.98s/it, loss=1.0991, lr=8.83e-06]Steps:  30%|███       | 1503/5000 [5:36:48<11:38:10, 11.98s/it, loss=1.1190, lr=8.82e-06]Steps:  30%|███       | 1504/5000 [5:37:00<11:35:57, 11.94s/it, loss=1.1190, lr=8.82e-06]Steps:  30%|███       | 1504/5000 [5:37:00<11:35:57, 11.94s/it, loss=0.8374, lr=8.82e-06]Steps:  30%|███       | 1505/5000 [5:37:12<11:34:40, 11.93s/it, loss=0.8374, lr=8.82e-06]Steps:  30%|███       | 1505/5000 [5:37:12<11:34:40, 11.93s/it, loss=0.5679, lr=8.82e-06]Steps:  30%|███       | 1506/5000 [5:37:24<11:35:11, 11.94s/it, loss=0.5679, lr=8.82e-06]Steps:  30%|███       | 1506/5000 [5:37:24<11:35:11, 11.94s/it, loss=0.5395, lr=8.82e-06]Steps:  30%|███       | 1507/5000 [5:37:36<11:35:14, 11.94s/it, loss=0.5395, lr=8.82e-06]Steps:  30%|███       | 1507/5000 [5:37:36<11:35:14, 11.94s/it, loss=0.4929, lr=8.81e-06]Steps:  30%|███       | 1508/5000 [5:37:48<11:33:01, 11.91s/it, loss=0.4929, lr=8.81e-06]Steps:  30%|███       | 1508/5000 [5:37:48<11:33:01, 11.91s/it, loss=1.2191, lr=8.81e-06]Steps:  30%|███       | 1509/5000 [5:38:00<11:37:24, 11.99s/it, loss=1.2191, lr=8.81e-06]Steps:  30%|███       | 1509/5000 [5:38:00<11:37:24, 11.99s/it, loss=0.3717, lr=8.81e-06]Steps:  30%|███       | 1510/5000 [5:38:12<11:35:47, 11.96s/it, loss=0.3717, lr=8.81e-06]Steps:  30%|███       | 1510/5000 [5:38:12<11:35:47, 11.96s/it, loss=0.7391, lr=8.81e-06]
[Step 1510] Training Debug Info:
  Loss: 1.170582
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0013, std: 0.9570
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0002, std: 1.3828
  Model pred mean: 0.0034, std: 0.8711
  Sigmas: [0.2119140625]... (timesteps: [212.0])

[Step 1510] Training Debug Info:
  Loss: 0.553203
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.9648
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0083, std: 1.3906
  Model pred mean: 0.0055, std: 1.1797
  Sigmas: [0.6328125]... (timesteps: [634.0])

[Step 1510] Training Debug Info:
  Loss: 0.655198
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0086, std: 0.9648
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0071, std: 1.3906
  Model pred mean: -0.0103, std: 1.1328
  Sigmas: [0.52734375]... (timesteps: [527.0])

[Step 1510] Training Debug Info:
  Loss: 0.577837
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0156, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0166, std: 1.3594
  Model pred mean: -0.0157, std: 1.1250
  Sigmas: [0.55078125]... (timesteps: [550.0])
Steps:  30%|███       | 1511/5000 [5:38:24<11:36:07, 11.97s/it, loss=0.7391, lr=8.81e-06]Steps:  30%|███       | 1511/5000 [5:38:24<11:36:07, 11.97s/it, loss=0.5778, lr=8.81e-06]Steps:  30%|███       | 1512/5000 [5:38:36<11:35:24, 11.96s/it, loss=0.5778, lr=8.81e-06]Steps:  30%|███       | 1512/5000 [5:38:36<11:35:24, 11.96s/it, loss=0.8787, lr=8.80e-06]Steps:  30%|███       | 1513/5000 [5:38:48<11:34:30, 11.95s/it, loss=0.8787, lr=8.80e-06]Steps:  30%|███       | 1513/5000 [5:38:48<11:34:30, 11.95s/it, loss=0.6008, lr=8.80e-06]Steps:  30%|███       | 1514/5000 [5:39:00<11:34:07, 11.95s/it, loss=0.6008, lr=8.80e-06]Steps:  30%|███       | 1514/5000 [5:39:00<11:34:07, 11.95s/it, loss=1.1792, lr=8.80e-06]Steps:  30%|███       | 1515/5000 [5:39:12<11:35:51, 11.98s/it, loss=1.1792, lr=8.80e-06]Steps:  30%|███       | 1515/5000 [5:39:12<11:35:51, 11.98s/it, loss=1.1053, lr=8.80e-06]Steps:  30%|███       | 1516/5000 [5:39:24<11:40:56, 12.07s/it, loss=1.1053, lr=8.80e-06]Steps:  30%|███       | 1516/5000 [5:39:24<11:40:56, 12.07s/it, loss=1.1194, lr=8.79e-06]Steps:  30%|███       | 1517/5000 [5:39:36<11:38:43, 12.04s/it, loss=1.1194, lr=8.79e-06]Steps:  30%|███       | 1517/5000 [5:39:36<11:38:43, 12.04s/it, loss=0.4226, lr=8.79e-06]Steps:  30%|███       | 1518/5000 [5:39:48<11:35:47, 11.99s/it, loss=0.4226, lr=8.79e-06]Steps:  30%|███       | 1518/5000 [5:39:48<11:35:47, 11.99s/it, loss=0.4960, lr=8.79e-06]Steps:  30%|███       | 1519/5000 [5:40:00<11:33:49, 11.96s/it, loss=0.4960, lr=8.79e-06]Steps:  30%|███       | 1519/5000 [5:40:00<11:33:49, 11.96s/it, loss=0.3827, lr=8.79e-06]Steps:  30%|███       | 1520/5000 [5:40:12<11:33:20, 11.95s/it, loss=0.3827, lr=8.79e-06]Steps:  30%|███       | 1520/5000 [5:40:12<11:33:20, 11.95s/it, loss=0.4678, lr=8.78e-06]
[Step 1520] Training Debug Info:
  Loss: 0.616166
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0272, std: 0.9922
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0304, std: 1.4141
  Model pred mean: -0.0292, std: 1.1719
  Sigmas: [0.5078125]... (timesteps: [507.0000305175781])

[Step 1520] Training Debug Info:
  Loss: 0.374951
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0084, std: 0.9297
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0098, std: 1.3672
  Model pred mean: -0.0056, std: 1.2266
  Sigmas: [0.76953125]... (timesteps: [768.0])

[Step 1520] Training Debug Info:
  Loss: 0.717578
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0403, std: 0.9219
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0396, std: 1.3594
  Model pred mean: -0.0187, std: 1.0781
  Sigmas: [0.99609375]... (timesteps: [995.0])

[Step 1520] Training Debug Info:
  Loss: 0.817542
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0427, std: 0.9688
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0454, std: 1.3906
  Model pred mean: -0.0469, std: 1.0625
  Sigmas: [0.38671875]... (timesteps: [387.0])
Steps:  30%|███       | 1521/5000 [5:40:24<11:32:00, 11.93s/it, loss=0.4678, lr=8.78e-06]Steps:  30%|███       | 1521/5000 [5:40:24<11:32:00, 11.93s/it, loss=0.8175, lr=8.78e-06]Steps:  30%|███       | 1522/5000 [5:40:36<11:35:00, 11.99s/it, loss=0.8175, lr=8.78e-06]Steps:  30%|███       | 1522/5000 [5:40:36<11:35:00, 11.99s/it, loss=0.9150, lr=8.78e-06]Steps:  30%|███       | 1523/5000 [5:40:48<11:33:36, 11.97s/it, loss=0.9150, lr=8.78e-06]Steps:  30%|███       | 1523/5000 [5:40:48<11:33:36, 11.97s/it, loss=0.5201, lr=8.78e-06]Steps:  30%|███       | 1524/5000 [5:41:00<11:34:02, 11.98s/it, loss=0.5201, lr=8.78e-06]Steps:  30%|███       | 1524/5000 [5:41:00<11:34:02, 11.98s/it, loss=1.0922, lr=8.78e-06]Steps:  30%|███       | 1525/5000 [5:41:12<11:32:52, 11.96s/it, loss=1.0922, lr=8.78e-06]Steps:  30%|███       | 1525/5000 [5:41:12<11:32:52, 11.96s/it, loss=0.4661, lr=8.77e-06]Steps:  31%|███       | 1526/5000 [5:41:23<11:30:58, 11.93s/it, loss=0.4661, lr=8.77e-06]Steps:  31%|███       | 1526/5000 [5:41:23<11:30:58, 11.93s/it, loss=0.6827, lr=8.77e-06]Steps:  31%|███       | 1527/5000 [5:41:35<11:30:23, 11.93s/it, loss=0.6827, lr=8.77e-06]Steps:  31%|███       | 1527/5000 [5:41:35<11:30:23, 11.93s/it, loss=0.9281, lr=8.77e-06]Steps:  31%|███       | 1528/5000 [5:41:47<11:29:44, 11.92s/it, loss=0.9281, lr=8.77e-06]Steps:  31%|███       | 1528/5000 [5:41:47<11:29:44, 11.92s/it, loss=0.5947, lr=8.77e-06]Steps:  31%|███       | 1529/5000 [5:42:00<11:35:41, 12.03s/it, loss=0.5947, lr=8.77e-06]Steps:  31%|███       | 1529/5000 [5:42:00<11:35:41, 12.03s/it, loss=1.1091, lr=8.76e-06]Steps:  31%|███       | 1530/5000 [5:42:11<11:34:26, 12.01s/it, loss=1.1091, lr=8.76e-06]Steps:  31%|███       | 1530/5000 [5:42:11<11:34:26, 12.01s/it, loss=0.3774, lr=8.76e-06]
[Step 1530] Training Debug Info:
  Loss: 0.740210
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0048, std: 0.9297
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0036, std: 1.3672
  Model pred mean: 0.0049, std: 1.0703
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 1530] Training Debug Info:
  Loss: 0.367169
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0146, std: 0.9297
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0130, std: 1.3672
  Model pred mean: -0.0204, std: 1.2188
  Sigmas: [0.875]... (timesteps: [876.0])

[Step 1530] Training Debug Info:
  Loss: 0.519008
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0156, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0161, std: 1.3750
  Model pred mean: -0.0171, std: 1.1719
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 1530] Training Debug Info:
  Loss: 0.430003
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0028, std: 0.9062
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: 0.0036, std: 1.1797
  Sigmas: [0.74609375]... (timesteps: [747.0])
Steps:  31%|███       | 1531/5000 [5:42:23<11:33:28, 11.99s/it, loss=0.3774, lr=8.76e-06]Steps:  31%|███       | 1531/5000 [5:42:23<11:33:28, 11.99s/it, loss=0.4300, lr=8.76e-06]Steps:  31%|███       | 1532/5000 [5:42:35<11:31:40, 11.97s/it, loss=0.4300, lr=8.76e-06]Steps:  31%|███       | 1532/5000 [5:42:35<11:31:40, 11.97s/it, loss=1.0130, lr=8.76e-06]Steps:  31%|███       | 1533/5000 [5:42:47<11:31:31, 11.97s/it, loss=1.0130, lr=8.76e-06]Steps:  31%|███       | 1533/5000 [5:42:47<11:31:31, 11.97s/it, loss=0.3405, lr=8.76e-06]Steps:  31%|███       | 1534/5000 [5:42:59<11:30:15, 11.95s/it, loss=0.3405, lr=8.76e-06]Steps:  31%|███       | 1534/5000 [5:42:59<11:30:15, 11.95s/it, loss=0.4563, lr=8.75e-06]Steps:  31%|███       | 1535/5000 [5:43:11<11:29:03, 11.93s/it, loss=0.4563, lr=8.75e-06]Steps:  31%|███       | 1535/5000 [5:43:11<11:29:03, 11.93s/it, loss=0.4773, lr=8.75e-06]Steps:  31%|███       | 1536/5000 [5:43:23<11:34:01, 12.02s/it, loss=0.4773, lr=8.75e-06]Steps:  31%|███       | 1536/5000 [5:43:23<11:34:01, 12.02s/it, loss=0.8197, lr=8.75e-06]Steps:  31%|███       | 1537/5000 [5:43:35<11:30:45, 11.97s/it, loss=0.8197, lr=8.75e-06]Steps:  31%|███       | 1537/5000 [5:43:35<11:30:45, 11.97s/it, loss=0.7289, lr=8.75e-06]Steps:  31%|███       | 1538/5000 [5:43:47<11:29:32, 11.95s/it, loss=0.7289, lr=8.75e-06]Steps:  31%|███       | 1538/5000 [5:43:47<11:29:32, 11.95s/it, loss=1.0591, lr=8.74e-06]Steps:  31%|███       | 1539/5000 [5:43:59<11:29:07, 11.95s/it, loss=1.0591, lr=8.74e-06]Steps:  31%|███       | 1539/5000 [5:43:59<11:29:07, 11.95s/it, loss=1.0566, lr=8.74e-06]Steps:  31%|███       | 1540/5000 [5:44:11<11:27:22, 11.92s/it, loss=1.0566, lr=8.74e-06]Steps:  31%|███       | 1540/5000 [5:44:11<11:27:22, 11.92s/it, loss=0.4933, lr=8.74e-06]
[Step 1540] Training Debug Info:
  Loss: 0.494302
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0134, std: 0.8711
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0142, std: 1.3281
  Model pred mean: 0.0234, std: 1.1094
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 1540] Training Debug Info:
  Loss: 1.043817
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0155, std: 0.9297
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0184, std: 1.3672
  Model pred mean: -0.0152, std: 0.9102
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 1540] Training Debug Info:
  Loss: 1.155511
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0002, std: 0.8789
  Noise mean: 0.0010, std: 0.9961
  Target mean: 0.0008, std: 1.3281
  Model pred mean: 0.0004, std: 0.7812
  Sigmas: [0.126953125]... (timesteps: [127.00000762939453])

[Step 1540] Training Debug Info:
  Loss: 1.064697
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0199, std: 0.9492
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0190, std: 1.3828
  Model pred mean: -0.0186, std: 0.9258
  Sigmas: [0.291015625]... (timesteps: [291.0])
Steps:  31%|███       | 1541/5000 [5:44:23<11:25:57, 11.90s/it, loss=0.4933, lr=8.74e-06]Steps:  31%|███       | 1541/5000 [5:44:23<11:25:57, 11.90s/it, loss=1.0647, lr=8.74e-06]Steps:  31%|███       | 1542/5000 [5:44:35<11:28:03, 11.94s/it, loss=1.0647, lr=8.74e-06]Steps:  31%|███       | 1542/5000 [5:44:35<11:28:03, 11.94s/it, loss=0.9075, lr=8.73e-06]Steps:  31%|███       | 1543/5000 [5:44:47<11:32:21, 12.02s/it, loss=0.9075, lr=8.73e-06]Steps:  31%|███       | 1543/5000 [5:44:47<11:32:21, 12.02s/it, loss=0.8879, lr=8.73e-06]Steps:  31%|███       | 1544/5000 [5:44:59<11:30:15, 11.98s/it, loss=0.8879, lr=8.73e-06]Steps:  31%|███       | 1544/5000 [5:44:59<11:30:15, 11.98s/it, loss=1.0304, lr=8.73e-06]Steps:  31%|███       | 1545/5000 [5:45:11<11:27:49, 11.94s/it, loss=1.0304, lr=8.73e-06]Steps:  31%|███       | 1545/5000 [5:45:11<11:27:49, 11.94s/it, loss=0.7975, lr=8.73e-06]Steps:  31%|███       | 1546/5000 [5:45:23<11:25:21, 11.91s/it, loss=0.7975, lr=8.73e-06]Steps:  31%|███       | 1546/5000 [5:45:23<11:25:21, 11.91s/it, loss=1.1552, lr=8.73e-06]Steps:  31%|███       | 1547/5000 [5:45:34<11:24:16, 11.89s/it, loss=1.1552, lr=8.73e-06]Steps:  31%|███       | 1547/5000 [5:45:34<11:24:16, 11.89s/it, loss=0.4138, lr=8.72e-06]Steps:  31%|███       | 1548/5000 [5:45:46<11:24:16, 11.89s/it, loss=0.4138, lr=8.72e-06]Steps:  31%|███       | 1548/5000 [5:45:46<11:24:16, 11.89s/it, loss=0.4999, lr=8.72e-06]Steps:  31%|███       | 1549/5000 [5:45:59<11:29:36, 11.99s/it, loss=0.4999, lr=8.72e-06]Steps:  31%|███       | 1549/5000 [5:45:59<11:29:36, 11.99s/it, loss=0.3711, lr=8.72e-06]Steps:  31%|███       | 1550/5000 [5:46:10<11:28:29, 11.97s/it, loss=0.3711, lr=8.72e-06]Steps:  31%|███       | 1550/5000 [5:46:10<11:28:29, 11.97s/it, loss=1.1229, lr=8.72e-06]
[Step 1550] Training Debug Info:
  Loss: 0.675955
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0791, std: 0.8984
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0801, std: 1.3438
  Model pred mean: -0.0791, std: 1.0781
  Sigmas: [0.4140625]... (timesteps: [414.0])

[Step 1550] Training Debug Info:
  Loss: 0.839717
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0004, std: 0.9375
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0020, std: 1.3750
  Model pred mean: 0.0007, std: 1.0234
  Sigmas: [0.419921875]... (timesteps: [419.0])

[Step 1550] Training Debug Info:
  Loss: 0.436757
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0140, std: 0.9531
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0113, std: 1.3828
  Model pred mean: -0.0151, std: 1.2109
  Sigmas: [0.875]... (timesteps: [876.0])

[Step 1550] Training Debug Info:
  Loss: 0.754782
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0588, std: 1.0078
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0564, std: 1.4219
  Model pred mean: -0.0596, std: 1.1328
  Sigmas: [0.359375]... (timesteps: [360.0])
Steps:  31%|███       | 1551/5000 [5:46:23<11:29:20, 11.99s/it, loss=1.1229, lr=8.72e-06]Steps:  31%|███       | 1551/5000 [5:46:23<11:29:20, 11.99s/it, loss=0.7548, lr=8.71e-06]Steps:  31%|███       | 1552/5000 [5:46:34<11:28:21, 11.98s/it, loss=0.7548, lr=8.71e-06]Steps:  31%|███       | 1552/5000 [5:46:34<11:28:21, 11.98s/it, loss=0.3836, lr=8.71e-06]Steps:  31%|███       | 1553/5000 [5:46:46<11:28:06, 11.98s/it, loss=0.3836, lr=8.71e-06]Steps:  31%|███       | 1553/5000 [5:46:46<11:28:06, 11.98s/it, loss=0.4420, lr=8.71e-06]Steps:  31%|███       | 1554/5000 [5:46:58<11:26:52, 11.96s/it, loss=0.4420, lr=8.71e-06]Steps:  31%|███       | 1554/5000 [5:46:58<11:26:52, 11.96s/it, loss=1.0755, lr=8.71e-06]Steps:  31%|███       | 1555/5000 [5:47:10<11:26:54, 11.96s/it, loss=1.0755, lr=8.71e-06]Steps:  31%|███       | 1555/5000 [5:47:10<11:26:54, 11.96s/it, loss=0.9864, lr=8.70e-06]Steps:  31%|███       | 1556/5000 [5:47:23<11:32:12, 12.06s/it, loss=0.9864, lr=8.70e-06]Steps:  31%|███       | 1556/5000 [5:47:23<11:32:12, 12.06s/it, loss=0.4318, lr=8.70e-06]Steps:  31%|███       | 1557/5000 [5:47:35<11:30:32, 12.03s/it, loss=0.4318, lr=8.70e-06]Steps:  31%|███       | 1557/5000 [5:47:35<11:30:32, 12.03s/it, loss=0.7180, lr=8.70e-06]Steps:  31%|███       | 1558/5000 [5:47:47<11:29:04, 12.01s/it, loss=0.7180, lr=8.70e-06]Steps:  31%|███       | 1558/5000 [5:47:47<11:29:04, 12.01s/it, loss=0.5070, lr=8.70e-06]Steps:  31%|███       | 1559/5000 [5:47:58<11:27:13, 11.98s/it, loss=0.5070, lr=8.70e-06]Steps:  31%|███       | 1559/5000 [5:47:58<11:27:13, 11.98s/it, loss=0.3906, lr=8.69e-06]Steps:  31%|███       | 1560/5000 [5:48:11<11:28:18, 12.01s/it, loss=0.3906, lr=8.69e-06]Steps:  31%|███       | 1560/5000 [5:48:11<11:28:18, 12.01s/it, loss=1.1290, lr=8.69e-06]
[Step 1560] Training Debug Info:
  Loss: 0.558871
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0084, std: 0.9062
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0110, std: 1.3516
  Model pred mean: -0.0058, std: 1.1250
  Sigmas: [0.625]... (timesteps: [625.0])

[Step 1560] Training Debug Info:
  Loss: 0.440545
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0010, std: 0.9570
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0002, std: 1.3828
  Model pred mean: -0.0003, std: 1.2109
  Sigmas: [0.7421875]... (timesteps: [741.0])

[Step 1560] Training Debug Info:
  Loss: 0.685403
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0227, std: 0.9297
  Noise mean: 0.0010, std: 0.9961
  Target mean: -0.0216, std: 1.3672
  Model pred mean: -0.0270, std: 1.0859
  Sigmas: [0.9921875]... (timesteps: [994.0])

[Step 1560] Training Debug Info:
  Loss: 1.159474
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0299, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0320, std: 1.3359
  Model pred mean: -0.0302, std: 0.7969
  Sigmas: [0.15625]... (timesteps: [156.0])
Steps:  31%|███       | 1561/5000 [5:48:22<11:27:31, 12.00s/it, loss=1.1290, lr=8.69e-06]Steps:  31%|███       | 1561/5000 [5:48:22<11:27:31, 12.00s/it, loss=1.1595, lr=8.69e-06]Steps:  31%|███       | 1562/5000 [5:48:34<11:26:37, 11.98s/it, loss=1.1595, lr=8.69e-06]Steps:  31%|███       | 1562/5000 [5:48:34<11:26:37, 11.98s/it, loss=0.3824, lr=8.69e-06]Steps:  31%|███▏      | 1563/5000 [5:48:47<11:30:53, 12.06s/it, loss=0.3824, lr=8.69e-06]Steps:  31%|███▏      | 1563/5000 [5:48:47<11:30:53, 12.06s/it, loss=0.4314, lr=8.69e-06]Steps:  31%|███▏      | 1564/5000 [5:48:59<11:28:13, 12.02s/it, loss=0.4314, lr=8.69e-06]Steps:  31%|███▏      | 1564/5000 [5:48:59<11:28:13, 12.02s/it, loss=0.4381, lr=8.68e-06]Steps:  31%|███▏      | 1565/5000 [5:49:11<11:27:10, 12.00s/it, loss=0.4381, lr=8.68e-06]Steps:  31%|███▏      | 1565/5000 [5:49:11<11:27:10, 12.00s/it, loss=0.3565, lr=8.68e-06]Steps:  31%|███▏      | 1566/5000 [5:49:22<11:25:19, 11.97s/it, loss=0.3565, lr=8.68e-06]Steps:  31%|███▏      | 1566/5000 [5:49:22<11:25:19, 11.97s/it, loss=0.7624, lr=8.68e-06]Steps:  31%|███▏      | 1567/5000 [5:49:34<11:23:41, 11.95s/it, loss=0.7624, lr=8.68e-06]Steps:  31%|███▏      | 1567/5000 [5:49:34<11:23:41, 11.95s/it, loss=1.0166, lr=8.68e-06]Steps:  31%|███▏      | 1568/5000 [5:49:46<11:23:33, 11.95s/it, loss=1.0166, lr=8.68e-06]Steps:  31%|███▏      | 1568/5000 [5:49:46<11:23:33, 11.95s/it, loss=1.1407, lr=8.67e-06]Steps:  31%|███▏      | 1569/5000 [5:49:58<11:25:12, 11.98s/it, loss=1.1407, lr=8.67e-06]Steps:  31%|███▏      | 1569/5000 [5:49:58<11:25:12, 11.98s/it, loss=0.8240, lr=8.67e-06]Steps:  31%|███▏      | 1570/5000 [5:50:11<11:29:55, 12.07s/it, loss=0.8240, lr=8.67e-06]Steps:  31%|███▏      | 1570/5000 [5:50:11<11:29:55, 12.07s/it, loss=0.6485, lr=8.67e-06]
[Step 1570] Training Debug Info:
  Loss: 1.080094
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.8945
  Noise mean: -0.0005, std: 0.9961
  Target mean: -0.0001, std: 1.3359
  Model pred mean: -0.0012, std: 0.8477
  Sigmas: [0.283203125]... (timesteps: [284.0])

[Step 1570] Training Debug Info:
  Loss: 1.178438
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0007, std: 0.8906
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0004, std: 1.3359
  Model pred mean: -0.0037, std: 0.7812
  Sigmas: [0.208984375]... (timesteps: [209.0])

[Step 1570] Training Debug Info:
  Loss: 0.918036
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0112, std: 0.9023
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0121, std: 1.3438
  Model pred mean: -0.0143, std: 0.9570
  Sigmas: [0.3828125]... (timesteps: [382.0])

[Step 1570] Training Debug Info:
  Loss: 1.139366
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.8789
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0027, std: 1.3359
  Model pred mean: 0.0009, std: 0.8047
  Sigmas: [0.271484375]... (timesteps: [272.0])
Steps:  31%|███▏      | 1571/5000 [5:50:23<11:28:29, 12.05s/it, loss=0.6485, lr=8.67e-06]Steps:  31%|███▏      | 1571/5000 [5:50:23<11:28:29, 12.05s/it, loss=1.1394, lr=8.67e-06]Steps:  31%|███▏      | 1572/5000 [5:50:35<11:27:10, 12.03s/it, loss=1.1394, lr=8.67e-06]Steps:  31%|███▏      | 1572/5000 [5:50:35<11:27:10, 12.03s/it, loss=0.7461, lr=8.66e-06]Steps:  31%|███▏      | 1573/5000 [5:50:47<11:25:05, 11.99s/it, loss=0.7461, lr=8.66e-06]Steps:  31%|███▏      | 1573/5000 [5:50:47<11:25:05, 11.99s/it, loss=0.4846, lr=8.66e-06]Steps:  31%|███▏      | 1574/5000 [5:50:58<11:24:11, 11.98s/it, loss=0.4846, lr=8.66e-06]Steps:  31%|███▏      | 1574/5000 [5:50:58<11:24:11, 11.98s/it, loss=0.8344, lr=8.66e-06]Steps:  32%|███▏      | 1575/5000 [5:51:10<11:21:36, 11.94s/it, loss=0.8344, lr=8.66e-06]Steps:  32%|███▏      | 1575/5000 [5:51:10<11:21:36, 11.94s/it, loss=1.0327, lr=8.66e-06]Steps:  32%|███▏      | 1576/5000 [5:51:23<11:26:22, 12.03s/it, loss=1.0327, lr=8.66e-06]Steps:  32%|███▏      | 1576/5000 [5:51:23<11:26:22, 12.03s/it, loss=0.5850, lr=8.65e-06]Steps:  32%|███▏      | 1577/5000 [5:51:34<11:23:50, 11.99s/it, loss=0.5850, lr=8.65e-06]Steps:  32%|███▏      | 1577/5000 [5:51:34<11:23:50, 11.99s/it, loss=1.0601, lr=8.65e-06]Steps:  32%|███▏      | 1578/5000 [5:51:47<11:25:00, 12.01s/it, loss=1.0601, lr=8.65e-06]Steps:  32%|███▏      | 1578/5000 [5:51:47<11:25:00, 12.01s/it, loss=1.0068, lr=8.65e-06]Steps:  32%|███▏      | 1579/5000 [5:51:58<11:23:21, 11.99s/it, loss=1.0068, lr=8.65e-06]Steps:  32%|███▏      | 1579/5000 [5:51:58<11:23:21, 11.99s/it, loss=0.6093, lr=8.65e-06]Steps:  32%|███▏      | 1580/5000 [5:52:10<11:20:41, 11.94s/it, loss=0.6093, lr=8.65e-06]Steps:  32%|███▏      | 1580/5000 [5:52:10<11:20:41, 11.94s/it, loss=0.4676, lr=8.64e-06]
[Step 1580] Training Debug Info:
  Loss: 0.933085
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0164, std: 0.9258
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0165, std: 1.3594
  Model pred mean: 0.0154, std: 0.9688
  Sigmas: [0.390625]... (timesteps: [391.0])

[Step 1580] Training Debug Info:
  Loss: 0.646868
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0095, std: 0.9453
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0079, std: 1.3750
  Model pred mean: -0.0118, std: 1.1172
  Sigmas: [0.51953125]... (timesteps: [519.0])

[Step 1580] Training Debug Info:
  Loss: 0.371953
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.8477
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0066, std: 1.3125
  Model pred mean: 0.0117, std: 1.1641
  Sigmas: [0.93359375]... (timesteps: [933.0])

[Step 1580] Training Debug Info:
  Loss: 0.526725
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0004, std: 0.9453
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0012, std: 1.3750
  Model pred mean: 0.0045, std: 1.1875
  Sigmas: [0.90234375]... (timesteps: [901.0])
Steps:  32%|███▏      | 1581/5000 [5:52:22<11:19:11, 11.92s/it, loss=0.4676, lr=8.64e-06]Steps:  32%|███▏      | 1581/5000 [5:52:22<11:19:11, 11.92s/it, loss=0.5267, lr=8.64e-06]Steps:  32%|███▏      | 1582/5000 [5:52:34<11:18:33, 11.91s/it, loss=0.5267, lr=8.64e-06]Steps:  32%|███▏      | 1582/5000 [5:52:34<11:18:33, 11.91s/it, loss=0.3839, lr=8.64e-06]Steps:  32%|███▏      | 1583/5000 [5:52:46<11:23:37, 12.00s/it, loss=0.3839, lr=8.64e-06]Steps:  32%|███▏      | 1583/5000 [5:52:46<11:23:37, 12.00s/it, loss=1.0862, lr=8.64e-06]Steps:  32%|███▏      | 1584/5000 [5:52:58<11:21:56, 11.98s/it, loss=1.0862, lr=8.64e-06]Steps:  32%|███▏      | 1584/5000 [5:52:58<11:21:56, 11.98s/it, loss=0.7559, lr=8.64e-06]Steps:  32%|███▏      | 1585/5000 [5:53:10<11:20:37, 11.96s/it, loss=0.7559, lr=8.64e-06]Steps:  32%|███▏      | 1585/5000 [5:53:10<11:20:37, 11.96s/it, loss=0.9219, lr=8.63e-06]Steps:  32%|███▏      | 1586/5000 [5:53:22<11:19:58, 11.95s/it, loss=0.9219, lr=8.63e-06]Steps:  32%|███▏      | 1586/5000 [5:53:22<11:19:58, 11.95s/it, loss=1.0356, lr=8.63e-06]Steps:  32%|███▏      | 1587/5000 [5:53:34<11:21:10, 11.98s/it, loss=1.0356, lr=8.63e-06]Steps:  32%|███▏      | 1587/5000 [5:53:34<11:21:10, 11.98s/it, loss=0.4296, lr=8.63e-06]Steps:  32%|███▏      | 1588/5000 [5:53:46<11:20:27, 11.97s/it, loss=0.4296, lr=8.63e-06]Steps:  32%|███▏      | 1588/5000 [5:53:46<11:20:27, 11.97s/it, loss=0.4328, lr=8.63e-06]Steps:  32%|███▏      | 1589/5000 [5:53:58<11:19:16, 11.95s/it, loss=0.4328, lr=8.63e-06]Steps:  32%|███▏      | 1589/5000 [5:53:58<11:19:16, 11.95s/it, loss=0.8561, lr=8.62e-06]Steps:  32%|███▏      | 1590/5000 [5:54:10<11:24:48, 12.05s/it, loss=0.8561, lr=8.62e-06]Steps:  32%|███▏      | 1590/5000 [5:54:10<11:24:48, 12.05s/it, loss=0.4292, lr=8.62e-06]
[Step 1590] Training Debug Info:
  Loss: 0.639903
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0302, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0294, std: 1.3594
  Model pred mean: 0.0147, std: 1.0781
  Sigmas: [0.96875]... (timesteps: [969.0])

[Step 1590] Training Debug Info:
  Loss: 0.636065
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0293, std: 0.9297
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0320, std: 1.3672
  Model pred mean: -0.0264, std: 1.1094
  Sigmas: [0.9609375]... (timesteps: [962.0])

[Step 1590] Training Debug Info:
  Loss: 0.453960
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0135, std: 0.9336
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0148, std: 1.3672
  Model pred mean: -0.0140, std: 1.1797
  Sigmas: [0.69140625]... (timesteps: [690.0])

[Step 1590] Training Debug Info:
  Loss: 1.068145
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0272, std: 0.9375
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0303, std: 1.3750
  Model pred mean: -0.0234, std: 0.9102
  Sigmas: [0.3125]... (timesteps: [313.0])
Steps:  32%|███▏      | 1591/5000 [5:54:22<11:21:14, 11.99s/it, loss=0.4292, lr=8.62e-06]Steps:  32%|███▏      | 1591/5000 [5:54:22<11:21:14, 11.99s/it, loss=1.0681, lr=8.62e-06]Steps:  32%|███▏      | 1592/5000 [5:54:34<11:19:58, 11.97s/it, loss=1.0681, lr=8.62e-06]Steps:  32%|███▏      | 1592/5000 [5:54:34<11:19:58, 11.97s/it, loss=1.0190, lr=8.62e-06]Steps:  32%|███▏      | 1593/5000 [5:54:46<11:18:08, 11.94s/it, loss=1.0190, lr=8.62e-06]Steps:  32%|███▏      | 1593/5000 [5:54:46<11:18:08, 11.94s/it, loss=0.4698, lr=8.61e-06]Steps:  32%|███▏      | 1594/5000 [5:54:58<11:18:02, 11.94s/it, loss=0.4698, lr=8.61e-06]Steps:  32%|███▏      | 1594/5000 [5:54:58<11:18:02, 11.94s/it, loss=0.5647, lr=8.61e-06]Steps:  32%|███▏      | 1595/5000 [5:55:10<11:17:32, 11.94s/it, loss=0.5647, lr=8.61e-06]Steps:  32%|███▏      | 1595/5000 [5:55:10<11:17:32, 11.94s/it, loss=0.5083, lr=8.61e-06]Steps:  32%|███▏      | 1596/5000 [5:55:22<11:18:17, 11.96s/it, loss=0.5083, lr=8.61e-06]Steps:  32%|███▏      | 1596/5000 [5:55:22<11:18:17, 11.96s/it, loss=0.4895, lr=8.61e-06]Steps:  32%|███▏      | 1597/5000 [5:55:34<11:21:27, 12.02s/it, loss=0.4895, lr=8.61e-06]Steps:  32%|███▏      | 1597/5000 [5:55:34<11:21:27, 12.02s/it, loss=0.9163, lr=8.60e-06]Steps:  32%|███▏      | 1598/5000 [5:55:46<11:18:30, 11.97s/it, loss=0.9163, lr=8.60e-06]Steps:  32%|███▏      | 1598/5000 [5:55:46<11:18:30, 11.97s/it, loss=0.5478, lr=8.60e-06]Steps:  32%|███▏      | 1599/5000 [5:55:58<11:17:49, 11.96s/it, loss=0.5478, lr=8.60e-06]Steps:  32%|███▏      | 1599/5000 [5:55:58<11:17:49, 11.96s/it, loss=0.5003, lr=8.60e-06]Steps:  32%|███▏      | 1600/5000 [5:56:10<11:16:44, 11.94s/it, loss=0.5003, lr=8.60e-06]Steps:  32%|███▏      | 1600/5000 [5:56:10<11:16:44, 11.94s/it, loss=0.4051, lr=8.60e-06]01/22/2026 13:41:56 - INFO - __main__ - 
[Step 1600] ✅ Loss in normal range (0.4051)
01/22/2026 13:41:56 - INFO - __main__ -   Loss avg (last 100): 0.7255
01/22/2026 13:41:56 - INFO - __main__ -   Loss range: [0.3405, 1.2191]
01/22/2026 13:41:56 - INFO - __main__ - 
🔍 Running validation at step 1600...
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1600 (parquet mode)...
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1600...
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 13:41:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.47it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.46it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.46it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.46it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.46it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 13:42:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 13:42:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 13:42:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 13:42:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 13:42:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 13:42:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 13:43:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 13:43:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 13:43:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 13:43:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 13:44:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 13:44:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 13:44:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 13:44:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 13:44:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 13:44:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 13:45:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 13:45:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 13:45:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 13:45:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.41it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 13:45:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 13:45:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 13:46:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600/step001600_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 13:46:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 13:46:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 13:46:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001600
01/22/2026 13:46:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1600] Training Debug Info:
  Loss: 1.184984
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0009, std: 0.8789
  Noise mean: -0.0037, std: 1.0000
  Target mean: -0.0047, std: 1.3281
  Model pred mean: -0.0036, std: 0.7617
  Sigmas: [0.19921875]... (timesteps: [199.0])

[Step 1600] Training Debug Info:
  Loss: 0.497585
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0152, std: 0.9375
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0148, std: 1.3672
  Model pred mean: -0.0101, std: 1.1875
  Sigmas: [0.68359375]... (timesteps: [685.0])

[Step 1600] Training Debug Info:
  Loss: 0.956623
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0057, std: 0.8828
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0084, std: 1.3359
  Model pred mean: 0.0015, std: 0.9141
  Sigmas: [0.37109375]... (timesteps: [372.0])

[Step 1600] Training Debug Info:
  Loss: 0.720255
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0327, std: 0.9336
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0317, std: 1.3672
  Model pred mean: -0.0320, std: 1.0781
  Sigmas: [0.470703125]... (timesteps: [471.0])
Steps:  32%|███▏      | 1601/5000 [6:00:32<82:21:34, 87.23s/it, loss=0.4051, lr=8.60e-06]Steps:  32%|███▏      | 1601/5000 [6:00:32<82:21:34, 87.23s/it, loss=0.7203, lr=8.59e-06]Steps:  32%|███▏      | 1602/5000 [6:00:44<60:59:10, 64.61s/it, loss=0.7203, lr=8.59e-06]Steps:  32%|███▏      | 1602/5000 [6:00:44<60:59:10, 64.61s/it, loss=0.5770, lr=8.59e-06]Steps:  32%|███▏      | 1603/5000 [6:00:56<46:07:29, 48.88s/it, loss=0.5770, lr=8.59e-06]Steps:  32%|███▏      | 1603/5000 [6:00:56<46:07:29, 48.88s/it, loss=0.3874, lr=8.59e-06]Steps:  32%|███▏      | 1604/5000 [6:01:08<35:40:09, 37.81s/it, loss=0.3874, lr=8.59e-06]Steps:  32%|███▏      | 1604/5000 [6:01:08<35:40:09, 37.81s/it, loss=0.5893, lr=8.59e-06]Steps:  32%|███▏      | 1605/5000 [6:01:20<28:21:00, 30.06s/it, loss=0.5893, lr=8.59e-06]Steps:  32%|███▏      | 1605/5000 [6:01:20<28:21:00, 30.06s/it, loss=0.7526, lr=8.58e-06]Steps:  32%|███▏      | 1606/5000 [6:01:32<23:13:59, 24.64s/it, loss=0.7526, lr=8.58e-06]Steps:  32%|███▏      | 1606/5000 [6:01:32<23:13:59, 24.64s/it, loss=1.1797, lr=8.58e-06]Steps:  32%|███▏      | 1607/5000 [6:01:44<19:38:50, 20.85s/it, loss=1.1797, lr=8.58e-06]Steps:  32%|███▏      | 1607/5000 [6:01:44<19:38:50, 20.85s/it, loss=0.4762, lr=8.58e-06]Steps:  32%|███▏      | 1608/5000 [6:01:56<17:06:48, 18.16s/it, loss=0.4762, lr=8.58e-06]Steps:  32%|███▏      | 1608/5000 [6:01:56<17:06:48, 18.16s/it, loss=0.8796, lr=8.58e-06]Steps:  32%|███▏      | 1609/5000 [6:02:08<15:21:21, 16.30s/it, loss=0.8796, lr=8.58e-06]Steps:  32%|███▏      | 1609/5000 [6:02:08<15:21:21, 16.30s/it, loss=0.4610, lr=8.57e-06]Steps:  32%|███▏      | 1610/5000 [6:02:21<14:11:58, 15.08s/it, loss=0.4610, lr=8.57e-06]Steps:  32%|███▏      | 1610/5000 [6:02:21<14:11:58, 15.08s/it, loss=1.0389, lr=8.57e-06]
[Step 1610] Training Debug Info:
  Loss: 0.480856
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0239, std: 0.9492
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0255, std: 1.3750
  Model pred mean: -0.0220, std: 1.1953
  Sigmas: [0.69140625]... (timesteps: [692.0])

[Step 1610] Training Debug Info:
  Loss: 0.958710
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0085, std: 0.9141
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0060, std: 1.3516
  Model pred mean: -0.0095, std: 0.9492
  Sigmas: [0.41015625]... (timesteps: [410.0])

[Step 1610] Training Debug Info:
  Loss: 0.563916
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0067, std: 0.8984
  Noise mean: -0.0036, std: 1.0000
  Target mean: -0.0103, std: 1.3438
  Model pred mean: -0.0067, std: 1.1250
  Sigmas: [0.609375]... (timesteps: [611.0])

[Step 1610] Training Debug Info:
  Loss: 0.512638
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0272, std: 0.9180
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0256, std: 1.3516
  Model pred mean: 0.0287, std: 1.1562
  Sigmas: [0.62109375]... (timesteps: [622.0])
Steps:  32%|███▏      | 1611/5000 [6:02:32<13:18:37, 14.14s/it, loss=1.0389, lr=8.57e-06]Steps:  32%|███▏      | 1611/5000 [6:02:32<13:18:37, 14.14s/it, loss=0.5126, lr=8.57e-06]Steps:  32%|███▏      | 1612/5000 [6:02:44<12:40:44, 13.47s/it, loss=0.5126, lr=8.57e-06]Steps:  32%|███▏      | 1612/5000 [6:02:44<12:40:44, 13.47s/it, loss=0.7132, lr=8.57e-06]Steps:  32%|███▏      | 1613/5000 [6:02:56<12:14:38, 13.01s/it, loss=0.7132, lr=8.57e-06]Steps:  32%|███▏      | 1613/5000 [6:02:56<12:14:38, 13.01s/it, loss=0.4496, lr=8.57e-06]Steps:  32%|███▏      | 1614/5000 [6:03:08<11:56:03, 12.69s/it, loss=0.4496, lr=8.57e-06]Steps:  32%|███▏      | 1614/5000 [6:03:08<11:56:03, 12.69s/it, loss=0.6967, lr=8.56e-06]Steps:  32%|███▏      | 1615/5000 [6:03:20<11:42:30, 12.45s/it, loss=0.6967, lr=8.56e-06]Steps:  32%|███▏      | 1615/5000 [6:03:20<11:42:30, 12.45s/it, loss=0.4555, lr=8.56e-06]Steps:  32%|███▏      | 1616/5000 [6:03:32<11:32:51, 12.28s/it, loss=0.4555, lr=8.56e-06]Steps:  32%|███▏      | 1616/5000 [6:03:32<11:32:51, 12.28s/it, loss=1.0469, lr=8.56e-06]Steps:  32%|███▏      | 1617/5000 [6:03:44<11:31:53, 12.27s/it, loss=1.0469, lr=8.56e-06]Steps:  32%|███▏      | 1617/5000 [6:03:44<11:31:53, 12.27s/it, loss=0.7317, lr=8.56e-06]Steps:  32%|███▏      | 1618/5000 [6:03:56<11:25:56, 12.17s/it, loss=0.7317, lr=8.56e-06]Steps:  32%|███▏      | 1618/5000 [6:03:56<11:25:56, 12.17s/it, loss=1.1703, lr=8.55e-06]Steps:  32%|███▏      | 1619/5000 [6:04:08<11:21:22, 12.09s/it, loss=1.1703, lr=8.55e-06]Steps:  32%|███▏      | 1619/5000 [6:04:08<11:21:22, 12.09s/it, loss=0.6536, lr=8.55e-06]Steps:  32%|███▏      | 1620/5000 [6:04:20<11:18:47, 12.05s/it, loss=0.6536, lr=8.55e-06]Steps:  32%|███▏      | 1620/5000 [6:04:20<11:18:47, 12.05s/it, loss=1.0289, lr=8.55e-06]
[Step 1620] Training Debug Info:
  Loss: 1.167916
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0261, std: 0.9180
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0273, std: 1.3594
  Model pred mean: 0.0231, std: 0.8164
  Sigmas: [0.19140625]... (timesteps: [191.0])

[Step 1620] Training Debug Info:
  Loss: 0.373392
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0192, std: 0.8828
  Noise mean: -0.0007, std: 0.9961
  Target mean: 0.0184, std: 1.3281
  Model pred mean: 0.0155, std: 1.1875
  Sigmas: [0.90625]... (timesteps: [905.0])

[Step 1620] Training Debug Info:
  Loss: 0.630505
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0017, std: 0.9492
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0019, std: 1.3828
  Model pred mean: 0.0005, std: 1.1250
  Sigmas: [0.52734375]... (timesteps: [529.0])

[Step 1620] Training Debug Info:
  Loss: 1.105561
  Latent shape: torch.Size([1, 32, 96, 90]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0286, std: 0.9180
  Noise mean: -0.0037, std: 1.0000
  Target mean: -0.0322, std: 1.3594
  Model pred mean: -0.0294, std: 0.8594
  Sigmas: [0.181640625]... (timesteps: [182.0])
Steps:  32%|███▏      | 1621/5000 [6:04:32<11:16:22, 12.01s/it, loss=1.0289, lr=8.55e-06]Steps:  32%|███▏      | 1621/5000 [6:04:32<11:16:22, 12.01s/it, loss=1.1056, lr=8.55e-06]Steps:  32%|███▏      | 1622/5000 [6:04:44<11:14:48, 11.99s/it, loss=1.1056, lr=8.55e-06]Steps:  32%|███▏      | 1622/5000 [6:04:44<11:14:48, 11.99s/it, loss=1.1060, lr=8.54e-06]Steps:  32%|███▏      | 1623/5000 [6:04:56<11:13:21, 11.96s/it, loss=1.1060, lr=8.54e-06]Steps:  32%|███▏      | 1623/5000 [6:04:56<11:13:21, 11.96s/it, loss=1.1600, lr=8.54e-06]Steps:  32%|███▏      | 1624/5000 [6:05:08<11:19:12, 12.07s/it, loss=1.1600, lr=8.54e-06]Steps:  32%|███▏      | 1624/5000 [6:05:08<11:19:12, 12.07s/it, loss=0.4496, lr=8.54e-06]Steps:  32%|███▎      | 1625/5000 [6:05:20<11:16:10, 12.02s/it, loss=0.4496, lr=8.54e-06]Steps:  32%|███▎      | 1625/5000 [6:05:20<11:16:10, 12.02s/it, loss=1.0783, lr=8.54e-06]Steps:  33%|███▎      | 1626/5000 [6:05:32<11:14:40, 12.00s/it, loss=1.0783, lr=8.54e-06]Steps:  33%|███▎      | 1626/5000 [6:05:32<11:14:40, 12.00s/it, loss=1.1026, lr=8.53e-06]Steps:  33%|███▎      | 1627/5000 [6:05:44<11:14:46, 12.00s/it, loss=1.1026, lr=8.53e-06]Steps:  33%|███▎      | 1627/5000 [6:05:44<11:14:46, 12.00s/it, loss=0.5394, lr=8.53e-06]Steps:  33%|███▎      | 1628/5000 [6:05:56<11:13:47, 11.99s/it, loss=0.5394, lr=8.53e-06]Steps:  33%|███▎      | 1628/5000 [6:05:56<11:13:47, 11.99s/it, loss=0.3552, lr=8.53e-06]Steps:  33%|███▎      | 1629/5000 [6:06:08<11:13:17, 11.98s/it, loss=0.3552, lr=8.53e-06]Steps:  33%|███▎      | 1629/5000 [6:06:08<11:13:17, 11.98s/it, loss=1.1562, lr=8.53e-06]Steps:  33%|███▎      | 1630/5000 [6:06:20<11:15:56, 12.03s/it, loss=1.1562, lr=8.53e-06]Steps:  33%|███▎      | 1630/5000 [6:06:20<11:15:56, 12.03s/it, loss=1.1295, lr=8.52e-06]
[Step 1630] Training Debug Info:
  Loss: 1.004875
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.8789
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0039, std: 1.3281
  Model pred mean: -0.0079, std: 0.8711
  Sigmas: [0.0019989013671875]... (timesteps: [2.0])

[Step 1630] Training Debug Info:
  Loss: 0.790990
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9297
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0217, std: 1.3672
  Model pred mean: -0.0208, std: 1.0391
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 1630] Training Debug Info:
  Loss: 0.449847
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 0.9219
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0339, std: 1.3594
  Model pred mean: -0.0330, std: 1.1719
  Sigmas: [0.66796875]... (timesteps: [667.0])

[Step 1630] Training Debug Info:
  Loss: 1.038655
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0442, std: 0.9258
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0422, std: 1.3594
  Model pred mean: -0.0435, std: 0.9062
  Sigmas: [0.21875]... (timesteps: [219.0])
Steps:  33%|███▎      | 1631/5000 [6:06:32<11:12:45, 11.98s/it, loss=1.1295, lr=8.52e-06]Steps:  33%|███▎      | 1631/5000 [6:06:32<11:12:45, 11.98s/it, loss=1.0387, lr=8.52e-06]Steps:  33%|███▎      | 1632/5000 [6:06:44<11:12:22, 11.98s/it, loss=1.0387, lr=8.52e-06]Steps:  33%|███▎      | 1632/5000 [6:06:44<11:12:22, 11.98s/it, loss=0.6989, lr=8.52e-06]Steps:  33%|███▎      | 1633/5000 [6:06:56<11:13:25, 12.00s/it, loss=0.6989, lr=8.52e-06]Steps:  33%|███▎      | 1633/5000 [6:06:56<11:13:25, 12.00s/it, loss=0.6784, lr=8.52e-06]Steps:  33%|███▎      | 1634/5000 [6:07:08<11:11:55, 11.98s/it, loss=0.6784, lr=8.52e-06]Steps:  33%|███▎      | 1634/5000 [6:07:08<11:11:55, 11.98s/it, loss=1.1085, lr=8.51e-06]Steps:  33%|███▎      | 1635/5000 [6:07:20<11:09:39, 11.94s/it, loss=1.1085, lr=8.51e-06]Steps:  33%|███▎      | 1635/5000 [6:07:20<11:09:39, 11.94s/it, loss=1.0486, lr=8.51e-06]Steps:  33%|███▎      | 1636/5000 [6:07:32<11:09:34, 11.94s/it, loss=1.0486, lr=8.51e-06]Steps:  33%|███▎      | 1636/5000 [6:07:32<11:09:34, 11.94s/it, loss=0.7235, lr=8.51e-06]Steps:  33%|███▎      | 1637/5000 [6:07:44<11:13:37, 12.02s/it, loss=0.7235, lr=8.51e-06]Steps:  33%|███▎      | 1637/5000 [6:07:44<11:13:37, 12.02s/it, loss=0.5297, lr=8.51e-06]Steps:  33%|███▎      | 1638/5000 [6:07:56<11:12:41, 12.01s/it, loss=0.5297, lr=8.51e-06]Steps:  33%|███▎      | 1638/5000 [6:07:56<11:12:41, 12.01s/it, loss=0.5005, lr=8.50e-06]Steps:  33%|███▎      | 1639/5000 [6:08:08<11:11:12, 11.98s/it, loss=0.5005, lr=8.50e-06]Steps:  33%|███▎      | 1639/5000 [6:08:08<11:11:12, 11.98s/it, loss=0.3790, lr=8.50e-06]Steps:  33%|███▎      | 1640/5000 [6:08:20<11:08:30, 11.94s/it, loss=0.3790, lr=8.50e-06]Steps:  33%|███▎      | 1640/5000 [6:08:20<11:08:30, 11.94s/it, loss=1.0791, lr=8.50e-06]
[Step 1640] Training Debug Info:
  Loss: 1.066644
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0079, std: 0.9102
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0096, std: 1.3516
  Model pred mean: 0.0075, std: 0.8945
  Sigmas: [0.0390625]... (timesteps: [39.0])

[Step 1640] Training Debug Info:
  Loss: 0.520997
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0103, std: 0.9219
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0120, std: 1.3594
  Model pred mean: -0.0031, std: 1.1484
  Sigmas: [0.92578125]... (timesteps: [927.0])

[Step 1640] Training Debug Info:
  Loss: 1.136132
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0175, std: 0.8945
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0184, std: 1.3438
  Model pred mean: -0.0159, std: 0.8242
  Sigmas: [0.126953125]... (timesteps: [127.00000762939453])

[Step 1640] Training Debug Info:
  Loss: 0.842527
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0050, std: 0.9023
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0048, std: 1.3438
  Model pred mean: 0.0036, std: 0.9883
  Sigmas: [0.431640625]... (timesteps: [431.0])
Steps:  33%|███▎      | 1641/5000 [6:08:32<11:07:41, 11.93s/it, loss=1.0791, lr=8.50e-06]Steps:  33%|███▎      | 1641/5000 [6:08:32<11:07:41, 11.93s/it, loss=0.8425, lr=8.50e-06]Steps:  33%|███▎      | 1642/5000 [6:08:44<11:08:33, 11.95s/it, loss=0.8425, lr=8.50e-06]Steps:  33%|███▎      | 1642/5000 [6:08:44<11:08:33, 11.95s/it, loss=0.6289, lr=8.49e-06]Steps:  33%|███▎      | 1643/5000 [6:08:56<11:08:42, 11.95s/it, loss=0.6289, lr=8.49e-06]Steps:  33%|███▎      | 1643/5000 [6:08:56<11:08:42, 11.95s/it, loss=1.1530, lr=8.49e-06]Steps:  33%|███▎      | 1644/5000 [6:09:08<11:12:37, 12.03s/it, loss=1.1530, lr=8.49e-06]Steps:  33%|███▎      | 1644/5000 [6:09:08<11:12:37, 12.03s/it, loss=1.1226, lr=8.49e-06]Steps:  33%|███▎      | 1645/5000 [6:09:20<11:09:40, 11.98s/it, loss=1.1226, lr=8.49e-06]Steps:  33%|███▎      | 1645/5000 [6:09:20<11:09:40, 11.98s/it, loss=1.1100, lr=8.49e-06]Steps:  33%|███▎      | 1646/5000 [6:09:32<11:08:58, 11.97s/it, loss=1.1100, lr=8.49e-06]Steps:  33%|███▎      | 1646/5000 [6:09:32<11:08:58, 11.97s/it, loss=0.7808, lr=8.48e-06]Steps:  33%|███▎      | 1647/5000 [6:09:43<11:07:35, 11.95s/it, loss=0.7808, lr=8.48e-06]Steps:  33%|███▎      | 1647/5000 [6:09:43<11:07:35, 11.95s/it, loss=0.4943, lr=8.48e-06]Steps:  33%|███▎      | 1648/5000 [6:09:55<11:05:19, 11.91s/it, loss=0.4943, lr=8.48e-06]Steps:  33%|███▎      | 1648/5000 [6:09:55<11:05:19, 11.91s/it, loss=0.4598, lr=8.48e-06]Steps:  33%|███▎      | 1649/5000 [6:10:07<11:05:00, 11.91s/it, loss=0.4598, lr=8.48e-06]Steps:  33%|███▎      | 1649/5000 [6:10:07<11:05:00, 11.91s/it, loss=0.5179, lr=8.48e-06]Steps:  33%|███▎      | 1650/5000 [6:10:19<11:04:49, 11.91s/it, loss=0.5179, lr=8.48e-06]Steps:  33%|███▎      | 1650/5000 [6:10:19<11:04:49, 11.91s/it, loss=0.3874, lr=8.47e-06]
[Step 1650] Training Debug Info:
  Loss: 0.433045
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0043, std: 0.8867
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0065, std: 1.3359
  Model pred mean: -0.0009, std: 1.1641
  Sigmas: [0.72265625]... (timesteps: [722.0])

[Step 1650] Training Debug Info:
  Loss: 0.411549
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0393, std: 0.9297
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0391, std: 1.3672
  Model pred mean: -0.0405, std: 1.2031
  Sigmas: [0.7109375]... (timesteps: [709.0])

[Step 1650] Training Debug Info:
  Loss: 0.448632
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0028, std: 0.9258
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0028, std: 1.3594
  Model pred mean: -0.0067, std: 1.1953
  Sigmas: [0.8828125]... (timesteps: [881.0])

[Step 1650] Training Debug Info:
  Loss: 1.067731
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0059, std: 0.8633
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0059, std: 1.3203
  Model pred mean: 0.0106, std: 0.8242
  Sigmas: [0.033935546875]... (timesteps: [34.0])
Steps:  33%|███▎      | 1651/5000 [6:10:31<11:11:13, 12.03s/it, loss=0.3874, lr=8.47e-06]Steps:  33%|███▎      | 1651/5000 [6:10:31<11:11:13, 12.03s/it, loss=1.0677, lr=8.47e-06]Steps:  33%|███▎      | 1652/5000 [6:10:43<11:08:44, 11.98s/it, loss=1.0677, lr=8.47e-06]Steps:  33%|███▎      | 1652/5000 [6:10:43<11:08:44, 11.98s/it, loss=1.1232, lr=8.47e-06]Steps:  33%|███▎      | 1653/5000 [6:10:55<11:06:51, 11.95s/it, loss=1.1232, lr=8.47e-06]Steps:  33%|███▎      | 1653/5000 [6:10:55<11:06:51, 11.95s/it, loss=1.1745, lr=8.47e-06]Steps:  33%|███▎      | 1654/5000 [6:11:07<11:05:47, 11.94s/it, loss=1.1745, lr=8.47e-06]Steps:  33%|███▎      | 1654/5000 [6:11:07<11:05:47, 11.94s/it, loss=1.0585, lr=8.46e-06]Steps:  33%|███▎      | 1655/5000 [6:11:19<11:06:15, 11.95s/it, loss=1.0585, lr=8.46e-06]Steps:  33%|███▎      | 1655/5000 [6:11:19<11:06:15, 11.95s/it, loss=0.9555, lr=8.46e-06]Steps:  33%|███▎      | 1656/5000 [6:11:31<11:04:41, 11.93s/it, loss=0.9555, lr=8.46e-06]Steps:  33%|███▎      | 1656/5000 [6:11:31<11:04:41, 11.93s/it, loss=1.1454, lr=8.46e-06]Steps:  33%|███▎      | 1657/5000 [6:11:43<11:09:50, 12.02s/it, loss=1.1454, lr=8.46e-06]Steps:  33%|███▎      | 1657/5000 [6:11:43<11:09:50, 12.02s/it, loss=1.1754, lr=8.46e-06]Steps:  33%|███▎      | 1658/5000 [6:11:55<11:06:59, 11.97s/it, loss=1.1754, lr=8.46e-06]Steps:  33%|███▎      | 1658/5000 [6:11:55<11:06:59, 11.97s/it, loss=0.6580, lr=8.45e-06]Steps:  33%|███▎      | 1659/5000 [6:12:07<11:04:35, 11.94s/it, loss=0.6580, lr=8.45e-06]Steps:  33%|███▎      | 1659/5000 [6:12:07<11:04:35, 11.94s/it, loss=0.5076, lr=8.45e-06]Steps:  33%|███▎      | 1660/5000 [6:12:19<11:05:59, 11.96s/it, loss=0.5076, lr=8.45e-06]Steps:  33%|███▎      | 1660/5000 [6:12:19<11:05:59, 11.96s/it, loss=0.6445, lr=8.45e-06]
[Step 1660] Training Debug Info:
  Loss: 0.690299
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0183, std: 0.9180
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0201, std: 1.3516
  Model pred mean: -0.0089, std: 1.0781
  Sigmas: [0.984375]... (timesteps: [986.0])

[Step 1660] Training Debug Info:
  Loss: 1.133366
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0197, std: 0.9258
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0176, std: 1.3594
  Model pred mean: -0.0204, std: 0.8477
  Sigmas: [0.26171875]... (timesteps: [261.0])

[Step 1660] Training Debug Info:
  Loss: 0.456105
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0215, std: 0.8867
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0234, std: 1.3359
  Model pred mean: -0.0220, std: 1.1562
  Sigmas: [0.7734375]... (timesteps: [773.0])

[Step 1660] Training Debug Info:
  Loss: 0.370883
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0059, std: 0.9141
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0062, std: 1.3594
  Model pred mean: 0.0026, std: 1.2031
  Sigmas: [0.92578125]... (timesteps: [926.0])
Steps:  33%|███▎      | 1661/5000 [6:12:31<11:05:06, 11.95s/it, loss=0.6445, lr=8.45e-06]Steps:  33%|███▎      | 1661/5000 [6:12:31<11:05:06, 11.95s/it, loss=0.3709, lr=8.45e-06]Steps:  33%|███▎      | 1662/5000 [6:12:43<11:03:05, 11.92s/it, loss=0.3709, lr=8.45e-06]Steps:  33%|███▎      | 1662/5000 [6:12:43<11:03:05, 11.92s/it, loss=0.5989, lr=8.44e-06]Steps:  33%|███▎      | 1663/5000 [6:12:55<11:02:59, 11.92s/it, loss=0.5989, lr=8.44e-06]Steps:  33%|███▎      | 1663/5000 [6:12:55<11:02:59, 11.92s/it, loss=0.6654, lr=8.44e-06]Steps:  33%|███▎      | 1664/5000 [6:13:07<11:07:08, 12.00s/it, loss=0.6654, lr=8.44e-06]Steps:  33%|███▎      | 1664/5000 [6:13:07<11:07:08, 12.00s/it, loss=1.0409, lr=8.44e-06]Steps:  33%|███▎      | 1665/5000 [6:13:19<11:05:15, 11.97s/it, loss=1.0409, lr=8.44e-06]Steps:  33%|███▎      | 1665/5000 [6:13:19<11:05:15, 11.97s/it, loss=0.7882, lr=8.44e-06]Steps:  33%|███▎      | 1666/5000 [6:13:31<11:04:55, 11.97s/it, loss=0.7882, lr=8.44e-06]Steps:  33%|███▎      | 1666/5000 [6:13:31<11:04:55, 11.97s/it, loss=0.6849, lr=8.43e-06]Steps:  33%|███▎      | 1667/5000 [6:13:43<11:04:10, 11.96s/it, loss=0.6849, lr=8.43e-06]Steps:  33%|███▎      | 1667/5000 [6:13:43<11:04:10, 11.96s/it, loss=0.6960, lr=8.43e-06]Steps:  33%|███▎      | 1668/5000 [6:13:54<11:03:25, 11.95s/it, loss=0.6960, lr=8.43e-06]Steps:  33%|███▎      | 1668/5000 [6:13:54<11:03:25, 11.95s/it, loss=0.3417, lr=8.43e-06]Steps:  33%|███▎      | 1669/5000 [6:14:06<11:04:13, 11.96s/it, loss=0.3417, lr=8.43e-06]Steps:  33%|███▎      | 1669/5000 [6:14:06<11:04:13, 11.96s/it, loss=1.1097, lr=8.43e-06]Steps:  33%|███▎      | 1670/5000 [6:14:18<11:01:55, 11.93s/it, loss=1.1097, lr=8.43e-06]Steps:  33%|███▎      | 1670/5000 [6:14:18<11:01:55, 11.93s/it, loss=0.4393, lr=8.42e-06]
[Step 1670] Training Debug Info:
  Loss: 0.413154
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0175, std: 0.8398
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0173, std: 1.3047
  Model pred mean: 0.0188, std: 1.1406
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 1670] Training Debug Info:
  Loss: 1.049437
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0283, std: 0.8867
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0278, std: 1.3359
  Model pred mean: -0.0273, std: 0.8594
  Sigmas: [0.33984375]... (timesteps: [339.0])

[Step 1670] Training Debug Info:
  Loss: 1.154611
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0011, std: 0.8828
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0034, std: 1.3359
  Model pred mean: -0.0045, std: 0.7812
  Sigmas: [0.10791015625]... (timesteps: [108.0])

[Step 1670] Training Debug Info:
  Loss: 0.383225
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0177, std: 0.9062
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0183, std: 1.3516
  Model pred mean: 0.0199, std: 1.1953
  Sigmas: [0.8828125]... (timesteps: [884.0])
Steps:  33%|███▎      | 1671/5000 [6:14:30<11:05:39, 12.00s/it, loss=0.4393, lr=8.42e-06]Steps:  33%|███▎      | 1671/5000 [6:14:30<11:05:39, 12.00s/it, loss=0.3832, lr=8.42e-06]Steps:  33%|███▎      | 1672/5000 [6:14:42<11:03:14, 11.96s/it, loss=0.3832, lr=8.42e-06]Steps:  33%|███▎      | 1672/5000 [6:14:42<11:03:14, 11.96s/it, loss=0.4304, lr=8.42e-06]Steps:  33%|███▎      | 1673/5000 [6:14:54<11:02:12, 11.94s/it, loss=0.4304, lr=8.42e-06]Steps:  33%|███▎      | 1673/5000 [6:14:54<11:02:12, 11.94s/it, loss=1.1153, lr=8.42e-06]Steps:  33%|███▎      | 1674/5000 [6:15:06<11:00:45, 11.92s/it, loss=1.1153, lr=8.42e-06]Steps:  33%|███▎      | 1674/5000 [6:15:06<11:00:45, 11.92s/it, loss=0.5868, lr=8.41e-06]Steps:  34%|███▎      | 1675/5000 [6:15:18<11:00:38, 11.92s/it, loss=0.5868, lr=8.41e-06]Steps:  34%|███▎      | 1675/5000 [6:15:18<11:00:38, 11.92s/it, loss=0.6507, lr=8.41e-06]Steps:  34%|███▎      | 1676/5000 [6:15:30<11:01:45, 11.95s/it, loss=0.6507, lr=8.41e-06]Steps:  34%|███▎      | 1676/5000 [6:15:30<11:01:45, 11.95s/it, loss=0.6757, lr=8.41e-06]Steps:  34%|███▎      | 1677/5000 [6:15:42<11:01:24, 11.94s/it, loss=0.6757, lr=8.41e-06]Steps:  34%|███▎      | 1677/5000 [6:15:42<11:01:24, 11.94s/it, loss=1.1837, lr=8.40e-06]Steps:  34%|███▎      | 1678/5000 [6:15:54<11:07:37, 12.06s/it, loss=1.1837, lr=8.40e-06]Steps:  34%|███▎      | 1678/5000 [6:15:54<11:07:37, 12.06s/it, loss=0.4056, lr=8.40e-06]Steps:  34%|███▎      | 1679/5000 [6:16:06<11:04:12, 12.00s/it, loss=0.4056, lr=8.40e-06]Steps:  34%|███▎      | 1679/5000 [6:16:06<11:04:12, 12.00s/it, loss=0.5623, lr=8.40e-06]Steps:  34%|███▎      | 1680/5000 [6:16:18<11:02:58, 11.98s/it, loss=0.5623, lr=8.40e-06]Steps:  34%|███▎      | 1680/5000 [6:16:18<11:02:58, 11.98s/it, loss=0.5802, lr=8.40e-06]
[Step 1680] Training Debug Info:
  Loss: 0.729105
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0588, std: 0.9453
  Noise mean: 0.0020, std: 0.9961
  Target mean: -0.0569, std: 1.3750
  Model pred mean: -0.0522, std: 1.0781
  Sigmas: [0.3828125]... (timesteps: [382.0])

[Step 1680] Training Debug Info:
  Loss: 0.947173
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0074, std: 0.9258
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0047, std: 1.3672
  Model pred mean: 0.0126, std: 0.9570
  Sigmas: [0.369140625]... (timesteps: [369.0])

[Step 1680] Training Debug Info:
  Loss: 0.437798
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0097, std: 0.8828
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0086, std: 1.3359
  Model pred mean: -0.0060, std: 1.1641
  Sigmas: [0.7578125]... (timesteps: [757.0])

[Step 1680] Training Debug Info:
  Loss: 0.694088
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0116, std: 0.9102
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0105, std: 1.3594
  Model pred mean: 0.0182, std: 1.0703
  Sigmas: [0.48828125]... (timesteps: [488.0])
Steps:  34%|███▎      | 1681/5000 [6:16:30<11:01:42, 11.96s/it, loss=0.5802, lr=8.40e-06]Steps:  34%|███▎      | 1681/5000 [6:16:30<11:01:42, 11.96s/it, loss=0.6941, lr=8.39e-06]Steps:  34%|███▎      | 1682/5000 [6:16:42<10:59:49, 11.93s/it, loss=0.6941, lr=8.39e-06]Steps:  34%|███▎      | 1682/5000 [6:16:42<10:59:49, 11.93s/it, loss=0.7700, lr=8.39e-06]Steps:  34%|███▎      | 1683/5000 [6:16:54<10:58:55, 11.92s/it, loss=0.7700, lr=8.39e-06]Steps:  34%|███▎      | 1683/5000 [6:16:54<10:58:55, 11.92s/it, loss=0.5278, lr=8.39e-06]Steps:  34%|███▎      | 1684/5000 [6:17:06<11:03:19, 12.00s/it, loss=0.5278, lr=8.39e-06]Steps:  34%|███▎      | 1684/5000 [6:17:06<11:03:19, 12.00s/it, loss=0.8366, lr=8.39e-06]Steps:  34%|███▎      | 1685/5000 [6:17:18<11:02:43, 11.99s/it, loss=0.8366, lr=8.39e-06]Steps:  34%|███▎      | 1685/5000 [6:17:18<11:02:43, 11.99s/it, loss=0.8403, lr=8.38e-06]Steps:  34%|███▎      | 1686/5000 [6:17:30<11:00:41, 11.96s/it, loss=0.8403, lr=8.38e-06]Steps:  34%|███▎      | 1686/5000 [6:17:30<11:00:41, 11.96s/it, loss=0.3301, lr=8.38e-06]Steps:  34%|███▎      | 1687/5000 [6:17:42<11:03:07, 12.01s/it, loss=0.3301, lr=8.38e-06]Steps:  34%|███▎      | 1687/5000 [6:17:42<11:03:07, 12.01s/it, loss=0.4989, lr=8.38e-06]Steps:  34%|███▍      | 1688/5000 [6:17:54<11:02:04, 11.99s/it, loss=0.4989, lr=8.38e-06]Steps:  34%|███▍      | 1688/5000 [6:17:54<11:02:04, 11.99s/it, loss=1.0837, lr=8.38e-06]Steps:  34%|███▍      | 1689/5000 [6:18:06<11:00:14, 11.96s/it, loss=1.0837, lr=8.38e-06]Steps:  34%|███▍      | 1689/5000 [6:18:06<11:00:14, 11.96s/it, loss=0.6794, lr=8.37e-06]Steps:  34%|███▍      | 1690/5000 [6:18:18<10:58:47, 11.94s/it, loss=0.6794, lr=8.37e-06]Steps:  34%|███▍      | 1690/5000 [6:18:18<10:58:47, 11.94s/it, loss=0.7137, lr=8.37e-06]
[Step 1690] Training Debug Info:
  Loss: 1.015466
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0201, std: 0.9336
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0198, std: 1.3672
  Model pred mean: -0.0210, std: 0.9258
  Sigmas: [0.3203125]... (timesteps: [320.0])

[Step 1690] Training Debug Info:
  Loss: 0.956051
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0139, std: 0.8672
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0137, std: 1.3203
  Model pred mean: -0.0168, std: 0.8945
  Sigmas: [0.388671875]... (timesteps: [389.0])

[Step 1690] Training Debug Info:
  Loss: 1.055139
  Latent shape: torch.Size([1, 32, 174, 48]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0192, std: 0.8555
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0171, std: 1.3203
  Model pred mean: 0.0177, std: 0.8320
  Sigmas: [0.0260009765625]... (timesteps: [26.0])

[Step 1690] Training Debug Info:
  Loss: 1.090508
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9297
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0020, std: 1.3672
  Model pred mean: 0.0009, std: 0.8828
  Sigmas: [0.21875]... (timesteps: [219.0])
Steps:  34%|███▍      | 1691/5000 [6:18:30<11:03:32, 12.03s/it, loss=0.7137, lr=8.37e-06]Steps:  34%|███▍      | 1691/5000 [6:18:30<11:03:32, 12.03s/it, loss=1.0905, lr=8.37e-06]Steps:  34%|███▍      | 1692/5000 [6:18:42<11:01:15, 11.99s/it, loss=1.0905, lr=8.37e-06]Steps:  34%|███▍      | 1692/5000 [6:18:42<11:01:15, 11.99s/it, loss=0.5503, lr=8.37e-06]Steps:  34%|███▍      | 1693/5000 [6:18:54<10:59:28, 11.96s/it, loss=0.5503, lr=8.37e-06]Steps:  34%|███▍      | 1693/5000 [6:18:54<10:59:28, 11.96s/it, loss=0.6070, lr=8.36e-06]Steps:  34%|███▍      | 1694/5000 [6:19:06<10:59:28, 11.97s/it, loss=0.6070, lr=8.36e-06]Steps:  34%|███▍      | 1694/5000 [6:19:06<10:59:28, 11.97s/it, loss=0.9657, lr=8.36e-06]Steps:  34%|███▍      | 1695/5000 [6:19:18<10:58:22, 11.95s/it, loss=0.9657, lr=8.36e-06]Steps:  34%|███▍      | 1695/5000 [6:19:18<10:58:22, 11.95s/it, loss=1.1411, lr=8.36e-06]Steps:  34%|███▍      | 1696/5000 [6:19:30<10:57:45, 11.94s/it, loss=1.1411, lr=8.36e-06]Steps:  34%|███▍      | 1696/5000 [6:19:30<10:57:45, 11.94s/it, loss=0.9059, lr=8.36e-06]Steps:  34%|███▍      | 1697/5000 [6:19:41<10:57:30, 11.94s/it, loss=0.9059, lr=8.36e-06]Steps:  34%|███▍      | 1697/5000 [6:19:41<10:57:30, 11.94s/it, loss=1.0974, lr=8.35e-06]Steps:  34%|███▍      | 1698/5000 [6:19:54<11:01:48, 12.03s/it, loss=1.0974, lr=8.35e-06]Steps:  34%|███▍      | 1698/5000 [6:19:54<11:01:48, 12.03s/it, loss=0.3507, lr=8.35e-06]Steps:  34%|███▍      | 1699/5000 [6:20:06<10:59:32, 11.99s/it, loss=0.3507, lr=8.35e-06]Steps:  34%|███▍      | 1699/5000 [6:20:06<10:59:32, 11.99s/it, loss=0.4134, lr=8.35e-06]Steps:  34%|███▍      | 1700/5000 [6:20:17<10:56:50, 11.94s/it, loss=0.4134, lr=8.35e-06]Steps:  34%|███▍      | 1700/5000 [6:20:17<10:56:50, 11.94s/it, loss=0.9693, lr=8.35e-06]01/22/2026 14:06:04 - INFO - __main__ - 
[Step 1700] ✅ Loss in normal range (0.9693)
01/22/2026 14:06:04 - INFO - __main__ -   Loss avg (last 100): 0.7687
01/22/2026 14:06:04 - INFO - __main__ -   Loss range: [0.3301, 1.1837]

[Step 1700] Training Debug Info:
  Loss: 0.469262
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0070, std: 0.8828
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0065, std: 1.3359
  Model pred mean: 0.0064, std: 1.1406
  Sigmas: [0.703125]... (timesteps: [702.0])

[Step 1700] Training Debug Info:
  Loss: 0.985772
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0064, std: 0.8672
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0073, std: 1.3203
  Model pred mean: 0.0037, std: 0.8750
  Sigmas: [0.37890625]... (timesteps: [378.0])

[Step 1700] Training Debug Info:
  Loss: 0.963852
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0222, std: 0.9609
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0190, std: 1.3906
  Model pred mean: -0.0236, std: 0.9805
  Sigmas: [0.283203125]... (timesteps: [284.0])

[Step 1700] Training Debug Info:
  Loss: 0.406875
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0078, std: 0.9180
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0085, std: 1.3516
  Model pred mean: -0.0049, std: 1.1953
  Sigmas: [0.80859375]... (timesteps: [809.0])
Steps:  34%|███▍      | 1701/5000 [6:20:29<10:55:56, 11.93s/it, loss=0.9693, lr=8.35e-06]Steps:  34%|███▍      | 1701/5000 [6:20:29<10:55:56, 11.93s/it, loss=0.4069, lr=8.34e-06]Steps:  34%|███▍      | 1702/5000 [6:20:41<10:55:38, 11.93s/it, loss=0.4069, lr=8.34e-06]Steps:  34%|███▍      | 1702/5000 [6:20:41<10:55:38, 11.93s/it, loss=0.3544, lr=8.34e-06]Steps:  34%|███▍      | 1703/5000 [6:20:53<10:55:06, 11.92s/it, loss=0.3544, lr=8.34e-06]Steps:  34%|███▍      | 1703/5000 [6:20:53<10:55:06, 11.92s/it, loss=0.6690, lr=8.34e-06]Steps:  34%|███▍      | 1704/5000 [6:21:05<10:55:48, 11.94s/it, loss=0.6690, lr=8.34e-06]Steps:  34%|███▍      | 1704/5000 [6:21:05<10:55:48, 11.94s/it, loss=0.3948, lr=8.34e-06]Steps:  34%|███▍      | 1705/5000 [6:21:17<11:02:19, 12.06s/it, loss=0.3948, lr=8.34e-06]Steps:  34%|███▍      | 1705/5000 [6:21:17<11:02:19, 12.06s/it, loss=0.6631, lr=8.33e-06]Steps:  34%|███▍      | 1706/5000 [6:21:29<10:59:24, 12.01s/it, loss=0.6631, lr=8.33e-06]Steps:  34%|███▍      | 1706/5000 [6:21:29<10:59:24, 12.01s/it, loss=0.4926, lr=8.33e-06]Steps:  34%|███▍      | 1707/5000 [6:21:41<10:57:56, 11.99s/it, loss=0.4926, lr=8.33e-06]Steps:  34%|███▍      | 1707/5000 [6:21:41<10:57:56, 11.99s/it, loss=1.0691, lr=8.33e-06]Steps:  34%|███▍      | 1708/5000 [6:21:53<10:56:23, 11.96s/it, loss=1.0691, lr=8.33e-06]Steps:  34%|███▍      | 1708/5000 [6:21:53<10:56:23, 11.96s/it, loss=0.6949, lr=8.32e-06]Steps:  34%|███▍      | 1709/5000 [6:22:05<10:54:54, 11.94s/it, loss=0.6949, lr=8.32e-06]Steps:  34%|███▍      | 1709/5000 [6:22:05<10:54:54, 11.94s/it, loss=0.6917, lr=8.32e-06]Steps:  34%|███▍      | 1710/5000 [6:22:17<10:54:01, 11.93s/it, loss=0.6917, lr=8.32e-06]Steps:  34%|███▍      | 1710/5000 [6:22:17<10:54:01, 11.93s/it, loss=0.9723, lr=8.32e-06]
[Step 1710] Training Debug Info:
  Loss: 1.060090
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0256, std: 0.9062
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0238, std: 1.3516
  Model pred mean: 0.0256, std: 0.8750
  Sigmas: [0.322265625]... (timesteps: [322.0])

[Step 1710] Training Debug Info:
  Loss: 1.123476
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0148, std: 0.9023
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0141, std: 1.3516
  Model pred mean: -0.0133, std: 0.8320
  Sigmas: [0.2236328125]... (timesteps: [224.0])

[Step 1710] Training Debug Info:
  Loss: 0.366305
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0051, std: 0.8711
  Noise mean: -0.0034, std: 1.0000
  Target mean: 0.0017, std: 1.3281
  Model pred mean: 0.0079, std: 1.1797
  Sigmas: [0.8515625]... (timesteps: [851.0])

[Step 1710] Training Debug Info:
  Loss: 0.503976
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0220, std: 0.9336
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0216, std: 1.3672
  Model pred mean: -0.0295, std: 1.1719
  Sigmas: [0.90625]... (timesteps: [908.0])
Steps:  34%|███▍      | 1711/5000 [6:22:29<10:58:08, 12.01s/it, loss=0.9723, lr=8.32e-06]Steps:  34%|███▍      | 1711/5000 [6:22:29<10:58:08, 12.01s/it, loss=0.5040, lr=8.32e-06]Steps:  34%|███▍      | 1712/5000 [6:22:41<10:56:02, 11.97s/it, loss=0.5040, lr=8.32e-06]Steps:  34%|███▍      | 1712/5000 [6:22:41<10:56:02, 11.97s/it, loss=1.0387, lr=8.31e-06]Steps:  34%|███▍      | 1713/5000 [6:22:53<10:54:30, 11.95s/it, loss=1.0387, lr=8.31e-06]Steps:  34%|███▍      | 1713/5000 [6:22:53<10:54:30, 11.95s/it, loss=0.2937, lr=8.31e-06]Steps:  34%|███▍      | 1714/5000 [6:23:05<10:55:08, 11.96s/it, loss=0.2937, lr=8.31e-06]Steps:  34%|███▍      | 1714/5000 [6:23:05<10:55:08, 11.96s/it, loss=1.0090, lr=8.31e-06]Steps:  34%|███▍      | 1715/5000 [6:23:17<10:54:18, 11.95s/it, loss=1.0090, lr=8.31e-06]Steps:  34%|███▍      | 1715/5000 [6:23:17<10:54:18, 11.95s/it, loss=1.1613, lr=8.31e-06]Steps:  34%|███▍      | 1716/5000 [6:23:29<10:53:22, 11.94s/it, loss=1.1613, lr=8.31e-06]Steps:  34%|███▍      | 1716/5000 [6:23:29<10:53:22, 11.94s/it, loss=0.8985, lr=8.30e-06]Steps:  34%|███▍      | 1717/5000 [6:23:41<10:51:54, 11.91s/it, loss=0.8985, lr=8.30e-06]Steps:  34%|███▍      | 1717/5000 [6:23:41<10:51:54, 11.91s/it, loss=0.6576, lr=8.30e-06]Steps:  34%|███▍      | 1718/5000 [6:23:53<10:56:03, 11.99s/it, loss=0.6576, lr=8.30e-06]Steps:  34%|███▍      | 1718/5000 [6:23:53<10:56:03, 11.99s/it, loss=1.2257, lr=8.30e-06]Steps:  34%|███▍      | 1719/5000 [6:24:05<10:54:28, 11.97s/it, loss=1.2257, lr=8.30e-06]Steps:  34%|███▍      | 1719/5000 [6:24:05<10:54:28, 11.97s/it, loss=0.5323, lr=8.30e-06]Steps:  34%|███▍      | 1720/5000 [6:24:17<10:52:30, 11.94s/it, loss=0.5323, lr=8.30e-06]Steps:  34%|███▍      | 1720/5000 [6:24:17<10:52:30, 11.94s/it, loss=0.4801, lr=8.29e-06]
[Step 1720] Training Debug Info:
  Loss: 0.593334
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0254, std: 0.9336
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0227, std: 1.3672
  Model pred mean: -0.0152, std: 1.1562
  Sigmas: [0.9140625]... (timesteps: [915.0])

[Step 1720] Training Debug Info:
  Loss: 0.499666
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0019, std: 0.8711
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0040, std: 1.3281
  Model pred mean: 0.0120, std: 1.1406
  Sigmas: [0.93359375]... (timesteps: [934.0])

[Step 1720] Training Debug Info:
  Loss: 0.379803
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0021, std: 0.9141
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0003, std: 1.3516
  Model pred mean: 0.0024, std: 1.2031
  Sigmas: [0.8203125]... (timesteps: [822.0])

[Step 1720] Training Debug Info:
  Loss: 0.420783
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0059, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0048, std: 1.3516
  Model pred mean: 0.0078, std: 1.1953
  Sigmas: [0.86328125]... (timesteps: [863.0])
Steps:  34%|███▍      | 1721/5000 [6:24:29<10:52:21, 11.94s/it, loss=0.4801, lr=8.29e-06]Steps:  34%|███▍      | 1721/5000 [6:24:29<10:52:21, 11.94s/it, loss=0.4208, lr=8.29e-06]Steps:  34%|███▍      | 1722/5000 [6:24:40<10:51:45, 11.93s/it, loss=0.4208, lr=8.29e-06]Steps:  34%|███▍      | 1722/5000 [6:24:40<10:51:45, 11.93s/it, loss=0.7452, lr=8.29e-06]Steps:  34%|███▍      | 1723/5000 [6:24:52<10:53:02, 11.96s/it, loss=0.7452, lr=8.29e-06]Steps:  34%|███▍      | 1723/5000 [6:24:52<10:53:02, 11.96s/it, loss=0.5952, lr=8.29e-06]Steps:  34%|███▍      | 1724/5000 [6:25:04<10:53:21, 11.97s/it, loss=0.5952, lr=8.29e-06]Steps:  34%|███▍      | 1724/5000 [6:25:04<10:53:21, 11.97s/it, loss=0.5833, lr=8.28e-06]Steps:  34%|███▍      | 1725/5000 [6:25:17<10:57:05, 12.04s/it, loss=0.5833, lr=8.28e-06]Steps:  34%|███▍      | 1725/5000 [6:25:17<10:57:05, 12.04s/it, loss=0.4962, lr=8.28e-06]Steps:  35%|███▍      | 1726/5000 [6:25:29<10:55:15, 12.01s/it, loss=0.4962, lr=8.28e-06]Steps:  35%|███▍      | 1726/5000 [6:25:29<10:55:15, 12.01s/it, loss=0.4016, lr=8.28e-06]Steps:  35%|███▍      | 1727/5000 [6:25:41<10:53:39, 11.98s/it, loss=0.4016, lr=8.28e-06]Steps:  35%|███▍      | 1727/5000 [6:25:41<10:53:39, 11.98s/it, loss=1.2005, lr=8.28e-06]Steps:  35%|███▍      | 1728/5000 [6:25:52<10:51:30, 11.95s/it, loss=1.2005, lr=8.28e-06]Steps:  35%|███▍      | 1728/5000 [6:25:52<10:51:30, 11.95s/it, loss=1.1069, lr=8.27e-06]Steps:  35%|███▍      | 1729/5000 [6:26:04<10:50:53, 11.94s/it, loss=1.1069, lr=8.27e-06]Steps:  35%|███▍      | 1729/5000 [6:26:04<10:50:53, 11.94s/it, loss=0.5681, lr=8.27e-06]Steps:  35%|███▍      | 1730/5000 [6:26:16<10:50:27, 11.94s/it, loss=0.5681, lr=8.27e-06]Steps:  35%|███▍      | 1730/5000 [6:26:16<10:50:27, 11.94s/it, loss=0.5652, lr=8.27e-06]
[Step 1730] Training Debug Info:
  Loss: 1.025566
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0208, std: 0.9102
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0201, std: 1.3516
  Model pred mean: 0.0205, std: 0.8984
  Sigmas: [0.01202392578125]... (timesteps: [12.0])

[Step 1730] Training Debug Info:
  Loss: 0.656786
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0118, std: 0.8945
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0118, std: 1.3438
  Model pred mean: 0.0154, std: 1.0781
  Sigmas: [0.56640625]... (timesteps: [565.0])

[Step 1730] Training Debug Info:
  Loss: 0.988891
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0540, std: 0.9414
  Noise mean: -0.0016, std: 0.9961
  Target mean: -0.0557, std: 1.3750
  Model pred mean: -0.0510, std: 0.9492
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 1730] Training Debug Info:
  Loss: 0.476549
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0610, std: 0.9492
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0635, std: 1.3828
  Model pred mean: 0.0615, std: 1.1953
  Sigmas: [0.57421875]... (timesteps: [574.0])
Steps:  35%|███▍      | 1731/5000 [6:26:28<10:50:49, 11.95s/it, loss=0.5652, lr=8.27e-06]Steps:  35%|███▍      | 1731/5000 [6:26:28<10:50:49, 11.95s/it, loss=0.4765, lr=8.26e-06]Steps:  35%|███▍      | 1732/5000 [6:26:40<10:55:16, 12.03s/it, loss=0.4765, lr=8.26e-06]Steps:  35%|███▍      | 1732/5000 [6:26:40<10:55:16, 12.03s/it, loss=0.3958, lr=8.26e-06]Steps:  35%|███▍      | 1733/5000 [6:26:52<10:52:57, 11.99s/it, loss=0.3958, lr=8.26e-06]Steps:  35%|███▍      | 1733/5000 [6:26:52<10:52:57, 11.99s/it, loss=0.6146, lr=8.26e-06]Steps:  35%|███▍      | 1734/5000 [6:27:04<10:51:56, 11.98s/it, loss=0.6146, lr=8.26e-06]Steps:  35%|███▍      | 1734/5000 [6:27:04<10:51:56, 11.98s/it, loss=1.1241, lr=8.26e-06]Steps:  35%|███▍      | 1735/5000 [6:27:16<10:50:23, 11.95s/it, loss=1.1241, lr=8.26e-06]Steps:  35%|███▍      | 1735/5000 [6:27:16<10:50:23, 11.95s/it, loss=0.7332, lr=8.25e-06]Steps:  35%|███▍      | 1736/5000 [6:27:28<10:49:44, 11.94s/it, loss=0.7332, lr=8.25e-06]Steps:  35%|███▍      | 1736/5000 [6:27:28<10:49:44, 11.94s/it, loss=1.1299, lr=8.25e-06]Steps:  35%|███▍      | 1737/5000 [6:27:40<10:49:24, 11.94s/it, loss=1.1299, lr=8.25e-06]Steps:  35%|███▍      | 1737/5000 [6:27:40<10:49:24, 11.94s/it, loss=0.6727, lr=8.25e-06]Steps:  35%|███▍      | 1738/5000 [6:27:52<10:53:50, 12.03s/it, loss=0.6727, lr=8.25e-06]Steps:  35%|███▍      | 1738/5000 [6:27:52<10:53:50, 12.03s/it, loss=0.5988, lr=8.25e-06]Steps:  35%|███▍      | 1739/5000 [6:28:04<10:53:06, 12.02s/it, loss=0.5988, lr=8.25e-06]Steps:  35%|███▍      | 1739/5000 [6:28:04<10:53:06, 12.02s/it, loss=0.3721, lr=8.24e-06]Steps:  35%|███▍      | 1740/5000 [6:28:16<10:52:24, 12.01s/it, loss=0.3721, lr=8.24e-06]Steps:  35%|███▍      | 1740/5000 [6:28:16<10:52:24, 12.01s/it, loss=0.9712, lr=8.24e-06]
[Step 1740] Training Debug Info:
  Loss: 0.907133
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0074, std: 1.3359
  Model pred mean: -0.0098, std: 0.9414
  Sigmas: [0.412109375]... (timesteps: [413.0])

[Step 1740] Training Debug Info:
  Loss: 0.693712
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0134, std: 0.8555
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0142, std: 1.3125
  Model pred mean: 0.0118, std: 1.0234
  Sigmas: [0.55078125]... (timesteps: [550.0])

[Step 1740] Training Debug Info:
  Loss: 1.122730
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0092, std: 0.8984
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0115, std: 1.3438
  Model pred mean: 0.0114, std: 0.8203
  Sigmas: [0.0849609375]... (timesteps: [85.0])

[Step 1740] Training Debug Info:
  Loss: 0.678913
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0347, std: 0.9180
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0352, std: 1.3594
  Model pred mean: 0.0349, std: 1.0781
  Sigmas: [0.5]... (timesteps: [501.0])
Steps:  35%|███▍      | 1741/5000 [6:28:28<10:53:21, 12.03s/it, loss=0.9712, lr=8.24e-06]Steps:  35%|███▍      | 1741/5000 [6:28:28<10:53:21, 12.03s/it, loss=0.6789, lr=8.24e-06]Steps:  35%|███▍      | 1742/5000 [6:28:40<10:51:56, 12.01s/it, loss=0.6789, lr=8.24e-06]Steps:  35%|███▍      | 1742/5000 [6:28:40<10:51:56, 12.01s/it, loss=0.7454, lr=8.24e-06]Steps:  35%|███▍      | 1743/5000 [6:28:52<10:51:14, 12.00s/it, loss=0.7454, lr=8.24e-06]Steps:  35%|███▍      | 1743/5000 [6:28:52<10:51:14, 12.00s/it, loss=0.5018, lr=8.23e-06]Steps:  35%|███▍      | 1744/5000 [6:29:04<10:49:51, 11.98s/it, loss=0.5018, lr=8.23e-06]Steps:  35%|███▍      | 1744/5000 [6:29:04<10:49:51, 11.98s/it, loss=0.5163, lr=8.23e-06]Steps:  35%|███▍      | 1745/5000 [6:29:16<10:52:33, 12.03s/it, loss=0.5163, lr=8.23e-06]Steps:  35%|███▍      | 1745/5000 [6:29:16<10:52:33, 12.03s/it, loss=0.5393, lr=8.23e-06]Steps:  35%|███▍      | 1746/5000 [6:29:28<10:49:51, 11.98s/it, loss=0.5393, lr=8.23e-06]Steps:  35%|███▍      | 1746/5000 [6:29:28<10:49:51, 11.98s/it, loss=0.5805, lr=8.22e-06]Steps:  35%|███▍      | 1747/5000 [6:29:40<10:48:41, 11.96s/it, loss=0.5805, lr=8.22e-06]Steps:  35%|███▍      | 1747/5000 [6:29:40<10:48:41, 11.96s/it, loss=1.1561, lr=8.22e-06]Steps:  35%|███▍      | 1748/5000 [6:29:52<10:48:06, 11.96s/it, loss=1.1561, lr=8.22e-06]Steps:  35%|███▍      | 1748/5000 [6:29:52<10:48:06, 11.96s/it, loss=1.1519, lr=8.22e-06]Steps:  35%|███▍      | 1749/5000 [6:30:04<10:46:37, 11.93s/it, loss=1.1519, lr=8.22e-06]Steps:  35%|███▍      | 1749/5000 [6:30:04<10:46:37, 11.93s/it, loss=0.5406, lr=8.22e-06]Steps:  35%|███▌      | 1750/5000 [6:30:16<10:48:21, 11.97s/it, loss=0.5406, lr=8.22e-06]Steps:  35%|███▌      | 1750/5000 [6:30:16<10:48:21, 11.97s/it, loss=0.6233, lr=8.21e-06]
[Step 1750] Training Debug Info:
  Loss: 0.729471
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0055, std: 0.8711
  Noise mean: 0.0035, std: 1.0000
  Target mean: -0.0021, std: 1.3281
  Model pred mean: -0.0090, std: 1.0234
  Sigmas: [0.5234375]... (timesteps: [525.0])

[Step 1750] Training Debug Info:
  Loss: 0.738087
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0249, std: 0.9570
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0250, std: 1.3828
  Model pred mean: -0.0371, std: 1.0859
  Sigmas: [0.9453125]... (timesteps: [944.0])

[Step 1750] Training Debug Info:
  Loss: 0.519367
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0349, std: 0.9102
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0325, std: 1.3516
  Model pred mean: -0.0408, std: 1.1484
  Sigmas: [0.70703125]... (timesteps: [708.0])

[Step 1750] Training Debug Info:
  Loss: 0.483682
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0088, std: 0.9062
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0123, std: 1.3516
  Model pred mean: -0.0136, std: 1.1641
  Sigmas: [0.66015625]... (timesteps: [659.0])
Steps:  35%|███▌      | 1751/5000 [6:30:28<10:47:12, 11.95s/it, loss=0.6233, lr=8.21e-06]Steps:  35%|███▌      | 1751/5000 [6:30:28<10:47:12, 11.95s/it, loss=0.4837, lr=8.21e-06]Steps:  35%|███▌      | 1752/5000 [6:30:40<10:50:30, 12.02s/it, loss=0.4837, lr=8.21e-06]Steps:  35%|███▌      | 1752/5000 [6:30:40<10:50:30, 12.02s/it, loss=1.0889, lr=8.21e-06]Steps:  35%|███▌      | 1753/5000 [6:30:52<10:48:38, 11.99s/it, loss=1.0889, lr=8.21e-06]Steps:  35%|███▌      | 1753/5000 [6:30:52<10:48:38, 11.99s/it, loss=0.6713, lr=8.21e-06]Steps:  35%|███▌      | 1754/5000 [6:31:04<10:45:50, 11.94s/it, loss=0.6713, lr=8.21e-06]Steps:  35%|███▌      | 1754/5000 [6:31:04<10:45:50, 11.94s/it, loss=0.9740, lr=8.20e-06]Steps:  35%|███▌      | 1755/5000 [6:31:16<10:45:31, 11.94s/it, loss=0.9740, lr=8.20e-06]Steps:  35%|███▌      | 1755/5000 [6:31:16<10:45:31, 11.94s/it, loss=1.0649, lr=8.20e-06]Steps:  35%|███▌      | 1756/5000 [6:31:28<10:44:26, 11.92s/it, loss=1.0649, lr=8.20e-06]Steps:  35%|███▌      | 1756/5000 [6:31:28<10:44:26, 11.92s/it, loss=0.5124, lr=8.20e-06]Steps:  35%|███▌      | 1757/5000 [6:31:39<10:42:50, 11.89s/it, loss=0.5124, lr=8.20e-06]Steps:  35%|███▌      | 1757/5000 [6:31:39<10:42:50, 11.89s/it, loss=0.5443, lr=8.20e-06]Steps:  35%|███▌      | 1758/5000 [6:31:51<10:42:05, 11.88s/it, loss=0.5443, lr=8.20e-06]Steps:  35%|███▌      | 1758/5000 [6:31:51<10:42:05, 11.88s/it, loss=0.4418, lr=8.19e-06]Steps:  35%|███▌      | 1759/5000 [6:32:04<10:48:50, 12.01s/it, loss=0.4418, lr=8.19e-06]Steps:  35%|███▌      | 1759/5000 [6:32:04<10:48:50, 12.01s/it, loss=0.8401, lr=8.19e-06]Steps:  35%|███▌      | 1760/5000 [6:32:16<10:46:53, 11.98s/it, loss=0.8401, lr=8.19e-06]Steps:  35%|███▌      | 1760/5000 [6:32:16<10:46:53, 11.98s/it, loss=0.7881, lr=8.19e-06]
[Step 1760] Training Debug Info:
  Loss: 0.440627
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0042, std: 0.8828
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0034, std: 1.3359
  Model pred mean: -0.0056, std: 1.1562
  Sigmas: [0.91015625]... (timesteps: [909.0])

[Step 1760] Training Debug Info:
  Loss: 0.541457
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0037, std: 1.0234
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0018, std: 1.4297
  Model pred mean: 0.0035, std: 1.2266
  Sigmas: [0.86328125]... (timesteps: [864.0])

[Step 1760] Training Debug Info:
  Loss: 1.037791
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0144, std: 0.9258
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0127, std: 1.3594
  Model pred mean: -0.0149, std: 0.9062
  Sigmas: [0.2490234375]... (timesteps: [249.0])

[Step 1760] Training Debug Info:
  Loss: 0.401937
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0181, std: 0.9492
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0165, std: 1.3828
  Model pred mean: 0.0209, std: 1.2266
  Sigmas: [0.75]... (timesteps: [750.0])
Steps:  35%|███▌      | 1761/5000 [6:32:27<10:44:54, 11.95s/it, loss=0.7881, lr=8.19e-06]Steps:  35%|███▌      | 1761/5000 [6:32:27<10:44:54, 11.95s/it, loss=0.4019, lr=8.18e-06]Steps:  35%|███▌      | 1762/5000 [6:32:39<10:42:49, 11.91s/it, loss=0.4019, lr=8.18e-06]Steps:  35%|███▌      | 1762/5000 [6:32:39<10:42:49, 11.91s/it, loss=0.4259, lr=8.18e-06]Steps:  35%|███▌      | 1763/5000 [6:32:51<10:43:57, 11.94s/it, loss=0.4259, lr=8.18e-06]Steps:  35%|███▌      | 1763/5000 [6:32:51<10:43:57, 11.94s/it, loss=0.4033, lr=8.18e-06]Steps:  35%|███▌      | 1764/5000 [6:33:03<10:43:20, 11.93s/it, loss=0.4033, lr=8.18e-06]Steps:  35%|███▌      | 1764/5000 [6:33:03<10:43:20, 11.93s/it, loss=0.4768, lr=8.18e-06]Steps:  35%|███▌      | 1765/5000 [6:33:15<10:47:45, 12.01s/it, loss=0.4768, lr=8.18e-06]Steps:  35%|███▌      | 1765/5000 [6:33:15<10:47:45, 12.01s/it, loss=1.0429, lr=8.17e-06]Steps:  35%|███▌      | 1766/5000 [6:33:27<10:46:29, 11.99s/it, loss=1.0429, lr=8.17e-06]Steps:  35%|███▌      | 1766/5000 [6:33:27<10:46:29, 11.99s/it, loss=0.5108, lr=8.17e-06]Steps:  35%|███▌      | 1767/5000 [6:33:39<10:42:59, 11.93s/it, loss=0.5108, lr=8.17e-06]Steps:  35%|███▌      | 1767/5000 [6:33:39<10:42:59, 11.93s/it, loss=0.4072, lr=8.17e-06]Steps:  35%|███▌      | 1768/5000 [6:33:51<10:44:06, 11.96s/it, loss=0.4072, lr=8.17e-06]Steps:  35%|███▌      | 1768/5000 [6:33:51<10:44:06, 11.96s/it, loss=0.9671, lr=8.17e-06]Steps:  35%|███▌      | 1769/5000 [6:34:03<10:42:46, 11.94s/it, loss=0.9671, lr=8.17e-06]Steps:  35%|███▌      | 1769/5000 [6:34:03<10:42:46, 11.94s/it, loss=0.6431, lr=8.16e-06]Steps:  35%|███▌      | 1770/5000 [6:34:15<10:41:49, 11.92s/it, loss=0.6431, lr=8.16e-06]Steps:  35%|███▌      | 1770/5000 [6:34:15<10:41:49, 11.92s/it, loss=0.7943, lr=8.16e-06]
[Step 1770] Training Debug Info:
  Loss: 0.530597
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0190, std: 0.9453
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0167, std: 1.3750
  Model pred mean: -0.0186, std: 1.1719
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 1770] Training Debug Info:
  Loss: 1.069324
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0154, std: 0.9258
  Noise mean: -0.0004, std: 0.9961
  Target mean: -0.0159, std: 1.3594
  Model pred mean: -0.0154, std: 0.8906
  Sigmas: [0.052001953125]... (timesteps: [52.0])

[Step 1770] Training Debug Info:
  Loss: 0.828728
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0033, std: 0.9297
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0034, std: 1.3672
  Model pred mean: 0.0037, std: 1.0078
  Sigmas: [0.388671875]... (timesteps: [388.0])

[Step 1770] Training Debug Info:
  Loss: 1.120689
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0148, std: 0.9414
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0156, std: 1.3750
  Model pred mean: -0.0154, std: 0.8750
  Sigmas: [0.138671875]... (timesteps: [139.0])
Steps:  35%|███▌      | 1771/5000 [6:34:27<10:41:04, 11.91s/it, loss=0.7943, lr=8.16e-06]Steps:  35%|███▌      | 1771/5000 [6:34:27<10:41:04, 11.91s/it, loss=1.1207, lr=8.16e-06]Steps:  35%|███▌      | 1772/5000 [6:34:39<10:43:53, 11.97s/it, loss=1.1207, lr=8.16e-06]Steps:  35%|███▌      | 1772/5000 [6:34:39<10:43:53, 11.97s/it, loss=0.8057, lr=8.15e-06]Steps:  35%|███▌      | 1773/5000 [6:34:51<10:43:04, 11.96s/it, loss=0.8057, lr=8.15e-06]Steps:  35%|███▌      | 1773/5000 [6:34:51<10:43:04, 11.96s/it, loss=0.4215, lr=8.15e-06]Steps:  35%|███▌      | 1774/5000 [6:35:03<10:42:00, 11.94s/it, loss=0.4215, lr=8.15e-06]Steps:  35%|███▌      | 1774/5000 [6:35:03<10:42:00, 11.94s/it, loss=1.1445, lr=8.15e-06]Steps:  36%|███▌      | 1775/5000 [6:35:15<10:42:37, 11.96s/it, loss=1.1445, lr=8.15e-06]Steps:  36%|███▌      | 1775/5000 [6:35:15<10:42:37, 11.96s/it, loss=1.1140, lr=8.15e-06]Steps:  36%|███▌      | 1776/5000 [6:35:27<10:42:17, 11.95s/it, loss=1.1140, lr=8.15e-06]Steps:  36%|███▌      | 1776/5000 [6:35:27<10:42:17, 11.95s/it, loss=1.1166, lr=8.14e-06]Steps:  36%|███▌      | 1777/5000 [6:35:39<10:43:19, 11.98s/it, loss=1.1166, lr=8.14e-06]Steps:  36%|███▌      | 1777/5000 [6:35:39<10:43:19, 11.98s/it, loss=1.0908, lr=8.14e-06]Steps:  36%|███▌      | 1778/5000 [6:35:51<10:42:43, 11.97s/it, loss=1.0908, lr=8.14e-06]Steps:  36%|███▌      | 1778/5000 [6:35:51<10:42:43, 11.97s/it, loss=0.8827, lr=8.14e-06]Steps:  36%|███▌      | 1779/5000 [6:36:03<10:46:50, 12.05s/it, loss=0.8827, lr=8.14e-06]Steps:  36%|███▌      | 1779/5000 [6:36:03<10:46:50, 12.05s/it, loss=0.4828, lr=8.14e-06]Steps:  36%|███▌      | 1780/5000 [6:36:15<10:44:04, 12.00s/it, loss=0.4828, lr=8.14e-06]Steps:  36%|███▌      | 1780/5000 [6:36:15<10:44:04, 12.00s/it, loss=0.4354, lr=8.13e-06]
[Step 1780] Training Debug Info:
  Loss: 0.698788
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0364, std: 0.9297
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0347, std: 1.3672
  Model pred mean: -0.0308, std: 1.0781
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 1780] Training Debug Info:
  Loss: 0.349876
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0110, std: 0.9258
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0106, std: 1.3594
  Model pred mean: 0.0154, std: 1.2031
  Sigmas: [0.9140625]... (timesteps: [913.0])

[Step 1780] Training Debug Info:
  Loss: 0.906620
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0162, std: 0.9453
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0153, std: 1.3750
  Model pred mean: -0.0103, std: 0.9844
  Sigmas: [0.4140625]... (timesteps: [414.0])

[Step 1780] Training Debug Info:
  Loss: 0.377608
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0073, std: 0.8477
  Noise mean: -0.0029, std: 1.0000
  Target mean: 0.0044, std: 1.3125
  Model pred mean: 0.0087, std: 1.1562
  Sigmas: [0.828125]... (timesteps: [829.0])
Steps:  36%|███▌      | 1781/5000 [6:36:27<10:42:07, 11.97s/it, loss=0.4354, lr=8.13e-06]Steps:  36%|███▌      | 1781/5000 [6:36:27<10:42:07, 11.97s/it, loss=0.3776, lr=8.13e-06]Steps:  36%|███▌      | 1782/5000 [6:36:38<10:39:28, 11.92s/it, loss=0.3776, lr=8.13e-06]Steps:  36%|███▌      | 1782/5000 [6:36:38<10:39:28, 11.92s/it, loss=1.1663, lr=8.13e-06]Steps:  36%|███▌      | 1783/5000 [6:36:50<10:39:25, 11.93s/it, loss=1.1663, lr=8.13e-06]Steps:  36%|███▌      | 1783/5000 [6:36:50<10:39:25, 11.93s/it, loss=0.3637, lr=8.12e-06]Steps:  36%|███▌      | 1784/5000 [6:37:02<10:38:32, 11.91s/it, loss=0.3637, lr=8.12e-06]Steps:  36%|███▌      | 1784/5000 [6:37:02<10:38:32, 11.91s/it, loss=0.6766, lr=8.12e-06]Steps:  36%|███▌      | 1785/5000 [6:37:14<10:37:46, 11.90s/it, loss=0.6766, lr=8.12e-06]Steps:  36%|███▌      | 1785/5000 [6:37:14<10:37:46, 11.90s/it, loss=0.7804, lr=8.12e-06]Steps:  36%|███▌      | 1786/5000 [6:37:27<10:44:46, 12.04s/it, loss=0.7804, lr=8.12e-06]Steps:  36%|███▌      | 1786/5000 [6:37:27<10:44:46, 12.04s/it, loss=0.6110, lr=8.12e-06]Steps:  36%|███▌      | 1787/5000 [6:37:38<10:41:52, 11.99s/it, loss=0.6110, lr=8.12e-06]Steps:  36%|███▌      | 1787/5000 [6:37:38<10:41:52, 11.99s/it, loss=1.1305, lr=8.11e-06]Steps:  36%|███▌      | 1788/5000 [6:37:50<10:40:50, 11.97s/it, loss=1.1305, lr=8.11e-06]Steps:  36%|███▌      | 1788/5000 [6:37:50<10:40:50, 11.97s/it, loss=1.0944, lr=8.11e-06]Steps:  36%|███▌      | 1789/5000 [6:38:02<10:38:18, 11.93s/it, loss=1.0944, lr=8.11e-06]Steps:  36%|███▌      | 1789/5000 [6:38:02<10:38:18, 11.93s/it, loss=1.0699, lr=8.11e-06]Steps:  36%|███▌      | 1790/5000 [6:38:14<10:38:37, 11.94s/it, loss=1.0699, lr=8.11e-06]Steps:  36%|███▌      | 1790/5000 [6:38:14<10:38:37, 11.94s/it, loss=1.1199, lr=8.11e-06]
[Step 1790] Training Debug Info:
  Loss: 0.875155
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0200, std: 0.9336
  Noise mean: 0.0013, std: 1.0000
  Target mean: 0.0214, std: 1.3672
  Model pred mean: 0.0200, std: 0.9961
  Sigmas: [0.4140625]... (timesteps: [414.0])

[Step 1790] Training Debug Info:
  Loss: 0.656165
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0032, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0041, std: 1.3594
  Model pred mean: 0.0023, std: 1.0859
  Sigmas: [0.53125]... (timesteps: [531.0])

[Step 1790] Training Debug Info:
  Loss: 0.681014
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0197, std: 0.8828
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0199, std: 1.3359
  Model pred mean: -0.0181, std: 1.0547
  Sigmas: [0.48046875]... (timesteps: [481.0])

[Step 1790] Training Debug Info:
  Loss: 1.076016
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0130, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0135, std: 1.3516
  Model pred mean: 0.0150, std: 0.8594
  Sigmas: [0.044921875]... (timesteps: [45.0])
Steps:  36%|███▌      | 1791/5000 [6:38:26<10:38:21, 11.94s/it, loss=1.1199, lr=8.11e-06]Steps:  36%|███▌      | 1791/5000 [6:38:26<10:38:21, 11.94s/it, loss=1.0760, lr=8.10e-06]Steps:  36%|███▌      | 1792/5000 [6:38:38<10:41:18, 11.99s/it, loss=1.0760, lr=8.10e-06]Steps:  36%|███▌      | 1792/5000 [6:38:38<10:41:18, 11.99s/it, loss=0.8208, lr=8.10e-06]Steps:  36%|███▌      | 1793/5000 [6:38:50<10:38:57, 11.95s/it, loss=0.8208, lr=8.10e-06]Steps:  36%|███▌      | 1793/5000 [6:38:50<10:38:57, 11.95s/it, loss=0.6984, lr=8.10e-06]Steps:  36%|███▌      | 1794/5000 [6:39:02<10:37:53, 11.94s/it, loss=0.6984, lr=8.10e-06]Steps:  36%|███▌      | 1794/5000 [6:39:02<10:37:53, 11.94s/it, loss=0.4226, lr=8.09e-06]Steps:  36%|███▌      | 1795/5000 [6:39:14<10:39:43, 11.98s/it, loss=0.4226, lr=8.09e-06]Steps:  36%|███▌      | 1795/5000 [6:39:14<10:39:43, 11.98s/it, loss=0.5313, lr=8.09e-06]Steps:  36%|███▌      | 1796/5000 [6:39:26<10:38:10, 11.95s/it, loss=0.5313, lr=8.09e-06]Steps:  36%|███▌      | 1796/5000 [6:39:26<10:38:10, 11.95s/it, loss=0.6519, lr=8.09e-06]Steps:  36%|███▌      | 1797/5000 [6:39:38<10:37:56, 11.95s/it, loss=0.6519, lr=8.09e-06]Steps:  36%|███▌      | 1797/5000 [6:39:38<10:37:56, 11.95s/it, loss=0.9511, lr=8.09e-06]Steps:  36%|███▌      | 1798/5000 [6:39:50<10:36:44, 11.93s/it, loss=0.9511, lr=8.09e-06]Steps:  36%|███▌      | 1798/5000 [6:39:50<10:36:44, 11.93s/it, loss=0.5590, lr=8.08e-06]Steps:  36%|███▌      | 1799/5000 [6:40:02<10:41:54, 12.03s/it, loss=0.5590, lr=8.08e-06]Steps:  36%|███▌      | 1799/5000 [6:40:02<10:41:54, 12.03s/it, loss=1.1303, lr=8.08e-06]Steps:  36%|███▌      | 1800/5000 [6:40:14<10:38:40, 11.98s/it, loss=1.1303, lr=8.08e-06]Steps:  36%|███▌      | 1800/5000 [6:40:14<10:38:40, 11.98s/it, loss=1.0308, lr=8.08e-06]01/22/2026 14:26:01 - INFO - __main__ - 
[Step 1800] ✅ Loss in normal range (1.0308)
01/22/2026 14:26:01 - INFO - __main__ -   Loss avg (last 100): 0.7338
01/22/2026 14:26:01 - INFO - __main__ -   Loss range: [0.2937, 1.2257]
01/22/2026 14:26:01 - INFO - __main__ - 
🔍 Running validation at step 1800...
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1800 (parquet mode)...
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1800...
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 14:26:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.46it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.46it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 14:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 14:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 14:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 14:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.41it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 14:27:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 14:27:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 14:27:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 14:27:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 14:27:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 14:27:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 14:28:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 14:28:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 14:28:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 14:28:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 14:28:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 14:28:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 14:29:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 14:29:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 14:29:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 14:29:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 14:29:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 14:29:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 14:30:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800/step001800_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 14:30:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 14:30:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 14:30:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_001800
01/22/2026 14:30:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1800] Training Debug Info:
  Loss: 0.357615
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0084, std: 0.9336
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0070, std: 1.3672
  Model pred mean: -0.0079, std: 1.2344
  Sigmas: [0.85546875]... (timesteps: [856.0])

[Step 1800] Training Debug Info:
  Loss: 1.177309
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0070, std: 0.8867
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0080, std: 1.3359
  Model pred mean: 0.0056, std: 0.7812
  Sigmas: [0.1962890625]... (timesteps: [196.0])

[Step 1800] Training Debug Info:
  Loss: 0.623117
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0046, std: 0.8945
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0061, std: 1.3438
  Model pred mean: 0.0027, std: 1.0781
  Sigmas: [0.5703125]... (timesteps: [571.0])

[Step 1800] Training Debug Info:
  Loss: 0.454586
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0247, std: 0.9336
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0261, std: 1.3672
  Model pred mean: -0.0264, std: 1.1875
  Sigmas: [0.68359375]... (timesteps: [683.0])
Steps:  36%|███▌      | 1801/5000 [6:44:37<77:37:40, 87.36s/it, loss=1.0308, lr=8.08e-06]Steps:  36%|███▌      | 1801/5000 [6:44:37<77:37:40, 87.36s/it, loss=0.4546, lr=8.08e-06]Steps:  36%|███▌      | 1802/5000 [6:44:49<57:29:51, 64.73s/it, loss=0.4546, lr=8.08e-06]Steps:  36%|███▌      | 1802/5000 [6:44:49<57:29:51, 64.73s/it, loss=0.9222, lr=8.07e-06]Steps:  36%|███▌      | 1803/5000 [6:45:01<43:25:16, 48.89s/it, loss=0.9222, lr=8.07e-06]Steps:  36%|███▌      | 1803/5000 [6:45:01<43:25:16, 48.89s/it, loss=0.4125, lr=8.07e-06]Steps:  36%|███▌      | 1804/5000 [6:45:13<33:34:09, 37.81s/it, loss=0.4125, lr=8.07e-06]Steps:  36%|███▌      | 1804/5000 [6:45:13<33:34:09, 37.81s/it, loss=0.9937, lr=8.07e-06]Steps:  36%|███▌      | 1805/5000 [6:45:25<26:40:06, 30.05s/it, loss=0.9937, lr=8.07e-06]Steps:  36%|███▌      | 1805/5000 [6:45:25<26:40:06, 30.05s/it, loss=0.5763, lr=8.06e-06]Steps:  36%|███▌      | 1806/5000 [6:45:37<21:54:51, 24.70s/it, loss=0.5763, lr=8.06e-06]Steps:  36%|███▌      | 1806/5000 [6:45:37<21:54:51, 24.70s/it, loss=1.1344, lr=8.06e-06]Steps:  36%|███▌      | 1807/5000 [6:45:49<18:29:22, 20.85s/it, loss=1.1344, lr=8.06e-06]Steps:  36%|███▌      | 1807/5000 [6:45:49<18:29:22, 20.85s/it, loss=1.1680, lr=8.06e-06]Steps:  36%|███▌      | 1808/5000 [6:46:01<16:07:10, 18.18s/it, loss=1.1680, lr=8.06e-06]Steps:  36%|███▌      | 1808/5000 [6:46:01<16:07:10, 18.18s/it, loss=1.0757, lr=8.06e-06]Steps:  36%|███▌      | 1809/5000 [6:46:13<14:26:28, 16.29s/it, loss=1.0757, lr=8.06e-06]Steps:  36%|███▌      | 1809/5000 [6:46:13<14:26:28, 16.29s/it, loss=0.5920, lr=8.05e-06]Steps:  36%|███▌      | 1810/5000 [6:46:25<13:17:27, 15.00s/it, loss=0.5920, lr=8.05e-06]Steps:  36%|███▌      | 1810/5000 [6:46:25<13:17:27, 15.00s/it, loss=0.6681, lr=8.05e-06]
[Step 1810] Training Debug Info:
  Loss: 0.696146
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0142, std: 0.9336
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0151, std: 1.3672
  Model pred mean: -0.0126, std: 1.0859
  Sigmas: [0.55078125]... (timesteps: [551.0])

[Step 1810] Training Debug Info:
  Loss: 0.972934
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0211, std: 0.9023
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0189, std: 1.3516
  Model pred mean: -0.0206, std: 0.9141
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 1810] Training Debug Info:
  Loss: 1.146609
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0140, std: 0.9023
  Noise mean: -0.0038, std: 1.0000
  Target mean: -0.0177, std: 1.3438
  Model pred mean: -0.0120, std: 0.8125
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 1810] Training Debug Info:
  Loss: 0.370598
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0129, std: 0.8477
  Noise mean: 0.0015, std: 0.9961
  Target mean: 0.0144, std: 1.3047
  Model pred mean: 0.0104, std: 1.1641
  Sigmas: [0.86328125]... (timesteps: [862.0])
Steps:  36%|███▌      | 1811/5000 [6:46:37<12:28:52, 14.09s/it, loss=0.6681, lr=8.05e-06]Steps:  36%|███▌      | 1811/5000 [6:46:37<12:28:52, 14.09s/it, loss=0.3706, lr=8.05e-06]Steps:  36%|███▌      | 1812/5000 [6:46:49<11:54:36, 13.45s/it, loss=0.3706, lr=8.05e-06]Steps:  36%|███▌      | 1812/5000 [6:46:49<11:54:36, 13.45s/it, loss=1.1492, lr=8.05e-06]Steps:  36%|███▋      | 1813/5000 [6:47:01<11:33:54, 13.06s/it, loss=1.1492, lr=8.05e-06]Steps:  36%|███▋      | 1813/5000 [6:47:01<11:33:54, 13.06s/it, loss=0.9231, lr=8.04e-06]Steps:  36%|███▋      | 1814/5000 [6:47:13<11:15:39, 12.72s/it, loss=0.9231, lr=8.04e-06]Steps:  36%|███▋      | 1814/5000 [6:47:13<11:15:39, 12.72s/it, loss=0.9213, lr=8.04e-06]Steps:  36%|███▋      | 1815/5000 [6:47:25<11:03:12, 12.49s/it, loss=0.9213, lr=8.04e-06]Steps:  36%|███▋      | 1815/5000 [6:47:25<11:03:12, 12.49s/it, loss=0.6309, lr=8.04e-06]Steps:  36%|███▋      | 1816/5000 [6:47:37<10:53:26, 12.31s/it, loss=0.6309, lr=8.04e-06]Steps:  36%|███▋      | 1816/5000 [6:47:37<10:53:26, 12.31s/it, loss=1.1345, lr=8.03e-06]Steps:  36%|███▋      | 1817/5000 [6:47:48<10:46:26, 12.19s/it, loss=1.1345, lr=8.03e-06]Steps:  36%|███▋      | 1817/5000 [6:47:48<10:46:26, 12.19s/it, loss=0.4072, lr=8.03e-06]Steps:  36%|███▋      | 1818/5000 [6:48:00<10:42:28, 12.11s/it, loss=0.4072, lr=8.03e-06]Steps:  36%|███▋      | 1818/5000 [6:48:00<10:42:28, 12.11s/it, loss=1.1700, lr=8.03e-06]Steps:  36%|███▋      | 1819/5000 [6:48:13<10:44:02, 12.15s/it, loss=1.1700, lr=8.03e-06]Steps:  36%|███▋      | 1819/5000 [6:48:13<10:44:02, 12.15s/it, loss=0.3948, lr=8.03e-06]Steps:  36%|███▋      | 1820/5000 [6:48:25<10:40:32, 12.09s/it, loss=0.3948, lr=8.03e-06]Steps:  36%|███▋      | 1820/5000 [6:48:25<10:40:32, 12.09s/it, loss=0.3781, lr=8.02e-06]
[Step 1820] Training Debug Info:
  Loss: 0.886219
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0093, std: 0.8672
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0066, std: 1.3281
  Model pred mean: 0.0117, std: 0.9258
  Sigmas: [0.44140625]... (timesteps: [441.0])

[Step 1820] Training Debug Info:
  Loss: 0.593247
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0265, std: 0.8828
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0277, std: 1.3359
  Model pred mean: -0.0287, std: 1.0938
  Sigmas: [0.97265625]... (timesteps: [974.0])

[Step 1820] Training Debug Info:
  Loss: 1.137859
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0151, std: 0.8906
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0161, std: 1.3438
  Model pred mean: -0.0135, std: 0.8086
  Sigmas: [0.1748046875]... (timesteps: [175.0])

[Step 1820] Training Debug Info:
  Loss: 1.010386
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0090, std: 0.8867
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0112, std: 1.3359
  Model pred mean: 0.0105, std: 0.8828
  Sigmas: [0.353515625]... (timesteps: [353.0])
Steps:  36%|███▋      | 1821/5000 [6:48:36<10:37:01, 12.02s/it, loss=0.3781, lr=8.02e-06]Steps:  36%|███▋      | 1821/5000 [6:48:36<10:37:01, 12.02s/it, loss=1.0104, lr=8.02e-06]Steps:  36%|███▋      | 1822/5000 [6:48:49<10:37:48, 12.04s/it, loss=1.0104, lr=8.02e-06]Steps:  36%|███▋      | 1822/5000 [6:48:49<10:37:48, 12.04s/it, loss=1.1828, lr=8.02e-06]Steps:  36%|███▋      | 1823/5000 [6:49:00<10:35:34, 12.00s/it, loss=1.1828, lr=8.02e-06]Steps:  36%|███▋      | 1823/5000 [6:49:00<10:35:34, 12.00s/it, loss=1.0307, lr=8.01e-06]Steps:  36%|███▋      | 1824/5000 [6:49:12<10:34:23, 11.98s/it, loss=1.0307, lr=8.01e-06]Steps:  36%|███▋      | 1824/5000 [6:49:12<10:34:23, 11.98s/it, loss=0.4163, lr=8.01e-06]Steps:  36%|███▋      | 1825/5000 [6:49:24<10:33:42, 11.98s/it, loss=0.4163, lr=8.01e-06]Steps:  36%|███▋      | 1825/5000 [6:49:24<10:33:42, 11.98s/it, loss=0.4026, lr=8.01e-06]Steps:  37%|███▋      | 1826/5000 [6:49:37<10:38:15, 12.07s/it, loss=0.4026, lr=8.01e-06]Steps:  37%|███▋      | 1826/5000 [6:49:37<10:38:15, 12.07s/it, loss=1.1449, lr=8.01e-06]Steps:  37%|███▋      | 1827/5000 [6:49:49<10:37:02, 12.05s/it, loss=1.1449, lr=8.01e-06]Steps:  37%|███▋      | 1827/5000 [6:49:49<10:37:02, 12.05s/it, loss=0.4742, lr=8.00e-06]Steps:  37%|███▋      | 1828/5000 [6:50:01<10:36:43, 12.04s/it, loss=0.4742, lr=8.00e-06]Steps:  37%|███▋      | 1828/5000 [6:50:01<10:36:43, 12.04s/it, loss=0.7022, lr=8.00e-06]Steps:  37%|███▋      | 1829/5000 [6:50:13<10:38:15, 12.08s/it, loss=0.7022, lr=8.00e-06]Steps:  37%|███▋      | 1829/5000 [6:50:13<10:38:15, 12.08s/it, loss=0.5840, lr=8.00e-06]Steps:  37%|███▋      | 1830/5000 [6:50:25<10:36:01, 12.04s/it, loss=0.5840, lr=8.00e-06]Steps:  37%|███▋      | 1830/5000 [6:50:25<10:36:01, 12.04s/it, loss=0.7231, lr=8.00e-06]
[Step 1830] Training Debug Info:
  Loss: 0.430744
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0291, std: 0.9219
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0273, std: 1.3594
  Model pred mean: -0.0277, std: 1.1953
  Sigmas: [0.67578125]... (timesteps: [674.0])

[Step 1830] Training Debug Info:
  Loss: 0.898050
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0140, std: 0.8750
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0118, std: 1.3281
  Model pred mean: -0.0137, std: 0.9297
  Sigmas: [0.41015625]... (timesteps: [410.0])

[Step 1830] Training Debug Info:
  Loss: 1.012119
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0845, std: 0.9531
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0835, std: 1.3828
  Model pred mean: -0.0811, std: 0.9492
  Sigmas: [0.1376953125]... (timesteps: [138.0])

[Step 1830] Training Debug Info:
  Loss: 0.496759
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0128, std: 0.9141
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0134, std: 1.3516
  Model pred mean: -0.0121, std: 1.1562
  Sigmas: [0.66015625]... (timesteps: [662.0])
Steps:  37%|███▋      | 1831/5000 [6:50:37<10:34:57, 12.02s/it, loss=0.7231, lr=8.00e-06]Steps:  37%|███▋      | 1831/5000 [6:50:37<10:34:57, 12.02s/it, loss=0.4968, lr=7.99e-06]Steps:  37%|███▋      | 1832/5000 [6:50:49<10:32:40, 11.98s/it, loss=0.4968, lr=7.99e-06]Steps:  37%|███▋      | 1832/5000 [6:50:49<10:32:40, 11.98s/it, loss=0.5275, lr=7.99e-06]Steps:  37%|███▋      | 1833/5000 [6:51:01<10:36:42, 12.06s/it, loss=0.5275, lr=7.99e-06]Steps:  37%|███▋      | 1833/5000 [6:51:01<10:36:42, 12.06s/it, loss=0.6142, lr=7.99e-06]Steps:  37%|███▋      | 1834/5000 [6:51:13<10:33:30, 12.01s/it, loss=0.6142, lr=7.99e-06]Steps:  37%|███▋      | 1834/5000 [6:51:13<10:33:30, 12.01s/it, loss=1.0759, lr=7.98e-06]Steps:  37%|███▋      | 1835/5000 [6:51:25<10:31:31, 11.97s/it, loss=1.0759, lr=7.98e-06]Steps:  37%|███▋      | 1835/5000 [6:51:25<10:31:31, 11.97s/it, loss=0.6345, lr=7.98e-06]Steps:  37%|███▋      | 1836/5000 [6:51:37<10:35:31, 12.05s/it, loss=0.6345, lr=7.98e-06]Steps:  37%|███▋      | 1836/5000 [6:51:37<10:35:31, 12.05s/it, loss=1.0302, lr=7.98e-06]Steps:  37%|███▋      | 1837/5000 [6:51:49<10:32:41, 12.00s/it, loss=1.0302, lr=7.98e-06]Steps:  37%|███▋      | 1837/5000 [6:51:49<10:32:41, 12.00s/it, loss=0.6249, lr=7.98e-06]Steps:  37%|███▋      | 1838/5000 [6:52:01<10:31:05, 11.98s/it, loss=0.6249, lr=7.98e-06]Steps:  37%|███▋      | 1838/5000 [6:52:01<10:31:05, 11.98s/it, loss=0.6322, lr=7.97e-06]Steps:  37%|███▋      | 1839/5000 [6:52:13<10:28:56, 11.94s/it, loss=0.6322, lr=7.97e-06]Steps:  37%|███▋      | 1839/5000 [6:52:13<10:28:56, 11.94s/it, loss=0.3655, lr=7.97e-06]Steps:  37%|███▋      | 1840/5000 [6:52:25<10:32:43, 12.01s/it, loss=0.3655, lr=7.97e-06]Steps:  37%|███▋      | 1840/5000 [6:52:25<10:32:43, 12.01s/it, loss=0.6843, lr=7.97e-06]
[Step 1840] Training Debug Info:
  Loss: 0.380755
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.8828
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0098, std: 1.3359
  Model pred mean: -0.0111, std: 1.1875
  Sigmas: [0.875]... (timesteps: [876.0])

[Step 1840] Training Debug Info:
  Loss: 1.177117
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0135, std: 0.8789
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0137, std: 1.3281
  Model pred mean: -0.0160, std: 0.7656
  Sigmas: [0.2119140625]... (timesteps: [212.0])

[Step 1840] Training Debug Info:
  Loss: 1.178768
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0001, std: 0.8828
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0022, std: 1.3359
  Model pred mean: -0.0003, std: 0.7695
  Sigmas: [0.1708984375]... (timesteps: [171.0])

[Step 1840] Training Debug Info:
  Loss: 1.075561
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0131, std: 0.8438
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0121, std: 1.3125
  Model pred mean: 0.0103, std: 0.8008
  Sigmas: [0.0400390625]... (timesteps: [40.0])
Steps:  37%|███▋      | 1841/5000 [6:52:37<10:30:59, 11.98s/it, loss=0.6843, lr=7.97e-06]Steps:  37%|███▋      | 1841/5000 [6:52:37<10:30:59, 11.98s/it, loss=1.0756, lr=7.96e-06]Steps:  37%|███▋      | 1842/5000 [6:52:49<10:30:09, 11.97s/it, loss=1.0756, lr=7.96e-06]Steps:  37%|███▋      | 1842/5000 [6:52:49<10:30:09, 11.97s/it, loss=0.4378, lr=7.96e-06]Steps:  37%|███▋      | 1843/5000 [6:53:01<10:29:47, 11.97s/it, loss=0.4378, lr=7.96e-06]Steps:  37%|███▋      | 1843/5000 [6:53:01<10:29:47, 11.97s/it, loss=0.6346, lr=7.96e-06]Steps:  37%|███▋      | 1844/5000 [6:53:13<10:29:02, 11.96s/it, loss=0.6346, lr=7.96e-06]Steps:  37%|███▋      | 1844/5000 [6:53:13<10:29:02, 11.96s/it, loss=0.6092, lr=7.96e-06]Steps:  37%|███▋      | 1845/5000 [6:53:24<10:28:27, 11.95s/it, loss=0.6092, lr=7.96e-06]Steps:  37%|███▋      | 1845/5000 [6:53:24<10:28:27, 11.95s/it, loss=0.5520, lr=7.95e-06]Steps:  37%|███▋      | 1846/5000 [6:53:37<10:33:06, 12.04s/it, loss=0.5520, lr=7.95e-06]Steps:  37%|███▋      | 1846/5000 [6:53:37<10:33:06, 12.04s/it, loss=0.5539, lr=7.95e-06]Steps:  37%|███▋      | 1847/5000 [6:53:49<10:31:30, 12.02s/it, loss=0.5539, lr=7.95e-06]Steps:  37%|███▋      | 1847/5000 [6:53:49<10:31:30, 12.02s/it, loss=1.1178, lr=7.95e-06]Steps:  37%|███▋      | 1848/5000 [6:54:01<10:30:47, 12.01s/it, loss=1.1178, lr=7.95e-06]Steps:  37%|███▋      | 1848/5000 [6:54:01<10:30:47, 12.01s/it, loss=0.3702, lr=7.94e-06]Steps:  37%|███▋      | 1849/5000 [6:54:13<10:30:10, 12.00s/it, loss=0.3702, lr=7.94e-06]Steps:  37%|███▋      | 1849/5000 [6:54:13<10:30:10, 12.00s/it, loss=0.3427, lr=7.94e-06]Steps:  37%|███▋      | 1850/5000 [6:54:25<10:28:39, 11.97s/it, loss=0.3427, lr=7.94e-06]Steps:  37%|███▋      | 1850/5000 [6:54:25<10:28:39, 11.97s/it, loss=0.4294, lr=7.94e-06]
[Step 1850] Training Debug Info:
  Loss: 1.054216
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0190, std: 0.9453
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0183, std: 1.3750
  Model pred mean: 0.0228, std: 0.9219
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 1850] Training Debug Info:
  Loss: 0.371402
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0092, std: 0.9375
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0085, std: 1.3750
  Model pred mean: 0.0069, std: 1.2266
  Sigmas: [0.76953125]... (timesteps: [769.0])

[Step 1850] Training Debug Info:
  Loss: 0.469747
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0117, std: 0.8867
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0122, std: 1.3359
  Model pred mean: -0.0156, std: 1.1484
  Sigmas: [0.70703125]... (timesteps: [708.0])

[Step 1850] Training Debug Info:
  Loss: 1.079759
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0146, std: 0.8828
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0177, std: 1.3359
  Model pred mean: -0.0147, std: 0.8438
  Sigmas: [0.3125]... (timesteps: [313.0])
Steps:  37%|███▋      | 1851/5000 [6:54:37<10:28:18, 11.97s/it, loss=0.4294, lr=7.94e-06]Steps:  37%|███▋      | 1851/5000 [6:54:37<10:28:18, 11.97s/it, loss=1.0798, lr=7.94e-06]Steps:  37%|███▋      | 1852/5000 [6:54:49<10:31:09, 12.03s/it, loss=1.0798, lr=7.94e-06]Steps:  37%|███▋      | 1852/5000 [6:54:49<10:31:09, 12.03s/it, loss=0.7352, lr=7.93e-06]Steps:  37%|███▋      | 1853/5000 [6:55:01<10:33:23, 12.08s/it, loss=0.7352, lr=7.93e-06]Steps:  37%|███▋      | 1853/5000 [6:55:01<10:33:23, 12.08s/it, loss=1.0405, lr=7.93e-06]Steps:  37%|███▋      | 1854/5000 [6:55:13<10:29:30, 12.01s/it, loss=1.0405, lr=7.93e-06]Steps:  37%|███▋      | 1854/5000 [6:55:13<10:29:30, 12.01s/it, loss=1.0362, lr=7.93e-06]Steps:  37%|███▋      | 1855/5000 [6:55:25<10:27:24, 11.97s/it, loss=1.0362, lr=7.93e-06]Steps:  37%|███▋      | 1855/5000 [6:55:25<10:27:24, 11.97s/it, loss=0.9612, lr=7.92e-06]Steps:  37%|███▋      | 1856/5000 [6:55:37<10:26:24, 11.95s/it, loss=0.9612, lr=7.92e-06]Steps:  37%|███▋      | 1856/5000 [6:55:37<10:26:24, 11.95s/it, loss=1.0916, lr=7.92e-06]Steps:  37%|███▋      | 1857/5000 [6:55:48<10:25:19, 11.94s/it, loss=1.0916, lr=7.92e-06]Steps:  37%|███▋      | 1857/5000 [6:55:48<10:25:19, 11.94s/it, loss=0.5994, lr=7.92e-06]Steps:  37%|███▋      | 1858/5000 [6:56:00<10:24:04, 11.92s/it, loss=0.5994, lr=7.92e-06]Steps:  37%|███▋      | 1858/5000 [6:56:00<10:24:04, 11.92s/it, loss=0.6033, lr=7.92e-06]Steps:  37%|███▋      | 1859/5000 [6:56:12<10:23:48, 11.92s/it, loss=0.6033, lr=7.92e-06]Steps:  37%|███▋      | 1859/5000 [6:56:12<10:23:48, 11.92s/it, loss=0.5231, lr=7.91e-06]Steps:  37%|███▋      | 1860/5000 [6:56:24<10:27:54, 12.00s/it, loss=0.5231, lr=7.91e-06]Steps:  37%|███▋      | 1860/5000 [6:56:24<10:27:54, 12.00s/it, loss=1.1548, lr=7.91e-06]
[Step 1860] Training Debug Info:
  Loss: 1.011070
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0025, std: 0.8984
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0026, std: 1.3438
  Model pred mean: 0.0035, std: 0.8984
  Sigmas: [0.349609375]... (timesteps: [350.0])

[Step 1860] Training Debug Info:
  Loss: 0.686689
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0138, std: 0.9258
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0131, std: 1.3672
  Model pred mean: 0.0137, std: 1.0859
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 1860] Training Debug Info:
  Loss: 0.767103
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0064, std: 0.9492
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0061, std: 1.3750
  Model pred mean: 0.0030, std: 1.0625
  Sigmas: [0.515625]... (timesteps: [516.0])

[Step 1860] Training Debug Info:
  Loss: 0.565189
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0415, std: 0.9531
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0408, std: 1.3828
  Model pred mean: -0.0461, std: 1.1562
  Sigmas: [0.87890625]... (timesteps: [880.0])
Steps:  37%|███▋      | 1861/5000 [6:56:37<10:29:32, 12.03s/it, loss=1.1548, lr=7.91e-06]Steps:  37%|███▋      | 1861/5000 [6:56:37<10:29:32, 12.03s/it, loss=0.5652, lr=7.91e-06]Steps:  37%|███▋      | 1862/5000 [6:56:48<10:27:47, 12.00s/it, loss=0.5652, lr=7.91e-06]Steps:  37%|███▋      | 1862/5000 [6:56:48<10:27:47, 12.00s/it, loss=1.1106, lr=7.90e-06]Steps:  37%|███▋      | 1863/5000 [6:57:00<10:26:40, 11.99s/it, loss=1.1106, lr=7.90e-06]Steps:  37%|███▋      | 1863/5000 [6:57:00<10:26:40, 11.99s/it, loss=0.4034, lr=7.90e-06]Steps:  37%|███▋      | 1864/5000 [6:57:12<10:26:45, 11.99s/it, loss=0.4034, lr=7.90e-06]Steps:  37%|███▋      | 1864/5000 [6:57:12<10:26:45, 11.99s/it, loss=1.1835, lr=7.90e-06]Steps:  37%|███▋      | 1865/5000 [6:57:24<10:26:40, 11.99s/it, loss=1.1835, lr=7.90e-06]Steps:  37%|███▋      | 1865/5000 [6:57:24<10:26:40, 11.99s/it, loss=0.5343, lr=7.90e-06]Steps:  37%|███▋      | 1866/5000 [6:57:36<10:25:33, 11.98s/it, loss=0.5343, lr=7.90e-06]Steps:  37%|███▋      | 1866/5000 [6:57:36<10:25:33, 11.98s/it, loss=1.1703, lr=7.89e-06]Steps:  37%|███▋      | 1867/5000 [6:57:49<10:28:38, 12.04s/it, loss=1.1703, lr=7.89e-06]Steps:  37%|███▋      | 1867/5000 [6:57:49<10:28:38, 12.04s/it, loss=0.4695, lr=7.89e-06]Steps:  37%|███▋      | 1868/5000 [6:58:00<10:26:38, 12.00s/it, loss=0.4695, lr=7.89e-06]Steps:  37%|███▋      | 1868/5000 [6:58:00<10:26:38, 12.00s/it, loss=0.9701, lr=7.89e-06]Steps:  37%|███▋      | 1869/5000 [6:58:12<10:26:13, 12.00s/it, loss=0.9701, lr=7.89e-06]Steps:  37%|███▋      | 1869/5000 [6:58:12<10:26:13, 12.00s/it, loss=1.1499, lr=7.89e-06]Steps:  37%|███▋      | 1870/5000 [6:58:24<10:26:31, 12.01s/it, loss=1.1499, lr=7.89e-06]Steps:  37%|███▋      | 1870/5000 [6:58:24<10:26:31, 12.01s/it, loss=0.5190, lr=7.88e-06]
[Step 1870] Training Debug Info:
  Loss: 0.524817
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0243, std: 0.9141
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0225, std: 1.3594
  Model pred mean: -0.0226, std: 1.1484
  Sigmas: [0.7421875]... (timesteps: [744.0])

[Step 1870] Training Debug Info:
  Loss: 0.571376
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0173, std: 0.8828
  Noise mean: -0.0040, std: 1.0000
  Target mean: -0.0214, std: 1.3359
  Model pred mean: -0.0168, std: 1.1016
  Sigmas: [0.61328125]... (timesteps: [612.0])

[Step 1870] Training Debug Info:
  Loss: 1.044620
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0033, std: 0.9414
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0027, std: 1.3672
  Model pred mean: 0.0022, std: 0.9141
  Sigmas: [0.1962890625]... (timesteps: [196.0])

[Step 1870] Training Debug Info:
  Loss: 0.640143
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0332, std: 0.8984
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0327, std: 1.3438
  Model pred mean: -0.0327, std: 1.0703
  Sigmas: [0.96875]... (timesteps: [968.0])
Steps:  37%|███▋      | 1871/5000 [6:58:36<10:24:55, 11.98s/it, loss=0.5190, lr=7.88e-06]Steps:  37%|███▋      | 1871/5000 [6:58:36<10:24:55, 11.98s/it, loss=0.6401, lr=7.88e-06]Steps:  37%|███▋      | 1872/5000 [6:58:48<10:24:24, 11.98s/it, loss=0.6401, lr=7.88e-06]Steps:  37%|███▋      | 1872/5000 [6:58:48<10:24:24, 11.98s/it, loss=0.5416, lr=7.88e-06]Steps:  37%|███▋      | 1873/5000 [6:59:01<10:27:46, 12.05s/it, loss=0.5416, lr=7.88e-06]Steps:  37%|███▋      | 1873/5000 [6:59:01<10:27:46, 12.05s/it, loss=1.1759, lr=7.87e-06]Steps:  37%|███▋      | 1874/5000 [6:59:13<10:26:41, 12.03s/it, loss=1.1759, lr=7.87e-06]Steps:  37%|███▋      | 1874/5000 [6:59:13<10:26:41, 12.03s/it, loss=0.3693, lr=7.87e-06]Steps:  38%|███▊      | 1875/5000 [6:59:24<10:25:15, 12.00s/it, loss=0.3693, lr=7.87e-06]Steps:  38%|███▊      | 1875/5000 [6:59:24<10:25:15, 12.00s/it, loss=1.1106, lr=7.87e-06]Steps:  38%|███▊      | 1876/5000 [6:59:36<10:23:11, 11.97s/it, loss=1.1106, lr=7.87e-06]Steps:  38%|███▊      | 1876/5000 [6:59:36<10:23:11, 11.97s/it, loss=0.7414, lr=7.87e-06]Steps:  38%|███▊      | 1877/5000 [6:59:48<10:22:28, 11.96s/it, loss=0.7414, lr=7.87e-06]Steps:  38%|███▊      | 1877/5000 [6:59:48<10:22:28, 11.96s/it, loss=1.0642, lr=7.86e-06]Steps:  38%|███▊      | 1878/5000 [7:00:00<10:21:32, 11.94s/it, loss=1.0642, lr=7.86e-06]Steps:  38%|███▊      | 1878/5000 [7:00:00<10:21:32, 11.94s/it, loss=1.1510, lr=7.86e-06]Steps:  38%|███▊      | 1879/5000 [7:00:12<10:23:31, 11.99s/it, loss=1.1510, lr=7.86e-06]Steps:  38%|███▊      | 1879/5000 [7:00:12<10:23:31, 11.99s/it, loss=1.0684, lr=7.86e-06]Steps:  38%|███▊      | 1880/5000 [7:00:25<10:26:53, 12.06s/it, loss=1.0684, lr=7.86e-06]Steps:  38%|███▊      | 1880/5000 [7:00:25<10:26:53, 12.06s/it, loss=0.5346, lr=7.85e-06]
[Step 1880] Training Debug Info:
  Loss: 0.365655
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0435, std: 0.8867
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0422, std: 1.3359
  Model pred mean: 0.0378, std: 1.1953
  Sigmas: [0.859375]... (timesteps: [859.0])

[Step 1880] Training Debug Info:
  Loss: 0.496429
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0172, std: 1.3516
  Model pred mean: -0.0157, std: 1.1484
  Sigmas: [0.6328125]... (timesteps: [631.0])

[Step 1880] Training Debug Info:
  Loss: 0.391186
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0344, std: 0.8633
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0352, std: 1.3203
  Model pred mean: 0.0284, std: 1.1641
  Sigmas: [0.94921875]... (timesteps: [948.0])

[Step 1880] Training Debug Info:
  Loss: 1.084080
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0052, std: 0.9453
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0048, std: 1.3750
  Model pred mean: 0.0083, std: 0.8945
  Sigmas: [0.06787109375]... (timesteps: [68.0])
Steps:  38%|███▊      | 1881/5000 [7:00:36<10:24:22, 12.01s/it, loss=0.5346, lr=7.85e-06]Steps:  38%|███▊      | 1881/5000 [7:00:36<10:24:22, 12.01s/it, loss=1.0841, lr=7.85e-06]Steps:  38%|███▊      | 1882/5000 [7:00:48<10:22:25, 11.98s/it, loss=1.0841, lr=7.85e-06]Steps:  38%|███▊      | 1882/5000 [7:00:48<10:22:25, 11.98s/it, loss=0.4116, lr=7.85e-06]Steps:  38%|███▊      | 1883/5000 [7:01:00<10:22:26, 11.98s/it, loss=0.4116, lr=7.85e-06]Steps:  38%|███▊      | 1883/5000 [7:01:00<10:22:26, 11.98s/it, loss=1.1366, lr=7.84e-06]Steps:  38%|███▊      | 1884/5000 [7:01:12<10:20:23, 11.95s/it, loss=1.1366, lr=7.84e-06]Steps:  38%|███▊      | 1884/5000 [7:01:12<10:20:23, 11.95s/it, loss=0.4778, lr=7.84e-06]Steps:  38%|███▊      | 1885/5000 [7:01:24<10:18:41, 11.92s/it, loss=0.4778, lr=7.84e-06]Steps:  38%|███▊      | 1885/5000 [7:01:24<10:18:41, 11.92s/it, loss=1.0767, lr=7.84e-06]Steps:  38%|███▊      | 1886/5000 [7:01:36<10:18:47, 11.92s/it, loss=1.0767, lr=7.84e-06]Steps:  38%|███▊      | 1886/5000 [7:01:36<10:18:47, 11.92s/it, loss=1.1526, lr=7.84e-06]Steps:  38%|███▊      | 1887/5000 [7:01:48<10:22:54, 12.01s/it, loss=1.1526, lr=7.84e-06]Steps:  38%|███▊      | 1887/5000 [7:01:48<10:22:54, 12.01s/it, loss=1.0951, lr=7.83e-06]Steps:  38%|███▊      | 1888/5000 [7:02:00<10:22:15, 12.00s/it, loss=1.0951, lr=7.83e-06]Steps:  38%|███▊      | 1888/5000 [7:02:00<10:22:15, 12.00s/it, loss=0.7463, lr=7.83e-06]Steps:  38%|███▊      | 1889/5000 [7:02:12<10:19:45, 11.95s/it, loss=0.7463, lr=7.83e-06]Steps:  38%|███▊      | 1889/5000 [7:02:12<10:19:45, 11.95s/it, loss=0.4374, lr=7.83e-06]Steps:  38%|███▊      | 1890/5000 [7:02:24<10:19:19, 11.95s/it, loss=0.4374, lr=7.83e-06]Steps:  38%|███▊      | 1890/5000 [7:02:24<10:19:19, 11.95s/it, loss=0.8201, lr=7.82e-06]
[Step 1890] Training Debug Info:
  Loss: 0.866102
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0267, std: 0.9414
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0245, std: 1.3750
  Model pred mean: -0.0261, std: 1.0156
  Sigmas: [0.341796875]... (timesteps: [341.0])

[Step 1890] Training Debug Info:
  Loss: 0.509819
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0159, std: 0.8867
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0171, std: 1.3359
  Model pred mean: 0.0175, std: 1.1328
  Sigmas: [0.6796875]... (timesteps: [680.0])

[Step 1890] Training Debug Info:
  Loss: 1.093739
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0260, std: 0.9062
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0242, std: 1.3516
  Model pred mean: -0.0234, std: 0.8555
  Sigmas: [0.2333984375]... (timesteps: [233.0])

[Step 1890] Training Debug Info:
  Loss: 0.378433
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0159, std: 0.8828
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0165, std: 1.3359
  Model pred mean: 0.0156, std: 1.1875
  Sigmas: [0.8203125]... (timesteps: [821.0])
Steps:  38%|███▊      | 1891/5000 [7:02:36<10:19:41, 11.96s/it, loss=0.8201, lr=7.82e-06]Steps:  38%|███▊      | 1891/5000 [7:02:36<10:19:41, 11.96s/it, loss=0.3784, lr=7.82e-06]Steps:  38%|███▊      | 1892/5000 [7:02:48<10:19:13, 11.95s/it, loss=0.3784, lr=7.82e-06]Steps:  38%|███▊      | 1892/5000 [7:02:48<10:19:13, 11.95s/it, loss=1.0351, lr=7.82e-06]Steps:  38%|███▊      | 1893/5000 [7:03:00<10:18:04, 11.94s/it, loss=1.0351, lr=7.82e-06]Steps:  38%|███▊      | 1893/5000 [7:03:00<10:18:04, 11.94s/it, loss=0.4873, lr=7.82e-06]Steps:  38%|███▊      | 1894/5000 [7:03:12<10:21:32, 12.01s/it, loss=0.4873, lr=7.82e-06]Steps:  38%|███▊      | 1894/5000 [7:03:12<10:21:32, 12.01s/it, loss=0.8317, lr=7.81e-06]Steps:  38%|███▊      | 1895/5000 [7:03:24<10:21:30, 12.01s/it, loss=0.8317, lr=7.81e-06]Steps:  38%|███▊      | 1895/5000 [7:03:24<10:21:30, 12.01s/it, loss=1.0821, lr=7.81e-06]Steps:  38%|███▊      | 1896/5000 [7:03:36<10:21:02, 12.00s/it, loss=1.0821, lr=7.81e-06]Steps:  38%|███▊      | 1896/5000 [7:03:36<10:21:02, 12.00s/it, loss=0.8817, lr=7.81e-06]Steps:  38%|███▊      | 1897/5000 [7:03:48<10:22:00, 12.03s/it, loss=0.8817, lr=7.81e-06]Steps:  38%|███▊      | 1897/5000 [7:03:48<10:22:00, 12.03s/it, loss=1.1099, lr=7.80e-06]Steps:  38%|███▊      | 1898/5000 [7:04:00<10:20:22, 12.00s/it, loss=1.1099, lr=7.80e-06]Steps:  38%|███▊      | 1898/5000 [7:04:00<10:20:22, 12.00s/it, loss=0.4452, lr=7.80e-06]Steps:  38%|███▊      | 1899/5000 [7:04:12<10:18:44, 11.97s/it, loss=0.4452, lr=7.80e-06]Steps:  38%|███▊      | 1899/5000 [7:04:12<10:18:44, 11.97s/it, loss=0.4354, lr=7.80e-06]Steps:  38%|███▊      | 1900/5000 [7:04:24<10:21:24, 12.03s/it, loss=0.4354, lr=7.80e-06]Steps:  38%|███▊      | 1900/5000 [7:04:24<10:21:24, 12.03s/it, loss=1.0954, lr=7.80e-06]01/22/2026 14:50:11 - INFO - __main__ - 
[Step 1900] ✅ Loss in normal range (1.0954)
01/22/2026 14:50:11 - INFO - __main__ -   Loss avg (last 100): 0.7748
01/22/2026 14:50:11 - INFO - __main__ -   Loss range: [0.3427, 1.1835]

[Step 1900] Training Debug Info:
  Loss: 0.400551
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0264, std: 0.8633
  Noise mean: 0.0011, std: 0.9961
  Target mean: 0.0275, std: 1.3203
  Model pred mean: 0.0247, std: 1.1562
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 1900] Training Debug Info:
  Loss: 0.733173
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0171, std: 0.9453
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0168, std: 1.3750
  Model pred mean: -0.0189, std: 1.0938
  Sigmas: [0.9609375]... (timesteps: [962.0])

[Step 1900] Training Debug Info:
  Loss: 0.884150
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0097, std: 0.9062
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0098, std: 1.3516
  Model pred mean: 0.0050, std: 0.9688
  Sigmas: [0.40234375]... (timesteps: [403.0])

[Step 1900] Training Debug Info:
  Loss: 0.605580
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0187, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0177, std: 1.3516
  Model pred mean: 0.0168, std: 1.1172
  Sigmas: [0.5703125]... (timesteps: [572.0])
Steps:  38%|███▊      | 1901/5000 [7:04:36<10:19:17, 11.99s/it, loss=1.0954, lr=7.80e-06]Steps:  38%|███▊      | 1901/5000 [7:04:36<10:19:17, 11.99s/it, loss=0.6056, lr=7.79e-06]Steps:  38%|███▊      | 1902/5000 [7:04:48<10:17:07, 11.95s/it, loss=0.6056, lr=7.79e-06]Steps:  38%|███▊      | 1902/5000 [7:04:48<10:17:07, 11.95s/it, loss=0.4545, lr=7.79e-06]Steps:  38%|███▊      | 1903/5000 [7:05:00<10:17:05, 11.96s/it, loss=0.4545, lr=7.79e-06]Steps:  38%|███▊      | 1903/5000 [7:05:00<10:17:05, 11.96s/it, loss=0.6026, lr=7.79e-06]Steps:  38%|███▊      | 1904/5000 [7:05:12<10:16:57, 11.96s/it, loss=0.6026, lr=7.79e-06]Steps:  38%|███▊      | 1904/5000 [7:05:12<10:16:57, 11.96s/it, loss=0.7948, lr=7.78e-06]Steps:  38%|███▊      | 1905/5000 [7:05:24<10:16:28, 11.95s/it, loss=0.7948, lr=7.78e-06]Steps:  38%|███▊      | 1905/5000 [7:05:24<10:16:28, 11.95s/it, loss=0.6452, lr=7.78e-06]Steps:  38%|███▊      | 1906/5000 [7:05:36<10:17:51, 11.98s/it, loss=0.6452, lr=7.78e-06]Steps:  38%|███▊      | 1906/5000 [7:05:36<10:17:51, 11.98s/it, loss=0.4460, lr=7.78e-06]Steps:  38%|███▊      | 1907/5000 [7:05:48<10:21:15, 12.05s/it, loss=0.4460, lr=7.78e-06]Steps:  38%|███▊      | 1907/5000 [7:05:48<10:21:15, 12.05s/it, loss=0.4693, lr=7.78e-06]Steps:  38%|███▊      | 1908/5000 [7:06:00<10:18:15, 12.00s/it, loss=0.4693, lr=7.78e-06]Steps:  38%|███▊      | 1908/5000 [7:06:00<10:18:15, 12.00s/it, loss=1.1165, lr=7.77e-06]Steps:  38%|███▊      | 1909/5000 [7:06:12<10:17:11, 11.98s/it, loss=1.1165, lr=7.77e-06]Steps:  38%|███▊      | 1909/5000 [7:06:12<10:17:11, 11.98s/it, loss=0.8212, lr=7.77e-06]Steps:  38%|███▊      | 1910/5000 [7:06:24<10:16:14, 11.97s/it, loss=0.8212, lr=7.77e-06]Steps:  38%|███▊      | 1910/5000 [7:06:24<10:16:14, 11.97s/it, loss=0.4441, lr=7.77e-06]
[Step 1910] Training Debug Info:
  Loss: 1.079214
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0547, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0535, std: 1.3672
  Model pred mean: -0.0525, std: 0.8867
  Sigmas: [0.1845703125]... (timesteps: [185.0])

[Step 1910] Training Debug Info:
  Loss: 0.812125
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0074, std: 0.8750
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0091, std: 1.3281
  Model pred mean: 0.0063, std: 0.9688
  Sigmas: [0.474609375]... (timesteps: [475.0])

[Step 1910] Training Debug Info:
  Loss: 0.415002
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0021, std: 0.9023
  Noise mean: -0.0024, std: 0.9961
  Target mean: -0.0045, std: 1.3438
  Model pred mean: -0.0027, std: 1.1797
  Sigmas: [0.73828125]... (timesteps: [738.0])

[Step 1910] Training Debug Info:
  Loss: 0.350094
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0153, std: 0.9492
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0170, std: 1.3750
  Model pred mean: -0.0128, std: 1.2422
  Sigmas: [0.7421875]... (timesteps: [743.0])
Steps:  38%|███▊      | 1911/5000 [7:06:36<10:14:33, 11.94s/it, loss=0.4441, lr=7.77e-06]Steps:  38%|███▊      | 1911/5000 [7:06:36<10:14:33, 11.94s/it, loss=0.3501, lr=7.76e-06]Steps:  38%|███▊      | 1912/5000 [7:06:47<10:13:17, 11.92s/it, loss=0.3501, lr=7.76e-06]Steps:  38%|███▊      | 1912/5000 [7:06:47<10:13:17, 11.92s/it, loss=1.0903, lr=7.76e-06]Steps:  38%|███▊      | 1913/5000 [7:06:59<10:12:42, 11.91s/it, loss=1.0903, lr=7.76e-06]Steps:  38%|███▊      | 1913/5000 [7:06:59<10:12:42, 11.91s/it, loss=1.0866, lr=7.76e-06]Steps:  38%|███▊      | 1914/5000 [7:07:11<10:17:03, 12.00s/it, loss=1.0866, lr=7.76e-06]Steps:  38%|███▊      | 1914/5000 [7:07:11<10:17:03, 12.00s/it, loss=1.1353, lr=7.76e-06]Steps:  38%|███▊      | 1915/5000 [7:07:24<10:17:50, 12.02s/it, loss=1.1353, lr=7.76e-06]Steps:  38%|███▊      | 1915/5000 [7:07:24<10:17:50, 12.02s/it, loss=1.0874, lr=7.75e-06]Steps:  38%|███▊      | 1916/5000 [7:07:35<10:15:14, 11.97s/it, loss=1.0874, lr=7.75e-06]Steps:  38%|███▊      | 1916/5000 [7:07:35<10:15:14, 11.97s/it, loss=0.6003, lr=7.75e-06]Steps:  38%|███▊      | 1917/5000 [7:07:47<10:14:06, 11.95s/it, loss=0.6003, lr=7.75e-06]Steps:  38%|███▊      | 1917/5000 [7:07:47<10:14:06, 11.95s/it, loss=0.8962, lr=7.75e-06]Steps:  38%|███▊      | 1918/5000 [7:07:59<10:12:31, 11.92s/it, loss=0.8962, lr=7.75e-06]Steps:  38%|███▊      | 1918/5000 [7:07:59<10:12:31, 11.92s/it, loss=0.4912, lr=7.74e-06]Steps:  38%|███▊      | 1919/5000 [7:08:11<10:11:49, 11.91s/it, loss=0.4912, lr=7.74e-06]Steps:  38%|███▊      | 1919/5000 [7:08:11<10:11:49, 11.91s/it, loss=0.9280, lr=7.74e-06]Steps:  38%|███▊      | 1920/5000 [7:08:23<10:10:27, 11.89s/it, loss=0.9280, lr=7.74e-06]Steps:  38%|███▊      | 1920/5000 [7:08:23<10:10:27, 11.89s/it, loss=0.6236, lr=7.74e-06]
[Step 1920] Training Debug Info:
  Loss: 0.548413
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0025, std: 0.8750
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0009, std: 1.3281
  Model pred mean: -0.0045, std: 1.1016
  Sigmas: [0.640625]... (timesteps: [640.0])

[Step 1920] Training Debug Info:
  Loss: 1.132510
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0024, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0032, std: 1.3594
  Model pred mean: -0.0027, std: 0.8438
  Sigmas: [0.10107421875]... (timesteps: [101.0])

[Step 1920] Training Debug Info:
  Loss: 1.120155
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0029, std: 0.9258
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0030, std: 1.3594
  Model pred mean: 0.0050, std: 0.8594
  Sigmas: [0.248046875]... (timesteps: [248.0])

[Step 1920] Training Debug Info:
  Loss: 1.033629
  Latent shape: torch.Size([1, 32, 144, 60]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0215, std: 0.9297
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0208, std: 1.3672
  Model pred mean: -0.0164, std: 0.9141
  Sigmas: [0.1787109375]... (timesteps: [179.0])
Steps:  38%|███▊      | 1921/5000 [7:08:35<10:14:24, 11.97s/it, loss=0.6236, lr=7.74e-06]Steps:  38%|███▊      | 1921/5000 [7:08:35<10:14:24, 11.97s/it, loss=1.0336, lr=7.73e-06]Steps:  38%|███▊      | 1922/5000 [7:08:47<10:12:45, 11.94s/it, loss=1.0336, lr=7.73e-06]Steps:  38%|███▊      | 1922/5000 [7:08:47<10:12:45, 11.94s/it, loss=0.4244, lr=7.73e-06]Steps:  38%|███▊      | 1923/5000 [7:08:59<10:11:38, 11.93s/it, loss=0.4244, lr=7.73e-06]Steps:  38%|███▊      | 1923/5000 [7:08:59<10:11:38, 11.93s/it, loss=0.7830, lr=7.73e-06]Steps:  38%|███▊      | 1924/5000 [7:09:11<10:13:12, 11.96s/it, loss=0.7830, lr=7.73e-06]Steps:  38%|███▊      | 1924/5000 [7:09:11<10:13:12, 11.96s/it, loss=0.4824, lr=7.73e-06]Steps:  38%|███▊      | 1925/5000 [7:09:23<10:12:19, 11.95s/it, loss=0.4824, lr=7.73e-06]Steps:  38%|███▊      | 1925/5000 [7:09:23<10:12:19, 11.95s/it, loss=0.4525, lr=7.72e-06]Steps:  39%|███▊      | 1926/5000 [7:09:35<10:12:27, 11.95s/it, loss=0.4525, lr=7.72e-06]Steps:  39%|███▊      | 1926/5000 [7:09:35<10:12:27, 11.95s/it, loss=0.6221, lr=7.72e-06]Steps:  39%|███▊      | 1927/5000 [7:09:47<10:16:17, 12.03s/it, loss=0.6221, lr=7.72e-06]Steps:  39%|███▊      | 1927/5000 [7:09:47<10:16:17, 12.03s/it, loss=0.7501, lr=7.72e-06]Steps:  39%|███▊      | 1928/5000 [7:09:59<10:14:57, 12.01s/it, loss=0.7501, lr=7.72e-06]Steps:  39%|███▊      | 1928/5000 [7:09:59<10:14:57, 12.01s/it, loss=0.4528, lr=7.71e-06]Steps:  39%|███▊      | 1929/5000 [7:10:11<10:14:05, 12.00s/it, loss=0.4528, lr=7.71e-06]Steps:  39%|███▊      | 1929/5000 [7:10:11<10:14:05, 12.00s/it, loss=0.9519, lr=7.71e-06]Steps:  39%|███▊      | 1930/5000 [7:10:23<10:13:20, 11.99s/it, loss=0.9519, lr=7.71e-06]Steps:  39%|███▊      | 1930/5000 [7:10:23<10:13:20, 11.99s/it, loss=1.0604, lr=7.71e-06]
[Step 1930] Training Debug Info:
  Loss: 0.814888
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0410, std: 0.9688
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0417, std: 1.3906
  Model pred mean: -0.0425, std: 1.0547
  Sigmas: [0.37109375]... (timesteps: [372.0])

[Step 1930] Training Debug Info:
  Loss: 0.394885
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0082, std: 0.9727
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0074, std: 1.3984
  Model pred mean: -0.0080, std: 1.2422
  Sigmas: [0.828125]... (timesteps: [827.0])

[Step 1930] Training Debug Info:
  Loss: 0.891298
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0090, std: 0.9297
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0119, std: 1.3672
  Model pred mean: -0.0081, std: 0.9883
  Sigmas: [0.39453125]... (timesteps: [395.0])

[Step 1930] Training Debug Info:
  Loss: 0.394223
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0242, std: 0.8867
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0229, std: 1.3359
  Model pred mean: -0.0216, std: 1.1797
  Sigmas: [0.7890625]... (timesteps: [790.0])
Steps:  39%|███▊      | 1931/5000 [7:10:35<10:11:52, 11.96s/it, loss=1.0604, lr=7.71e-06]Steps:  39%|███▊      | 1931/5000 [7:10:35<10:11:52, 11.96s/it, loss=0.3942, lr=7.71e-06]Steps:  39%|███▊      | 1932/5000 [7:10:47<10:11:50, 11.97s/it, loss=0.3942, lr=7.71e-06]Steps:  39%|███▊      | 1932/5000 [7:10:47<10:11:50, 11.97s/it, loss=1.0243, lr=7.70e-06]Steps:  39%|███▊      | 1933/5000 [7:10:59<10:12:32, 11.98s/it, loss=1.0243, lr=7.70e-06]Steps:  39%|███▊      | 1933/5000 [7:10:59<10:12:32, 11.98s/it, loss=0.4533, lr=7.70e-06]Steps:  39%|███▊      | 1934/5000 [7:11:11<10:16:26, 12.06s/it, loss=0.4533, lr=7.70e-06]Steps:  39%|███▊      | 1934/5000 [7:11:11<10:16:26, 12.06s/it, loss=0.3926, lr=7.70e-06]Steps:  39%|███▊      | 1935/5000 [7:11:23<10:15:05, 12.04s/it, loss=0.3926, lr=7.70e-06]Steps:  39%|███▊      | 1935/5000 [7:11:23<10:15:05, 12.04s/it, loss=1.0655, lr=7.69e-06]Steps:  39%|███▊      | 1936/5000 [7:11:35<10:13:11, 12.01s/it, loss=1.0655, lr=7.69e-06]Steps:  39%|███▊      | 1936/5000 [7:11:35<10:13:11, 12.01s/it, loss=0.6222, lr=7.69e-06]Steps:  39%|███▊      | 1937/5000 [7:11:47<10:11:35, 11.98s/it, loss=0.6222, lr=7.69e-06]Steps:  39%|███▊      | 1937/5000 [7:11:47<10:11:35, 11.98s/it, loss=0.5497, lr=7.69e-06]Steps:  39%|███▉      | 1938/5000 [7:11:59<10:10:54, 11.97s/it, loss=0.5497, lr=7.69e-06]Steps:  39%|███▉      | 1938/5000 [7:11:59<10:10:54, 11.97s/it, loss=1.0851, lr=7.69e-06]Steps:  39%|███▉      | 1939/5000 [7:12:11<10:10:36, 11.97s/it, loss=1.0851, lr=7.69e-06]Steps:  39%|███▉      | 1939/5000 [7:12:11<10:10:36, 11.97s/it, loss=0.7592, lr=7.68e-06]Steps:  39%|███▉      | 1940/5000 [7:12:23<10:09:47, 11.96s/it, loss=0.7592, lr=7.68e-06]Steps:  39%|███▉      | 1940/5000 [7:12:23<10:09:47, 11.96s/it, loss=1.0354, lr=7.68e-06]
[Step 1940] Training Debug Info:
  Loss: 0.465861
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0057, std: 0.8789
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0037, std: 1.3281
  Model pred mean: -0.0059, std: 1.1328
  Sigmas: [0.73828125]... (timesteps: [740.0])

[Step 1940] Training Debug Info:
  Loss: 0.611544
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0630, std: 1.0234
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0649, std: 1.4297
  Model pred mean: -0.0598, std: 1.1953
  Sigmas: [0.83984375]... (timesteps: [841.0])

[Step 1940] Training Debug Info:
  Loss: 0.413573
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0157, std: 0.9102
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0171, std: 1.3594
  Model pred mean: -0.0181, std: 1.1953
  Sigmas: [0.72265625]... (timesteps: [722.0])

[Step 1940] Training Debug Info:
  Loss: 0.443033
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0262, std: 0.9336
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0266, std: 1.3672
  Model pred mean: -0.0234, std: 1.1875
  Sigmas: [0.859375]... (timesteps: [860.0])
Steps:  39%|███▉      | 1941/5000 [7:12:35<10:13:11, 12.03s/it, loss=1.0354, lr=7.68e-06]Steps:  39%|███▉      | 1941/5000 [7:12:35<10:13:11, 12.03s/it, loss=0.4430, lr=7.68e-06]Steps:  39%|███▉      | 1942/5000 [7:12:47<10:13:11, 12.03s/it, loss=0.4430, lr=7.68e-06]Steps:  39%|███▉      | 1942/5000 [7:12:47<10:13:11, 12.03s/it, loss=1.1840, lr=7.67e-06]Steps:  39%|███▉      | 1943/5000 [7:12:59<10:11:38, 12.00s/it, loss=1.1840, lr=7.67e-06]Steps:  39%|███▉      | 1943/5000 [7:12:59<10:11:38, 12.00s/it, loss=0.3679, lr=7.67e-06]Steps:  39%|███▉      | 1944/5000 [7:13:11<10:09:13, 11.96s/it, loss=0.3679, lr=7.67e-06]Steps:  39%|███▉      | 1944/5000 [7:13:11<10:09:13, 11.96s/it, loss=0.3780, lr=7.67e-06]Steps:  39%|███▉      | 1945/5000 [7:13:23<10:07:00, 11.92s/it, loss=0.3780, lr=7.67e-06]Steps:  39%|███▉      | 1945/5000 [7:13:23<10:07:00, 11.92s/it, loss=0.8568, lr=7.66e-06]Steps:  39%|███▉      | 1946/5000 [7:13:34<10:06:42, 11.92s/it, loss=0.8568, lr=7.66e-06]Steps:  39%|███▉      | 1946/5000 [7:13:34<10:06:42, 11.92s/it, loss=1.0706, lr=7.66e-06]Steps:  39%|███▉      | 1947/5000 [7:13:46<10:06:01, 11.91s/it, loss=1.0706, lr=7.66e-06]Steps:  39%|███▉      | 1947/5000 [7:13:46<10:06:01, 11.91s/it, loss=0.9275, lr=7.66e-06]Steps:  39%|███▉      | 1948/5000 [7:13:58<10:09:14, 11.98s/it, loss=0.9275, lr=7.66e-06]Steps:  39%|███▉      | 1948/5000 [7:13:58<10:09:14, 11.98s/it, loss=0.6539, lr=7.66e-06]Steps:  39%|███▉      | 1949/5000 [7:14:10<10:08:19, 11.96s/it, loss=0.6539, lr=7.66e-06]Steps:  39%|███▉      | 1949/5000 [7:14:10<10:08:19, 11.96s/it, loss=0.6640, lr=7.65e-06]Steps:  39%|███▉      | 1950/5000 [7:14:22<10:09:08, 11.98s/it, loss=0.6640, lr=7.65e-06]Steps:  39%|███▉      | 1950/5000 [7:14:22<10:09:08, 11.98s/it, loss=0.8542, lr=7.65e-06]
[Step 1950] Training Debug Info:
  Loss: 0.667616
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0349, std: 0.9141
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0337, std: 1.3516
  Model pred mean: -0.0369, std: 1.0781
  Sigmas: [0.96484375]... (timesteps: [966.0])

[Step 1950] Training Debug Info:
  Loss: 1.031429
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0077, std: 0.9609
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0099, std: 1.3906
  Model pred mean: 0.0080, std: 0.9492
  Sigmas: [0.359375]... (timesteps: [360.0])

[Step 1950] Training Debug Info:
  Loss: 0.375636
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0461, std: 0.9258
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0474, std: 1.3594
  Model pred mean: -0.0437, std: 1.2109
  Sigmas: [0.74609375]... (timesteps: [745.0])

[Step 1950] Training Debug Info:
  Loss: 0.366294
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0011, std: 0.8828
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0014, std: 1.3359
  Model pred mean: 0.0036, std: 1.1875
  Sigmas: [0.87890625]... (timesteps: [878.0])
Steps:  39%|███▉      | 1951/5000 [7:14:35<10:11:19, 12.03s/it, loss=0.8542, lr=7.65e-06]Steps:  39%|███▉      | 1951/5000 [7:14:35<10:11:19, 12.03s/it, loss=0.3663, lr=7.65e-06]Steps:  39%|███▉      | 1952/5000 [7:14:47<10:09:54, 12.01s/it, loss=0.3663, lr=7.65e-06]Steps:  39%|███▉      | 1952/5000 [7:14:47<10:09:54, 12.01s/it, loss=1.1394, lr=7.64e-06]Steps:  39%|███▉      | 1953/5000 [7:14:59<10:10:12, 12.02s/it, loss=1.1394, lr=7.64e-06]Steps:  39%|███▉      | 1953/5000 [7:14:59<10:10:12, 12.02s/it, loss=0.3621, lr=7.64e-06]Steps:  39%|███▉      | 1954/5000 [7:15:11<10:13:28, 12.08s/it, loss=0.3621, lr=7.64e-06]Steps:  39%|███▉      | 1954/5000 [7:15:11<10:13:28, 12.08s/it, loss=0.4089, lr=7.64e-06]Steps:  39%|███▉      | 1955/5000 [7:15:23<10:11:13, 12.04s/it, loss=0.4089, lr=7.64e-06]Steps:  39%|███▉      | 1955/5000 [7:15:23<10:11:13, 12.04s/it, loss=0.4156, lr=7.63e-06]Steps:  39%|███▉      | 1956/5000 [7:15:35<10:10:25, 12.03s/it, loss=0.4156, lr=7.63e-06]Steps:  39%|███▉      | 1956/5000 [7:15:35<10:10:25, 12.03s/it, loss=0.7107, lr=7.63e-06]Steps:  39%|███▉      | 1957/5000 [7:15:47<10:09:22, 12.02s/it, loss=0.7107, lr=7.63e-06]Steps:  39%|███▉      | 1957/5000 [7:15:47<10:09:22, 12.02s/it, loss=0.5375, lr=7.63e-06]Steps:  39%|███▉      | 1958/5000 [7:15:59<10:07:10, 11.98s/it, loss=0.5375, lr=7.63e-06]Steps:  39%|███▉      | 1958/5000 [7:15:59<10:07:10, 11.98s/it, loss=1.0314, lr=7.63e-06]Steps:  39%|███▉      | 1959/5000 [7:16:11<10:06:26, 11.97s/it, loss=1.0314, lr=7.63e-06]Steps:  39%|███▉      | 1959/5000 [7:16:11<10:06:26, 11.97s/it, loss=0.6699, lr=7.62e-06]Steps:  39%|███▉      | 1960/5000 [7:16:23<10:08:23, 12.01s/it, loss=0.6699, lr=7.62e-06]Steps:  39%|███▉      | 1960/5000 [7:16:23<10:08:23, 12.01s/it, loss=1.1292, lr=7.62e-06]
[Step 1960] Training Debug Info:
  Loss: 0.680318
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0143, std: 0.8750
  Noise mean: 0.0022, std: 0.9961
  Target mean: 0.0165, std: 1.3281
  Model pred mean: 0.0156, std: 1.0469
  Sigmas: [0.546875]... (timesteps: [546.0])

[Step 1960] Training Debug Info:
  Loss: 1.149572
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0075, std: 0.8984
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0059, std: 1.3438
  Model pred mean: 0.0118, std: 0.8086
  Sigmas: [0.1435546875]... (timesteps: [144.0])

[Step 1960] Training Debug Info:
  Loss: 0.698204
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0050, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0042, std: 1.3516
  Model pred mean: -0.0040, std: 1.0625
  Sigmas: [0.4765625]... (timesteps: [476.0])

[Step 1960] Training Debug Info:
  Loss: 0.857603
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0156, std: 0.8711
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0139, std: 1.3281
  Model pred mean: 0.0162, std: 0.9453
  Sigmas: [0.44921875]... (timesteps: [449.0])
Steps:  39%|███▉      | 1961/5000 [7:16:35<10:10:37, 12.06s/it, loss=1.1292, lr=7.62e-06]Steps:  39%|███▉      | 1961/5000 [7:16:35<10:10:37, 12.06s/it, loss=0.8576, lr=7.62e-06]Steps:  39%|███▉      | 1962/5000 [7:16:47<10:09:50, 12.04s/it, loss=0.8576, lr=7.62e-06]Steps:  39%|███▉      | 1962/5000 [7:16:47<10:09:50, 12.04s/it, loss=1.0960, lr=7.61e-06]Steps:  39%|███▉      | 1963/5000 [7:16:59<10:08:45, 12.03s/it, loss=1.0960, lr=7.61e-06]Steps:  39%|███▉      | 1963/5000 [7:16:59<10:08:45, 12.03s/it, loss=1.1147, lr=7.61e-06]Steps:  39%|███▉      | 1964/5000 [7:17:11<10:07:05, 12.00s/it, loss=1.1147, lr=7.61e-06]Steps:  39%|███▉      | 1964/5000 [7:17:11<10:07:05, 12.00s/it, loss=0.5024, lr=7.61e-06]Steps:  39%|███▉      | 1965/5000 [7:17:23<10:06:37, 11.99s/it, loss=0.5024, lr=7.61e-06]Steps:  39%|███▉      | 1965/5000 [7:17:23<10:06:37, 11.99s/it, loss=1.0032, lr=7.61e-06]Steps:  39%|███▉      | 1966/5000 [7:17:35<10:06:17, 11.99s/it, loss=1.0032, lr=7.61e-06]Steps:  39%|███▉      | 1966/5000 [7:17:35<10:06:17, 11.99s/it, loss=0.3888, lr=7.60e-06]Steps:  39%|███▉      | 1967/5000 [7:17:47<10:06:41, 12.00s/it, loss=0.3888, lr=7.60e-06]Steps:  39%|███▉      | 1967/5000 [7:17:47<10:06:41, 12.00s/it, loss=0.4063, lr=7.60e-06]Steps:  39%|███▉      | 1968/5000 [7:17:59<10:09:33, 12.06s/it, loss=0.4063, lr=7.60e-06]Steps:  39%|███▉      | 1968/5000 [7:17:59<10:09:33, 12.06s/it, loss=1.1789, lr=7.60e-06]Steps:  39%|███▉      | 1969/5000 [7:18:11<10:10:06, 12.08s/it, loss=1.1789, lr=7.60e-06]Steps:  39%|███▉      | 1969/5000 [7:18:11<10:10:06, 12.08s/it, loss=1.0561, lr=7.59e-06]Steps:  39%|███▉      | 1970/5000 [7:18:23<10:08:21, 12.05s/it, loss=1.0561, lr=7.59e-06]Steps:  39%|███▉      | 1970/5000 [7:18:23<10:08:21, 12.05s/it, loss=0.3685, lr=7.59e-06]
[Step 1970] Training Debug Info:
  Loss: 1.145184
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0125, std: 0.9023
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0140, std: 1.3438
  Model pred mean: 0.0103, std: 0.8164
  Sigmas: [0.1220703125]... (timesteps: [122.0])

[Step 1970] Training Debug Info:
  Loss: 0.548519
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0001, std: 0.9336
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0045, std: 1.3672
  Model pred mean: -0.0037, std: 1.1484
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 1970] Training Debug Info:
  Loss: 0.711880
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0214, std: 1.3594
  Model pred mean: -0.0267, std: 1.0703
  Sigmas: [0.46484375]... (timesteps: [464.0])

[Step 1970] Training Debug Info:
  Loss: 1.129046
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0132, std: 0.8906
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0130, std: 1.3438
  Model pred mean: -0.0144, std: 0.8164
  Sigmas: [0.2578125]... (timesteps: [257.0])
Steps:  39%|███▉      | 1971/5000 [7:18:35<10:07:36, 12.04s/it, loss=0.3685, lr=7.59e-06]Steps:  39%|███▉      | 1971/5000 [7:18:35<10:07:36, 12.04s/it, loss=1.1290, lr=7.59e-06]Steps:  39%|███▉      | 1972/5000 [7:18:47<10:06:35, 12.02s/it, loss=1.1290, lr=7.59e-06]Steps:  39%|███▉      | 1972/5000 [7:18:47<10:06:35, 12.02s/it, loss=0.3717, lr=7.58e-06]Steps:  39%|███▉      | 1973/5000 [7:18:59<10:05:00, 11.99s/it, loss=0.3717, lr=7.58e-06]Steps:  39%|███▉      | 1973/5000 [7:18:59<10:05:00, 11.99s/it, loss=1.1620, lr=7.58e-06]Steps:  39%|███▉      | 1974/5000 [7:19:11<10:02:49, 11.95s/it, loss=1.1620, lr=7.58e-06]Steps:  39%|███▉      | 1974/5000 [7:19:11<10:02:49, 11.95s/it, loss=1.0818, lr=7.58e-06]Steps:  40%|███▉      | 1975/5000 [7:19:23<10:06:49, 12.04s/it, loss=1.0818, lr=7.58e-06]Steps:  40%|███▉      | 1975/5000 [7:19:23<10:06:49, 12.04s/it, loss=0.7309, lr=7.58e-06]Steps:  40%|███▉      | 1976/5000 [7:19:35<10:05:18, 12.01s/it, loss=0.7309, lr=7.58e-06]Steps:  40%|███▉      | 1976/5000 [7:19:35<10:05:18, 12.01s/it, loss=1.0406, lr=7.57e-06]Steps:  40%|███▉      | 1977/5000 [7:19:47<10:04:20, 12.00s/it, loss=1.0406, lr=7.57e-06]Steps:  40%|███▉      | 1977/5000 [7:19:47<10:04:20, 12.00s/it, loss=1.0360, lr=7.57e-06]Steps:  40%|███▉      | 1978/5000 [7:19:59<10:04:24, 12.00s/it, loss=1.0360, lr=7.57e-06]Steps:  40%|███▉      | 1978/5000 [7:19:59<10:04:24, 12.00s/it, loss=0.4023, lr=7.57e-06]Steps:  40%|███▉      | 1979/5000 [7:20:11<10:03:24, 11.98s/it, loss=0.4023, lr=7.57e-06]Steps:  40%|███▉      | 1979/5000 [7:20:11<10:03:24, 11.98s/it, loss=0.9655, lr=7.56e-06]Steps:  40%|███▉      | 1980/5000 [7:20:23<10:02:08, 11.96s/it, loss=0.9655, lr=7.56e-06]Steps:  40%|███▉      | 1980/5000 [7:20:23<10:02:08, 11.96s/it, loss=0.6931, lr=7.56e-06]
[Step 1980] Training Debug Info:
  Loss: 0.796975
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0036, std: 0.9414
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0056, std: 1.3750
  Model pred mean: -0.0035, std: 1.0469
  Sigmas: [0.419921875]... (timesteps: [419.0])

[Step 1980] Training Debug Info:
  Loss: 1.037941
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0442, std: 0.8633
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0457, std: 1.3203
  Model pred mean: 0.0449, std: 0.8320
  Sigmas: [0.36328125]... (timesteps: [364.0])

[Step 1980] Training Debug Info:
  Loss: 0.469387
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0175, std: 0.9492
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0176, std: 1.3750
  Model pred mean: -0.0184, std: 1.1953
  Sigmas: [0.6640625]... (timesteps: [665.0])

[Step 1980] Training Debug Info:
  Loss: 0.388040
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0081, std: 0.8867
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0053, std: 1.3359
  Model pred mean: -0.0087, std: 1.1719
  Sigmas: [0.82421875]... (timesteps: [824.0])
Steps:  40%|███▉      | 1981/5000 [7:20:35<10:04:32, 12.01s/it, loss=0.6931, lr=7.56e-06]Steps:  40%|███▉      | 1981/5000 [7:20:35<10:04:32, 12.01s/it, loss=0.3880, lr=7.56e-06]Steps:  40%|███▉      | 1982/5000 [7:20:47<10:02:23, 11.98s/it, loss=0.3880, lr=7.56e-06]Steps:  40%|███▉      | 1982/5000 [7:20:47<10:02:23, 11.98s/it, loss=0.5837, lr=7.55e-06]Steps:  40%|███▉      | 1983/5000 [7:20:59<10:01:42, 11.97s/it, loss=0.5837, lr=7.55e-06]Steps:  40%|███▉      | 1983/5000 [7:20:59<10:01:42, 11.97s/it, loss=0.6668, lr=7.55e-06]Steps:  40%|███▉      | 1984/5000 [7:21:11<10:00:24, 11.94s/it, loss=0.6668, lr=7.55e-06]Steps:  40%|███▉      | 1984/5000 [7:21:11<10:00:24, 11.94s/it, loss=0.4007, lr=7.55e-06]Steps:  40%|███▉      | 1985/5000 [7:21:23<10:00:17, 11.95s/it, loss=0.4007, lr=7.55e-06]Steps:  40%|███▉      | 1985/5000 [7:21:23<10:00:17, 11.95s/it, loss=0.8231, lr=7.55e-06]Steps:  40%|███▉      | 1986/5000 [7:21:35<9:59:55, 11.94s/it, loss=0.8231, lr=7.55e-06] Steps:  40%|███▉      | 1986/5000 [7:21:35<9:59:55, 11.94s/it, loss=0.5098, lr=7.54e-06]Steps:  40%|███▉      | 1987/5000 [7:21:47<10:00:54, 11.97s/it, loss=0.5098, lr=7.54e-06]Steps:  40%|███▉      | 1987/5000 [7:21:47<10:00:54, 11.97s/it, loss=0.4421, lr=7.54e-06]Steps:  40%|███▉      | 1988/5000 [7:21:59<10:03:40, 12.03s/it, loss=0.4421, lr=7.54e-06]Steps:  40%|███▉      | 1988/5000 [7:21:59<10:03:40, 12.03s/it, loss=0.5728, lr=7.54e-06]Steps:  40%|███▉      | 1989/5000 [7:22:11<10:02:01, 12.00s/it, loss=0.5728, lr=7.54e-06]Steps:  40%|███▉      | 1989/5000 [7:22:11<10:02:01, 12.00s/it, loss=1.1426, lr=7.53e-06]Steps:  40%|███▉      | 1990/5000 [7:22:23<10:00:32, 11.97s/it, loss=1.1426, lr=7.53e-06]Steps:  40%|███▉      | 1990/5000 [7:22:23<10:00:32, 11.97s/it, loss=1.0264, lr=7.53e-06]
[Step 1990] Training Debug Info:
  Loss: 0.432866
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0085, std: 0.9023
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0098, std: 1.3516
  Model pred mean: 0.0066, std: 1.1797
  Sigmas: [0.75390625]... (timesteps: [754.0])

[Step 1990] Training Debug Info:
  Loss: 1.099292
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0515, std: 0.9727
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0518, std: 1.3984
  Model pred mean: -0.0486, std: 0.9258
  Sigmas: [0.2236328125]... (timesteps: [224.0])

[Step 1990] Training Debug Info:
  Loss: 0.683517
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0010, std: 0.9727
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0012, std: 1.3984
  Model pred mean: -0.0020, std: 1.1250
  Sigmas: [0.57421875]... (timesteps: [575.0])

[Step 1990] Training Debug Info:
  Loss: 0.431310
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0122, std: 0.9258
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0140, std: 1.3594
  Model pred mean: 0.0147, std: 1.1953
  Sigmas: [0.70703125]... (timesteps: [707.0])
Steps:  40%|███▉      | 1991/5000 [7:22:35<9:59:22, 11.95s/it, loss=1.0264, lr=7.53e-06] Steps:  40%|███▉      | 1991/5000 [7:22:35<9:59:22, 11.95s/it, loss=0.4313, lr=7.53e-06]Steps:  40%|███▉      | 1992/5000 [7:22:46<9:57:59, 11.93s/it, loss=0.4313, lr=7.53e-06]Steps:  40%|███▉      | 1992/5000 [7:22:46<9:57:59, 11.93s/it, loss=0.5602, lr=7.52e-06]Steps:  40%|███▉      | 1993/5000 [7:22:58<9:57:57, 11.93s/it, loss=0.5602, lr=7.52e-06]Steps:  40%|███▉      | 1993/5000 [7:22:58<9:57:57, 11.93s/it, loss=0.5958, lr=7.52e-06]Steps:  40%|███▉      | 1994/5000 [7:23:10<9:56:43, 11.91s/it, loss=0.5958, lr=7.52e-06]Steps:  40%|███▉      | 1994/5000 [7:23:10<9:56:43, 11.91s/it, loss=0.5797, lr=7.52e-06]Steps:  40%|███▉      | 1995/5000 [7:23:22<10:00:52, 12.00s/it, loss=0.5797, lr=7.52e-06]Steps:  40%|███▉      | 1995/5000 [7:23:22<10:00:52, 12.00s/it, loss=0.8676, lr=7.52e-06]Steps:  40%|███▉      | 1996/5000 [7:23:34<10:01:03, 12.01s/it, loss=0.8676, lr=7.52e-06]Steps:  40%|███▉      | 1996/5000 [7:23:34<10:01:03, 12.01s/it, loss=0.9364, lr=7.51e-06]Steps:  40%|███▉      | 1997/5000 [7:23:46<9:59:13, 11.97s/it, loss=0.9364, lr=7.51e-06] Steps:  40%|███▉      | 1997/5000 [7:23:46<9:59:13, 11.97s/it, loss=0.4539, lr=7.51e-06]Steps:  40%|███▉      | 1998/5000 [7:23:58<9:58:46, 11.97s/it, loss=0.4539, lr=7.51e-06]Steps:  40%|███▉      | 1998/5000 [7:23:58<9:58:46, 11.97s/it, loss=0.6469, lr=7.51e-06]Steps:  40%|███▉      | 1999/5000 [7:24:10<9:59:08, 11.98s/it, loss=0.6469, lr=7.51e-06]Steps:  40%|███▉      | 1999/5000 [7:24:10<9:59:08, 11.98s/it, loss=0.7105, lr=7.50e-06]Steps:  40%|████      | 2000/5000 [7:24:22<10:00:13, 12.00s/it, loss=0.7105, lr=7.50e-06]Steps:  40%|████      | 2000/5000 [7:24:22<10:00:13, 12.00s/it, loss=0.5833, lr=7.50e-06]01/22/2026 15:10:09 - INFO - __main__ - 
[Step 2000] ✅ Loss in normal range (0.5833)
01/22/2026 15:10:09 - INFO - __main__ -   Loss avg (last 100): 0.7276
01/22/2026 15:10:09 - INFO - __main__ -   Loss range: [0.3501, 1.1840]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/transformer/diffusion_pytorch_model.safetensors
01/22/2026 15:10:58 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000
01/22/2026 15:10:58 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/accelerator
01/22/2026 15:10:58 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/22/2026 15:12:51 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/accelerator/pytorch_model
01/22/2026 15:12:51 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/accelerator/scheduler.bin
01/22/2026 15:12:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/accelerator/sampler.bin
01/22/2026 15:12:51 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-2000/accelerator/random_states_0.pkl
01/22/2026 15:12:51 - INFO - __main__ - 
🔍 Running validation at step 2000...
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2000 (parquet mode)...
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2000...
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 15:12:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.50it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 15:13:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 15:13:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 15:13:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 15:13:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 15:13:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 15:13:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 15:14:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 15:14:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 15:14:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 15:14:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 15:14:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 15:14:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 15:15:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 15:15:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 15:15:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 15:15:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 15:15:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 15:15:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 15:16:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 15:16:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 15:16:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 15:16:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 15:16:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000/step002000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 15:16:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 15:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 15:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002000
01/22/2026 15:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 2000] Training Debug Info:
  Loss: 0.364790
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0096, std: 0.9375
  Noise mean: -0.0006, std: 0.9961
  Target mean: -0.0103, std: 1.3672
  Model pred mean: -0.0134, std: 1.2266
  Sigmas: [0.80859375]... (timesteps: [810.0])

[Step 2000] Training Debug Info:
  Loss: 1.163787
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0193, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0209, std: 1.3281
  Model pred mean: 0.0109, std: 0.7734
  Sigmas: [0.1240234375]... (timesteps: [124.0])

[Step 2000] Training Debug Info:
  Loss: 0.968070
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0183, std: 0.8711
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0168, std: 1.3281
  Model pred mean: 0.0151, std: 0.8906
  Sigmas: [0.3984375]... (timesteps: [399.0])

[Step 2000] Training Debug Info:
  Loss: 0.408889
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0027, std: 0.9023
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0003, std: 1.3438
  Model pred mean: -0.0009, std: 1.1875
  Sigmas: [0.8359375]... (timesteps: [835.0])
Steps:  40%|████      | 2001/5000 [7:31:29<113:36:37, 136.38s/it, loss=0.5833, lr=7.50e-06]Steps:  40%|████      | 2001/5000 [7:31:29<113:36:37, 136.38s/it, loss=0.4089, lr=7.50e-06]Steps:  40%|████      | 2002/5000 [7:31:41<82:30:52, 99.08s/it, loss=0.4089, lr=7.50e-06]  Steps:  40%|████      | 2002/5000 [7:31:41<82:30:52, 99.08s/it, loss=1.1161, lr=7.49e-06]Steps:  40%|████      | 2003/5000 [7:31:53<60:42:43, 72.93s/it, loss=1.1161, lr=7.49e-06]Steps:  40%|████      | 2003/5000 [7:31:53<60:42:43, 72.93s/it, loss=0.5127, lr=7.49e-06]Steps:  40%|████      | 2004/5000 [7:32:05<45:28:05, 54.63s/it, loss=0.5127, lr=7.49e-06]Steps:  40%|████      | 2004/5000 [7:32:05<45:28:05, 54.63s/it, loss=1.1639, lr=7.49e-06]Steps:  40%|████      | 2005/5000 [7:32:17<34:49:01, 41.85s/it, loss=1.1639, lr=7.49e-06]Steps:  40%|████      | 2005/5000 [7:32:17<34:49:01, 41.85s/it, loss=1.0593, lr=7.48e-06]Steps:  40%|████      | 2006/5000 [7:32:29<27:20:38, 32.88s/it, loss=1.0593, lr=7.48e-06]Steps:  40%|████      | 2006/5000 [7:32:29<27:20:38, 32.88s/it, loss=0.6873, lr=7.48e-06]Steps:  40%|████      | 2007/5000 [7:32:41<22:07:22, 26.61s/it, loss=0.6873, lr=7.48e-06]Steps:  40%|████      | 2007/5000 [7:32:41<22:07:22, 26.61s/it, loss=1.1692, lr=7.48e-06]Steps:  40%|████      | 2008/5000 [7:32:53<18:27:42, 22.21s/it, loss=1.1692, lr=7.48e-06]Steps:  40%|████      | 2008/5000 [7:32:53<18:27:42, 22.21s/it, loss=0.5285, lr=7.48e-06]Steps:  40%|████      | 2009/5000 [7:33:05<15:55:59, 19.18s/it, loss=0.5285, lr=7.48e-06]Steps:  40%|████      | 2009/5000 [7:33:05<15:55:59, 19.18s/it, loss=0.3757, lr=7.47e-06]Steps:  40%|████      | 2010/5000 [7:33:17<14:06:34, 16.99s/it, loss=0.3757, lr=7.47e-06]Steps:  40%|████      | 2010/5000 [7:33:17<14:06:34, 16.99s/it, loss=1.1169, lr=7.47e-06]
[Step 2010] Training Debug Info:
  Loss: 0.762248
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0359, std: 0.9258
  Noise mean: -0.0021, std: 0.9961
  Target mean: -0.0381, std: 1.3594
  Model pred mean: -0.0347, std: 1.0469
  Sigmas: [0.423828125]... (timesteps: [424.0])

[Step 2010] Training Debug Info:
  Loss: 0.786825
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0327, std: 0.9648
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0330, std: 1.3906
  Model pred mean: -0.0056, std: 1.0703
  Sigmas: [0.96875]... (timesteps: [970.0])

[Step 2010] Training Debug Info:
  Loss: 0.449414
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0522, std: 0.9453
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0530, std: 1.3750
  Model pred mean: -0.0417, std: 1.1953
  Sigmas: [0.87109375]... (timesteps: [870.0])

[Step 2010] Training Debug Info:
  Loss: 0.564094
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0000, std: 0.8672
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0003, std: 1.3203
  Model pred mean: -0.0004, std: 1.0859
  Sigmas: [0.62890625]... (timesteps: [627.0])
Steps:  40%|████      | 2011/5000 [7:33:29<12:50:22, 15.46s/it, loss=1.1169, lr=7.47e-06]Steps:  40%|████      | 2011/5000 [7:33:29<12:50:22, 15.46s/it, loss=0.5641, lr=7.47e-06]Steps:  40%|████      | 2012/5000 [7:33:41<11:57:24, 14.41s/it, loss=0.5641, lr=7.47e-06]Steps:  40%|████      | 2012/5000 [7:33:41<11:57:24, 14.41s/it, loss=1.0495, lr=7.46e-06]Steps:  40%|████      | 2013/5000 [7:33:52<11:19:46, 13.65s/it, loss=1.0495, lr=7.46e-06]Steps:  40%|████      | 2013/5000 [7:33:52<11:19:46, 13.65s/it, loss=0.8840, lr=7.46e-06]Steps:  40%|████      | 2014/5000 [7:34:05<10:55:20, 13.17s/it, loss=0.8840, lr=7.46e-06]Steps:  40%|████      | 2014/5000 [7:34:05<10:55:20, 13.17s/it, loss=1.0096, lr=7.46e-06]Steps:  40%|████      | 2015/5000 [7:34:16<10:36:26, 12.79s/it, loss=1.0096, lr=7.46e-06]Steps:  40%|████      | 2015/5000 [7:34:16<10:36:26, 12.79s/it, loss=1.0823, lr=7.45e-06]Steps:  40%|████      | 2016/5000 [7:34:28<10:25:14, 12.57s/it, loss=1.0823, lr=7.45e-06]Steps:  40%|████      | 2016/5000 [7:34:28<10:25:14, 12.57s/it, loss=0.9822, lr=7.45e-06]Steps:  40%|████      | 2017/5000 [7:34:40<10:15:49, 12.39s/it, loss=0.9822, lr=7.45e-06]Steps:  40%|████      | 2017/5000 [7:34:40<10:15:49, 12.39s/it, loss=0.3564, lr=7.45e-06]Steps:  40%|████      | 2018/5000 [7:34:52<10:07:54, 12.23s/it, loss=0.3564, lr=7.45e-06]Steps:  40%|████      | 2018/5000 [7:34:52<10:07:54, 12.23s/it, loss=0.4639, lr=7.45e-06]Steps:  40%|████      | 2019/5000 [7:35:04<10:03:47, 12.15s/it, loss=0.4639, lr=7.45e-06]Steps:  40%|████      | 2019/5000 [7:35:04<10:03:47, 12.15s/it, loss=1.0261, lr=7.44e-06]Steps:  40%|████      | 2020/5000 [7:35:16<9:58:51, 12.06s/it, loss=1.0261, lr=7.44e-06] Steps:  40%|████      | 2020/5000 [7:35:16<9:58:51, 12.06s/it, loss=0.4694, lr=7.44e-06]
[Step 2020] Training Debug Info:
  Loss: 0.450238
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0003, std: 0.9297
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0014, std: 1.3672
  Model pred mean: -0.0115, std: 1.1953
  Sigmas: [0.90234375]... (timesteps: [904.0])

[Step 2020] Training Debug Info:
  Loss: 0.414696
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0217, std: 0.9727
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0234, std: 1.3906
  Model pred mean: -0.0282, std: 1.2344
  Sigmas: [0.796875]... (timesteps: [796.0])

[Step 2020] Training Debug Info:
  Loss: 1.110730
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0032, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0041, std: 1.3516
  Model pred mean: -0.0028, std: 0.8477
  Sigmas: [0.2734375]... (timesteps: [274.0])

[Step 2020] Training Debug Info:
  Loss: 0.963840
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0062, std: 0.8750
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0079, std: 1.3281
  Model pred mean: -0.0096, std: 0.8984
  Sigmas: [0.390625]... (timesteps: [391.0])
Steps:  40%|████      | 2021/5000 [7:35:28<9:55:12, 11.99s/it, loss=0.4694, lr=7.44e-06]Steps:  40%|████      | 2021/5000 [7:35:28<9:55:12, 11.99s/it, loss=0.9638, lr=7.44e-06]Steps:  40%|████      | 2022/5000 [7:35:40<9:57:06, 12.03s/it, loss=0.9638, lr=7.44e-06]Steps:  40%|████      | 2022/5000 [7:35:40<9:57:06, 12.03s/it, loss=0.4819, lr=7.43e-06]Steps:  40%|████      | 2023/5000 [7:35:52<9:54:54, 11.99s/it, loss=0.4819, lr=7.43e-06]Steps:  40%|████      | 2023/5000 [7:35:52<9:54:54, 11.99s/it, loss=0.4802, lr=7.43e-06]Steps:  40%|████      | 2024/5000 [7:36:04<9:55:48, 12.01s/it, loss=0.4802, lr=7.43e-06]Steps:  40%|████      | 2024/5000 [7:36:04<9:55:48, 12.01s/it, loss=0.5012, lr=7.43e-06]Steps:  40%|████      | 2025/5000 [7:36:16<9:54:06, 11.98s/it, loss=0.5012, lr=7.43e-06]Steps:  40%|████      | 2025/5000 [7:36:16<9:54:06, 11.98s/it, loss=1.0361, lr=7.42e-06]Steps:  41%|████      | 2026/5000 [7:36:28<9:52:54, 11.96s/it, loss=1.0361, lr=7.42e-06]Steps:  41%|████      | 2026/5000 [7:36:28<9:52:54, 11.96s/it, loss=0.4565, lr=7.42e-06]Steps:  41%|████      | 2027/5000 [7:36:40<9:52:27, 11.96s/it, loss=0.4565, lr=7.42e-06]Steps:  41%|████      | 2027/5000 [7:36:40<9:52:27, 11.96s/it, loss=0.5934, lr=7.42e-06]Steps:  41%|████      | 2028/5000 [7:36:52<9:51:16, 11.94s/it, loss=0.5934, lr=7.42e-06]Steps:  41%|████      | 2028/5000 [7:36:52<9:51:16, 11.94s/it, loss=1.0955, lr=7.41e-06]Steps:  41%|████      | 2029/5000 [7:37:04<9:52:38, 11.97s/it, loss=1.0955, lr=7.41e-06]Steps:  41%|████      | 2029/5000 [7:37:04<9:52:38, 11.97s/it, loss=0.6079, lr=7.41e-06]Steps:  41%|████      | 2030/5000 [7:37:16<9:51:55, 11.96s/it, loss=0.6079, lr=7.41e-06]Steps:  41%|████      | 2030/5000 [7:37:16<9:51:55, 11.96s/it, loss=1.0624, lr=7.41e-06]
[Step 2030] Training Debug Info:
  Loss: 1.096244
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0197, std: 0.9297
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0187, std: 1.3672
  Model pred mean: -0.0198, std: 0.8750
  Sigmas: [0.1591796875]... (timesteps: [159.0])

[Step 2030] Training Debug Info:
  Loss: 1.125342
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0245, std: 0.9766
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0233, std: 1.3984
  Model pred mean: -0.0234, std: 0.9141
  Sigmas: [0.0849609375]... (timesteps: [85.0])

[Step 2030] Training Debug Info:
  Loss: 1.110309
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0010, std: 0.8906
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0001, std: 1.3359
  Model pred mean: 0.0003, std: 0.8281
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 2030] Training Debug Info:
  Loss: 0.880100
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0176, std: 0.9336
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0164, std: 1.3672
  Model pred mean: 0.0184, std: 1.0000
  Sigmas: [0.38671875]... (timesteps: [386.0])
Steps:  41%|████      | 2031/5000 [7:37:28<9:50:15, 11.93s/it, loss=1.0624, lr=7.41e-06]Steps:  41%|████      | 2031/5000 [7:37:28<9:50:15, 11.93s/it, loss=0.8801, lr=7.41e-06]Steps:  41%|████      | 2032/5000 [7:37:39<9:49:59, 11.93s/it, loss=0.8801, lr=7.41e-06]Steps:  41%|████      | 2032/5000 [7:37:39<9:49:59, 11.93s/it, loss=1.0397, lr=7.40e-06]Steps:  41%|████      | 2033/5000 [7:37:51<9:51:05, 11.95s/it, loss=1.0397, lr=7.40e-06]Steps:  41%|████      | 2033/5000 [7:37:51<9:51:05, 11.95s/it, loss=1.0153, lr=7.40e-06]Steps:  41%|████      | 2034/5000 [7:38:03<9:50:31, 11.95s/it, loss=1.0153, lr=7.40e-06]Steps:  41%|████      | 2034/5000 [7:38:03<9:50:31, 11.95s/it, loss=1.0775, lr=7.40e-06]Steps:  41%|████      | 2035/5000 [7:38:15<9:50:19, 11.95s/it, loss=1.0775, lr=7.40e-06]Steps:  41%|████      | 2035/5000 [7:38:15<9:50:19, 11.95s/it, loss=1.1695, lr=7.39e-06]Steps:  41%|████      | 2036/5000 [7:38:27<9:51:39, 11.98s/it, loss=1.1695, lr=7.39e-06]Steps:  41%|████      | 2036/5000 [7:38:27<9:51:39, 11.98s/it, loss=0.9579, lr=7.39e-06]Steps:  41%|████      | 2037/5000 [7:38:39<9:50:36, 11.96s/it, loss=0.9579, lr=7.39e-06]Steps:  41%|████      | 2037/5000 [7:38:39<9:50:36, 11.96s/it, loss=0.5589, lr=7.39e-06]Steps:  41%|████      | 2038/5000 [7:38:51<9:50:47, 11.97s/it, loss=0.5589, lr=7.39e-06]Steps:  41%|████      | 2038/5000 [7:38:51<9:50:47, 11.97s/it, loss=1.0633, lr=7.38e-06]Steps:  41%|████      | 2039/5000 [7:39:03<9:50:33, 11.97s/it, loss=1.0633, lr=7.38e-06]Steps:  41%|████      | 2039/5000 [7:39:03<9:50:33, 11.97s/it, loss=1.0335, lr=7.38e-06]Steps:  41%|████      | 2040/5000 [7:39:15<9:50:31, 11.97s/it, loss=1.0335, lr=7.38e-06]Steps:  41%|████      | 2040/5000 [7:39:15<9:50:31, 11.97s/it, loss=0.5781, lr=7.38e-06]
[Step 2040] Training Debug Info:
  Loss: 1.110896
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0177, std: 0.8945
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0183, std: 1.3438
  Model pred mean: -0.0162, std: 0.8320
  Sigmas: [0.267578125]... (timesteps: [267.0])

[Step 2040] Training Debug Info:
  Loss: 1.143697
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0128, std: 0.9023
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0128, std: 1.3438
  Model pred mean: -0.0106, std: 0.8125
  Sigmas: [0.10302734375]... (timesteps: [103.0])

[Step 2040] Training Debug Info:
  Loss: 0.464598
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0141, std: 0.8984
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0142, std: 1.3438
  Model pred mean: -0.0057, std: 1.1641
  Sigmas: [0.9140625]... (timesteps: [916.0])

[Step 2040] Training Debug Info:
  Loss: 0.437259
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0139, std: 0.9180
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0142, std: 1.3594
  Model pred mean: -0.0132, std: 1.1875
  Sigmas: [0.74609375]... (timesteps: [748.0])
Steps:  41%|████      | 2041/5000 [7:39:27<9:51:29, 11.99s/it, loss=0.5781, lr=7.38e-06]Steps:  41%|████      | 2041/5000 [7:39:27<9:51:29, 11.99s/it, loss=0.4373, lr=7.38e-06]Steps:  41%|████      | 2042/5000 [7:39:39<9:53:59, 12.05s/it, loss=0.4373, lr=7.38e-06]Steps:  41%|████      | 2042/5000 [7:39:39<9:53:59, 12.05s/it, loss=0.4589, lr=7.37e-06]Steps:  41%|████      | 2043/5000 [7:39:52<9:55:50, 12.09s/it, loss=0.4589, lr=7.37e-06]Steps:  41%|████      | 2043/5000 [7:39:52<9:55:50, 12.09s/it, loss=0.5291, lr=7.37e-06]Steps:  41%|████      | 2044/5000 [7:40:04<9:54:10, 12.06s/it, loss=0.5291, lr=7.37e-06]Steps:  41%|████      | 2044/5000 [7:40:04<9:54:10, 12.06s/it, loss=0.6903, lr=7.37e-06]Steps:  41%|████      | 2045/5000 [7:40:16<9:53:28, 12.05s/it, loss=0.6903, lr=7.37e-06]Steps:  41%|████      | 2045/5000 [7:40:16<9:53:28, 12.05s/it, loss=0.3821, lr=7.36e-06]Steps:  41%|████      | 2046/5000 [7:40:28<9:51:59, 12.02s/it, loss=0.3821, lr=7.36e-06]Steps:  41%|████      | 2046/5000 [7:40:28<9:51:59, 12.02s/it, loss=0.3950, lr=7.36e-06]Steps:  41%|████      | 2047/5000 [7:40:39<9:49:33, 11.98s/it, loss=0.3950, lr=7.36e-06]Steps:  41%|████      | 2047/5000 [7:40:39<9:49:33, 11.98s/it, loss=0.5431, lr=7.36e-06]Steps:  41%|████      | 2048/5000 [7:40:52<9:50:29, 12.00s/it, loss=0.5431, lr=7.36e-06]Steps:  41%|████      | 2048/5000 [7:40:52<9:50:29, 12.00s/it, loss=0.5616, lr=7.35e-06]Steps:  41%|████      | 2049/5000 [7:41:04<9:52:11, 12.04s/it, loss=0.5616, lr=7.35e-06]Steps:  41%|████      | 2049/5000 [7:41:04<9:52:11, 12.04s/it, loss=0.8097, lr=7.35e-06]Steps:  41%|████      | 2050/5000 [7:41:16<9:53:04, 12.06s/it, loss=0.8097, lr=7.35e-06]Steps:  41%|████      | 2050/5000 [7:41:16<9:53:04, 12.06s/it, loss=0.5788, lr=7.35e-06]
[Step 2050] Training Debug Info:
  Loss: 0.439759
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0021, std: 0.9531
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0039, std: 1.3828
  Model pred mean: -0.0053, std: 1.2109
  Sigmas: [0.84375]... (timesteps: [843.0])

[Step 2050] Training Debug Info:
  Loss: 0.387627
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0089, std: 0.9414
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0103, std: 1.3750
  Model pred mean: -0.0063, std: 1.2188
  Sigmas: [0.75390625]... (timesteps: [752.0])

[Step 2050] Training Debug Info:
  Loss: 0.501235
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0039, std: 0.8789
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0005, std: 1.3359
  Model pred mean: -0.0049, std: 1.1250
  Sigmas: [0.67578125]... (timesteps: [675.0])

[Step 2050] Training Debug Info:
  Loss: 0.541819
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0315, std: 0.9375
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0315, std: 1.3672
  Model pred mean: -0.0334, std: 1.1562
  Sigmas: [0.58984375]... (timesteps: [591.0])
Steps:  41%|████      | 2051/5000 [7:41:28<9:50:46, 12.02s/it, loss=0.5788, lr=7.35e-06]Steps:  41%|████      | 2051/5000 [7:41:28<9:50:46, 12.02s/it, loss=0.5418, lr=7.34e-06]Steps:  41%|████      | 2052/5000 [7:41:40<9:48:55, 11.99s/it, loss=0.5418, lr=7.34e-06]Steps:  41%|████      | 2052/5000 [7:41:40<9:48:55, 11.99s/it, loss=0.3696, lr=7.34e-06]Steps:  41%|████      | 2053/5000 [7:41:52<9:47:33, 11.96s/it, loss=0.3696, lr=7.34e-06]Steps:  41%|████      | 2053/5000 [7:41:52<9:47:33, 11.96s/it, loss=1.1695, lr=7.34e-06]Steps:  41%|████      | 2054/5000 [7:42:03<9:46:46, 11.95s/it, loss=1.1695, lr=7.34e-06]Steps:  41%|████      | 2054/5000 [7:42:03<9:46:46, 11.95s/it, loss=0.8356, lr=7.34e-06]Steps:  41%|████      | 2055/5000 [7:42:15<9:46:29, 11.95s/it, loss=0.8356, lr=7.34e-06]Steps:  41%|████      | 2055/5000 [7:42:15<9:46:29, 11.95s/it, loss=0.4395, lr=7.33e-06]Steps:  41%|████      | 2056/5000 [7:42:27<9:47:45, 11.98s/it, loss=0.4395, lr=7.33e-06]Steps:  41%|████      | 2056/5000 [7:42:27<9:47:45, 11.98s/it, loss=1.0809, lr=7.33e-06]Steps:  41%|████      | 2057/5000 [7:42:39<9:45:52, 11.94s/it, loss=1.0809, lr=7.33e-06]Steps:  41%|████      | 2057/5000 [7:42:39<9:45:52, 11.94s/it, loss=1.0420, lr=7.33e-06]Steps:  41%|████      | 2058/5000 [7:42:51<9:46:00, 11.95s/it, loss=1.0420, lr=7.33e-06]Steps:  41%|████      | 2058/5000 [7:42:51<9:46:00, 11.95s/it, loss=1.0526, lr=7.32e-06]Steps:  41%|████      | 2059/5000 [7:43:03<9:46:38, 11.97s/it, loss=1.0526, lr=7.32e-06]Steps:  41%|████      | 2059/5000 [7:43:03<9:46:38, 11.97s/it, loss=0.6277, lr=7.32e-06]Steps:  41%|████      | 2060/5000 [7:43:15<9:45:32, 11.95s/it, loss=0.6277, lr=7.32e-06]Steps:  41%|████      | 2060/5000 [7:43:15<9:45:32, 11.95s/it, loss=0.3844, lr=7.32e-06]
[Step 2060] Training Debug Info:
  Loss: 0.671259
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0237, std: 0.9102
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0220, std: 1.3516
  Model pred mean: -0.0203, std: 1.0781
  Sigmas: [0.48046875]... (timesteps: [480.0])

[Step 2060] Training Debug Info:
  Loss: 1.083407
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0532, std: 0.9414
  Noise mean: -0.0022, std: 0.9961
  Target mean: -0.0554, std: 1.3750
  Model pred mean: -0.0505, std: 0.8984
  Sigmas: [0.09912109375]... (timesteps: [99.0])

[Step 2060] Training Debug Info:
  Loss: 0.988200
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0182, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0170, std: 1.3516
  Model pred mean: 0.0228, std: 0.9141
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 2060] Training Debug Info:
  Loss: 0.754296
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0383, std: 0.9297
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0413, std: 1.3672
  Model pred mean: -0.0337, std: 1.0547
  Sigmas: [0.4296875]... (timesteps: [430.0])
Steps:  41%|████      | 2061/5000 [7:43:27<9:45:09, 11.95s/it, loss=0.3844, lr=7.32e-06]Steps:  41%|████      | 2061/5000 [7:43:27<9:45:09, 11.95s/it, loss=0.7543, lr=7.31e-06]Steps:  41%|████      | 2062/5000 [7:43:39<9:44:27, 11.94s/it, loss=0.7543, lr=7.31e-06]Steps:  41%|████      | 2062/5000 [7:43:39<9:44:27, 11.94s/it, loss=1.1355, lr=7.31e-06]Steps:  41%|████▏     | 2063/5000 [7:43:51<9:46:15, 11.98s/it, loss=1.1355, lr=7.31e-06]Steps:  41%|████▏     | 2063/5000 [7:43:51<9:46:15, 11.98s/it, loss=0.4888, lr=7.31e-06]Steps:  41%|████▏     | 2064/5000 [7:44:03<9:44:55, 11.95s/it, loss=0.4888, lr=7.31e-06]Steps:  41%|████▏     | 2064/5000 [7:44:03<9:44:55, 11.95s/it, loss=1.1120, lr=7.30e-06]Steps:  41%|████▏     | 2065/5000 [7:44:15<9:45:18, 11.97s/it, loss=1.1120, lr=7.30e-06]Steps:  41%|████▏     | 2065/5000 [7:44:15<9:45:18, 11.97s/it, loss=1.1130, lr=7.30e-06]Steps:  41%|████▏     | 2066/5000 [7:44:27<9:43:56, 11.94s/it, loss=1.1130, lr=7.30e-06]Steps:  41%|████▏     | 2066/5000 [7:44:27<9:43:56, 11.94s/it, loss=0.5308, lr=7.30e-06]Steps:  41%|████▏     | 2067/5000 [7:44:39<9:43:31, 11.94s/it, loss=0.5308, lr=7.30e-06]Steps:  41%|████▏     | 2067/5000 [7:44:39<9:43:31, 11.94s/it, loss=0.4432, lr=7.29e-06]Steps:  41%|████▏     | 2068/5000 [7:44:51<9:44:43, 11.97s/it, loss=0.4432, lr=7.29e-06]Steps:  41%|████▏     | 2068/5000 [7:44:51<9:44:43, 11.97s/it, loss=0.4079, lr=7.29e-06]Steps:  41%|████▏     | 2069/5000 [7:45:03<9:45:31, 11.99s/it, loss=0.4079, lr=7.29e-06]Steps:  41%|████▏     | 2069/5000 [7:45:03<9:45:31, 11.99s/it, loss=0.5371, lr=7.29e-06]Steps:  41%|████▏     | 2070/5000 [7:45:15<9:47:53, 12.04s/it, loss=0.5371, lr=7.29e-06]Steps:  41%|████▏     | 2070/5000 [7:45:15<9:47:53, 12.04s/it, loss=0.4646, lr=7.29e-06]
[Step 2070] Training Debug Info:
  Loss: 0.633455
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0070, std: 0.9062
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0058, std: 1.3516
  Model pred mean: 0.0062, std: 1.0938
  Sigmas: [0.55078125]... (timesteps: [549.0])

[Step 2070] Training Debug Info:
  Loss: 0.414503
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0228, std: 0.9180
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0217, std: 1.3594
  Model pred mean: -0.0179, std: 1.1875
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 2070] Training Debug Info:
  Loss: 0.390102
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0095, std: 0.9180
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0074, std: 1.3594
  Model pred mean: 0.0112, std: 1.2031
  Sigmas: [0.828125]... (timesteps: [829.0])

[Step 2070] Training Debug Info:
  Loss: 0.822845
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0265, std: 0.9180
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0258, std: 1.3594
  Model pred mean: -0.0278, std: 1.0078
  Sigmas: [0.390625]... (timesteps: [391.0])
Steps:  41%|████▏     | 2071/5000 [7:45:27<9:45:48, 12.00s/it, loss=0.4646, lr=7.29e-06]Steps:  41%|████▏     | 2071/5000 [7:45:27<9:45:48, 12.00s/it, loss=0.8228, lr=7.28e-06]Steps:  41%|████▏     | 2072/5000 [7:45:39<9:48:02, 12.05s/it, loss=0.8228, lr=7.28e-06]Steps:  41%|████▏     | 2072/5000 [7:45:39<9:48:02, 12.05s/it, loss=1.0998, lr=7.28e-06]Steps:  41%|████▏     | 2073/5000 [7:45:51<9:47:05, 12.03s/it, loss=1.0998, lr=7.28e-06]Steps:  41%|████▏     | 2073/5000 [7:45:51<9:47:05, 12.03s/it, loss=1.1102, lr=7.28e-06]Steps:  41%|████▏     | 2074/5000 [7:46:03<9:45:44, 12.01s/it, loss=1.1102, lr=7.28e-06]Steps:  41%|████▏     | 2074/5000 [7:46:03<9:45:44, 12.01s/it, loss=1.1293, lr=7.27e-06]Steps:  42%|████▏     | 2075/5000 [7:46:15<9:43:21, 11.97s/it, loss=1.1293, lr=7.27e-06]Steps:  42%|████▏     | 2075/5000 [7:46:15<9:43:21, 11.97s/it, loss=0.3594, lr=7.27e-06]Steps:  42%|████▏     | 2076/5000 [7:46:27<9:44:09, 11.99s/it, loss=0.3594, lr=7.27e-06]Steps:  42%|████▏     | 2076/5000 [7:46:27<9:44:09, 11.99s/it, loss=0.9513, lr=7.27e-06]Steps:  42%|████▏     | 2077/5000 [7:46:39<9:44:37, 12.00s/it, loss=0.9513, lr=7.27e-06]Steps:  42%|████▏     | 2077/5000 [7:46:39<9:44:37, 12.00s/it, loss=1.0948, lr=7.26e-06]Steps:  42%|████▏     | 2078/5000 [7:46:51<9:43:19, 11.98s/it, loss=1.0948, lr=7.26e-06]Steps:  42%|████▏     | 2078/5000 [7:46:51<9:43:19, 11.98s/it, loss=1.0472, lr=7.26e-06]Steps:  42%|████▏     | 2079/5000 [7:47:03<9:45:54, 12.04s/it, loss=1.0472, lr=7.26e-06]Steps:  42%|████▏     | 2079/5000 [7:47:03<9:45:54, 12.04s/it, loss=1.1728, lr=7.26e-06]Steps:  42%|████▏     | 2080/5000 [7:47:15<9:43:35, 11.99s/it, loss=1.1728, lr=7.26e-06]Steps:  42%|████▏     | 2080/5000 [7:47:15<9:43:35, 11.99s/it, loss=0.7829, lr=7.25e-06]
[Step 2080] Training Debug Info:
  Loss: 1.046482
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0166, std: 0.9219
  Noise mean: 0.0054, std: 1.0000
  Target mean: -0.0111, std: 1.3594
  Model pred mean: -0.0172, std: 0.8945
  Sigmas: [0.2255859375]... (timesteps: [226.0])

[Step 2080] Training Debug Info:
  Loss: 1.092077
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0101, std: 0.9062
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0109, std: 1.3516
  Model pred mean: -0.0119, std: 0.8555
  Sigmas: [0.06201171875]... (timesteps: [62.0])

[Step 2080] Training Debug Info:
  Loss: 0.711332
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0371, std: 0.9570
  Noise mean: 0.0029, std: 1.0000
  Target mean: -0.0342, std: 1.3828
  Model pred mean: -0.0369, std: 1.0938
  Sigmas: [0.48828125]... (timesteps: [489.0])

[Step 2080] Training Debug Info:
  Loss: 0.507780
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0135, std: 0.9219
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0142, std: 1.3594
  Model pred mean: -0.0179, std: 1.1641
  Sigmas: [0.6875]... (timesteps: [686.0])
Steps:  42%|████▏     | 2081/5000 [7:47:27<9:43:09, 11.99s/it, loss=0.7829, lr=7.25e-06]Steps:  42%|████▏     | 2081/5000 [7:47:27<9:43:09, 11.99s/it, loss=0.5078, lr=7.25e-06]Steps:  42%|████▏     | 2082/5000 [7:47:39<9:41:30, 11.96s/it, loss=0.5078, lr=7.25e-06]Steps:  42%|████▏     | 2082/5000 [7:47:39<9:41:30, 11.96s/it, loss=0.4481, lr=7.25e-06]Steps:  42%|████▏     | 2083/5000 [7:47:51<9:43:55, 12.01s/it, loss=0.4481, lr=7.25e-06]Steps:  42%|████▏     | 2083/5000 [7:47:51<9:43:55, 12.01s/it, loss=1.1776, lr=7.25e-06]Steps:  42%|████▏     | 2084/5000 [7:48:03<9:42:02, 11.98s/it, loss=1.1776, lr=7.25e-06]Steps:  42%|████▏     | 2084/5000 [7:48:03<9:42:02, 11.98s/it, loss=0.4556, lr=7.24e-06]Steps:  42%|████▏     | 2085/5000 [7:48:15<9:41:48, 11.98s/it, loss=0.4556, lr=7.24e-06]Steps:  42%|████▏     | 2085/5000 [7:48:15<9:41:48, 11.98s/it, loss=0.6025, lr=7.24e-06]Steps:  42%|████▏     | 2086/5000 [7:48:27<9:42:25, 11.99s/it, loss=0.6025, lr=7.24e-06]Steps:  42%|████▏     | 2086/5000 [7:48:27<9:42:25, 11.99s/it, loss=0.8592, lr=7.24e-06]Steps:  42%|████▏     | 2087/5000 [7:48:39<9:41:19, 11.97s/it, loss=0.8592, lr=7.24e-06]Steps:  42%|████▏     | 2087/5000 [7:48:39<9:41:19, 11.97s/it, loss=0.9928, lr=7.23e-06]Steps:  42%|████▏     | 2088/5000 [7:48:51<9:40:39, 11.96s/it, loss=0.9928, lr=7.23e-06]Steps:  42%|████▏     | 2088/5000 [7:48:51<9:40:39, 11.96s/it, loss=0.9867, lr=7.23e-06]Steps:  42%|████▏     | 2089/5000 [7:49:03<9:39:44, 11.95s/it, loss=0.9867, lr=7.23e-06]Steps:  42%|████▏     | 2089/5000 [7:49:03<9:39:44, 11.95s/it, loss=1.0455, lr=7.23e-06]Steps:  42%|████▏     | 2090/5000 [7:49:15<9:40:37, 11.97s/it, loss=1.0455, lr=7.23e-06]Steps:  42%|████▏     | 2090/5000 [7:49:15<9:40:37, 11.97s/it, loss=0.3964, lr=7.22e-06]
[Step 2090] Training Debug Info:
  Loss: 0.375711
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0266, std: 0.9062
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0240, std: 1.3516
  Model pred mean: -0.0212, std: 1.2031
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 2090] Training Debug Info:
  Loss: 0.530328
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0122, std: 0.8867
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0112, std: 1.3359
  Model pred mean: -0.0071, std: 1.1250
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 2090] Training Debug Info:
  Loss: 0.955821
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0103, std: 0.9141
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0096, std: 1.3516
  Model pred mean: 0.0093, std: 0.9375
  Sigmas: [0.359375]... (timesteps: [359.0])

[Step 2090] Training Debug Info:
  Loss: 0.963259
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0102, std: 0.8945
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0115, std: 1.3438
  Model pred mean: -0.0082, std: 0.9219
  Sigmas: [0.37109375]... (timesteps: [371.0])
Steps:  42%|████▏     | 2091/5000 [7:49:27<9:38:54, 11.94s/it, loss=0.3964, lr=7.22e-06]Steps:  42%|████▏     | 2091/5000 [7:49:27<9:38:54, 11.94s/it, loss=0.9633, lr=7.22e-06]Steps:  42%|████▏     | 2092/5000 [7:49:39<9:38:44, 11.94s/it, loss=0.9633, lr=7.22e-06]Steps:  42%|████▏     | 2092/5000 [7:49:39<9:38:44, 11.94s/it, loss=0.5146, lr=7.22e-06]Steps:  42%|████▏     | 2093/5000 [7:49:50<9:38:47, 11.95s/it, loss=0.5146, lr=7.22e-06]Steps:  42%|████▏     | 2093/5000 [7:49:50<9:38:47, 11.95s/it, loss=0.9790, lr=7.21e-06]Steps:  42%|████▏     | 2094/5000 [7:50:02<9:38:05, 11.94s/it, loss=0.9790, lr=7.21e-06]Steps:  42%|████▏     | 2094/5000 [7:50:02<9:38:05, 11.94s/it, loss=0.8750, lr=7.21e-06]Steps:  42%|████▏     | 2095/5000 [7:50:14<9:40:23, 11.99s/it, loss=0.8750, lr=7.21e-06]Steps:  42%|████▏     | 2095/5000 [7:50:14<9:40:23, 11.99s/it, loss=1.1054, lr=7.21e-06]Steps:  42%|████▏     | 2096/5000 [7:50:26<9:38:28, 11.95s/it, loss=1.1054, lr=7.21e-06]Steps:  42%|████▏     | 2096/5000 [7:50:26<9:38:28, 11.95s/it, loss=0.9751, lr=7.20e-06]Steps:  42%|████▏     | 2097/5000 [7:50:38<9:39:27, 11.98s/it, loss=0.9751, lr=7.20e-06]Steps:  42%|████▏     | 2097/5000 [7:50:38<9:39:27, 11.98s/it, loss=1.1649, lr=7.20e-06]Steps:  42%|████▏     | 2098/5000 [7:50:50<9:38:13, 11.96s/it, loss=1.1649, lr=7.20e-06]Steps:  42%|████▏     | 2098/5000 [7:50:50<9:38:13, 11.96s/it, loss=0.6718, lr=7.20e-06]Steps:  42%|████▏     | 2099/5000 [7:51:02<9:37:47, 11.95s/it, loss=0.6718, lr=7.20e-06]Steps:  42%|████▏     | 2099/5000 [7:51:02<9:37:47, 11.95s/it, loss=1.0597, lr=7.19e-06]Steps:  42%|████▏     | 2100/5000 [7:51:14<9:38:12, 11.96s/it, loss=1.0597, lr=7.19e-06]Steps:  42%|████▏     | 2100/5000 [7:51:14<9:38:12, 11.96s/it, loss=0.6230, lr=7.19e-06]01/22/2026 15:37:01 - INFO - __main__ - 
[Step 2100] ✅ Loss in normal range (0.6230)
01/22/2026 15:37:01 - INFO - __main__ -   Loss avg (last 100): 0.7857
01/22/2026 15:37:01 - INFO - __main__ -   Loss range: [0.3564, 1.1776]

[Step 2100] Training Debug Info:
  Loss: 0.449906
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0155, std: 0.8828
  Noise mean: 0.0042, std: 1.0000
  Target mean: -0.0114, std: 1.3359
  Model pred mean: -0.0161, std: 1.1562
  Sigmas: [0.76171875]... (timesteps: [762.0])

[Step 2100] Training Debug Info:
  Loss: 1.162192
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0077, std: 0.8906
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0066, std: 1.3438
  Model pred mean: 0.0100, std: 0.7930
  Sigmas: [0.1357421875]... (timesteps: [136.0])

[Step 2100] Training Debug Info:
  Loss: 0.411741
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0111, std: 0.9258
  Noise mean: 0.0035, std: 1.0000
  Target mean: 0.0146, std: 1.3672
  Model pred mean: 0.0068, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [860.0])

[Step 2100] Training Debug Info:
  Loss: 0.561737
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0135, std: 0.9492
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0145, std: 1.3828
  Model pred mean: -0.0205, std: 1.1562
  Sigmas: [0.9296875]... (timesteps: [931.0])
Steps:  42%|████▏     | 2101/5000 [7:51:26<9:37:38, 11.96s/it, loss=0.6230, lr=7.19e-06]Steps:  42%|████▏     | 2101/5000 [7:51:26<9:37:38, 11.96s/it, loss=0.5617, lr=7.19e-06]Steps:  42%|████▏     | 2102/5000 [7:51:38<9:36:57, 11.95s/it, loss=0.5617, lr=7.19e-06]Steps:  42%|████▏     | 2102/5000 [7:51:38<9:36:57, 11.95s/it, loss=0.4077, lr=7.19e-06]Steps:  42%|████▏     | 2103/5000 [7:51:50<9:37:48, 11.97s/it, loss=0.4077, lr=7.19e-06]Steps:  42%|████▏     | 2103/5000 [7:51:50<9:37:48, 11.97s/it, loss=0.3622, lr=7.18e-06]Steps:  42%|████▏     | 2104/5000 [7:52:02<9:38:58, 12.00s/it, loss=0.3622, lr=7.18e-06]Steps:  42%|████▏     | 2104/5000 [7:52:02<9:38:58, 12.00s/it, loss=1.1200, lr=7.18e-06]Steps:  42%|████▏     | 2105/5000 [7:52:14<9:36:30, 11.95s/it, loss=1.1200, lr=7.18e-06]Steps:  42%|████▏     | 2105/5000 [7:52:14<9:36:30, 11.95s/it, loss=1.0645, lr=7.18e-06]Steps:  42%|████▏     | 2106/5000 [7:52:26<9:36:34, 11.95s/it, loss=1.0645, lr=7.18e-06]Steps:  42%|████▏     | 2106/5000 [7:52:26<9:36:34, 11.95s/it, loss=0.5644, lr=7.17e-06]Steps:  42%|████▏     | 2107/5000 [7:52:38<9:35:52, 11.94s/it, loss=0.5644, lr=7.17e-06]Steps:  42%|████▏     | 2107/5000 [7:52:38<9:35:52, 11.94s/it, loss=1.0315, lr=7.17e-06]Steps:  42%|████▏     | 2108/5000 [7:52:50<9:35:27, 11.94s/it, loss=1.0315, lr=7.17e-06]Steps:  42%|████▏     | 2108/5000 [7:52:50<9:35:27, 11.94s/it, loss=1.0653, lr=7.17e-06]Steps:  42%|████▏     | 2109/5000 [7:53:02<9:35:49, 11.95s/it, loss=1.0653, lr=7.17e-06]Steps:  42%|████▏     | 2109/5000 [7:53:02<9:35:49, 11.95s/it, loss=0.3698, lr=7.16e-06]Steps:  42%|████▏     | 2110/5000 [7:53:14<9:35:45, 11.95s/it, loss=0.3698, lr=7.16e-06]Steps:  42%|████▏     | 2110/5000 [7:53:14<9:35:45, 11.95s/it, loss=0.3688, lr=7.16e-06]
[Step 2110] Training Debug Info:
  Loss: 0.364539
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0242, std: 0.8984
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0228, std: 1.3438
  Model pred mean: 0.0103, std: 1.2031
  Sigmas: [0.91015625]... (timesteps: [909.0])

[Step 2110] Training Debug Info:
  Loss: 0.594162
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0063, std: 0.9531
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0045, std: 1.3828
  Model pred mean: -0.0060, std: 1.1406
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 2110] Training Debug Info:
  Loss: 1.120654
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0240, std: 0.9102
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0275, std: 1.3516
  Model pred mean: -0.0259, std: 0.8359
  Sigmas: [0.12890625]... (timesteps: [129.0])

[Step 2110] Training Debug Info:
  Loss: 0.466334
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0201, std: 0.9570
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0227, std: 1.3828
  Model pred mean: -0.0232, std: 1.2031
  Sigmas: [0.87890625]... (timesteps: [880.0])
Steps:  42%|████▏     | 2111/5000 [7:53:26<9:35:06, 11.94s/it, loss=0.3688, lr=7.16e-06]Steps:  42%|████▏     | 2111/5000 [7:53:26<9:35:06, 11.94s/it, loss=0.4663, lr=7.16e-06]Steps:  42%|████▏     | 2112/5000 [7:53:38<9:35:06, 11.95s/it, loss=0.4663, lr=7.16e-06]Steps:  42%|████▏     | 2112/5000 [7:53:38<9:35:06, 11.95s/it, loss=1.1529, lr=7.15e-06]Steps:  42%|████▏     | 2113/5000 [7:53:50<9:37:57, 12.01s/it, loss=1.1529, lr=7.15e-06]Steps:  42%|████▏     | 2113/5000 [7:53:50<9:37:57, 12.01s/it, loss=0.4577, lr=7.15e-06]Steps:  42%|████▏     | 2114/5000 [7:54:02<9:37:20, 12.00s/it, loss=0.4577, lr=7.15e-06]Steps:  42%|████▏     | 2114/5000 [7:54:02<9:37:20, 12.00s/it, loss=0.5217, lr=7.15e-06]Steps:  42%|████▏     | 2115/5000 [7:54:14<9:37:20, 12.01s/it, loss=0.5217, lr=7.15e-06]Steps:  42%|████▏     | 2115/5000 [7:54:14<9:37:20, 12.01s/it, loss=0.5399, lr=7.14e-06]Steps:  42%|████▏     | 2116/5000 [7:54:26<9:37:00, 12.00s/it, loss=0.5399, lr=7.14e-06]Steps:  42%|████▏     | 2116/5000 [7:54:26<9:37:00, 12.00s/it, loss=0.6584, lr=7.14e-06]Steps:  42%|████▏     | 2117/5000 [7:54:38<9:37:19, 12.02s/it, loss=0.6584, lr=7.14e-06]Steps:  42%|████▏     | 2117/5000 [7:54:38<9:37:19, 12.02s/it, loss=0.7367, lr=7.14e-06]Steps:  42%|████▏     | 2118/5000 [7:54:50<9:35:55, 11.99s/it, loss=0.7367, lr=7.14e-06]Steps:  42%|████▏     | 2118/5000 [7:54:50<9:35:55, 11.99s/it, loss=0.9652, lr=7.14e-06]Steps:  42%|████▏     | 2119/5000 [7:55:02<9:35:37, 11.99s/it, loss=0.9652, lr=7.14e-06]Steps:  42%|████▏     | 2119/5000 [7:55:02<9:35:37, 11.99s/it, loss=0.7383, lr=7.13e-06]Steps:  42%|████▏     | 2120/5000 [7:55:14<9:34:30, 11.97s/it, loss=0.7383, lr=7.13e-06]Steps:  42%|████▏     | 2120/5000 [7:55:14<9:34:30, 11.97s/it, loss=1.1239, lr=7.13e-06]
[Step 2120] Training Debug Info:
  Loss: 0.465538
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0190, std: 0.9531
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0200, std: 1.3828
  Model pred mean: -0.0197, std: 1.2031
  Sigmas: [0.640625]... (timesteps: [641.0])

[Step 2120] Training Debug Info:
  Loss: 0.426175
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0068, std: 0.8867
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0056, std: 1.3359
  Model pred mean: -0.0038, std: 1.1719
  Sigmas: [0.7578125]... (timesteps: [756.0])

[Step 2120] Training Debug Info:
  Loss: 0.839764
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0195, std: 0.9102
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0188, std: 1.3516
  Model pred mean: -0.0215, std: 0.9922
  Sigmas: [0.400390625]... (timesteps: [400.0])

[Step 2120] Training Debug Info:
  Loss: 0.500369
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0020, std: 0.8984
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0036, std: 1.3438
  Model pred mean: -0.0098, std: 1.1328
  Sigmas: [0.91796875]... (timesteps: [918.0])
Steps:  42%|████▏     | 2121/5000 [7:55:26<9:34:39, 11.98s/it, loss=1.1239, lr=7.13e-06]Steps:  42%|████▏     | 2121/5000 [7:55:26<9:34:39, 11.98s/it, loss=0.5004, lr=7.13e-06]Steps:  42%|████▏     | 2122/5000 [7:55:38<9:37:21, 12.04s/it, loss=0.5004, lr=7.13e-06]Steps:  42%|████▏     | 2122/5000 [7:55:38<9:37:21, 12.04s/it, loss=1.0289, lr=7.12e-06]Steps:  42%|████▏     | 2123/5000 [7:55:50<9:35:08, 11.99s/it, loss=1.0289, lr=7.12e-06]Steps:  42%|████▏     | 2123/5000 [7:55:50<9:35:08, 11.99s/it, loss=0.4405, lr=7.12e-06]Steps:  42%|████▏     | 2124/5000 [7:56:02<9:36:33, 12.03s/it, loss=0.4405, lr=7.12e-06]Steps:  42%|████▏     | 2124/5000 [7:56:02<9:36:33, 12.03s/it, loss=0.5497, lr=7.12e-06]Steps:  42%|████▎     | 2125/5000 [7:56:14<9:35:56, 12.02s/it, loss=0.5497, lr=7.12e-06]Steps:  42%|████▎     | 2125/5000 [7:56:14<9:35:56, 12.02s/it, loss=1.1900, lr=7.11e-06]Steps:  43%|████▎     | 2126/5000 [7:56:26<9:34:26, 11.99s/it, loss=1.1900, lr=7.11e-06]Steps:  43%|████▎     | 2126/5000 [7:56:26<9:34:26, 11.99s/it, loss=0.9229, lr=7.11e-06]Steps:  43%|████▎     | 2127/5000 [7:56:38<9:33:54, 11.99s/it, loss=0.9229, lr=7.11e-06]Steps:  43%|████▎     | 2127/5000 [7:56:38<9:33:54, 11.99s/it, loss=1.0374, lr=7.11e-06]Steps:  43%|████▎     | 2128/5000 [7:56:50<9:32:26, 11.96s/it, loss=1.0374, lr=7.11e-06]Steps:  43%|████▎     | 2128/5000 [7:56:50<9:32:26, 11.96s/it, loss=0.4075, lr=7.10e-06]Steps:  43%|████▎     | 2129/5000 [7:57:01<9:29:59, 11.91s/it, loss=0.4075, lr=7.10e-06]Steps:  43%|████▎     | 2129/5000 [7:57:01<9:29:59, 11.91s/it, loss=1.1073, lr=7.10e-06]Steps:  43%|████▎     | 2130/5000 [7:57:14<9:33:44, 11.99s/it, loss=1.1073, lr=7.10e-06]Steps:  43%|████▎     | 2130/5000 [7:57:14<9:33:44, 11.99s/it, loss=1.0759, lr=7.10e-06]
[Step 2130] Training Debug Info:
  Loss: 0.362480
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0117, std: 0.9023
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0118, std: 1.3438
  Model pred mean: -0.0078, std: 1.2031
  Sigmas: [0.8828125]... (timesteps: [882.0])

[Step 2130] Training Debug Info:
  Loss: 0.559053
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0066, std: 0.8945
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0076, std: 1.3438
  Model pred mean: -0.0096, std: 1.1094
  Sigmas: [0.6328125]... (timesteps: [634.0])

[Step 2130] Training Debug Info:
  Loss: 0.363645
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0032, std: 0.8945
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0023, std: 1.3359
  Model pred mean: -0.0061, std: 1.1953
  Sigmas: [0.8046875]... (timesteps: [805.0])

[Step 2130] Training Debug Info:
  Loss: 0.598595
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0422, std: 0.9297
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0388, std: 1.3672
  Model pred mean: -0.0239, std: 1.1094
  Sigmas: [0.953125]... (timesteps: [953.0])
Steps:  43%|████▎     | 2131/5000 [7:57:26<9:34:08, 12.01s/it, loss=1.0759, lr=7.10e-06]Steps:  43%|████▎     | 2131/5000 [7:57:26<9:34:08, 12.01s/it, loss=0.5986, lr=7.09e-06]Steps:  43%|████▎     | 2132/5000 [7:57:38<9:32:56, 11.99s/it, loss=0.5986, lr=7.09e-06]Steps:  43%|████▎     | 2132/5000 [7:57:38<9:32:56, 11.99s/it, loss=1.1513, lr=7.09e-06]Steps:  43%|████▎     | 2133/5000 [7:57:50<9:32:50, 11.99s/it, loss=1.1513, lr=7.09e-06]Steps:  43%|████▎     | 2133/5000 [7:57:50<9:32:50, 11.99s/it, loss=0.8161, lr=7.09e-06]Steps:  43%|████▎     | 2134/5000 [7:58:01<9:30:49, 11.95s/it, loss=0.8161, lr=7.09e-06]Steps:  43%|████▎     | 2134/5000 [7:58:01<9:30:49, 11.95s/it, loss=0.4562, lr=7.08e-06]Steps:  43%|████▎     | 2135/5000 [7:58:13<9:30:25, 11.95s/it, loss=0.4562, lr=7.08e-06]Steps:  43%|████▎     | 2135/5000 [7:58:13<9:30:25, 11.95s/it, loss=0.9948, lr=7.08e-06]Steps:  43%|████▎     | 2136/5000 [7:58:25<9:29:52, 11.94s/it, loss=0.9948, lr=7.08e-06]Steps:  43%|████▎     | 2136/5000 [7:58:25<9:29:52, 11.94s/it, loss=0.4746, lr=7.08e-06]Steps:  43%|████▎     | 2137/5000 [7:58:37<9:31:46, 11.98s/it, loss=0.4746, lr=7.08e-06]Steps:  43%|████▎     | 2137/5000 [7:58:37<9:31:46, 11.98s/it, loss=0.6134, lr=7.08e-06]Steps:  43%|████▎     | 2138/5000 [7:58:49<9:31:32, 11.98s/it, loss=0.6134, lr=7.08e-06]Steps:  43%|████▎     | 2138/5000 [7:58:49<9:31:32, 11.98s/it, loss=0.4344, lr=7.07e-06]Steps:  43%|████▎     | 2139/5000 [7:59:01<9:30:26, 11.96s/it, loss=0.4344, lr=7.07e-06]Steps:  43%|████▎     | 2139/5000 [7:59:01<9:30:26, 11.96s/it, loss=0.9712, lr=7.07e-06]Steps:  43%|████▎     | 2140/5000 [7:59:13<9:30:33, 11.97s/it, loss=0.9712, lr=7.07e-06]Steps:  43%|████▎     | 2140/5000 [7:59:13<9:30:33, 11.97s/it, loss=1.1230, lr=7.07e-06]
[Step 2140] Training Debug Info:
  Loss: 1.008896
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0024, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0022, std: 1.3516
  Model pred mean: 0.0011, std: 0.9102
  Sigmas: [0.0030059814453125]... (timesteps: [3.0])

[Step 2140] Training Debug Info:
  Loss: 0.992858
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0194, std: 0.9688
  Noise mean: -0.0033, std: 0.9961
  Target mean: -0.0227, std: 1.3906
  Model pred mean: -0.0175, std: 0.9688
  Sigmas: [0.2890625]... (timesteps: [289.0])

[Step 2140] Training Debug Info:
  Loss: 0.607203
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0222, std: 0.9102
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0219, std: 1.3516
  Model pred mean: -0.0199, std: 1.1016
  Sigmas: [0.5390625]... (timesteps: [540.0])

[Step 2140] Training Debug Info:
  Loss: 1.116795
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0254, std: 0.8867
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0275, std: 1.3359
  Model pred mean: 0.0261, std: 0.8203
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:  43%|████▎     | 2141/5000 [7:59:25<9:30:19, 11.97s/it, loss=1.1230, lr=7.07e-06]Steps:  43%|████▎     | 2141/5000 [7:59:25<9:30:19, 11.97s/it, loss=1.1168, lr=7.06e-06]Steps:  43%|████▎     | 2142/5000 [7:59:37<9:29:34, 11.96s/it, loss=1.1168, lr=7.06e-06]Steps:  43%|████▎     | 2142/5000 [7:59:37<9:29:34, 11.96s/it, loss=1.0542, lr=7.06e-06]Steps:  43%|████▎     | 2143/5000 [7:59:49<9:29:27, 11.96s/it, loss=1.0542, lr=7.06e-06]Steps:  43%|████▎     | 2143/5000 [7:59:49<9:29:27, 11.96s/it, loss=0.3968, lr=7.06e-06]Steps:  43%|████▎     | 2144/5000 [8:00:01<9:31:05, 12.00s/it, loss=0.3968, lr=7.06e-06]Steps:  43%|████▎     | 2144/5000 [8:00:01<9:31:05, 12.00s/it, loss=0.3877, lr=7.05e-06]Steps:  43%|████▎     | 2145/5000 [8:00:13<9:32:58, 12.04s/it, loss=0.3877, lr=7.05e-06]Steps:  43%|████▎     | 2145/5000 [8:00:13<9:32:58, 12.04s/it, loss=1.0485, lr=7.05e-06]Steps:  43%|████▎     | 2146/5000 [8:00:25<9:31:00, 12.00s/it, loss=1.0485, lr=7.05e-06]Steps:  43%|████▎     | 2146/5000 [8:00:25<9:31:00, 12.00s/it, loss=1.1328, lr=7.05e-06]Steps:  43%|████▎     | 2147/5000 [8:00:37<9:29:35, 11.98s/it, loss=1.1328, lr=7.05e-06]Steps:  43%|████▎     | 2147/5000 [8:00:37<9:29:35, 11.98s/it, loss=0.5448, lr=7.04e-06]Steps:  43%|████▎     | 2148/5000 [8:00:49<9:29:22, 11.98s/it, loss=0.5448, lr=7.04e-06]Steps:  43%|████▎     | 2148/5000 [8:00:49<9:29:22, 11.98s/it, loss=1.0990, lr=7.04e-06]Steps:  43%|████▎     | 2149/5000 [8:01:01<9:30:04, 12.00s/it, loss=1.0990, lr=7.04e-06]Steps:  43%|████▎     | 2149/5000 [8:01:01<9:30:04, 12.00s/it, loss=0.4094, lr=7.04e-06]Steps:  43%|████▎     | 2150/5000 [8:01:13<9:29:11, 11.98s/it, loss=0.4094, lr=7.04e-06]Steps:  43%|████▎     | 2150/5000 [8:01:13<9:29:11, 11.98s/it, loss=0.4508, lr=7.03e-06]
[Step 2150] Training Debug Info:
  Loss: 0.850992
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0070, std: 0.8633
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0073, std: 1.3281
  Model pred mean: 0.0057, std: 0.9492
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 2150] Training Debug Info:
  Loss: 1.050657
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0130, std: 0.8867
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0109, std: 1.3359
  Model pred mean: -0.0166, std: 0.8555
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 2150] Training Debug Info:
  Loss: 0.498569
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0029, std: 0.8672
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0014, std: 1.3203
  Model pred mean: 0.0040, std: 1.1172
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 2150] Training Debug Info:
  Loss: 0.441620
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0280, std: 0.9766
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0271, std: 1.3984
  Model pred mean: -0.0270, std: 1.2266
  Sigmas: [0.703125]... (timesteps: [702.0])
Steps:  43%|████▎     | 2151/5000 [8:01:25<9:29:19, 11.99s/it, loss=0.4508, lr=7.03e-06]Steps:  43%|████▎     | 2151/5000 [8:01:25<9:29:19, 11.99s/it, loss=0.4416, lr=7.03e-06]Steps:  43%|████▎     | 2152/5000 [8:01:37<9:30:42, 12.02s/it, loss=0.4416, lr=7.03e-06]Steps:  43%|████▎     | 2152/5000 [8:01:37<9:30:42, 12.02s/it, loss=0.5575, lr=7.03e-06]Steps:  43%|████▎     | 2153/5000 [8:01:49<9:28:58, 11.99s/it, loss=0.5575, lr=7.03e-06]Steps:  43%|████▎     | 2153/5000 [8:01:49<9:28:58, 11.99s/it, loss=0.8297, lr=7.02e-06]Steps:  43%|████▎     | 2154/5000 [8:02:01<9:26:45, 11.95s/it, loss=0.8297, lr=7.02e-06]Steps:  43%|████▎     | 2154/5000 [8:02:01<9:26:45, 11.95s/it, loss=0.3710, lr=7.02e-06]Steps:  43%|████▎     | 2155/5000 [8:02:13<9:26:22, 11.94s/it, loss=0.3710, lr=7.02e-06]Steps:  43%|████▎     | 2155/5000 [8:02:13<9:26:22, 11.94s/it, loss=1.0553, lr=7.02e-06]Steps:  43%|████▎     | 2156/5000 [8:02:25<9:25:48, 11.94s/it, loss=1.0553, lr=7.02e-06]Steps:  43%|████▎     | 2156/5000 [8:02:25<9:25:48, 11.94s/it, loss=0.9885, lr=7.01e-06]Steps:  43%|████▎     | 2157/5000 [8:02:37<9:28:15, 11.99s/it, loss=0.9885, lr=7.01e-06]Steps:  43%|████▎     | 2157/5000 [8:02:37<9:28:15, 11.99s/it, loss=0.5685, lr=7.01e-06]Steps:  43%|████▎     | 2158/5000 [8:02:49<9:28:26, 12.00s/it, loss=0.5685, lr=7.01e-06]Steps:  43%|████▎     | 2158/5000 [8:02:49<9:28:26, 12.00s/it, loss=0.7037, lr=7.01e-06]Steps:  43%|████▎     | 2159/5000 [8:03:01<9:31:22, 12.07s/it, loss=0.7037, lr=7.01e-06]Steps:  43%|████▎     | 2159/5000 [8:03:01<9:31:22, 12.07s/it, loss=0.3719, lr=7.00e-06]Steps:  43%|████▎     | 2160/5000 [8:03:13<9:29:33, 12.03s/it, loss=0.3719, lr=7.00e-06]Steps:  43%|████▎     | 2160/5000 [8:03:13<9:29:33, 12.03s/it, loss=1.1229, lr=7.00e-06]
[Step 2160] Training Debug Info:
  Loss: 0.909180
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0134, std: 0.8906
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0140, std: 1.3438
  Model pred mean: -0.0128, std: 0.9375
  Sigmas: [0.400390625]... (timesteps: [401.0])

[Step 2160] Training Debug Info:
  Loss: 1.012580
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0066, std: 0.9258
  Noise mean: 0.0003, std: 0.9961
  Target mean: 0.0068, std: 1.3594
  Model pred mean: 0.0046, std: 0.9180
  Sigmas: [0.314453125]... (timesteps: [314.0])

[Step 2160] Training Debug Info:
  Loss: 0.434105
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0269, std: 0.8906
  Noise mean: 0.0044, std: 1.0000
  Target mean: -0.0225, std: 1.3359
  Model pred mean: -0.0223, std: 1.1641
  Sigmas: [0.90234375]... (timesteps: [904.0])

[Step 2160] Training Debug Info:
  Loss: 0.478092
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0420, std: 0.8984
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0442, std: 1.3438
  Model pred mean: -0.0444, std: 1.1562
  Sigmas: [0.86328125]... (timesteps: [864.0])
Steps:  43%|████▎     | 2161/5000 [8:03:25<9:29:27, 12.03s/it, loss=1.1229, lr=7.00e-06]Steps:  43%|████▎     | 2161/5000 [8:03:25<9:29:27, 12.03s/it, loss=0.4781, lr=7.00e-06]Steps:  43%|████▎     | 2162/5000 [8:03:37<9:27:57, 12.01s/it, loss=0.4781, lr=7.00e-06]Steps:  43%|████▎     | 2162/5000 [8:03:37<9:27:57, 12.01s/it, loss=0.3824, lr=7.00e-06]Steps:  43%|████▎     | 2163/5000 [8:03:49<9:27:27, 12.00s/it, loss=0.3824, lr=7.00e-06]Steps:  43%|████▎     | 2163/5000 [8:03:49<9:27:27, 12.00s/it, loss=0.7420, lr=6.99e-06]Steps:  43%|████▎     | 2164/5000 [8:04:01<9:29:18, 12.04s/it, loss=0.7420, lr=6.99e-06]Steps:  43%|████▎     | 2164/5000 [8:04:01<9:29:18, 12.04s/it, loss=0.5071, lr=6.99e-06]Steps:  43%|████▎     | 2165/5000 [8:04:13<9:28:02, 12.02s/it, loss=0.5071, lr=6.99e-06]Steps:  43%|████▎     | 2165/5000 [8:04:13<9:28:02, 12.02s/it, loss=0.3528, lr=6.99e-06]Steps:  43%|████▎     | 2166/5000 [8:04:25<9:26:40, 12.00s/it, loss=0.3528, lr=6.99e-06]Steps:  43%|████▎     | 2166/5000 [8:04:25<9:26:40, 12.00s/it, loss=0.4375, lr=6.98e-06]Steps:  43%|████▎     | 2167/5000 [8:04:37<9:28:14, 12.03s/it, loss=0.4375, lr=6.98e-06]Steps:  43%|████▎     | 2167/5000 [8:04:37<9:28:14, 12.03s/it, loss=1.1692, lr=6.98e-06]Steps:  43%|████▎     | 2168/5000 [8:04:49<9:25:48, 11.99s/it, loss=1.1692, lr=6.98e-06]Steps:  43%|████▎     | 2168/5000 [8:04:49<9:25:48, 11.99s/it, loss=0.5166, lr=6.98e-06]Steps:  43%|████▎     | 2169/5000 [8:05:01<9:25:14, 11.98s/it, loss=0.5166, lr=6.98e-06]Steps:  43%|████▎     | 2169/5000 [8:05:01<9:25:14, 11.98s/it, loss=0.8086, lr=6.97e-06]Steps:  43%|████▎     | 2170/5000 [8:05:13<9:23:56, 11.96s/it, loss=0.8086, lr=6.97e-06]Steps:  43%|████▎     | 2170/5000 [8:05:13<9:23:56, 11.96s/it, loss=1.1802, lr=6.97e-06]
[Step 2170] Training Debug Info:
  Loss: 0.486559
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0547, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0554, std: 1.3516
  Model pred mean: 0.0625, std: 1.1562
  Sigmas: [0.62109375]... (timesteps: [620.0])

[Step 2170] Training Debug Info:
  Loss: 0.567608
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0049, std: 0.9258
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0050, std: 1.3672
  Model pred mean: -0.0028, std: 1.1328
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 2170] Training Debug Info:
  Loss: 0.673710
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0227, std: 0.9219
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0249, std: 1.3594
  Model pred mean: -0.0254, std: 1.0859
  Sigmas: [0.95703125]... (timesteps: [956.0])

[Step 2170] Training Debug Info:
  Loss: 1.103737
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0149, std: 0.9219
  Noise mean: 0.0046, std: 1.0000
  Target mean: -0.0103, std: 1.3594
  Model pred mean: -0.0167, std: 0.8516
  Sigmas: [0.06591796875]... (timesteps: [66.0])
Steps:  43%|████▎     | 2171/5000 [8:05:25<9:24:59, 11.98s/it, loss=1.1802, lr=6.97e-06]Steps:  43%|████▎     | 2171/5000 [8:05:25<9:24:59, 11.98s/it, loss=1.1037, lr=6.97e-06]Steps:  43%|████▎     | 2172/5000 [8:05:37<9:25:29, 12.00s/it, loss=1.1037, lr=6.97e-06]Steps:  43%|████▎     | 2172/5000 [8:05:37<9:25:29, 12.00s/it, loss=1.0260, lr=6.96e-06]Steps:  43%|████▎     | 2173/5000 [8:05:49<9:24:13, 11.97s/it, loss=1.0260, lr=6.96e-06]Steps:  43%|████▎     | 2173/5000 [8:05:49<9:24:13, 11.97s/it, loss=0.6222, lr=6.96e-06]Steps:  43%|████▎     | 2174/5000 [8:06:01<9:21:55, 11.93s/it, loss=0.6222, lr=6.96e-06]Steps:  43%|████▎     | 2174/5000 [8:06:01<9:21:55, 11.93s/it, loss=0.6753, lr=6.96e-06]Steps:  44%|████▎     | 2175/5000 [8:06:13<9:20:52, 11.91s/it, loss=0.6753, lr=6.96e-06]Steps:  44%|████▎     | 2175/5000 [8:06:13<9:20:52, 11.91s/it, loss=0.7553, lr=6.95e-06]Steps:  44%|████▎     | 2176/5000 [8:06:25<9:22:01, 11.94s/it, loss=0.7553, lr=6.95e-06]Steps:  44%|████▎     | 2176/5000 [8:06:25<9:22:01, 11.94s/it, loss=0.5065, lr=6.95e-06]Steps:  44%|████▎     | 2177/5000 [8:06:37<9:21:29, 11.93s/it, loss=0.5065, lr=6.95e-06]Steps:  44%|████▎     | 2177/5000 [8:06:37<9:21:29, 11.93s/it, loss=0.3804, lr=6.95e-06]Steps:  44%|████▎     | 2178/5000 [8:06:49<9:22:43, 11.96s/it, loss=0.3804, lr=6.95e-06]Steps:  44%|████▎     | 2178/5000 [8:06:49<9:22:43, 11.96s/it, loss=1.0393, lr=6.94e-06]Steps:  44%|████▎     | 2179/5000 [8:07:01<9:25:02, 12.02s/it, loss=1.0393, lr=6.94e-06]Steps:  44%|████▎     | 2179/5000 [8:07:01<9:25:02, 12.02s/it, loss=0.4627, lr=6.94e-06]Steps:  44%|████▎     | 2180/5000 [8:07:13<9:23:36, 11.99s/it, loss=0.4627, lr=6.94e-06]Steps:  44%|████▎     | 2180/5000 [8:07:13<9:23:36, 11.99s/it, loss=0.3582, lr=6.94e-06]
[Step 2180] Training Debug Info:
  Loss: 1.130016
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0106, std: 0.8906
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0096, std: 1.3359
  Model pred mean: 0.0128, std: 0.8164
  Sigmas: [0.28515625]... (timesteps: [285.0])

[Step 2180] Training Debug Info:
  Loss: 0.920453
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0181, std: 0.9297
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0188, std: 1.3672
  Model pred mean: 0.0186, std: 0.9688
  Sigmas: [0.33984375]... (timesteps: [339.0])

[Step 2180] Training Debug Info:
  Loss: 0.763091
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0055, std: 0.8906
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0079, std: 1.3359
  Model pred mean: -0.0041, std: 1.0156
  Sigmas: [0.494140625]... (timesteps: [495.0])

[Step 2180] Training Debug Info:
  Loss: 0.773201
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0092, std: 0.9258
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0117, std: 1.3594
  Model pred mean: -0.0101, std: 1.0469
  Sigmas: [0.458984375]... (timesteps: [459.0])
Steps:  44%|████▎     | 2181/5000 [8:07:25<9:22:57, 11.98s/it, loss=0.3582, lr=6.94e-06]Steps:  44%|████▎     | 2181/5000 [8:07:25<9:22:57, 11.98s/it, loss=0.7732, lr=6.93e-06]Steps:  44%|████▎     | 2182/5000 [8:07:37<9:21:46, 11.96s/it, loss=0.7732, lr=6.93e-06]Steps:  44%|████▎     | 2182/5000 [8:07:37<9:21:46, 11.96s/it, loss=0.6517, lr=6.93e-06]Steps:  44%|████▎     | 2183/5000 [8:07:49<9:21:00, 11.95s/it, loss=0.6517, lr=6.93e-06]Steps:  44%|████▎     | 2183/5000 [8:07:49<9:21:00, 11.95s/it, loss=0.4642, lr=6.93e-06]Steps:  44%|████▎     | 2184/5000 [8:08:01<9:22:11, 11.98s/it, loss=0.4642, lr=6.93e-06]Steps:  44%|████▎     | 2184/5000 [8:08:01<9:22:11, 11.98s/it, loss=0.8831, lr=6.92e-06]Steps:  44%|████▎     | 2185/5000 [8:08:13<9:22:54, 12.00s/it, loss=0.8831, lr=6.92e-06]Steps:  44%|████▎     | 2185/5000 [8:08:13<9:22:54, 12.00s/it, loss=0.8010, lr=6.92e-06]Steps:  44%|████▎     | 2186/5000 [8:08:25<9:25:25, 12.06s/it, loss=0.8010, lr=6.92e-06]Steps:  44%|████▎     | 2186/5000 [8:08:25<9:25:25, 12.06s/it, loss=0.9335, lr=6.92e-06]Steps:  44%|████▎     | 2187/5000 [8:08:37<9:23:53, 12.03s/it, loss=0.9335, lr=6.92e-06]Steps:  44%|████▎     | 2187/5000 [8:08:37<9:23:53, 12.03s/it, loss=0.9902, lr=6.92e-06]Steps:  44%|████▍     | 2188/5000 [8:08:49<9:22:28, 12.00s/it, loss=0.9902, lr=6.92e-06]Steps:  44%|████▍     | 2188/5000 [8:08:49<9:22:28, 12.00s/it, loss=0.4171, lr=6.91e-06]Steps:  44%|████▍     | 2189/5000 [8:09:01<9:20:42, 11.97s/it, loss=0.4171, lr=6.91e-06]Steps:  44%|████▍     | 2189/5000 [8:09:01<9:20:42, 11.97s/it, loss=0.5685, lr=6.91e-06]Steps:  44%|████▍     | 2190/5000 [8:09:13<9:20:36, 11.97s/it, loss=0.5685, lr=6.91e-06]Steps:  44%|████▍     | 2190/5000 [8:09:13<9:20:36, 11.97s/it, loss=0.9358, lr=6.91e-06]
[Step 2190] Training Debug Info:
  Loss: 0.422543
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0134, std: 0.9141
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0145, std: 1.3594
  Model pred mean: -0.0055, std: 1.1875
  Sigmas: [0.78515625]... (timesteps: [785.0])

[Step 2190] Training Debug Info:
  Loss: 0.854859
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0530, std: 0.9766
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0508, std: 1.3984
  Model pred mean: -0.0537, std: 1.0469
  Sigmas: [0.357421875]... (timesteps: [358.0])

[Step 2190] Training Debug Info:
  Loss: 1.069450
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0645, std: 0.9570
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0649, std: 1.3828
  Model pred mean: -0.0649, std: 0.9258
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 2190] Training Debug Info:
  Loss: 0.353625
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0197, std: 0.9688
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0199, std: 1.3906
  Model pred mean: 0.0176, std: 1.2578
  Sigmas: [0.765625]... (timesteps: [765.0])
Steps:  44%|████▍     | 2191/5000 [8:09:25<9:22:31, 12.02s/it, loss=0.9358, lr=6.91e-06]Steps:  44%|████▍     | 2191/5000 [8:09:25<9:22:31, 12.02s/it, loss=0.3536, lr=6.90e-06]Steps:  44%|████▍     | 2192/5000 [8:09:37<9:21:58, 12.01s/it, loss=0.3536, lr=6.90e-06]Steps:  44%|████▍     | 2192/5000 [8:09:37<9:21:58, 12.01s/it, loss=0.9116, lr=6.90e-06]Steps:  44%|████▍     | 2193/5000 [8:09:49<9:20:01, 11.97s/it, loss=0.9116, lr=6.90e-06]Steps:  44%|████▍     | 2193/5000 [8:09:49<9:20:01, 11.97s/it, loss=0.5700, lr=6.90e-06]Steps:  44%|████▍     | 2194/5000 [8:10:01<9:18:14, 11.94s/it, loss=0.5700, lr=6.90e-06]Steps:  44%|████▍     | 2194/5000 [8:10:01<9:18:14, 11.94s/it, loss=0.3626, lr=6.89e-06]Steps:  44%|████▍     | 2195/5000 [8:10:13<9:19:13, 11.96s/it, loss=0.3626, lr=6.89e-06]Steps:  44%|████▍     | 2195/5000 [8:10:13<9:19:13, 11.96s/it, loss=0.5215, lr=6.89e-06]Steps:  44%|████▍     | 2196/5000 [8:10:24<9:18:14, 11.95s/it, loss=0.5215, lr=6.89e-06]Steps:  44%|████▍     | 2196/5000 [8:10:24<9:18:14, 11.95s/it, loss=0.7672, lr=6.89e-06]Steps:  44%|████▍     | 2197/5000 [8:10:36<9:18:17, 11.95s/it, loss=0.7672, lr=6.89e-06]Steps:  44%|████▍     | 2197/5000 [8:10:36<9:18:17, 11.95s/it, loss=1.1345, lr=6.88e-06]Steps:  44%|████▍     | 2198/5000 [8:10:49<9:20:29, 12.00s/it, loss=1.1345, lr=6.88e-06]Steps:  44%|████▍     | 2198/5000 [8:10:49<9:20:29, 12.00s/it, loss=0.8495, lr=6.88e-06]Steps:  44%|████▍     | 2199/5000 [8:11:01<9:19:58, 12.00s/it, loss=0.8495, lr=6.88e-06]Steps:  44%|████▍     | 2199/5000 [8:11:01<9:19:58, 12.00s/it, loss=1.1089, lr=6.88e-06]Steps:  44%|████▍     | 2200/5000 [8:11:12<9:18:35, 11.97s/it, loss=1.1089, lr=6.88e-06]Steps:  44%|████▍     | 2200/5000 [8:11:12<9:18:35, 11.97s/it, loss=1.1591, lr=6.87e-06]01/22/2026 15:56:59 - INFO - __main__ - 
[Step 2200] ✅ Loss in normal range (1.1591)
01/22/2026 15:56:59 - INFO - __main__ -   Loss avg (last 100): 0.7348
01/22/2026 15:56:59 - INFO - __main__ -   Loss range: [0.3528, 1.1900]
01/22/2026 15:56:59 - INFO - __main__ - 
🔍 Running validation at step 2200...
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2200 (parquet mode)...
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2200...
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 15:57:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.46it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 15:57:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 15:57:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 15:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 15:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 15:58:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 15:58:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 15:58:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 15:58:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 15:58:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 15:58:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 15:59:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 15:59:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 15:59:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 15:59:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 15:59:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 15:59:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:00:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 16:00:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 16:00:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 16:00:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 16:00:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 16:00:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.43it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 16:01:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200/step002200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 16:01:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 16:01:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 16:01:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002200
01/22/2026 16:01:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 2200] Training Debug Info:
  Loss: 1.000741
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0095, std: 0.9375
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0098, std: 1.3672
  Model pred mean: -0.0083, std: 0.9375
  Sigmas: [0.2490234375]... (timesteps: [249.0])

[Step 2200] Training Debug Info:
  Loss: 0.365176
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0143, std: 0.9375
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0135, std: 1.3672
  Model pred mean: 0.0096, std: 1.2266
  Sigmas: [0.77734375]... (timesteps: [778.0])

[Step 2200] Training Debug Info:
  Loss: 1.104286
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0083, std: 0.8867
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0105, std: 1.3359
  Model pred mean: -0.0084, std: 0.8242
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 2200] Training Debug Info:
  Loss: 0.622157
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0101, std: 0.9258
  Noise mean: -0.0001, std: 0.9961
  Target mean: -0.0103, std: 1.3594
  Model pred mean: -0.0128, std: 1.1172
  Sigmas: [0.484375]... (timesteps: [485.0])
Steps:  44%|████▍     | 2201/5000 [8:15:36<67:58:04, 87.42s/it, loss=1.1591, lr=6.87e-06]Steps:  44%|████▍     | 2201/5000 [8:15:36<67:58:04, 87.42s/it, loss=0.6222, lr=6.87e-06]Steps:  44%|████▍     | 2202/5000 [8:15:48<50:20:16, 64.77s/it, loss=0.6222, lr=6.87e-06]Steps:  44%|████▍     | 2202/5000 [8:15:48<50:20:16, 64.77s/it, loss=1.0481, lr=6.87e-06]Steps:  44%|████▍     | 2203/5000 [8:16:00<38:01:22, 48.94s/it, loss=1.0481, lr=6.87e-06]Steps:  44%|████▍     | 2203/5000 [8:16:00<38:01:22, 48.94s/it, loss=0.7354, lr=6.86e-06]Steps:  44%|████▍     | 2204/5000 [8:16:12<29:23:22, 37.84s/it, loss=0.7354, lr=6.86e-06]Steps:  44%|████▍     | 2204/5000 [8:16:12<29:23:22, 37.84s/it, loss=0.4435, lr=6.86e-06]Steps:  44%|████▍     | 2205/5000 [8:16:24<23:21:56, 30.10s/it, loss=0.4435, lr=6.86e-06]Steps:  44%|████▍     | 2205/5000 [8:16:24<23:21:56, 30.10s/it, loss=0.3764, lr=6.86e-06]Steps:  44%|████▍     | 2206/5000 [8:16:36<19:08:07, 24.66s/it, loss=0.3764, lr=6.86e-06]Steps:  44%|████▍     | 2206/5000 [8:16:36<19:08:07, 24.66s/it, loss=0.3993, lr=6.85e-06]Steps:  44%|████▍     | 2207/5000 [8:16:48<16:10:50, 20.86s/it, loss=0.3993, lr=6.85e-06]Steps:  44%|████▍     | 2207/5000 [8:16:48<16:10:50, 20.86s/it, loss=0.4878, lr=6.85e-06]Steps:  44%|████▍     | 2208/5000 [8:17:00<14:07:20, 18.21s/it, loss=0.4878, lr=6.85e-06]Steps:  44%|████▍     | 2208/5000 [8:17:00<14:07:20, 18.21s/it, loss=0.3474, lr=6.85e-06]Steps:  44%|████▍     | 2209/5000 [8:17:12<12:40:14, 16.34s/it, loss=0.3474, lr=6.85e-06]Steps:  44%|████▍     | 2209/5000 [8:17:12<12:40:14, 16.34s/it, loss=0.9572, lr=6.84e-06]Steps:  44%|████▍     | 2210/5000 [8:17:24<11:38:30, 15.02s/it, loss=0.9572, lr=6.84e-06]Steps:  44%|████▍     | 2210/5000 [8:17:24<11:38:30, 15.02s/it, loss=0.8876, lr=6.84e-06]
[Step 2210] Training Debug Info:
  Loss: 1.104582
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0190, std: 0.9297
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0168, std: 1.3672
  Model pred mean: -0.0209, std: 0.8711
  Sigmas: [0.080078125]... (timesteps: [80.0])

[Step 2210] Training Debug Info:
  Loss: 1.024683
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0299, std: 0.9258
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0306, std: 1.3594
  Model pred mean: -0.0292, std: 0.9102
  Sigmas: [0.2431640625]... (timesteps: [243.0])

[Step 2210] Training Debug Info:
  Loss: 0.600517
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0260, std: 0.9141
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0294, std: 1.3516
  Model pred mean: -0.0258, std: 1.1094
  Sigmas: [0.5625]... (timesteps: [564.0])

[Step 2210] Training Debug Info:
  Loss: 1.129368
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0018, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0009, std: 1.3516
  Model pred mean: 0.0021, std: 0.8320
  Sigmas: [0.2353515625]... (timesteps: [235.0])
Steps:  44%|████▍     | 2211/5000 [8:17:36<10:57:49, 14.15s/it, loss=0.8876, lr=6.84e-06]Steps:  44%|████▍     | 2211/5000 [8:17:36<10:57:49, 14.15s/it, loss=1.1294, lr=6.84e-06]Steps:  44%|████▍     | 2212/5000 [8:17:48<10:28:40, 13.53s/it, loss=1.1294, lr=6.84e-06]Steps:  44%|████▍     | 2212/5000 [8:17:48<10:28:40, 13.53s/it, loss=0.6068, lr=6.83e-06]Steps:  44%|████▍     | 2213/5000 [8:18:00<10:07:51, 13.09s/it, loss=0.6068, lr=6.83e-06]Steps:  44%|████▍     | 2213/5000 [8:18:00<10:07:51, 13.09s/it, loss=0.5787, lr=6.83e-06]Steps:  44%|████▍     | 2214/5000 [8:18:12<9:52:39, 12.76s/it, loss=0.5787, lr=6.83e-06] Steps:  44%|████▍     | 2214/5000 [8:18:12<9:52:39, 12.76s/it, loss=0.4036, lr=6.83e-06]Steps:  44%|████▍     | 2215/5000 [8:18:24<9:41:02, 12.52s/it, loss=0.4036, lr=6.83e-06]Steps:  44%|████▍     | 2215/5000 [8:18:24<9:41:02, 12.52s/it, loss=0.6387, lr=6.82e-06]Steps:  44%|████▍     | 2216/5000 [8:18:36<9:33:42, 12.36s/it, loss=0.6387, lr=6.82e-06]Steps:  44%|████▍     | 2216/5000 [8:18:36<9:33:42, 12.36s/it, loss=1.0293, lr=6.82e-06]Steps:  44%|████▍     | 2217/5000 [8:18:48<9:28:39, 12.26s/it, loss=1.0293, lr=6.82e-06]Steps:  44%|████▍     | 2217/5000 [8:18:48<9:28:39, 12.26s/it, loss=1.1227, lr=6.82e-06]Steps:  44%|████▍     | 2218/5000 [8:19:00<9:26:03, 12.21s/it, loss=1.1227, lr=6.82e-06]Steps:  44%|████▍     | 2218/5000 [8:19:00<9:26:03, 12.21s/it, loss=1.0085, lr=6.81e-06]Steps:  44%|████▍     | 2219/5000 [8:19:12<9:21:24, 12.11s/it, loss=1.0085, lr=6.81e-06]Steps:  44%|████▍     | 2219/5000 [8:19:12<9:21:24, 12.11s/it, loss=0.4028, lr=6.81e-06]Steps:  44%|████▍     | 2220/5000 [8:19:24<9:18:51, 12.06s/it, loss=0.4028, lr=6.81e-06]Steps:  44%|████▍     | 2220/5000 [8:19:24<9:18:51, 12.06s/it, loss=0.3689, lr=6.81e-06]
[Step 2220] Training Debug Info:
  Loss: 0.950121
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0038, std: 0.9141
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0035, std: 1.3516
  Model pred mean: -0.0024, std: 0.9414
  Sigmas: [0.361328125]... (timesteps: [361.0])

[Step 2220] Training Debug Info:
  Loss: 1.092706
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0106, std: 0.8906
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0084, std: 1.3359
  Model pred mean: -0.0146, std: 0.8438
  Sigmas: [0.05810546875]... (timesteps: [58.0])

[Step 2220] Training Debug Info:
  Loss: 0.583872
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0243, std: 0.9609
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0258, std: 1.3906
  Model pred mean: -0.0269, std: 1.1562
  Sigmas: [0.48828125]... (timesteps: [488.0])

[Step 2220] Training Debug Info:
  Loss: 0.593551
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0265, std: 0.9141
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0291, std: 1.3516
  Model pred mean: 0.0312, std: 1.1172
  Sigmas: [0.59375]... (timesteps: [594.0])
Steps:  44%|████▍     | 2221/5000 [8:19:36<9:18:40, 12.06s/it, loss=0.3689, lr=6.81e-06]Steps:  44%|████▍     | 2221/5000 [8:19:36<9:18:40, 12.06s/it, loss=0.5936, lr=6.80e-06]Steps:  44%|████▍     | 2222/5000 [8:19:48<9:18:42, 12.07s/it, loss=0.5936, lr=6.80e-06]Steps:  44%|████▍     | 2222/5000 [8:19:48<9:18:42, 12.07s/it, loss=0.4743, lr=6.80e-06]Steps:  44%|████▍     | 2223/5000 [8:20:00<9:15:57, 12.01s/it, loss=0.4743, lr=6.80e-06]Steps:  44%|████▍     | 2223/5000 [8:20:00<9:15:57, 12.01s/it, loss=0.4209, lr=6.80e-06]Steps:  44%|████▍     | 2224/5000 [8:20:12<9:14:45, 11.99s/it, loss=0.4209, lr=6.80e-06]Steps:  44%|████▍     | 2224/5000 [8:20:12<9:14:45, 11.99s/it, loss=0.7449, lr=6.80e-06]Steps:  44%|████▍     | 2225/5000 [8:20:24<9:15:12, 12.00s/it, loss=0.7449, lr=6.80e-06]Steps:  44%|████▍     | 2225/5000 [8:20:24<9:15:12, 12.00s/it, loss=0.3784, lr=6.79e-06]Steps:  45%|████▍     | 2226/5000 [8:20:36<9:12:38, 11.95s/it, loss=0.3784, lr=6.79e-06]Steps:  45%|████▍     | 2226/5000 [8:20:36<9:12:38, 11.95s/it, loss=0.8706, lr=6.79e-06]Steps:  45%|████▍     | 2227/5000 [8:20:48<9:11:51, 11.94s/it, loss=0.8706, lr=6.79e-06]Steps:  45%|████▍     | 2227/5000 [8:20:48<9:11:51, 11.94s/it, loss=0.5941, lr=6.79e-06]Steps:  45%|████▍     | 2228/5000 [8:21:00<9:11:07, 11.93s/it, loss=0.5941, lr=6.79e-06]Steps:  45%|████▍     | 2228/5000 [8:21:00<9:11:07, 11.93s/it, loss=1.0939, lr=6.78e-06]Steps:  45%|████▍     | 2229/5000 [8:21:12<9:15:11, 12.02s/it, loss=1.0939, lr=6.78e-06]Steps:  45%|████▍     | 2229/5000 [8:21:12<9:15:11, 12.02s/it, loss=1.0347, lr=6.78e-06]Steps:  45%|████▍     | 2230/5000 [8:21:24<9:16:51, 12.06s/it, loss=1.0347, lr=6.78e-06]Steps:  45%|████▍     | 2230/5000 [8:21:24<9:16:51, 12.06s/it, loss=0.5178, lr=6.78e-06]
[Step 2230] Training Debug Info:
  Loss: 0.611996
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0393, std: 0.9023
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0427, std: 1.3438
  Model pred mean: -0.0311, std: 1.0859
  Sigmas: [0.98046875]... (timesteps: [980.0])

[Step 2230] Training Debug Info:
  Loss: 0.827672
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0097, std: 0.8945
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0079, std: 1.3438
  Model pred mean: 0.0094, std: 0.9883
  Sigmas: [0.451171875]... (timesteps: [451.0])

[Step 2230] Training Debug Info:
  Loss: 0.396895
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0042, std: 0.9258
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0045, std: 1.3594
  Model pred mean: -0.0015, std: 1.2109
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 2230] Training Debug Info:
  Loss: 0.334280
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0109, std: 0.9023
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0129, std: 1.3516
  Model pred mean: -0.0102, std: 1.2188
  Sigmas: [0.8515625]... (timesteps: [851.0])
Steps:  45%|████▍     | 2231/5000 [8:21:36<9:16:24, 12.06s/it, loss=0.5178, lr=6.78e-06]Steps:  45%|████▍     | 2231/5000 [8:21:36<9:16:24, 12.06s/it, loss=0.3343, lr=6.77e-06]Steps:  45%|████▍     | 2232/5000 [8:21:48<9:16:58, 12.07s/it, loss=0.3343, lr=6.77e-06]Steps:  45%|████▍     | 2232/5000 [8:21:48<9:16:58, 12.07s/it, loss=1.1572, lr=6.77e-06]Steps:  45%|████▍     | 2233/5000 [8:22:00<9:15:46, 12.05s/it, loss=1.1572, lr=6.77e-06]Steps:  45%|████▍     | 2233/5000 [8:22:00<9:15:46, 12.05s/it, loss=1.1121, lr=6.77e-06]Steps:  45%|████▍     | 2234/5000 [8:22:12<9:15:01, 12.04s/it, loss=1.1121, lr=6.77e-06]Steps:  45%|████▍     | 2234/5000 [8:22:12<9:15:01, 12.04s/it, loss=0.5416, lr=6.76e-06]Steps:  45%|████▍     | 2235/5000 [8:22:24<9:14:26, 12.03s/it, loss=0.5416, lr=6.76e-06]Steps:  45%|████▍     | 2235/5000 [8:22:24<9:14:26, 12.03s/it, loss=1.0333, lr=6.76e-06]Steps:  45%|████▍     | 2236/5000 [8:22:36<9:17:10, 12.09s/it, loss=1.0333, lr=6.76e-06]Steps:  45%|████▍     | 2236/5000 [8:22:36<9:17:10, 12.09s/it, loss=1.0777, lr=6.76e-06]Steps:  45%|████▍     | 2237/5000 [8:22:48<9:15:19, 12.06s/it, loss=1.0777, lr=6.76e-06]Steps:  45%|████▍     | 2237/5000 [8:22:48<9:15:19, 12.06s/it, loss=0.4182, lr=6.75e-06]Steps:  45%|████▍     | 2238/5000 [8:23:00<9:15:44, 12.07s/it, loss=0.4182, lr=6.75e-06]Steps:  45%|████▍     | 2238/5000 [8:23:00<9:15:44, 12.07s/it, loss=0.9927, lr=6.75e-06]Steps:  45%|████▍     | 2239/5000 [8:23:12<9:14:33, 12.05s/it, loss=0.9927, lr=6.75e-06]Steps:  45%|████▍     | 2239/5000 [8:23:12<9:14:33, 12.05s/it, loss=0.7249, lr=6.75e-06]Steps:  45%|████▍     | 2240/5000 [8:23:24<9:13:52, 12.04s/it, loss=0.7249, lr=6.75e-06]Steps:  45%|████▍     | 2240/5000 [8:23:24<9:13:52, 12.04s/it, loss=1.1212, lr=6.74e-06]
[Step 2240] Training Debug Info:
  Loss: 1.172681
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0249, std: 0.9102
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0271, std: 1.3516
  Model pred mean: 0.0264, std: 0.8125
  Sigmas: [0.2353515625]... (timesteps: [235.0])

[Step 2240] Training Debug Info:
  Loss: 1.134971
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0107, std: 0.9219
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0103, std: 1.3594
  Model pred mean: -0.0079, std: 0.8477
  Sigmas: [0.10400390625]... (timesteps: [104.0])

[Step 2240] Training Debug Info:
  Loss: 1.022624
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0091, std: 0.9180
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0066, std: 1.3594
  Model pred mean: -0.0067, std: 0.9062
  Sigmas: [0.3125]... (timesteps: [312.0])

[Step 2240] Training Debug Info:
  Loss: 0.936516
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0143, std: 0.9531
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0154, std: 1.3828
  Model pred mean: -0.0102, std: 0.9844
  Sigmas: [0.357421875]... (timesteps: [358.0])
Steps:  45%|████▍     | 2241/5000 [8:23:36<9:13:34, 12.04s/it, loss=1.1212, lr=6.74e-06]Steps:  45%|████▍     | 2241/5000 [8:23:36<9:13:34, 12.04s/it, loss=0.9365, lr=6.74e-06]Steps:  45%|████▍     | 2242/5000 [8:23:48<9:12:18, 12.02s/it, loss=0.9365, lr=6.74e-06]Steps:  45%|████▍     | 2242/5000 [8:23:48<9:12:18, 12.02s/it, loss=1.1157, lr=6.74e-06]Steps:  45%|████▍     | 2243/5000 [8:24:00<9:12:14, 12.02s/it, loss=1.1157, lr=6.74e-06]Steps:  45%|████▍     | 2243/5000 [8:24:00<9:12:14, 12.02s/it, loss=0.3647, lr=6.73e-06]Steps:  45%|████▍     | 2244/5000 [8:24:12<9:10:49, 11.99s/it, loss=0.3647, lr=6.73e-06]Steps:  45%|████▍     | 2244/5000 [8:24:12<9:10:49, 11.99s/it, loss=0.4047, lr=6.73e-06]Steps:  45%|████▍     | 2245/5000 [8:24:24<9:11:48, 12.02s/it, loss=0.4047, lr=6.73e-06]Steps:  45%|████▍     | 2245/5000 [8:24:24<9:11:48, 12.02s/it, loss=0.9168, lr=6.73e-06]Steps:  45%|████▍     | 2246/5000 [8:24:36<9:10:31, 11.99s/it, loss=0.9168, lr=6.73e-06]Steps:  45%|████▍     | 2246/5000 [8:24:36<9:10:31, 11.99s/it, loss=0.8473, lr=6.72e-06]Steps:  45%|████▍     | 2247/5000 [8:24:48<9:08:25, 11.95s/it, loss=0.8473, lr=6.72e-06]Steps:  45%|████▍     | 2247/5000 [8:24:48<9:08:25, 11.95s/it, loss=0.5273, lr=6.72e-06]Steps:  45%|████▍     | 2248/5000 [8:25:00<9:09:46, 11.99s/it, loss=0.5273, lr=6.72e-06]Steps:  45%|████▍     | 2248/5000 [8:25:00<9:09:46, 11.99s/it, loss=1.1338, lr=6.72e-06]Steps:  45%|████▍     | 2249/5000 [8:25:12<9:09:16, 11.98s/it, loss=1.1338, lr=6.72e-06]Steps:  45%|████▍     | 2249/5000 [8:25:12<9:09:16, 11.98s/it, loss=0.6995, lr=6.71e-06]Steps:  45%|████▌     | 2250/5000 [8:25:24<9:08:44, 11.97s/it, loss=0.6995, lr=6.71e-06]Steps:  45%|████▌     | 2250/5000 [8:25:24<9:08:44, 11.97s/it, loss=1.1214, lr=6.71e-06]
[Step 2250] Training Debug Info:
  Loss: 0.635271
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0266, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0267, std: 1.3594
  Model pred mean: -0.0281, std: 1.1016
  Sigmas: [0.490234375]... (timesteps: [491.0])

[Step 2250] Training Debug Info:
  Loss: 1.109940
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0223, std: 0.9258
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0190, std: 1.3672
  Model pred mean: -0.0286, std: 0.8711
  Sigmas: [0.2158203125]... (timesteps: [216.0])

[Step 2250] Training Debug Info:
  Loss: 1.192535
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0347, std: 0.8945
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0349, std: 1.3438
  Model pred mean: 0.0306, std: 0.7852
  Sigmas: [0.224609375]... (timesteps: [225.0])

[Step 2250] Training Debug Info:
  Loss: 1.020913
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0007, std: 0.8867
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0007, std: 1.3359
  Model pred mean: -0.0052, std: 0.8711
  Sigmas: [0.32421875]... (timesteps: [325.0])
Steps:  45%|████▌     | 2251/5000 [8:25:36<9:07:19, 11.95s/it, loss=1.1214, lr=6.71e-06]Steps:  45%|████▌     | 2251/5000 [8:25:36<9:07:19, 11.95s/it, loss=1.0209, lr=6.71e-06]Steps:  45%|████▌     | 2252/5000 [8:25:48<9:09:36, 12.00s/it, loss=1.0209, lr=6.71e-06]Steps:  45%|████▌     | 2252/5000 [8:25:48<9:09:36, 12.00s/it, loss=0.6421, lr=6.70e-06]Steps:  45%|████▌     | 2253/5000 [8:26:00<9:08:33, 11.98s/it, loss=0.6421, lr=6.70e-06]Steps:  45%|████▌     | 2253/5000 [8:26:00<9:08:33, 11.98s/it, loss=0.4739, lr=6.70e-06]Steps:  45%|████▌     | 2254/5000 [8:26:12<9:07:24, 11.96s/it, loss=0.4739, lr=6.70e-06]Steps:  45%|████▌     | 2254/5000 [8:26:12<9:07:24, 11.96s/it, loss=1.1408, lr=6.70e-06]Steps:  45%|████▌     | 2255/5000 [8:26:24<9:05:39, 11.93s/it, loss=1.1408, lr=6.70e-06]Steps:  45%|████▌     | 2255/5000 [8:26:24<9:05:39, 11.93s/it, loss=1.1207, lr=6.69e-06]Steps:  45%|████▌     | 2256/5000 [8:26:36<9:04:56, 11.92s/it, loss=1.1207, lr=6.69e-06]Steps:  45%|████▌     | 2256/5000 [8:26:36<9:04:56, 11.92s/it, loss=1.1135, lr=6.69e-06]Steps:  45%|████▌     | 2257/5000 [8:26:48<9:04:33, 11.91s/it, loss=1.1135, lr=6.69e-06]Steps:  45%|████▌     | 2257/5000 [8:26:48<9:04:33, 11.91s/it, loss=0.8173, lr=6.69e-06]Steps:  45%|████▌     | 2258/5000 [8:27:00<9:02:56, 11.88s/it, loss=0.8173, lr=6.69e-06]Steps:  45%|████▌     | 2258/5000 [8:27:00<9:02:56, 11.88s/it, loss=1.0960, lr=6.68e-06]Steps:  45%|████▌     | 2259/5000 [8:27:12<9:04:29, 11.92s/it, loss=1.0960, lr=6.68e-06]Steps:  45%|████▌     | 2259/5000 [8:27:12<9:04:29, 11.92s/it, loss=0.7821, lr=6.68e-06]Steps:  45%|████▌     | 2260/5000 [8:27:23<9:04:34, 11.93s/it, loss=0.7821, lr=6.68e-06]Steps:  45%|████▌     | 2260/5000 [8:27:23<9:04:34, 11.93s/it, loss=0.3645, lr=6.68e-06]
[Step 2260] Training Debug Info:
  Loss: 0.978610
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0342, std: 0.9336
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0339, std: 1.3672
  Model pred mean: -0.0332, std: 0.9570
  Sigmas: [0.259765625]... (timesteps: [259.0])

[Step 2260] Training Debug Info:
  Loss: 0.759961
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0102, std: 0.9375
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0109, std: 1.3750
  Model pred mean: -0.0087, std: 1.0625
  Sigmas: [0.44921875]... (timesteps: [449.0])

[Step 2260] Training Debug Info:
  Loss: 0.794678
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0197, std: 0.9727
  Noise mean: 0.0029, std: 1.0000
  Target mean: -0.0167, std: 1.3984
  Model pred mean: -0.0187, std: 1.0703
  Sigmas: [0.9921875]... (timesteps: [992.0])

[Step 2260] Training Debug Info:
  Loss: 1.099701
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0427, std: 0.9219
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0439, std: 1.3594
  Model pred mean: -0.0442, std: 0.8711
  Sigmas: [0.0849609375]... (timesteps: [85.0])
Steps:  45%|████▌     | 2261/5000 [8:27:36<9:06:14, 11.97s/it, loss=0.3645, lr=6.68e-06]Steps:  45%|████▌     | 2261/5000 [8:27:36<9:06:14, 11.97s/it, loss=1.0997, lr=6.67e-06]Steps:  45%|████▌     | 2262/5000 [8:27:48<9:06:26, 11.97s/it, loss=1.0997, lr=6.67e-06]Steps:  45%|████▌     | 2262/5000 [8:27:48<9:06:26, 11.97s/it, loss=1.0839, lr=6.67e-06]Steps:  45%|████▌     | 2263/5000 [8:27:59<9:04:56, 11.95s/it, loss=1.0839, lr=6.67e-06]Steps:  45%|████▌     | 2263/5000 [8:27:59<9:04:56, 11.95s/it, loss=0.9936, lr=6.67e-06]Steps:  45%|████▌     | 2264/5000 [8:28:11<9:03:29, 11.92s/it, loss=0.9936, lr=6.67e-06]Steps:  45%|████▌     | 2264/5000 [8:28:11<9:03:29, 11.92s/it, loss=1.1747, lr=6.66e-06]Steps:  45%|████▌     | 2265/5000 [8:28:23<9:04:42, 11.95s/it, loss=1.1747, lr=6.66e-06]Steps:  45%|████▌     | 2265/5000 [8:28:23<9:04:42, 11.95s/it, loss=0.5370, lr=6.66e-06]Steps:  45%|████▌     | 2266/5000 [8:28:35<9:05:46, 11.98s/it, loss=0.5370, lr=6.66e-06]Steps:  45%|████▌     | 2266/5000 [8:28:35<9:05:46, 11.98s/it, loss=0.7390, lr=6.66e-06]Steps:  45%|████▌     | 2267/5000 [8:28:47<9:05:22, 11.97s/it, loss=0.7390, lr=6.66e-06]Steps:  45%|████▌     | 2267/5000 [8:28:47<9:05:22, 11.97s/it, loss=0.3555, lr=6.65e-06]Steps:  45%|████▌     | 2268/5000 [8:28:59<9:04:20, 11.95s/it, loss=0.3555, lr=6.65e-06]Steps:  45%|████▌     | 2268/5000 [8:28:59<9:04:20, 11.95s/it, loss=0.4185, lr=6.65e-06]Steps:  45%|████▌     | 2269/5000 [8:29:11<9:02:55, 11.93s/it, loss=0.4185, lr=6.65e-06]Steps:  45%|████▌     | 2269/5000 [8:29:11<9:02:55, 11.93s/it, loss=0.5955, lr=6.65e-06]Steps:  45%|████▌     | 2270/5000 [8:29:23<9:07:29, 12.03s/it, loss=0.5955, lr=6.65e-06]Steps:  45%|████▌     | 2270/5000 [8:29:23<9:07:29, 12.03s/it, loss=1.1162, lr=6.64e-06]
[Step 2270] Training Debug Info:
  Loss: 0.672159
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0708, std: 0.9570
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0718, std: 1.3828
  Model pred mean: -0.0737, std: 1.1172
  Sigmas: [0.373046875]... (timesteps: [373.0])

[Step 2270] Training Debug Info:
  Loss: 0.492217
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0211, std: 0.8633
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0199, std: 1.3203
  Model pred mean: 0.0250, std: 1.0938
  Sigmas: [0.984375]... (timesteps: [986.0])

[Step 2270] Training Debug Info:
  Loss: 1.171093
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0118, std: 0.8867
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0104, std: 1.3359
  Model pred mean: -0.0137, std: 0.7852
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 2270] Training Debug Info:
  Loss: 0.397153
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0055, std: 0.9023
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0042, std: 1.3438
  Model pred mean: 0.0023, std: 1.1953
  Sigmas: [0.78125]... (timesteps: [782.0])
Steps:  45%|████▌     | 2271/5000 [8:29:35<9:05:31, 11.99s/it, loss=1.1162, lr=6.64e-06]Steps:  45%|████▌     | 2271/5000 [8:29:35<9:05:31, 11.99s/it, loss=0.3972, lr=6.64e-06]Steps:  45%|████▌     | 2272/5000 [8:29:47<9:06:23, 12.02s/it, loss=0.3972, lr=6.64e-06]Steps:  45%|████▌     | 2272/5000 [8:29:47<9:06:23, 12.02s/it, loss=0.4300, lr=6.64e-06]Steps:  45%|████▌     | 2273/5000 [8:29:59<9:04:22, 11.98s/it, loss=0.4300, lr=6.64e-06]Steps:  45%|████▌     | 2273/5000 [8:29:59<9:04:22, 11.98s/it, loss=0.3981, lr=6.63e-06]Steps:  45%|████▌     | 2274/5000 [8:30:11<9:02:54, 11.95s/it, loss=0.3981, lr=6.63e-06]Steps:  45%|████▌     | 2274/5000 [8:30:11<9:02:54, 11.95s/it, loss=0.4387, lr=6.63e-06]Steps:  46%|████▌     | 2275/5000 [8:30:23<9:02:11, 11.94s/it, loss=0.4387, lr=6.63e-06]Steps:  46%|████▌     | 2275/5000 [8:30:23<9:02:11, 11.94s/it, loss=0.6725, lr=6.63e-06]Steps:  46%|████▌     | 2276/5000 [8:30:35<9:02:41, 11.95s/it, loss=0.6725, lr=6.63e-06]Steps:  46%|████▌     | 2276/5000 [8:30:35<9:02:41, 11.95s/it, loss=0.9609, lr=6.62e-06]Steps:  46%|████▌     | 2277/5000 [8:30:47<9:00:50, 11.92s/it, loss=0.9609, lr=6.62e-06]Steps:  46%|████▌     | 2277/5000 [8:30:47<9:00:50, 11.92s/it, loss=0.8454, lr=6.62e-06]Steps:  46%|████▌     | 2278/5000 [8:30:59<9:00:48, 11.92s/it, loss=0.8454, lr=6.62e-06]Steps:  46%|████▌     | 2278/5000 [8:30:59<9:00:48, 11.92s/it, loss=1.1185, lr=6.62e-06]Steps:  46%|████▌     | 2279/5000 [8:31:11<9:04:56, 12.02s/it, loss=1.1185, lr=6.62e-06]Steps:  46%|████▌     | 2279/5000 [8:31:11<9:04:56, 12.02s/it, loss=1.1287, lr=6.61e-06]Steps:  46%|████▌     | 2280/5000 [8:31:23<9:03:14, 11.98s/it, loss=1.1287, lr=6.61e-06]Steps:  46%|████▌     | 2280/5000 [8:31:23<9:03:14, 11.98s/it, loss=0.5080, lr=6.61e-06]
[Step 2280] Training Debug Info:
  Loss: 0.704745
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0060, std: 0.9883
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0083, std: 1.4062
  Model pred mean: -0.0083, std: 1.1328
  Sigmas: [0.47265625]... (timesteps: [472.0])

[Step 2280] Training Debug Info:
  Loss: 0.614947
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0198, std: 0.8867
  Noise mean: 0.0038, std: 0.9961
  Target mean: 0.0236, std: 1.3359
  Model pred mean: 0.0225, std: 1.0938
  Sigmas: [0.97265625]... (timesteps: [971.0])

[Step 2280] Training Debug Info:
  Loss: 0.378758
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0205, std: 0.9141
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0205, std: 1.3594
  Model pred mean: 0.0223, std: 1.2109
  Sigmas: [0.78515625]... (timesteps: [784.0])

[Step 2280] Training Debug Info:
  Loss: 0.626243
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0184, std: 0.9609
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0190, std: 1.3906
  Model pred mean: -0.0186, std: 1.1406
  Sigmas: [0.546875]... (timesteps: [547.0])
Steps:  46%|████▌     | 2281/5000 [8:31:35<9:02:31, 11.97s/it, loss=0.5080, lr=6.61e-06]Steps:  46%|████▌     | 2281/5000 [8:31:35<9:02:31, 11.97s/it, loss=0.6262, lr=6.61e-06]Steps:  46%|████▌     | 2282/5000 [8:31:47<9:01:38, 11.96s/it, loss=0.6262, lr=6.61e-06]Steps:  46%|████▌     | 2282/5000 [8:31:47<9:01:38, 11.96s/it, loss=0.9841, lr=6.60e-06]Steps:  46%|████▌     | 2283/5000 [8:31:59<9:00:55, 11.95s/it, loss=0.9841, lr=6.60e-06]Steps:  46%|████▌     | 2283/5000 [8:31:59<9:00:55, 11.95s/it, loss=0.4002, lr=6.60e-06]Steps:  46%|████▌     | 2284/5000 [8:32:11<9:01:49, 11.97s/it, loss=0.4002, lr=6.60e-06]Steps:  46%|████▌     | 2284/5000 [8:32:11<9:01:49, 11.97s/it, loss=0.4505, lr=6.60e-06]Steps:  46%|████▌     | 2285/5000 [8:32:23<9:01:12, 11.96s/it, loss=0.4505, lr=6.60e-06]Steps:  46%|████▌     | 2285/5000 [8:32:23<9:01:12, 11.96s/it, loss=0.8329, lr=6.59e-06]Steps:  46%|████▌     | 2286/5000 [8:32:35<9:01:11, 11.96s/it, loss=0.8329, lr=6.59e-06]Steps:  46%|████▌     | 2286/5000 [8:32:35<9:01:11, 11.96s/it, loss=0.6208, lr=6.59e-06]Steps:  46%|████▌     | 2287/5000 [8:32:47<9:00:59, 11.96s/it, loss=0.6208, lr=6.59e-06]Steps:  46%|████▌     | 2287/5000 [8:32:47<9:00:59, 11.96s/it, loss=0.3811, lr=6.59e-06]Steps:  46%|████▌     | 2288/5000 [8:32:59<9:02:09, 11.99s/it, loss=0.3811, lr=6.59e-06]Steps:  46%|████▌     | 2288/5000 [8:32:59<9:02:09, 11.99s/it, loss=0.7584, lr=6.58e-06]Steps:  46%|████▌     | 2289/5000 [8:33:11<9:01:02, 11.97s/it, loss=0.7584, lr=6.58e-06]Steps:  46%|████▌     | 2289/5000 [8:33:11<9:01:02, 11.97s/it, loss=1.1718, lr=6.58e-06]Steps:  46%|████▌     | 2290/5000 [8:33:23<9:00:43, 11.97s/it, loss=1.1718, lr=6.58e-06]Steps:  46%|████▌     | 2290/5000 [8:33:23<9:00:43, 11.97s/it, loss=1.1081, lr=6.58e-06]
[Step 2290] Training Debug Info:
  Loss: 0.956878
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0126, std: 0.9531
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0121, std: 1.3828
  Model pred mean: -0.0125, std: 0.9805
  Sigmas: [0.333984375]... (timesteps: [334.0])

[Step 2290] Training Debug Info:
  Loss: 1.199223
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0136, std: 0.8125
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0154, std: 1.2891
  Model pred mean: 0.0153, std: 0.6836
  Sigmas: [0.26953125]... (timesteps: [270.0])

[Step 2290] Training Debug Info:
  Loss: 0.361797
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0194, std: 0.9219
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0186, std: 1.3594
  Model pred mean: -0.0142, std: 1.2188
  Sigmas: [0.8359375]... (timesteps: [836.0])

[Step 2290] Training Debug Info:
  Loss: 1.119942
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0192, std: 0.9258
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0205, std: 1.3594
  Model pred mean: -0.0178, std: 0.8555
  Sigmas: [0.11083984375]... (timesteps: [111.0])
Steps:  46%|████▌     | 2291/5000 [8:33:34<8:59:52, 11.96s/it, loss=1.1081, lr=6.58e-06]Steps:  46%|████▌     | 2291/5000 [8:33:34<8:59:52, 11.96s/it, loss=1.1199, lr=6.57e-06]Steps:  46%|████▌     | 2292/5000 [8:33:47<9:00:57, 11.99s/it, loss=1.1199, lr=6.57e-06]Steps:  46%|████▌     | 2292/5000 [8:33:47<9:00:57, 11.99s/it, loss=1.1608, lr=6.57e-06]Steps:  46%|████▌     | 2293/5000 [8:33:59<9:01:08, 11.99s/it, loss=1.1608, lr=6.57e-06]Steps:  46%|████▌     | 2293/5000 [8:33:59<9:01:08, 11.99s/it, loss=1.0869, lr=6.57e-06]Steps:  46%|████▌     | 2294/5000 [8:34:11<9:00:53, 11.99s/it, loss=1.0869, lr=6.57e-06]Steps:  46%|████▌     | 2294/5000 [8:34:11<9:00:53, 11.99s/it, loss=0.3693, lr=6.56e-06]Steps:  46%|████▌     | 2295/5000 [8:34:23<9:00:37, 11.99s/it, loss=0.3693, lr=6.56e-06]Steps:  46%|████▌     | 2295/5000 [8:34:23<9:00:37, 11.99s/it, loss=1.1662, lr=6.56e-06]Steps:  46%|████▌     | 2296/5000 [8:34:34<8:59:29, 11.97s/it, loss=1.1662, lr=6.56e-06]Steps:  46%|████▌     | 2296/5000 [8:34:34<8:59:29, 11.97s/it, loss=1.0839, lr=6.56e-06]Steps:  46%|████▌     | 2297/5000 [8:34:46<9:00:09, 11.99s/it, loss=1.0839, lr=6.56e-06]Steps:  46%|████▌     | 2297/5000 [8:34:46<9:00:09, 11.99s/it, loss=1.1408, lr=6.56e-06]Steps:  46%|████▌     | 2298/5000 [8:34:58<8:59:07, 11.97s/it, loss=1.1408, lr=6.56e-06]Steps:  46%|████▌     | 2298/5000 [8:34:58<8:59:07, 11.97s/it, loss=1.1048, lr=6.55e-06]Steps:  46%|████▌     | 2299/5000 [8:35:11<9:01:01, 12.02s/it, loss=1.1048, lr=6.55e-06]Steps:  46%|████▌     | 2299/5000 [8:35:11<9:01:01, 12.02s/it, loss=1.1509, lr=6.55e-06]Steps:  46%|████▌     | 2300/5000 [8:35:23<9:00:00, 12.00s/it, loss=1.1509, lr=6.55e-06]Steps:  46%|████▌     | 2300/5000 [8:35:23<9:00:00, 12.00s/it, loss=1.1316, lr=6.55e-06]01/22/2026 16:21:09 - INFO - __main__ - 
[Step 2300] ✅ Loss in normal range (1.1316)
01/22/2026 16:21:09 - INFO - __main__ -   Loss avg (last 100): 0.7833
01/22/2026 16:21:09 - INFO - __main__ -   Loss range: [0.3343, 1.1747]

[Step 2300] Training Debug Info:
  Loss: 0.734913
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0479, std: 0.9258
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0483, std: 1.3594
  Model pred mean: -0.0464, std: 1.0547
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 2300] Training Debug Info:
  Loss: 1.165243
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0396, std: 0.8750
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0388, std: 1.3281
  Model pred mean: 0.0435, std: 0.7773
  Sigmas: [0.10888671875]... (timesteps: [109.0])

[Step 2300] Training Debug Info:
  Loss: 1.128987
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0032, std: 0.9414
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0038, std: 1.3750
  Model pred mean: -0.0042, std: 0.8750
  Sigmas: [0.232421875]... (timesteps: [232.0])

[Step 2300] Training Debug Info:
  Loss: 0.452889
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0256, std: 0.8906
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0265, std: 1.3359
  Model pred mean: -0.0240, std: 1.1641
  Sigmas: [0.74609375]... (timesteps: [746.0])
Steps:  46%|████▌     | 2301/5000 [8:35:34<8:58:03, 11.96s/it, loss=1.1316, lr=6.55e-06]Steps:  46%|████▌     | 2301/5000 [8:35:34<8:58:03, 11.96s/it, loss=0.4529, lr=6.54e-06]Steps:  46%|████▌     | 2302/5000 [8:35:46<8:57:27, 11.95s/it, loss=0.4529, lr=6.54e-06]Steps:  46%|████▌     | 2302/5000 [8:35:46<8:57:27, 11.95s/it, loss=1.0991, lr=6.54e-06]Steps:  46%|████▌     | 2303/5000 [8:35:58<8:56:52, 11.94s/it, loss=1.0991, lr=6.54e-06]Steps:  46%|████▌     | 2303/5000 [8:35:58<8:56:52, 11.94s/it, loss=0.9871, lr=6.54e-06]Steps:  46%|████▌     | 2304/5000 [8:36:10<8:55:41, 11.92s/it, loss=0.9871, lr=6.54e-06]Steps:  46%|████▌     | 2304/5000 [8:36:10<8:55:41, 11.92s/it, loss=0.3809, lr=6.53e-06]Steps:  46%|████▌     | 2305/5000 [8:36:22<8:55:37, 11.92s/it, loss=0.3809, lr=6.53e-06]Steps:  46%|████▌     | 2305/5000 [8:36:22<8:55:37, 11.92s/it, loss=1.0517, lr=6.53e-06]Steps:  46%|████▌     | 2306/5000 [8:36:34<8:56:57, 11.96s/it, loss=1.0517, lr=6.53e-06]Steps:  46%|████▌     | 2306/5000 [8:36:34<8:56:57, 11.96s/it, loss=0.6600, lr=6.53e-06]Steps:  46%|████▌     | 2307/5000 [8:36:46<8:56:52, 11.96s/it, loss=0.6600, lr=6.53e-06]Steps:  46%|████▌     | 2307/5000 [8:36:46<8:56:52, 11.96s/it, loss=0.4441, lr=6.52e-06]Steps:  46%|████▌     | 2308/5000 [8:36:58<8:54:49, 11.92s/it, loss=0.4441, lr=6.52e-06]Steps:  46%|████▌     | 2308/5000 [8:36:58<8:54:49, 11.92s/it, loss=0.4818, lr=6.52e-06]Steps:  46%|████▌     | 2309/5000 [8:37:10<8:53:28, 11.89s/it, loss=0.4818, lr=6.52e-06]Steps:  46%|████▌     | 2309/5000 [8:37:10<8:53:28, 11.89s/it, loss=0.5427, lr=6.52e-06]Steps:  46%|████▌     | 2310/5000 [8:37:22<8:53:29, 11.90s/it, loss=0.5427, lr=6.52e-06]Steps:  46%|████▌     | 2310/5000 [8:37:22<8:53:29, 11.90s/it, loss=1.0361, lr=6.51e-06]
[Step 2310] Training Debug Info:
  Loss: 1.078867
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0150, std: 0.9180
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0133, std: 1.3594
  Model pred mean: -0.0173, std: 0.8750
  Sigmas: [0.25]... (timesteps: [250.0])

[Step 2310] Training Debug Info:
  Loss: 0.575529
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0137, std: 0.9297
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0150, std: 1.3672
  Model pred mean: -0.0079, std: 1.1484
  Sigmas: [0.93359375]... (timesteps: [934.0])

[Step 2310] Training Debug Info:
  Loss: 0.749538
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0237, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0250, std: 1.3516
  Model pred mean: -0.0273, std: 1.0391
  Sigmas: [0.447265625]... (timesteps: [447.0])

[Step 2310] Training Debug Info:
  Loss: 0.556059
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0205, std: 0.9336
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0182, std: 1.3672
  Model pred mean: -0.0225, std: 1.1484
  Sigmas: [0.57421875]... (timesteps: [575.0])
Steps:  46%|████▌     | 2311/5000 [8:37:34<8:54:34, 11.93s/it, loss=1.0361, lr=6.51e-06]Steps:  46%|████▌     | 2311/5000 [8:37:34<8:54:34, 11.93s/it, loss=0.5561, lr=6.51e-06]Steps:  46%|████▌     | 2312/5000 [8:37:46<8:54:13, 11.92s/it, loss=0.5561, lr=6.51e-06]Steps:  46%|████▌     | 2312/5000 [8:37:46<8:54:13, 11.92s/it, loss=0.6232, lr=6.51e-06]Steps:  46%|████▋     | 2313/5000 [8:37:58<8:55:00, 11.95s/it, loss=0.6232, lr=6.51e-06]Steps:  46%|████▋     | 2313/5000 [8:37:58<8:55:00, 11.95s/it, loss=1.1620, lr=6.50e-06]Steps:  46%|████▋     | 2314/5000 [8:38:09<8:55:02, 11.95s/it, loss=1.1620, lr=6.50e-06]Steps:  46%|████▋     | 2314/5000 [8:38:09<8:55:02, 11.95s/it, loss=0.3637, lr=6.50e-06]Steps:  46%|████▋     | 2315/5000 [8:38:22<8:56:34, 11.99s/it, loss=0.3637, lr=6.50e-06]Steps:  46%|████▋     | 2315/5000 [8:38:22<8:56:34, 11.99s/it, loss=0.4737, lr=6.50e-06]Steps:  46%|████▋     | 2316/5000 [8:38:34<8:56:30, 11.99s/it, loss=0.4737, lr=6.50e-06]Steps:  46%|████▋     | 2316/5000 [8:38:34<8:56:30, 11.99s/it, loss=0.4330, lr=6.49e-06]Steps:  46%|████▋     | 2317/5000 [8:38:45<8:54:43, 11.96s/it, loss=0.4330, lr=6.49e-06]Steps:  46%|████▋     | 2317/5000 [8:38:45<8:54:43, 11.96s/it, loss=0.6326, lr=6.49e-06]Steps:  46%|████▋     | 2318/5000 [8:38:57<8:55:00, 11.97s/it, loss=0.6326, lr=6.49e-06]Steps:  46%|████▋     | 2318/5000 [8:38:57<8:55:00, 11.97s/it, loss=1.0883, lr=6.49e-06]Steps:  46%|████▋     | 2319/5000 [8:39:09<8:55:55, 11.99s/it, loss=1.0883, lr=6.49e-06]Steps:  46%|████▋     | 2319/5000 [8:39:09<8:55:55, 11.99s/it, loss=0.8029, lr=6.48e-06]Steps:  46%|████▋     | 2320/5000 [8:39:22<8:57:09, 12.03s/it, loss=0.8029, lr=6.48e-06]Steps:  46%|████▋     | 2320/5000 [8:39:22<8:57:09, 12.03s/it, loss=0.4241, lr=6.48e-06]
[Step 2320] Training Debug Info:
  Loss: 0.565328
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0522, std: 0.9844
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0520, std: 1.4062
  Model pred mean: -0.0466, std: 1.1719
  Sigmas: [0.89453125]... (timesteps: [893.0])

[Step 2320] Training Debug Info:
  Loss: 0.606486
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0344, std: 0.9180
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0371, std: 1.3594
  Model pred mean: -0.0310, std: 1.1172
  Sigmas: [0.49609375]... (timesteps: [497.0])

[Step 2320] Training Debug Info:
  Loss: 1.148442
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0155, std: 0.8711
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0172, std: 1.3281
  Model pred mean: -0.0140, std: 0.7930
  Sigmas: [0.22265625]... (timesteps: [223.0])

[Step 2320] Training Debug Info:
  Loss: 0.945254
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0041, std: 0.9102
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0045, std: 1.3516
  Model pred mean: -0.0039, std: 0.9492
  Sigmas: [0.369140625]... (timesteps: [370.0])
Steps:  46%|████▋     | 2321/5000 [8:39:33<8:54:11, 11.96s/it, loss=0.4241, lr=6.48e-06]Steps:  46%|████▋     | 2321/5000 [8:39:33<8:54:11, 11.96s/it, loss=0.9453, lr=6.48e-06]Steps:  46%|████▋     | 2322/5000 [8:39:45<8:53:27, 11.95s/it, loss=0.9453, lr=6.48e-06]Steps:  46%|████▋     | 2322/5000 [8:39:45<8:53:27, 11.95s/it, loss=0.4588, lr=6.47e-06]Steps:  46%|████▋     | 2323/5000 [8:39:57<8:53:37, 11.96s/it, loss=0.4588, lr=6.47e-06]Steps:  46%|████▋     | 2323/5000 [8:39:57<8:53:37, 11.96s/it, loss=0.8537, lr=6.47e-06]Steps:  46%|████▋     | 2324/5000 [8:40:09<8:54:01, 11.97s/it, loss=0.8537, lr=6.47e-06]Steps:  46%|████▋     | 2324/5000 [8:40:09<8:54:01, 11.97s/it, loss=0.6171, lr=6.47e-06]Steps:  46%|████▋     | 2325/5000 [8:40:21<8:53:06, 11.96s/it, loss=0.6171, lr=6.47e-06]Steps:  46%|████▋     | 2325/5000 [8:40:21<8:53:06, 11.96s/it, loss=0.5703, lr=6.46e-06]Steps:  47%|████▋     | 2326/5000 [8:40:33<8:54:43, 12.00s/it, loss=0.5703, lr=6.46e-06]Steps:  47%|████▋     | 2326/5000 [8:40:33<8:54:43, 12.00s/it, loss=1.0626, lr=6.46e-06]Steps:  47%|████▋     | 2327/5000 [8:40:45<8:53:46, 11.98s/it, loss=1.0626, lr=6.46e-06]Steps:  47%|████▋     | 2327/5000 [8:40:45<8:53:46, 11.98s/it, loss=1.2070, lr=6.46e-06]Steps:  47%|████▋     | 2328/5000 [8:40:57<8:52:47, 11.96s/it, loss=1.2070, lr=6.46e-06]Steps:  47%|████▋     | 2328/5000 [8:40:57<8:52:47, 11.96s/it, loss=0.4176, lr=6.45e-06]Steps:  47%|████▋     | 2329/5000 [8:41:09<8:53:07, 11.98s/it, loss=0.4176, lr=6.45e-06]Steps:  47%|████▋     | 2329/5000 [8:41:09<8:53:07, 11.98s/it, loss=1.0987, lr=6.45e-06]Steps:  47%|████▋     | 2330/5000 [8:41:21<8:52:21, 11.96s/it, loss=1.0987, lr=6.45e-06]Steps:  47%|████▋     | 2330/5000 [8:41:21<8:52:21, 11.96s/it, loss=1.1187, lr=6.45e-06]
[Step 2330] Training Debug Info:
  Loss: 1.004455
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0142, std: 0.9297
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0160, std: 1.3594
  Model pred mean: -0.0126, std: 0.9297
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 2330] Training Debug Info:
  Loss: 0.374839
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0175, std: 0.9258
  Noise mean: 0.0048, std: 1.0000
  Target mean: -0.0127, std: 1.3594
  Model pred mean: -0.0096, std: 1.2266
  Sigmas: [0.8359375]... (timesteps: [837.0])

[Step 2330] Training Debug Info:
  Loss: 1.025700
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0369, std: 0.9023
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0393, std: 1.3438
  Model pred mean: -0.0359, std: 0.8984
  Sigmas: [0.010986328125]... (timesteps: [11.0])

[Step 2330] Training Debug Info:
  Loss: 0.775104
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0101, std: 0.9688
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0098, std: 1.3906
  Model pred mean: -0.0002, std: 1.0625
  Sigmas: [0.9765625]... (timesteps: [976.0])
Steps:  47%|████▋     | 2331/5000 [8:41:33<8:51:30, 11.95s/it, loss=1.1187, lr=6.45e-06]Steps:  47%|████▋     | 2331/5000 [8:41:33<8:51:30, 11.95s/it, loss=0.7751, lr=6.44e-06]Steps:  47%|████▋     | 2332/5000 [8:41:45<8:51:24, 11.95s/it, loss=0.7751, lr=6.44e-06]Steps:  47%|████▋     | 2332/5000 [8:41:45<8:51:24, 11.95s/it, loss=0.9961, lr=6.44e-06]Steps:  47%|████▋     | 2333/5000 [8:41:57<8:52:31, 11.98s/it, loss=0.9961, lr=6.44e-06]Steps:  47%|████▋     | 2333/5000 [8:41:57<8:52:31, 11.98s/it, loss=1.0479, lr=6.44e-06]Steps:  47%|████▋     | 2334/5000 [8:42:09<8:51:20, 11.96s/it, loss=1.0479, lr=6.44e-06]Steps:  47%|████▋     | 2334/5000 [8:42:09<8:51:20, 11.96s/it, loss=1.0087, lr=6.43e-06]Steps:  47%|████▋     | 2335/5000 [8:42:21<8:50:42, 11.95s/it, loss=1.0087, lr=6.43e-06]Steps:  47%|████▋     | 2335/5000 [8:42:21<8:50:42, 11.95s/it, loss=0.5055, lr=6.43e-06]Steps:  47%|████▋     | 2336/5000 [8:42:33<8:50:09, 11.94s/it, loss=0.5055, lr=6.43e-06]Steps:  47%|████▋     | 2336/5000 [8:42:33<8:50:09, 11.94s/it, loss=0.8412, lr=6.43e-06]Steps:  47%|████▋     | 2337/5000 [8:42:45<8:49:49, 11.94s/it, loss=0.8412, lr=6.43e-06]Steps:  47%|████▋     | 2337/5000 [8:42:45<8:49:49, 11.94s/it, loss=0.5978, lr=6.42e-06]Steps:  47%|████▋     | 2338/5000 [8:42:57<8:50:59, 11.97s/it, loss=0.5978, lr=6.42e-06]Steps:  47%|████▋     | 2338/5000 [8:42:57<8:50:59, 11.97s/it, loss=0.3687, lr=6.42e-06]Steps:  47%|████▋     | 2339/5000 [8:43:09<8:50:51, 11.97s/it, loss=0.3687, lr=6.42e-06]Steps:  47%|████▋     | 2339/5000 [8:43:09<8:50:51, 11.97s/it, loss=1.1383, lr=6.42e-06]Steps:  47%|████▋     | 2340/5000 [8:43:21<8:52:14, 12.01s/it, loss=1.1383, lr=6.42e-06]Steps:  47%|████▋     | 2340/5000 [8:43:21<8:52:14, 12.01s/it, loss=1.0635, lr=6.41e-06]
[Step 2340] Training Debug Info:
  Loss: 1.033259
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0118, std: 0.8867
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0118, std: 1.3359
  Model pred mean: 0.0060, std: 0.8750
  Sigmas: [0.310546875]... (timesteps: [310.0])

[Step 2340] Training Debug Info:
  Loss: 0.372277
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0036, std: 0.9062
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0054, std: 1.3516
  Model pred mean: -0.0007, std: 1.2031
  Sigmas: [0.81640625]... (timesteps: [816.0])

[Step 2340] Training Debug Info:
  Loss: 0.392624
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0125, std: 0.8906
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0141, std: 1.3438
  Model pred mean: -0.0118, std: 1.1875
  Sigmas: [0.8359375]... (timesteps: [834.0])

[Step 2340] Training Debug Info:
  Loss: 0.665172
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0374, std: 0.9219
  Noise mean: 0.0031, std: 1.0000
  Target mean: -0.0342, std: 1.3594
  Model pred mean: -0.0211, std: 1.0938
  Sigmas: [0.94921875]... (timesteps: [948.0])
Steps:  47%|████▋     | 2341/5000 [8:43:33<8:51:32, 11.99s/it, loss=1.0635, lr=6.41e-06]Steps:  47%|████▋     | 2341/5000 [8:43:33<8:51:32, 11.99s/it, loss=0.6652, lr=6.41e-06]Steps:  47%|████▋     | 2342/5000 [8:43:45<8:51:47, 12.00s/it, loss=0.6652, lr=6.41e-06]Steps:  47%|████▋     | 2342/5000 [8:43:45<8:51:47, 12.00s/it, loss=0.4469, lr=6.41e-06]Steps:  47%|████▋     | 2343/5000 [8:43:57<8:50:17, 11.98s/it, loss=0.4469, lr=6.41e-06]Steps:  47%|████▋     | 2343/5000 [8:43:57<8:50:17, 11.98s/it, loss=1.1150, lr=6.40e-06]Steps:  47%|████▋     | 2344/5000 [8:44:09<8:48:38, 11.94s/it, loss=1.1150, lr=6.40e-06]Steps:  47%|████▋     | 2344/5000 [8:44:09<8:48:38, 11.94s/it, loss=1.0482, lr=6.40e-06]Steps:  47%|████▋     | 2345/5000 [8:44:20<8:47:34, 11.92s/it, loss=1.0482, lr=6.40e-06]Steps:  47%|████▋     | 2345/5000 [8:44:20<8:47:34, 11.92s/it, loss=0.5541, lr=6.39e-06]Steps:  47%|████▋     | 2346/5000 [8:44:33<8:49:16, 11.97s/it, loss=0.5541, lr=6.39e-06]Steps:  47%|████▋     | 2346/5000 [8:44:33<8:49:16, 11.97s/it, loss=1.1032, lr=6.39e-06]Steps:  47%|████▋     | 2347/5000 [8:44:45<8:49:48, 11.98s/it, loss=1.1032, lr=6.39e-06]Steps:  47%|████▋     | 2347/5000 [8:44:45<8:49:48, 11.98s/it, loss=0.6215, lr=6.39e-06]Steps:  47%|████▋     | 2348/5000 [8:44:56<8:48:38, 11.96s/it, loss=0.6215, lr=6.39e-06]Steps:  47%|████▋     | 2348/5000 [8:44:56<8:48:38, 11.96s/it, loss=0.4194, lr=6.38e-06]Steps:  47%|████▋     | 2349/5000 [8:45:08<8:47:46, 11.95s/it, loss=0.4194, lr=6.38e-06]Steps:  47%|████▋     | 2349/5000 [8:45:08<8:47:46, 11.95s/it, loss=0.3969, lr=6.38e-06]Steps:  47%|████▋     | 2350/5000 [8:45:20<8:47:25, 11.94s/it, loss=0.3969, lr=6.38e-06]Steps:  47%|████▋     | 2350/5000 [8:45:20<8:47:25, 11.94s/it, loss=0.4978, lr=6.38e-06]
[Step 2350] Training Debug Info:
  Loss: 1.102539
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0146, std: 0.9180
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0156, std: 1.3594
  Model pred mean: -0.0112, std: 0.8672
  Sigmas: [0.21875]... (timesteps: [219.0])

[Step 2350] Training Debug Info:
  Loss: 0.828954
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0042, std: 0.8594
  Noise mean: -0.0043, std: 1.0000
  Target mean: -0.0085, std: 1.3203
  Model pred mean: -0.0016, std: 0.9570
  Sigmas: [0.4765625]... (timesteps: [476.0])

[Step 2350] Training Debug Info:
  Loss: 0.961002
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0151, std: 0.9570
  Noise mean: 0.0039, std: 1.0000
  Target mean: -0.0112, std: 1.3828
  Model pred mean: -0.0119, std: 0.9844
  Sigmas: [0.2353515625]... (timesteps: [235.0])

[Step 2350] Training Debug Info:
  Loss: 0.727384
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0208, std: 0.9141
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0188, std: 1.3516
  Model pred mean: -0.0179, std: 1.0547
  Sigmas: [0.4921875]... (timesteps: [492.0])
Steps:  47%|████▋     | 2351/5000 [8:45:32<8:48:07, 11.96s/it, loss=0.4978, lr=6.38e-06]Steps:  47%|████▋     | 2351/5000 [8:45:32<8:48:07, 11.96s/it, loss=0.7274, lr=6.37e-06]Steps:  47%|████▋     | 2352/5000 [8:45:44<8:46:49, 11.94s/it, loss=0.7274, lr=6.37e-06]Steps:  47%|████▋     | 2352/5000 [8:45:44<8:46:49, 11.94s/it, loss=1.1875, lr=6.37e-06]Steps:  47%|████▋     | 2353/5000 [8:45:56<8:47:29, 11.96s/it, loss=1.1875, lr=6.37e-06]Steps:  47%|████▋     | 2353/5000 [8:45:56<8:47:29, 11.96s/it, loss=0.5063, lr=6.37e-06]Steps:  47%|████▋     | 2354/5000 [8:46:08<8:46:37, 11.94s/it, loss=0.5063, lr=6.37e-06]Steps:  47%|████▋     | 2354/5000 [8:46:08<8:46:37, 11.94s/it, loss=0.5911, lr=6.36e-06]Steps:  47%|████▋     | 2355/5000 [8:46:20<8:46:38, 11.95s/it, loss=0.5911, lr=6.36e-06]Steps:  47%|████▋     | 2355/5000 [8:46:20<8:46:38, 11.95s/it, loss=0.3565, lr=6.36e-06]Steps:  47%|████▋     | 2356/5000 [8:46:32<8:46:56, 11.96s/it, loss=0.3565, lr=6.36e-06]Steps:  47%|████▋     | 2356/5000 [8:46:32<8:46:56, 11.96s/it, loss=1.1745, lr=6.36e-06]Steps:  47%|████▋     | 2357/5000 [8:46:44<8:45:48, 11.94s/it, loss=1.1745, lr=6.36e-06]Steps:  47%|████▋     | 2357/5000 [8:46:44<8:45:48, 11.94s/it, loss=0.3662, lr=6.35e-06]Steps:  47%|████▋     | 2358/5000 [8:46:56<8:46:59, 11.97s/it, loss=0.3662, lr=6.35e-06]Steps:  47%|████▋     | 2358/5000 [8:46:56<8:46:59, 11.97s/it, loss=0.9611, lr=6.35e-06]Steps:  47%|████▋     | 2359/5000 [8:47:08<8:47:08, 11.98s/it, loss=0.9611, lr=6.35e-06]Steps:  47%|████▋     | 2359/5000 [8:47:08<8:47:08, 11.98s/it, loss=0.5991, lr=6.35e-06]Steps:  47%|████▋     | 2360/5000 [8:47:20<8:48:20, 12.01s/it, loss=0.5991, lr=6.35e-06]Steps:  47%|████▋     | 2360/5000 [8:47:20<8:48:20, 12.01s/it, loss=0.4688, lr=6.34e-06]
[Step 2360] Training Debug Info:
  Loss: 0.612518
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0059, std: 0.9023
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0067, std: 1.3438
  Model pred mean: -0.0442, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [989.0])

[Step 2360] Training Debug Info:
  Loss: 0.362473
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0142, std: 0.8945
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0126, std: 1.3359
  Model pred mean: 0.0119, std: 1.2031
  Sigmas: [0.88671875]... (timesteps: [886.0])

[Step 2360] Training Debug Info:
  Loss: 0.477337
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0145, std: 0.9062
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0137, std: 1.3516
  Model pred mean: 0.0132, std: 1.1641
  Sigmas: [0.71484375]... (timesteps: [715.0])

[Step 2360] Training Debug Info:
  Loss: 0.835653
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0161, std: 0.9258
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0156, std: 1.3594
  Model pred mean: -0.0149, std: 1.0078
  Sigmas: [0.451171875]... (timesteps: [452.0])
Steps:  47%|████▋     | 2361/5000 [8:47:32<8:47:10, 11.99s/it, loss=0.4688, lr=6.34e-06]Steps:  47%|████▋     | 2361/5000 [8:47:32<8:47:10, 11.99s/it, loss=0.8357, lr=6.34e-06]Steps:  47%|████▋     | 2362/5000 [8:47:44<8:45:39, 11.96s/it, loss=0.8357, lr=6.34e-06]Steps:  47%|████▋     | 2362/5000 [8:47:44<8:45:39, 11.96s/it, loss=1.0348, lr=6.34e-06]Steps:  47%|████▋     | 2363/5000 [8:47:56<8:45:33, 11.96s/it, loss=1.0348, lr=6.34e-06]Steps:  47%|████▋     | 2363/5000 [8:47:56<8:45:33, 11.96s/it, loss=0.4759, lr=6.33e-06]Steps:  47%|████▋     | 2364/5000 [8:48:08<8:45:41, 11.97s/it, loss=0.4759, lr=6.33e-06]Steps:  47%|████▋     | 2364/5000 [8:48:08<8:45:41, 11.97s/it, loss=0.6218, lr=6.33e-06]Steps:  47%|████▋     | 2365/5000 [8:48:20<8:45:36, 11.97s/it, loss=0.6218, lr=6.33e-06]Steps:  47%|████▋     | 2365/5000 [8:48:20<8:45:36, 11.97s/it, loss=0.9078, lr=6.33e-06]Steps:  47%|████▋     | 2366/5000 [8:48:32<8:45:48, 11.98s/it, loss=0.9078, lr=6.33e-06]Steps:  47%|████▋     | 2366/5000 [8:48:32<8:45:48, 11.98s/it, loss=0.5640, lr=6.32e-06]Steps:  47%|████▋     | 2367/5000 [8:48:44<8:47:14, 12.01s/it, loss=0.5640, lr=6.32e-06]Steps:  47%|████▋     | 2367/5000 [8:48:44<8:47:14, 12.01s/it, loss=0.8700, lr=6.32e-06]Steps:  47%|████▋     | 2368/5000 [8:48:56<8:45:41, 11.98s/it, loss=0.8700, lr=6.32e-06]Steps:  47%|████▋     | 2368/5000 [8:48:56<8:45:41, 11.98s/it, loss=1.0106, lr=6.32e-06]Steps:  47%|████▋     | 2369/5000 [8:49:08<8:45:51, 11.99s/it, loss=1.0106, lr=6.32e-06]Steps:  47%|████▋     | 2369/5000 [8:49:08<8:45:51, 11.99s/it, loss=0.6775, lr=6.31e-06]Steps:  47%|████▋     | 2370/5000 [8:49:20<8:44:34, 11.97s/it, loss=0.6775, lr=6.31e-06]Steps:  47%|████▋     | 2370/5000 [8:49:20<8:44:34, 11.97s/it, loss=0.6623, lr=6.31e-06]
[Step 2370] Training Debug Info:
  Loss: 0.415423
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0042, std: 0.9453
  Noise mean: 0.0011, std: 0.9961
  Target mean: 0.0052, std: 1.3750
  Model pred mean: 0.0062, std: 1.2109
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 2370] Training Debug Info:
  Loss: 1.127053
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0339, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0347, std: 1.3516
  Model pred mean: -0.0337, std: 0.8398
  Sigmas: [0.1591796875]... (timesteps: [159.0])

[Step 2370] Training Debug Info:
  Loss: 0.381404
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0025, std: 0.8789
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0033, std: 1.3281
  Model pred mean: 0.0000, std: 1.1797
  Sigmas: [0.890625]... (timesteps: [889.0])

[Step 2370] Training Debug Info:
  Loss: 1.058377
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0124, std: 0.9297
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0117, std: 1.3672
  Model pred mean: 0.0110, std: 0.9023
  Sigmas: [0.032958984375]... (timesteps: [33.0])
Steps:  47%|████▋     | 2371/5000 [8:49:32<8:44:15, 11.96s/it, loss=0.6623, lr=6.31e-06]Steps:  47%|████▋     | 2371/5000 [8:49:32<8:44:15, 11.96s/it, loss=1.0584, lr=6.31e-06]Steps:  47%|████▋     | 2372/5000 [8:49:44<8:42:51, 11.94s/it, loss=1.0584, lr=6.31e-06]Steps:  47%|████▋     | 2372/5000 [8:49:44<8:42:51, 11.94s/it, loss=0.7899, lr=6.30e-06]Steps:  47%|████▋     | 2373/5000 [8:49:56<8:45:24, 12.00s/it, loss=0.7899, lr=6.30e-06]Steps:  47%|████▋     | 2373/5000 [8:49:56<8:45:24, 12.00s/it, loss=0.4433, lr=6.30e-06]Steps:  47%|████▋     | 2374/5000 [8:50:08<8:45:19, 12.00s/it, loss=0.4433, lr=6.30e-06]Steps:  47%|████▋     | 2374/5000 [8:50:08<8:45:19, 12.00s/it, loss=1.0507, lr=6.30e-06]Steps:  48%|████▊     | 2375/5000 [8:50:20<8:44:20, 11.98s/it, loss=1.0507, lr=6.30e-06]Steps:  48%|████▊     | 2375/5000 [8:50:20<8:44:20, 11.98s/it, loss=0.3990, lr=6.29e-06]Steps:  48%|████▊     | 2376/5000 [8:50:32<8:45:03, 12.01s/it, loss=0.3990, lr=6.29e-06]Steps:  48%|████▊     | 2376/5000 [8:50:32<8:45:03, 12.01s/it, loss=1.0761, lr=6.29e-06]Steps:  48%|████▊     | 2377/5000 [8:50:44<8:43:45, 11.98s/it, loss=1.0761, lr=6.29e-06]Steps:  48%|████▊     | 2377/5000 [8:50:44<8:43:45, 11.98s/it, loss=1.1198, lr=6.29e-06]Steps:  48%|████▊     | 2378/5000 [8:50:56<8:43:18, 11.98s/it, loss=1.1198, lr=6.29e-06]Steps:  48%|████▊     | 2378/5000 [8:50:56<8:43:18, 11.98s/it, loss=0.4574, lr=6.28e-06]Steps:  48%|████▊     | 2379/5000 [8:51:08<8:42:22, 11.96s/it, loss=0.4574, lr=6.28e-06]Steps:  48%|████▊     | 2379/5000 [8:51:08<8:42:22, 11.96s/it, loss=1.0222, lr=6.28e-06]Steps:  48%|████▊     | 2380/5000 [8:51:20<8:44:03, 12.00s/it, loss=1.0222, lr=6.28e-06]Steps:  48%|████▊     | 2380/5000 [8:51:20<8:44:03, 12.00s/it, loss=0.4281, lr=6.28e-06]
[Step 2380] Training Debug Info:
  Loss: 0.861396
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0089, std: 0.9688
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0078, std: 1.3906
  Model pred mean: -0.0087, std: 1.0391
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 2380] Training Debug Info:
  Loss: 1.041010
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0408, std: 0.8984
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0432, std: 1.3438
  Model pred mean: 0.0391, std: 0.8789
  Sigmas: [0.01904296875]... (timesteps: [19.0])

[Step 2380] Training Debug Info:
  Loss: 0.365354
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0112, std: 0.8984
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0135, std: 1.3438
  Model pred mean: -0.0122, std: 1.1953
  Sigmas: [0.83203125]... (timesteps: [831.0])

[Step 2380] Training Debug Info:
  Loss: 0.729217
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0119, std: 0.9297
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0115, std: 1.3672
  Model pred mean: -0.0127, std: 1.0703
  Sigmas: [0.462890625]... (timesteps: [463.0])
Steps:  48%|████▊     | 2381/5000 [8:51:31<8:41:59, 11.96s/it, loss=0.4281, lr=6.28e-06]Steps:  48%|████▊     | 2381/5000 [8:51:31<8:41:59, 11.96s/it, loss=0.7292, lr=6.27e-06]Steps:  48%|████▊     | 2382/5000 [8:51:43<8:41:14, 11.95s/it, loss=0.7292, lr=6.27e-06]Steps:  48%|████▊     | 2382/5000 [8:51:43<8:41:14, 11.95s/it, loss=1.0822, lr=6.27e-06]Steps:  48%|████▊     | 2383/5000 [8:51:55<8:41:20, 11.95s/it, loss=1.0822, lr=6.27e-06]Steps:  48%|████▊     | 2383/5000 [8:51:55<8:41:20, 11.95s/it, loss=1.0790, lr=6.27e-06]Steps:  48%|████▊     | 2384/5000 [8:52:07<8:41:12, 11.95s/it, loss=1.0790, lr=6.27e-06]Steps:  48%|████▊     | 2384/5000 [8:52:07<8:41:12, 11.95s/it, loss=1.1386, lr=6.26e-06]Steps:  48%|████▊     | 2385/5000 [8:52:19<8:39:51, 11.93s/it, loss=1.1386, lr=6.26e-06]Steps:  48%|████▊     | 2385/5000 [8:52:19<8:39:51, 11.93s/it, loss=0.4738, lr=6.26e-06]Steps:  48%|████▊     | 2386/5000 [8:52:31<8:39:52, 11.93s/it, loss=0.4738, lr=6.26e-06]Steps:  48%|████▊     | 2386/5000 [8:52:31<8:39:52, 11.93s/it, loss=0.3871, lr=6.26e-06]Steps:  48%|████▊     | 2387/5000 [8:52:43<8:42:27, 12.00s/it, loss=0.3871, lr=6.26e-06]Steps:  48%|████▊     | 2387/5000 [8:52:43<8:42:27, 12.00s/it, loss=0.6619, lr=6.25e-06]Steps:  48%|████▊     | 2388/5000 [8:52:55<8:41:10, 11.97s/it, loss=0.6619, lr=6.25e-06]Steps:  48%|████▊     | 2388/5000 [8:52:55<8:41:10, 11.97s/it, loss=1.0736, lr=6.25e-06]Steps:  48%|████▊     | 2389/5000 [8:53:07<8:41:22, 11.98s/it, loss=1.0736, lr=6.25e-06]Steps:  48%|████▊     | 2389/5000 [8:53:07<8:41:22, 11.98s/it, loss=0.5939, lr=6.25e-06]Steps:  48%|████▊     | 2390/5000 [8:53:19<8:39:34, 11.94s/it, loss=0.5939, lr=6.25e-06]Steps:  48%|████▊     | 2390/5000 [8:53:19<8:39:34, 11.94s/it, loss=0.4976, lr=6.24e-06]
[Step 2390] Training Debug Info:
  Loss: 1.139654
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0112, std: 0.9023
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0136, std: 1.3438
  Model pred mean: 0.0063, std: 0.8203
  Sigmas: [0.09716796875]... (timesteps: [97.0])

[Step 2390] Training Debug Info:
  Loss: 0.950897
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0008, std: 0.8828
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0020, std: 1.3359
  Model pred mean: -0.0015, std: 0.9141
  Sigmas: [0.392578125]... (timesteps: [393.0])

[Step 2390] Training Debug Info:
  Loss: 0.379441
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0125, std: 0.9297
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0100, std: 1.3672
  Model pred mean: -0.0109, std: 1.2188
  Sigmas: [0.78125]... (timesteps: [780.0])

[Step 2390] Training Debug Info:
  Loss: 1.111617
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0310, std: 0.9531
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0298, std: 1.3828
  Model pred mean: -0.0322, std: 0.8945
  Sigmas: [0.275390625]... (timesteps: [276.0])
Steps:  48%|████▊     | 2391/5000 [8:53:31<8:39:00, 11.94s/it, loss=0.4976, lr=6.24e-06]Steps:  48%|████▊     | 2391/5000 [8:53:31<8:39:00, 11.94s/it, loss=1.1116, lr=6.24e-06]Steps:  48%|████▊     | 2392/5000 [8:53:43<8:38:31, 11.93s/it, loss=1.1116, lr=6.24e-06]Steps:  48%|████▊     | 2392/5000 [8:53:43<8:38:31, 11.93s/it, loss=1.0111, lr=6.24e-06]Steps:  48%|████▊     | 2393/5000 [8:53:55<8:37:39, 11.91s/it, loss=1.0111, lr=6.24e-06]Steps:  48%|████▊     | 2393/5000 [8:53:55<8:37:39, 11.91s/it, loss=0.4359, lr=6.23e-06]Steps:  48%|████▊     | 2394/5000 [8:54:07<8:39:27, 11.96s/it, loss=0.4359, lr=6.23e-06]Steps:  48%|████▊     | 2394/5000 [8:54:07<8:39:27, 11.96s/it, loss=1.0917, lr=6.23e-06]Steps:  48%|████▊     | 2395/5000 [8:54:19<8:38:38, 11.95s/it, loss=1.0917, lr=6.23e-06]Steps:  48%|████▊     | 2395/5000 [8:54:19<8:38:38, 11.95s/it, loss=0.6998, lr=6.23e-06]Steps:  48%|████▊     | 2396/5000 [8:54:31<8:38:43, 11.95s/it, loss=0.6998, lr=6.23e-06]Steps:  48%|████▊     | 2396/5000 [8:54:31<8:38:43, 11.95s/it, loss=0.5432, lr=6.22e-06]Steps:  48%|████▊     | 2397/5000 [8:54:43<8:37:26, 11.93s/it, loss=0.5432, lr=6.22e-06]Steps:  48%|████▊     | 2397/5000 [8:54:43<8:37:26, 11.93s/it, loss=0.7711, lr=6.22e-06]Steps:  48%|████▊     | 2398/5000 [8:54:55<8:37:57, 11.94s/it, loss=0.7711, lr=6.22e-06]Steps:  48%|████▊     | 2398/5000 [8:54:55<8:37:57, 11.94s/it, loss=0.3179, lr=6.22e-06]Steps:  48%|████▊     | 2399/5000 [8:55:07<8:38:46, 11.97s/it, loss=0.3179, lr=6.22e-06]Steps:  48%|████▊     | 2399/5000 [8:55:07<8:38:46, 11.97s/it, loss=1.0994, lr=6.21e-06]Steps:  48%|████▊     | 2400/5000 [8:55:19<8:41:09, 12.03s/it, loss=1.0994, lr=6.21e-06]Steps:  48%|████▊     | 2400/5000 [8:55:19<8:41:09, 12.03s/it, loss=0.8087, lr=6.21e-06]01/22/2026 16:41:06 - INFO - __main__ - 
[Step 2400] ✅ Loss in normal range (0.8087)
01/22/2026 16:41:06 - INFO - __main__ -   Loss avg (last 100): 0.7531
01/22/2026 16:41:06 - INFO - __main__ -   Loss range: [0.3179, 1.2070]
01/22/2026 16:41:06 - INFO - __main__ - 
🔍 Running validation at step 2400...
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2400 (parquet mode)...
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2400...
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 16:41:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 16:41:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 16:41:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.47it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.46it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.44it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.44it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.43it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.43it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.43it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.43it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.43it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 16:41:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 16:41:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 16:42:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 16:42:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:13,  2.07it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 16:42:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 16:42:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 16:42:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 16:42:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:43:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 16:43:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:43:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 16:43:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:43:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 16:43:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.59it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:44:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 16:44:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 16:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 16:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 16:44:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 16:44:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 16:45:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400/step002400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 16:45:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 16:45:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 16:45:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002400
01/22/2026 16:45:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 2400] Training Debug Info:
  Loss: 0.571181
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0133, std: 0.9102
  Noise mean: -0.0038, std: 1.0000
  Target mean: -0.0171, std: 1.3516
  Model pred mean: -0.0229, std: 1.1172
  Sigmas: [0.94140625]... (timesteps: [943.0])

[Step 2400] Training Debug Info:
  Loss: 0.435546
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0150, std: 0.9336
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0129, std: 1.3672
  Model pred mean: -0.0161, std: 1.2031
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 2400] Training Debug Info:
  Loss: 1.112858
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0171, std: 0.9023
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0170, std: 1.3516
  Model pred mean: -0.0139, std: 0.8398
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 2400] Training Debug Info:
  Loss: 1.078670
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0214, std: 0.9648
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0205, std: 1.3906
  Model pred mean: -0.0228, std: 0.9219
  Sigmas: [0.2138671875]... (timesteps: [214.0])
Steps:  48%|████▊     | 2401/5000 [8:59:43<63:23:10, 87.80s/it, loss=0.8087, lr=6.21e-06]Steps:  48%|████▊     | 2401/5000 [8:59:43<63:23:10, 87.80s/it, loss=1.0787, lr=6.21e-06]Steps:  48%|████▊     | 2402/5000 [8:59:55<46:55:39, 65.03s/it, loss=1.0787, lr=6.21e-06]Steps:  48%|████▊     | 2402/5000 [8:59:55<46:55:39, 65.03s/it, loss=0.4824, lr=6.20e-06]Steps:  48%|████▊     | 2403/5000 [9:00:07<35:25:01, 49.10s/it, loss=0.4824, lr=6.20e-06]Steps:  48%|████▊     | 2403/5000 [9:00:07<35:25:01, 49.10s/it, loss=0.6265, lr=6.20e-06]Steps:  48%|████▊     | 2404/5000 [9:00:19<27:22:10, 37.95s/it, loss=0.6265, lr=6.20e-06]Steps:  48%|████▊     | 2404/5000 [9:00:19<27:22:10, 37.95s/it, loss=1.1417, lr=6.20e-06]Steps:  48%|████▊     | 2405/5000 [9:00:31<21:43:42, 30.14s/it, loss=1.1417, lr=6.20e-06]Steps:  48%|████▊     | 2405/5000 [9:00:31<21:43:42, 30.14s/it, loss=1.0628, lr=6.19e-06]Steps:  48%|████▊     | 2406/5000 [9:00:43<17:47:38, 24.69s/it, loss=1.0628, lr=6.19e-06]Steps:  48%|████▊     | 2406/5000 [9:00:43<17:47:38, 24.69s/it, loss=0.5556, lr=6.19e-06]Steps:  48%|████▊     | 2407/5000 [9:00:55<15:03:47, 20.91s/it, loss=0.5556, lr=6.19e-06]Steps:  48%|████▊     | 2407/5000 [9:00:55<15:03:47, 20.91s/it, loss=0.3603, lr=6.19e-06]Steps:  48%|████▊     | 2408/5000 [9:01:07<13:07:09, 18.22s/it, loss=0.3603, lr=6.19e-06]Steps:  48%|████▊     | 2408/5000 [9:01:07<13:07:09, 18.22s/it, loss=0.9472, lr=6.18e-06]Steps:  48%|████▊     | 2409/5000 [9:01:19<11:45:51, 16.35s/it, loss=0.9472, lr=6.18e-06]Steps:  48%|████▊     | 2409/5000 [9:01:19<11:45:51, 16.35s/it, loss=0.3908, lr=6.18e-06]Steps:  48%|████▊     | 2410/5000 [9:01:31<10:49:27, 15.05s/it, loss=0.3908, lr=6.18e-06]Steps:  48%|████▊     | 2410/5000 [9:01:31<10:49:27, 15.05s/it, loss=1.0888, lr=6.18e-06]
[Step 2410] Training Debug Info:
  Loss: 1.045618
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0021, std: 0.8984
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0009, std: 1.3438
  Model pred mean: -0.0038, std: 0.8750
  Sigmas: [0.0250244140625]... (timesteps: [25.0])

[Step 2410] Training Debug Info:
  Loss: 1.119006
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0062, std: 0.9219
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0071, std: 1.3594
  Model pred mean: 0.0056, std: 0.8516
  Sigmas: [0.1259765625]... (timesteps: [126.0])

[Step 2410] Training Debug Info:
  Loss: 0.603154
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0454, std: 0.9375
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0479, std: 1.3672
  Model pred mean: -0.0476, std: 1.1250
  Sigmas: [0.474609375]... (timesteps: [475.0])

[Step 2410] Training Debug Info:
  Loss: 1.150524
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0256, std: 0.9219
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0244, std: 1.3594
  Model pred mean: -0.0273, std: 0.8398
  Sigmas: [0.15625]... (timesteps: [156.0])
Steps:  48%|████▊     | 2411/5000 [9:01:43<10:08:38, 14.11s/it, loss=1.0888, lr=6.18e-06]Steps:  48%|████▊     | 2411/5000 [9:01:43<10:08:38, 14.11s/it, loss=1.1505, lr=6.17e-06]Steps:  48%|████▊     | 2412/5000 [9:01:55<9:40:10, 13.45s/it, loss=1.1505, lr=6.17e-06] Steps:  48%|████▊     | 2412/5000 [9:01:55<9:40:10, 13.45s/it, loss=0.7058, lr=6.17e-06]Steps:  48%|████▊     | 2413/5000 [9:02:07<9:20:08, 12.99s/it, loss=0.7058, lr=6.17e-06]Steps:  48%|████▊     | 2413/5000 [9:02:07<9:20:08, 12.99s/it, loss=0.6339, lr=6.17e-06]Steps:  48%|████▊     | 2414/5000 [9:02:19<9:07:53, 12.71s/it, loss=0.6339, lr=6.17e-06]Steps:  48%|████▊     | 2414/5000 [9:02:19<9:07:53, 12.71s/it, loss=0.5947, lr=6.16e-06]Steps:  48%|████▊     | 2415/5000 [9:02:31<8:58:19, 12.49s/it, loss=0.5947, lr=6.16e-06]Steps:  48%|████▊     | 2415/5000 [9:02:31<8:58:19, 12.49s/it, loss=0.9218, lr=6.16e-06]Steps:  48%|████▊     | 2416/5000 [9:02:43<8:50:59, 12.33s/it, loss=0.9218, lr=6.16e-06]Steps:  48%|████▊     | 2416/5000 [9:02:43<8:50:59, 12.33s/it, loss=1.1236, lr=6.16e-06]Steps:  48%|████▊     | 2417/5000 [9:02:55<8:45:40, 12.21s/it, loss=1.1236, lr=6.16e-06]Steps:  48%|████▊     | 2417/5000 [9:02:55<8:45:40, 12.21s/it, loss=1.1455, lr=6.15e-06]Steps:  48%|████▊     | 2418/5000 [9:03:07<8:40:32, 12.10s/it, loss=1.1455, lr=6.15e-06]Steps:  48%|████▊     | 2418/5000 [9:03:07<8:40:32, 12.10s/it, loss=0.6410, lr=6.15e-06]Steps:  48%|████▊     | 2419/5000 [9:03:19<8:38:52, 12.06s/it, loss=0.6410, lr=6.15e-06]Steps:  48%|████▊     | 2419/5000 [9:03:19<8:38:52, 12.06s/it, loss=0.5523, lr=6.15e-06]Steps:  48%|████▊     | 2420/5000 [9:03:31<8:37:31, 12.04s/it, loss=0.5523, lr=6.15e-06]Steps:  48%|████▊     | 2420/5000 [9:03:31<8:37:31, 12.04s/it, loss=1.1547, lr=6.14e-06]
[Step 2420] Training Debug Info:
  Loss: 0.447357
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0209, std: 0.9141
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0211, std: 1.3516
  Model pred mean: -0.0229, std: 1.1797
  Sigmas: [0.87109375]... (timesteps: [871.0])

[Step 2420] Training Debug Info:
  Loss: 0.366815
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0256, std: 0.9297
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0237, std: 1.3672
  Model pred mean: -0.0227, std: 1.2266
  Sigmas: [0.77734375]... (timesteps: [779.0])

[Step 2420] Training Debug Info:
  Loss: 0.400263
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0071, std: 0.8906
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0093, std: 1.3438
  Model pred mean: 0.0150, std: 1.1797
  Sigmas: [0.8046875]... (timesteps: [805.0])

[Step 2420] Training Debug Info:
  Loss: 0.513191
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0084, std: 0.9844
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0070, std: 1.4062
  Model pred mean: -0.0015, std: 1.2109
  Sigmas: [0.9140625]... (timesteps: [915.0])
Steps:  48%|████▊     | 2421/5000 [9:03:43<8:38:46, 12.07s/it, loss=1.1547, lr=6.14e-06]Steps:  48%|████▊     | 2421/5000 [9:03:43<8:38:46, 12.07s/it, loss=0.5132, lr=6.14e-06]Steps:  48%|████▊     | 2422/5000 [9:03:55<8:38:15, 12.06s/it, loss=0.5132, lr=6.14e-06]Steps:  48%|████▊     | 2422/5000 [9:03:55<8:38:15, 12.06s/it, loss=0.4961, lr=6.13e-06]Steps:  48%|████▊     | 2423/5000 [9:04:07<8:35:46, 12.01s/it, loss=0.4961, lr=6.13e-06]Steps:  48%|████▊     | 2423/5000 [9:04:07<8:35:46, 12.01s/it, loss=1.1730, lr=6.13e-06]Steps:  48%|████▊     | 2424/5000 [9:04:19<8:34:52, 11.99s/it, loss=1.1730, lr=6.13e-06]Steps:  48%|████▊     | 2424/5000 [9:04:19<8:34:52, 11.99s/it, loss=0.4047, lr=6.13e-06]Steps:  48%|████▊     | 2425/5000 [9:04:30<8:34:05, 11.98s/it, loss=0.4047, lr=6.13e-06]Steps:  48%|████▊     | 2425/5000 [9:04:30<8:34:05, 11.98s/it, loss=1.0901, lr=6.12e-06]Steps:  49%|████▊     | 2426/5000 [9:04:42<8:34:10, 11.99s/it, loss=1.0901, lr=6.12e-06]Steps:  49%|████▊     | 2426/5000 [9:04:42<8:34:10, 11.99s/it, loss=0.4328, lr=6.12e-06]Steps:  49%|████▊     | 2427/5000 [9:04:55<8:35:18, 12.02s/it, loss=0.4328, lr=6.12e-06]Steps:  49%|████▊     | 2427/5000 [9:04:55<8:35:18, 12.02s/it, loss=1.0853, lr=6.12e-06]Steps:  49%|████▊     | 2428/5000 [9:05:07<8:33:59, 11.99s/it, loss=1.0853, lr=6.12e-06]Steps:  49%|████▊     | 2428/5000 [9:05:07<8:33:59, 11.99s/it, loss=0.4634, lr=6.11e-06]Steps:  49%|████▊     | 2429/5000 [9:05:19<8:36:04, 12.04s/it, loss=0.4634, lr=6.11e-06]Steps:  49%|████▊     | 2429/5000 [9:05:19<8:36:04, 12.04s/it, loss=1.1317, lr=6.11e-06]Steps:  49%|████▊     | 2430/5000 [9:05:31<8:34:14, 12.01s/it, loss=1.1317, lr=6.11e-06]Steps:  49%|████▊     | 2430/5000 [9:05:31<8:34:14, 12.01s/it, loss=0.4603, lr=6.11e-06]
[Step 2430] Training Debug Info:
  Loss: 1.126754
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0028, std: 0.9023
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0041, std: 1.3438
  Model pred mean: 0.0001, std: 0.8281
  Sigmas: [0.083984375]... (timesteps: [84.0])

[Step 2430] Training Debug Info:
  Loss: 0.915664
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0415, std: 0.8633
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0415, std: 1.3203
  Model pred mean: 0.0410, std: 0.9141
  Sigmas: [0.4375]... (timesteps: [438.0])

[Step 2430] Training Debug Info:
  Loss: 0.983532
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0064, std: 0.9219
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0091, std: 1.3594
  Model pred mean: -0.0048, std: 0.9336
  Sigmas: [0.326171875]... (timesteps: [327.0])

[Step 2430] Training Debug Info:
  Loss: 0.545213
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0031, std: 0.8789
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0045, std: 1.3359
  Model pred mean: 0.0039, std: 1.1094
  Sigmas: [0.99609375]... (timesteps: [998.0])
Steps:  49%|████▊     | 2431/5000 [9:05:43<8:32:55, 11.98s/it, loss=0.4603, lr=6.11e-06]Steps:  49%|████▊     | 2431/5000 [9:05:43<8:32:55, 11.98s/it, loss=0.5452, lr=6.10e-06]Steps:  49%|████▊     | 2432/5000 [9:05:54<8:31:21, 11.95s/it, loss=0.5452, lr=6.10e-06]Steps:  49%|████▊     | 2432/5000 [9:05:54<8:31:21, 11.95s/it, loss=1.1232, lr=6.10e-06]Steps:  49%|████▊     | 2433/5000 [9:06:06<8:32:04, 11.97s/it, loss=1.1232, lr=6.10e-06]Steps:  49%|████▊     | 2433/5000 [9:06:06<8:32:04, 11.97s/it, loss=0.7212, lr=6.10e-06]Steps:  49%|████▊     | 2434/5000 [9:06:18<8:33:18, 12.00s/it, loss=0.7212, lr=6.10e-06]Steps:  49%|████▊     | 2434/5000 [9:06:18<8:33:18, 12.00s/it, loss=0.4990, lr=6.09e-06]Steps:  49%|████▊     | 2435/5000 [9:06:30<8:31:36, 11.97s/it, loss=0.4990, lr=6.09e-06]Steps:  49%|████▊     | 2435/5000 [9:06:30<8:31:36, 11.97s/it, loss=1.1130, lr=6.09e-06]Steps:  49%|████▊     | 2436/5000 [9:06:42<8:33:24, 12.01s/it, loss=1.1130, lr=6.09e-06]Steps:  49%|████▊     | 2436/5000 [9:06:42<8:33:24, 12.01s/it, loss=1.0142, lr=6.09e-06]Steps:  49%|████▊     | 2437/5000 [9:06:54<8:32:24, 12.00s/it, loss=1.0142, lr=6.09e-06]Steps:  49%|████▊     | 2437/5000 [9:06:54<8:32:24, 12.00s/it, loss=0.6587, lr=6.08e-06]Steps:  49%|████▉     | 2438/5000 [9:07:06<8:30:09, 11.95s/it, loss=0.6587, lr=6.08e-06]Steps:  49%|████▉     | 2438/5000 [9:07:06<8:30:09, 11.95s/it, loss=0.3725, lr=6.08e-06]Steps:  49%|████▉     | 2439/5000 [9:07:18<8:29:03, 11.93s/it, loss=0.3725, lr=6.08e-06]Steps:  49%|████▉     | 2439/5000 [9:07:18<8:29:03, 11.93s/it, loss=0.5251, lr=6.08e-06]Steps:  49%|████▉     | 2440/5000 [9:07:30<8:29:19, 11.94s/it, loss=0.5251, lr=6.08e-06]Steps:  49%|████▉     | 2440/5000 [9:07:30<8:29:19, 11.94s/it, loss=0.5954, lr=6.07e-06]
[Step 2440] Training Debug Info:
  Loss: 0.468484
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0131, std: 0.9141
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0150, std: 1.3594
  Model pred mean: -0.0086, std: 1.1641
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 2440] Training Debug Info:
  Loss: 1.035671
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0256, std: 0.8867
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0247, std: 1.3359
  Model pred mean: 0.0262, std: 0.8789
  Sigmas: [0.345703125]... (timesteps: [346.0])

[Step 2440] Training Debug Info:
  Loss: 0.751834
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0171, std: 0.9844
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0145, std: 1.4062
  Model pred mean: -0.0155, std: 1.1016
  Sigmas: [0.9609375]... (timesteps: [960.0])

[Step 2440] Training Debug Info:
  Loss: 1.068511
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0097, std: 0.9492
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0081, std: 1.3750
  Model pred mean: -0.0093, std: 0.9258
  Sigmas: [0.037109375]... (timesteps: [37.0])
Steps:  49%|████▉     | 2441/5000 [9:07:42<8:31:41, 12.00s/it, loss=0.5954, lr=6.07e-06]Steps:  49%|████▉     | 2441/5000 [9:07:42<8:31:41, 12.00s/it, loss=1.0685, lr=6.07e-06]Steps:  49%|████▉     | 2442/5000 [9:07:54<8:30:33, 11.98s/it, loss=1.0685, lr=6.07e-06]Steps:  49%|████▉     | 2442/5000 [9:07:54<8:30:33, 11.98s/it, loss=0.5838, lr=6.07e-06]Steps:  49%|████▉     | 2443/5000 [9:08:06<8:30:22, 11.98s/it, loss=0.5838, lr=6.07e-06]Steps:  49%|████▉     | 2443/5000 [9:08:06<8:30:22, 11.98s/it, loss=0.5637, lr=6.06e-06]Steps:  49%|████▉     | 2444/5000 [9:08:18<8:29:06, 11.95s/it, loss=0.5637, lr=6.06e-06]Steps:  49%|████▉     | 2444/5000 [9:08:18<8:29:06, 11.95s/it, loss=0.7278, lr=6.06e-06]Steps:  49%|████▉     | 2445/5000 [9:08:30<8:27:37, 11.92s/it, loss=0.7278, lr=6.06e-06]Steps:  49%|████▉     | 2445/5000 [9:08:30<8:27:37, 11.92s/it, loss=0.7545, lr=6.06e-06]Steps:  49%|████▉     | 2446/5000 [9:08:42<8:28:38, 11.95s/it, loss=0.7545, lr=6.06e-06]Steps:  49%|████▉     | 2446/5000 [9:08:42<8:28:38, 11.95s/it, loss=0.3672, lr=6.05e-06]Steps:  49%|████▉     | 2447/5000 [9:08:54<8:28:48, 11.96s/it, loss=0.3672, lr=6.05e-06]Steps:  49%|████▉     | 2447/5000 [9:08:54<8:28:48, 11.96s/it, loss=0.9760, lr=6.05e-06]Steps:  49%|████▉     | 2448/5000 [9:09:06<8:29:21, 11.98s/it, loss=0.9760, lr=6.05e-06]Steps:  49%|████▉     | 2448/5000 [9:09:06<8:29:21, 11.98s/it, loss=0.5566, lr=6.05e-06]Steps:  49%|████▉     | 2449/5000 [9:09:18<8:28:37, 11.96s/it, loss=0.5566, lr=6.05e-06]Steps:  49%|████▉     | 2449/5000 [9:09:18<8:28:37, 11.96s/it, loss=0.5235, lr=6.04e-06]Steps:  49%|████▉     | 2450/5000 [9:09:30<8:27:29, 11.94s/it, loss=0.5235, lr=6.04e-06]Steps:  49%|████▉     | 2450/5000 [9:09:30<8:27:29, 11.94s/it, loss=1.0455, lr=6.04e-06]
[Step 2450] Training Debug Info:
  Loss: 1.118582
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0160, std: 0.9414
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0151, std: 1.3750
  Model pred mean: -0.0159, std: 0.8672
  Sigmas: [0.1318359375]... (timesteps: [132.0])

[Step 2450] Training Debug Info:
  Loss: 1.098495
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0045, std: 0.9492
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0049, std: 1.3750
  Model pred mean: 0.0027, std: 0.8828
  Sigmas: [0.1396484375]... (timesteps: [140.0])

[Step 2450] Training Debug Info:
  Loss: 0.817498
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0093, std: 0.9062
  Noise mean: 0.0017, std: 0.9961
  Target mean: -0.0077, std: 1.3438
  Model pred mean: -0.0120, std: 1.0000
  Sigmas: [0.44921875]... (timesteps: [449.0])

[Step 2450] Training Debug Info:
  Loss: 1.058870
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0089, std: 0.9453
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0093, std: 1.3750
  Model pred mean: -0.0093, std: 0.9023
  Sigmas: [0.044921875]... (timesteps: [45.0])
Steps:  49%|████▉     | 2451/5000 [9:09:42<8:26:23, 11.92s/it, loss=1.0455, lr=6.04e-06]Steps:  49%|████▉     | 2451/5000 [9:09:42<8:26:23, 11.92s/it, loss=1.0589, lr=6.04e-06]Steps:  49%|████▉     | 2452/5000 [9:09:54<8:26:45, 11.93s/it, loss=1.0589, lr=6.04e-06]Steps:  49%|████▉     | 2452/5000 [9:09:54<8:26:45, 11.93s/it, loss=0.7621, lr=6.03e-06]Steps:  49%|████▉     | 2453/5000 [9:10:06<8:27:39, 11.96s/it, loss=0.7621, lr=6.03e-06]Steps:  49%|████▉     | 2453/5000 [9:10:06<8:27:39, 11.96s/it, loss=1.1151, lr=6.03e-06]Steps:  49%|████▉     | 2454/5000 [9:10:18<8:28:31, 11.98s/it, loss=1.1151, lr=6.03e-06]Steps:  49%|████▉     | 2454/5000 [9:10:18<8:28:31, 11.98s/it, loss=0.6567, lr=6.03e-06]Steps:  49%|████▉     | 2455/5000 [9:10:30<8:28:25, 11.99s/it, loss=0.6567, lr=6.03e-06]Steps:  49%|████▉     | 2455/5000 [9:10:30<8:28:25, 11.99s/it, loss=0.4350, lr=6.02e-06]Steps:  49%|████▉     | 2456/5000 [9:10:42<8:27:13, 11.96s/it, loss=0.4350, lr=6.02e-06]Steps:  49%|████▉     | 2456/5000 [9:10:42<8:27:13, 11.96s/it, loss=0.6273, lr=6.02e-06]Steps:  49%|████▉     | 2457/5000 [9:10:53<8:26:48, 11.96s/it, loss=0.6273, lr=6.02e-06]Steps:  49%|████▉     | 2457/5000 [9:10:53<8:26:48, 11.96s/it, loss=0.3713, lr=6.02e-06]Steps:  49%|████▉     | 2458/5000 [9:11:05<8:26:37, 11.96s/it, loss=0.3713, lr=6.02e-06]Steps:  49%|████▉     | 2458/5000 [9:11:05<8:26:37, 11.96s/it, loss=0.8203, lr=6.01e-06]Steps:  49%|████▉     | 2459/5000 [9:11:17<8:26:45, 11.97s/it, loss=0.8203, lr=6.01e-06]Steps:  49%|████▉     | 2459/5000 [9:11:17<8:26:45, 11.97s/it, loss=0.5838, lr=6.01e-06]Steps:  49%|████▉     | 2460/5000 [9:11:29<8:26:19, 11.96s/it, loss=0.5838, lr=6.01e-06]Steps:  49%|████▉     | 2460/5000 [9:11:29<8:26:19, 11.96s/it, loss=0.8389, lr=6.01e-06]
[Step 2460] Training Debug Info:
  Loss: 1.116428
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0171, std: 0.9219
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0160, std: 1.3594
  Model pred mean: -0.0155, std: 0.8516
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 2460] Training Debug Info:
  Loss: 0.447298
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0137, std: 0.8984
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0137, std: 1.3438
  Model pred mean: 0.0204, std: 1.1641
  Sigmas: [0.71875]... (timesteps: [720.0])

[Step 2460] Training Debug Info:
  Loss: 1.086129
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0070, std: 0.8945
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0095, std: 1.3438
  Model pred mean: -0.0046, std: 0.8398
  Sigmas: [0.05908203125]... (timesteps: [59.0])

[Step 2460] Training Debug Info:
  Loss: 0.402801
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0209, std: 0.8516
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0216, std: 1.3125
  Model pred mean: 0.0225, std: 1.1406
  Sigmas: [0.78515625]... (timesteps: [785.0])
Steps:  49%|████▉     | 2461/5000 [9:11:42<8:29:41, 12.04s/it, loss=0.8389, lr=6.01e-06]Steps:  49%|████▉     | 2461/5000 [9:11:42<8:29:41, 12.04s/it, loss=0.4028, lr=6.00e-06]Steps:  49%|████▉     | 2462/5000 [9:11:54<8:28:13, 12.01s/it, loss=0.4028, lr=6.00e-06]Steps:  49%|████▉     | 2462/5000 [9:11:54<8:28:13, 12.01s/it, loss=0.5369, lr=6.00e-06]Steps:  49%|████▉     | 2463/5000 [9:12:05<8:26:16, 11.97s/it, loss=0.5369, lr=6.00e-06]Steps:  49%|████▉     | 2463/5000 [9:12:05<8:26:16, 11.97s/it, loss=0.5999, lr=6.00e-06]Steps:  49%|████▉     | 2464/5000 [9:12:17<8:26:11, 11.98s/it, loss=0.5999, lr=6.00e-06]Steps:  49%|████▉     | 2464/5000 [9:12:17<8:26:11, 11.98s/it, loss=0.4616, lr=5.99e-06]Steps:  49%|████▉     | 2465/5000 [9:12:29<8:25:36, 11.97s/it, loss=0.4616, lr=5.99e-06]Steps:  49%|████▉     | 2465/5000 [9:12:29<8:25:36, 11.97s/it, loss=0.5497, lr=5.99e-06]Steps:  49%|████▉     | 2466/5000 [9:12:41<8:27:06, 12.01s/it, loss=0.5497, lr=5.99e-06]Steps:  49%|████▉     | 2466/5000 [9:12:41<8:27:06, 12.01s/it, loss=1.1381, lr=5.98e-06]Steps:  49%|████▉     | 2467/5000 [9:12:54<8:27:44, 12.03s/it, loss=1.1381, lr=5.98e-06]Steps:  49%|████▉     | 2467/5000 [9:12:54<8:27:44, 12.03s/it, loss=1.1626, lr=5.98e-06]Steps:  49%|████▉     | 2468/5000 [9:13:06<8:29:20, 12.07s/it, loss=1.1626, lr=5.98e-06]Steps:  49%|████▉     | 2468/5000 [9:13:06<8:29:20, 12.07s/it, loss=1.0036, lr=5.98e-06]Steps:  49%|████▉     | 2469/5000 [9:13:18<8:26:23, 12.00s/it, loss=1.0036, lr=5.98e-06]Steps:  49%|████▉     | 2469/5000 [9:13:18<8:26:23, 12.00s/it, loss=0.5560, lr=5.97e-06]Steps:  49%|████▉     | 2470/5000 [9:13:30<8:27:00, 12.02s/it, loss=0.5560, lr=5.97e-06]Steps:  49%|████▉     | 2470/5000 [9:13:30<8:27:00, 12.02s/it, loss=0.9768, lr=5.97e-06]
[Step 2470] Training Debug Info:
  Loss: 0.605970
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0139, std: 0.9258
  Noise mean: 0.0042, std: 1.0000
  Target mean: 0.0181, std: 1.3672
  Model pred mean: 0.0177, std: 1.1250
  Sigmas: [0.9765625]... (timesteps: [975.0])

[Step 2470] Training Debug Info:
  Loss: 1.184608
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0076, std: 0.8711
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0063, std: 1.3281
  Model pred mean: -0.0088, std: 0.7578
  Sigmas: [0.1484375]... (timesteps: [148.0])

[Step 2470] Training Debug Info:
  Loss: 0.364051
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0383, std: 0.9531
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0371, std: 1.3828
  Model pred mean: -0.0427, std: 1.2422
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 2470] Training Debug Info:
  Loss: 0.395610
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0391, std: 0.8984
  Noise mean: -0.0016, std: 1.0078
  Target mean: -0.0405, std: 1.3438
  Model pred mean: -0.0417, std: 1.1875
  Sigmas: [0.76953125]... (timesteps: [769.0])
Steps:  49%|████▉     | 2471/5000 [9:13:42<8:25:39, 12.00s/it, loss=0.9768, lr=5.97e-06]Steps:  49%|████▉     | 2471/5000 [9:13:42<8:25:39, 12.00s/it, loss=0.3956, lr=5.97e-06]Steps:  49%|████▉     | 2472/5000 [9:13:54<8:25:02, 11.99s/it, loss=0.3956, lr=5.97e-06]Steps:  49%|████▉     | 2472/5000 [9:13:54<8:25:02, 11.99s/it, loss=0.8904, lr=5.96e-06]Steps:  49%|████▉     | 2473/5000 [9:14:06<8:24:49, 11.99s/it, loss=0.8904, lr=5.96e-06]Steps:  49%|████▉     | 2473/5000 [9:14:06<8:24:49, 11.99s/it, loss=1.1744, lr=5.96e-06]Steps:  49%|████▉     | 2474/5000 [9:14:17<8:23:14, 11.95s/it, loss=1.1744, lr=5.96e-06]Steps:  49%|████▉     | 2474/5000 [9:14:17<8:23:14, 11.95s/it, loss=0.7740, lr=5.96e-06]Steps:  50%|████▉     | 2475/5000 [9:14:30<8:25:12, 12.00s/it, loss=0.7740, lr=5.96e-06]Steps:  50%|████▉     | 2475/5000 [9:14:30<8:25:12, 12.00s/it, loss=0.4124, lr=5.95e-06]Steps:  50%|████▉     | 2476/5000 [9:14:41<8:24:32, 11.99s/it, loss=0.4124, lr=5.95e-06]Steps:  50%|████▉     | 2476/5000 [9:14:41<8:24:32, 11.99s/it, loss=0.5663, lr=5.95e-06]Steps:  50%|████▉     | 2477/5000 [9:14:53<8:23:24, 11.97s/it, loss=0.5663, lr=5.95e-06]Steps:  50%|████▉     | 2477/5000 [9:14:53<8:23:24, 11.97s/it, loss=0.5670, lr=5.95e-06]Steps:  50%|████▉     | 2478/5000 [9:15:05<8:22:26, 11.95s/it, loss=0.5670, lr=5.95e-06]Steps:  50%|████▉     | 2478/5000 [9:15:05<8:22:26, 11.95s/it, loss=0.6920, lr=5.94e-06]Steps:  50%|████▉     | 2479/5000 [9:15:17<8:22:18, 11.96s/it, loss=0.6920, lr=5.94e-06]Steps:  50%|████▉     | 2479/5000 [9:15:17<8:22:18, 11.96s/it, loss=0.4984, lr=5.94e-06]Steps:  50%|████▉     | 2480/5000 [9:15:29<8:21:36, 11.94s/it, loss=0.4984, lr=5.94e-06]Steps:  50%|████▉     | 2480/5000 [9:15:29<8:21:36, 11.94s/it, loss=1.1320, lr=5.94e-06]
[Step 2480] Training Debug Info:
  Loss: 0.502671
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0134, std: 0.9570
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0142, std: 1.3828
  Model pred mean: -0.0125, std: 1.1875
  Sigmas: [0.76171875]... (timesteps: [760.0])

[Step 2480] Training Debug Info:
  Loss: 1.077658
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0098, std: 0.8789
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0098, std: 1.3281
  Model pred mean: 0.0118, std: 0.8320
  Sigmas: [0.3125]... (timesteps: [313.0])

[Step 2480] Training Debug Info:
  Loss: 1.094428
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0144, std: 0.8984
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0125, std: 1.3438
  Model pred mean: -0.0126, std: 0.8516
  Sigmas: [0.271484375]... (timesteps: [271.0])

[Step 2480] Training Debug Info:
  Loss: 0.512992
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0162, std: 0.9180
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0164, std: 1.3594
  Model pred mean: -0.0115, std: 1.1719
  Sigmas: [0.921875]... (timesteps: [920.0])
Steps:  50%|████▉     | 2481/5000 [9:15:41<8:22:43, 11.97s/it, loss=1.1320, lr=5.94e-06]Steps:  50%|████▉     | 2481/5000 [9:15:41<8:22:43, 11.97s/it, loss=0.5130, lr=5.93e-06]Steps:  50%|████▉     | 2482/5000 [9:15:53<8:22:41, 11.98s/it, loss=0.5130, lr=5.93e-06]Steps:  50%|████▉     | 2482/5000 [9:15:53<8:22:41, 11.98s/it, loss=0.5932, lr=5.93e-06]Steps:  50%|████▉     | 2483/5000 [9:16:05<8:21:27, 11.95s/it, loss=0.5932, lr=5.93e-06]Steps:  50%|████▉     | 2483/5000 [9:16:05<8:21:27, 11.95s/it, loss=0.6298, lr=5.93e-06]Steps:  50%|████▉     | 2484/5000 [9:16:17<8:21:18, 11.95s/it, loss=0.6298, lr=5.93e-06]Steps:  50%|████▉     | 2484/5000 [9:16:17<8:21:18, 11.95s/it, loss=1.0580, lr=5.92e-06]Steps:  50%|████▉     | 2485/5000 [9:16:29<8:21:40, 11.97s/it, loss=1.0580, lr=5.92e-06]Steps:  50%|████▉     | 2485/5000 [9:16:29<8:21:40, 11.97s/it, loss=0.9797, lr=5.92e-06]Steps:  50%|████▉     | 2486/5000 [9:16:41<8:21:09, 11.96s/it, loss=0.9797, lr=5.92e-06]Steps:  50%|████▉     | 2486/5000 [9:16:41<8:21:09, 11.96s/it, loss=0.4173, lr=5.92e-06]Steps:  50%|████▉     | 2487/5000 [9:16:53<8:20:02, 11.94s/it, loss=0.4173, lr=5.92e-06]Steps:  50%|████▉     | 2487/5000 [9:16:53<8:20:02, 11.94s/it, loss=0.4355, lr=5.91e-06]Steps:  50%|████▉     | 2488/5000 [9:17:05<8:22:05, 11.99s/it, loss=0.4355, lr=5.91e-06]Steps:  50%|████▉     | 2488/5000 [9:17:05<8:22:05, 11.99s/it, loss=1.1479, lr=5.91e-06]Steps:  50%|████▉     | 2489/5000 [9:17:17<8:21:21, 11.98s/it, loss=1.1479, lr=5.91e-06]Steps:  50%|████▉     | 2489/5000 [9:17:17<8:21:21, 11.98s/it, loss=1.1489, lr=5.91e-06]Steps:  50%|████▉     | 2490/5000 [9:17:29<8:20:01, 11.95s/it, loss=1.1489, lr=5.91e-06]Steps:  50%|████▉     | 2490/5000 [9:17:29<8:20:01, 11.95s/it, loss=0.9983, lr=5.90e-06]
[Step 2490] Training Debug Info:
  Loss: 0.570822
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0051, std: 0.8672
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0030, std: 1.3203
  Model pred mean: 0.0020, std: 1.1016
  Sigmas: [0.95703125]... (timesteps: [958.0])

[Step 2490] Training Debug Info:
  Loss: 0.608710
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0011, std: 0.8945
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0016, std: 1.3438
  Model pred mean: -0.0023, std: 1.0938
  Sigmas: [0.58203125]... (timesteps: [583.0])

[Step 2490] Training Debug Info:
  Loss: 1.215158
  Latent shape: torch.Size([1, 32, 90, 96]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0115, std: 0.8633
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0142, std: 1.3203
  Model pred mean: 0.0135, std: 0.7266
  Sigmas: [0.193359375]... (timesteps: [193.0])

[Step 2490] Training Debug Info:
  Loss: 0.394438
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0045, std: 0.9336
  Noise mean: 0.0011, std: 0.9961
  Target mean: -0.0034, std: 1.3672
  Model pred mean: -0.0050, std: 1.2109
  Sigmas: [0.75]... (timesteps: [751.0])
Steps:  50%|████▉     | 2491/5000 [9:17:41<8:21:38, 12.00s/it, loss=0.9983, lr=5.90e-06]Steps:  50%|████▉     | 2491/5000 [9:17:41<8:21:38, 12.00s/it, loss=0.3944, lr=5.90e-06]Steps:  50%|████▉     | 2492/5000 [9:17:53<8:20:06, 11.96s/it, loss=0.3944, lr=5.90e-06]Steps:  50%|████▉     | 2492/5000 [9:17:53<8:20:06, 11.96s/it, loss=1.0428, lr=5.90e-06]Steps:  50%|████▉     | 2493/5000 [9:18:05<8:20:03, 11.97s/it, loss=1.0428, lr=5.90e-06]Steps:  50%|████▉     | 2493/5000 [9:18:05<8:20:03, 11.97s/it, loss=0.4999, lr=5.89e-06]Steps:  50%|████▉     | 2494/5000 [9:18:17<8:21:47, 12.01s/it, loss=0.4999, lr=5.89e-06]Steps:  50%|████▉     | 2494/5000 [9:18:17<8:21:47, 12.01s/it, loss=0.5150, lr=5.89e-06]Steps:  50%|████▉     | 2495/5000 [9:18:29<8:23:18, 12.06s/it, loss=0.5150, lr=5.89e-06]Steps:  50%|████▉     | 2495/5000 [9:18:29<8:23:18, 12.06s/it, loss=0.3786, lr=5.89e-06]Steps:  50%|████▉     | 2496/5000 [9:18:41<8:22:52, 12.05s/it, loss=0.3786, lr=5.89e-06]Steps:  50%|████▉     | 2496/5000 [9:18:41<8:22:52, 12.05s/it, loss=1.1345, lr=5.88e-06]Steps:  50%|████▉     | 2497/5000 [9:18:53<8:23:08, 12.06s/it, loss=1.1345, lr=5.88e-06]Steps:  50%|████▉     | 2497/5000 [9:18:53<8:23:08, 12.06s/it, loss=0.4352, lr=5.88e-06]Steps:  50%|████▉     | 2498/5000 [9:19:05<8:22:00, 12.04s/it, loss=0.4352, lr=5.88e-06]Steps:  50%|████▉     | 2498/5000 [9:19:05<8:22:00, 12.04s/it, loss=1.0835, lr=5.88e-06]Steps:  50%|████▉     | 2499/5000 [9:19:17<8:20:25, 12.01s/it, loss=1.0835, lr=5.88e-06]Steps:  50%|████▉     | 2499/5000 [9:19:17<8:20:25, 12.01s/it, loss=0.4189, lr=5.87e-06]Steps:  50%|█████     | 2500/5000 [9:19:29<8:20:44, 12.02s/it, loss=0.4189, lr=5.87e-06]Steps:  50%|█████     | 2500/5000 [9:19:29<8:20:44, 12.02s/it, loss=0.3823, lr=5.87e-06]01/22/2026 17:05:16 - INFO - __main__ - 
[Step 2500] ✅ Loss in normal range (0.3823)
01/22/2026 17:05:16 - INFO - __main__ -   Loss avg (last 100): 0.7391
01/22/2026 17:05:16 - INFO - __main__ -   Loss range: [0.3603, 1.1744]

[Step 2500] Training Debug Info:
  Loss: 0.397494
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0153, std: 0.9297
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0134, std: 1.3672
  Model pred mean: -0.0182, std: 1.2188
  Sigmas: [0.80078125]... (timesteps: [801.0])

[Step 2500] Training Debug Info:
  Loss: 0.371025
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0220, std: 0.9492
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0221, std: 1.3750
  Model pred mean: -0.0261, std: 1.2344
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 2500] Training Debug Info:
  Loss: 1.122059
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0181, std: 0.9023
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0203, std: 1.3438
  Model pred mean: -0.0184, std: 0.8281
  Sigmas: [0.236328125]... (timesteps: [236.0])

[Step 2500] Training Debug Info:
  Loss: 0.668255
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0229, std: 0.9531
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0248, std: 1.3828
  Model pred mean: -0.0273, std: 1.1172
  Sigmas: [0.515625]... (timesteps: [517.0])
Steps:  50%|█████     | 2501/5000 [9:19:41<8:19:24, 11.99s/it, loss=0.3823, lr=5.87e-06]Steps:  50%|█████     | 2501/5000 [9:19:41<8:19:24, 11.99s/it, loss=0.6683, lr=5.86e-06]Steps:  50%|█████     | 2502/5000 [9:19:53<8:21:09, 12.04s/it, loss=0.6683, lr=5.86e-06]Steps:  50%|█████     | 2502/5000 [9:19:53<8:21:09, 12.04s/it, loss=1.0610, lr=5.86e-06]Steps:  50%|█████     | 2503/5000 [9:20:05<8:18:48, 11.99s/it, loss=1.0610, lr=5.86e-06]Steps:  50%|█████     | 2503/5000 [9:20:05<8:18:48, 11.99s/it, loss=0.3883, lr=5.86e-06]Steps:  50%|█████     | 2504/5000 [9:20:17<8:17:09, 11.95s/it, loss=0.3883, lr=5.86e-06]Steps:  50%|█████     | 2504/5000 [9:20:17<8:17:09, 11.95s/it, loss=0.3759, lr=5.85e-06]Steps:  50%|█████     | 2505/5000 [9:20:29<8:16:29, 11.94s/it, loss=0.3759, lr=5.85e-06]Steps:  50%|█████     | 2505/5000 [9:20:29<8:16:29, 11.94s/it, loss=0.6167, lr=5.85e-06]Steps:  50%|█████     | 2506/5000 [9:20:41<8:18:07, 11.98s/it, loss=0.6167, lr=5.85e-06]Steps:  50%|█████     | 2506/5000 [9:20:41<8:18:07, 11.98s/it, loss=0.7204, lr=5.85e-06]Steps:  50%|█████     | 2507/5000 [9:20:53<8:16:26, 11.95s/it, loss=0.7204, lr=5.85e-06]Steps:  50%|█████     | 2507/5000 [9:20:53<8:16:26, 11.95s/it, loss=0.4780, lr=5.84e-06]Steps:  50%|█████     | 2508/5000 [9:21:05<8:17:37, 11.98s/it, loss=0.4780, lr=5.84e-06]Steps:  50%|█████     | 2508/5000 [9:21:05<8:17:37, 11.98s/it, loss=0.6928, lr=5.84e-06]Steps:  50%|█████     | 2509/5000 [9:21:17<8:17:36, 11.99s/it, loss=0.6928, lr=5.84e-06]Steps:  50%|█████     | 2509/5000 [9:21:17<8:17:36, 11.99s/it, loss=0.5077, lr=5.84e-06]Steps:  50%|█████     | 2510/5000 [9:21:29<8:16:47, 11.97s/it, loss=0.5077, lr=5.84e-06]Steps:  50%|█████     | 2510/5000 [9:21:29<8:16:47, 11.97s/it, loss=0.5532, lr=5.83e-06]
[Step 2510] Training Debug Info:
  Loss: 0.547329
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0366, std: 0.9570
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0369, std: 1.3828
  Model pred mean: -0.0376, std: 1.1641
  Sigmas: [0.5390625]... (timesteps: [539.0])

[Step 2510] Training Debug Info:
  Loss: 0.566021
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0089, std: 0.9922
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0108, std: 1.4062
  Model pred mean: -0.0064, std: 1.1953
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 2510] Training Debug Info:
  Loss: 1.008038
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0122, std: 0.9258
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0134, std: 1.3672
  Model pred mean: 0.0194, std: 0.9297
  Sigmas: [0.0019989013671875]... (timesteps: [2.0])

[Step 2510] Training Debug Info:
  Loss: 1.134239
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0219, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0206, std: 1.3672
  Model pred mean: -0.0206, std: 0.8594
  Sigmas: [0.1396484375]... (timesteps: [140.0])
Steps:  50%|█████     | 2511/5000 [9:21:41<8:16:51, 11.98s/it, loss=0.5532, lr=5.83e-06]Steps:  50%|█████     | 2511/5000 [9:21:41<8:16:51, 11.98s/it, loss=1.1342, lr=5.83e-06]Steps:  50%|█████     | 2512/5000 [9:21:53<8:16:00, 11.96s/it, loss=1.1342, lr=5.83e-06]Steps:  50%|█████     | 2512/5000 [9:21:53<8:16:00, 11.96s/it, loss=0.4953, lr=5.83e-06]Steps:  50%|█████     | 2513/5000 [9:22:05<8:14:31, 11.93s/it, loss=0.4953, lr=5.83e-06]Steps:  50%|█████     | 2513/5000 [9:22:05<8:14:31, 11.93s/it, loss=0.4021, lr=5.82e-06]Steps:  50%|█████     | 2514/5000 [9:22:17<8:14:09, 11.93s/it, loss=0.4021, lr=5.82e-06]Steps:  50%|█████     | 2514/5000 [9:22:17<8:14:09, 11.93s/it, loss=1.0725, lr=5.82e-06]Steps:  50%|█████     | 2515/5000 [9:22:29<8:17:25, 12.01s/it, loss=1.0725, lr=5.82e-06]Steps:  50%|█████     | 2515/5000 [9:22:29<8:17:25, 12.01s/it, loss=1.0588, lr=5.82e-06]Steps:  50%|█████     | 2516/5000 [9:22:41<8:16:56, 12.00s/it, loss=1.0588, lr=5.82e-06]Steps:  50%|█████     | 2516/5000 [9:22:41<8:16:56, 12.00s/it, loss=1.1167, lr=5.81e-06]Steps:  50%|█████     | 2517/5000 [9:22:53<8:16:41, 12.00s/it, loss=1.1167, lr=5.81e-06]Steps:  50%|█████     | 2517/5000 [9:22:53<8:16:41, 12.00s/it, loss=0.4088, lr=5.81e-06]Steps:  50%|█████     | 2518/5000 [9:23:05<8:16:31, 12.00s/it, loss=0.4088, lr=5.81e-06]Steps:  50%|█████     | 2518/5000 [9:23:05<8:16:31, 12.00s/it, loss=1.0411, lr=5.81e-06]Steps:  50%|█████     | 2519/5000 [9:23:17<8:15:19, 11.98s/it, loss=1.0411, lr=5.81e-06]Steps:  50%|█████     | 2519/5000 [9:23:17<8:15:19, 11.98s/it, loss=1.1348, lr=5.80e-06]Steps:  50%|█████     | 2520/5000 [9:23:29<8:14:23, 11.96s/it, loss=1.1348, lr=5.80e-06]Steps:  50%|█████     | 2520/5000 [9:23:29<8:14:23, 11.96s/it, loss=0.9087, lr=5.80e-06]
[Step 2520] Training Debug Info:
  Loss: 0.697783
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0055, std: 0.8906
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0084, std: 1.3359
  Model pred mean: -0.0070, std: 1.0469
  Sigmas: [0.51953125]... (timesteps: [521.0])

[Step 2520] Training Debug Info:
  Loss: 0.664744
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0554, std: 0.9492
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0549, std: 1.3750
  Model pred mean: -0.0413, std: 1.1016
  Sigmas: [0.953125]... (timesteps: [952.0])

[Step 2520] Training Debug Info:
  Loss: 0.485115
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0016, std: 0.9727
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0034, std: 1.3906
  Model pred mean: 0.0113, std: 1.2109
  Sigmas: [0.84375]... (timesteps: [843.0])

[Step 2520] Training Debug Info:
  Loss: 0.489554
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0217, std: 0.9219
  Noise mean: 0.0007, std: 0.9961
  Target mean: -0.0211, std: 1.3594
  Model pred mean: -0.0145, std: 1.1562
  Sigmas: [0.93359375]... (timesteps: [934.0])
Steps:  50%|█████     | 2521/5000 [9:23:40<8:12:36, 11.92s/it, loss=0.9087, lr=5.80e-06]Steps:  50%|█████     | 2521/5000 [9:23:40<8:12:36, 11.92s/it, loss=0.4896, lr=5.80e-06]Steps:  50%|█████     | 2522/5000 [9:23:52<8:13:30, 11.95s/it, loss=0.4896, lr=5.80e-06]Steps:  50%|█████     | 2522/5000 [9:23:52<8:13:30, 11.95s/it, loss=0.5007, lr=5.79e-06]Steps:  50%|█████     | 2523/5000 [9:24:05<8:16:10, 12.02s/it, loss=0.5007, lr=5.79e-06]Steps:  50%|█████     | 2523/5000 [9:24:05<8:16:10, 12.02s/it, loss=0.5171, lr=5.79e-06]Steps:  50%|█████     | 2524/5000 [9:24:17<8:14:43, 11.99s/it, loss=0.5171, lr=5.79e-06]Steps:  50%|█████     | 2524/5000 [9:24:17<8:14:43, 11.99s/it, loss=1.1152, lr=5.79e-06]Steps:  50%|█████     | 2525/5000 [9:24:29<8:14:27, 11.99s/it, loss=1.1152, lr=5.79e-06]Steps:  50%|█████     | 2525/5000 [9:24:29<8:14:27, 11.99s/it, loss=0.4494, lr=5.78e-06]Steps:  51%|█████     | 2526/5000 [9:24:40<8:13:44, 11.97s/it, loss=0.4494, lr=5.78e-06]Steps:  51%|█████     | 2526/5000 [9:24:40<8:13:44, 11.97s/it, loss=0.4437, lr=5.78e-06]Steps:  51%|█████     | 2527/5000 [9:24:53<8:14:48, 12.01s/it, loss=0.4437, lr=5.78e-06]Steps:  51%|█████     | 2527/5000 [9:24:53<8:14:48, 12.01s/it, loss=1.1327, lr=5.78e-06]Steps:  51%|█████     | 2528/5000 [9:25:04<8:13:33, 11.98s/it, loss=1.1327, lr=5.78e-06]Steps:  51%|█████     | 2528/5000 [9:25:04<8:13:33, 11.98s/it, loss=1.0240, lr=5.77e-06]Steps:  51%|█████     | 2529/5000 [9:25:17<8:14:45, 12.01s/it, loss=1.0240, lr=5.77e-06]Steps:  51%|█████     | 2529/5000 [9:25:17<8:14:45, 12.01s/it, loss=0.5655, lr=5.77e-06]Steps:  51%|█████     | 2530/5000 [9:25:28<8:13:46, 11.99s/it, loss=0.5655, lr=5.77e-06]Steps:  51%|█████     | 2530/5000 [9:25:28<8:13:46, 11.99s/it, loss=1.0132, lr=5.76e-06]
[Step 2530] Training Debug Info:
  Loss: 0.426519
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0007, std: 0.9375
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0012, std: 1.3750
  Model pred mean: -0.0046, std: 1.2109
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 2530] Training Debug Info:
  Loss: 0.447640
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0201, std: 0.9219
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0210, std: 1.3594
  Model pred mean: -0.0178, std: 1.1875
  Sigmas: [0.71484375]... (timesteps: [715.0])

[Step 2530] Training Debug Info:
  Loss: 0.843269
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0127, std: 0.9414
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0156, std: 1.3750
  Model pred mean: -0.0111, std: 1.0234
  Sigmas: [0.392578125]... (timesteps: [393.0])

[Step 2530] Training Debug Info:
  Loss: 0.927084
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0396, std: 0.9688
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0391, std: 1.3906
  Model pred mean: -0.0386, std: 1.0078
  Sigmas: [0.302734375]... (timesteps: [303.0])
Steps:  51%|█████     | 2531/5000 [9:25:41<8:15:14, 12.04s/it, loss=1.0132, lr=5.76e-06]Steps:  51%|█████     | 2531/5000 [9:25:41<8:15:14, 12.04s/it, loss=0.9271, lr=5.76e-06]Steps:  51%|█████     | 2532/5000 [9:25:53<8:14:31, 12.02s/it, loss=0.9271, lr=5.76e-06]Steps:  51%|█████     | 2532/5000 [9:25:53<8:14:31, 12.02s/it, loss=0.3790, lr=5.76e-06]Steps:  51%|█████     | 2533/5000 [9:26:05<8:13:05, 11.99s/it, loss=0.3790, lr=5.76e-06]Steps:  51%|█████     | 2533/5000 [9:26:05<8:13:05, 11.99s/it, loss=1.1351, lr=5.75e-06]Steps:  51%|█████     | 2534/5000 [9:26:17<8:12:49, 11.99s/it, loss=1.1351, lr=5.75e-06]Steps:  51%|█████     | 2534/5000 [9:26:17<8:12:49, 11.99s/it, loss=0.7191, lr=5.75e-06]Steps:  51%|█████     | 2535/5000 [9:26:29<8:15:17, 12.06s/it, loss=0.7191, lr=5.75e-06]Steps:  51%|█████     | 2535/5000 [9:26:29<8:15:17, 12.06s/it, loss=0.8480, lr=5.75e-06]Steps:  51%|█████     | 2536/5000 [9:26:41<8:15:51, 12.07s/it, loss=0.8480, lr=5.75e-06]Steps:  51%|█████     | 2536/5000 [9:26:41<8:15:51, 12.07s/it, loss=0.5003, lr=5.74e-06]Steps:  51%|█████     | 2537/5000 [9:26:53<8:14:44, 12.05s/it, loss=0.5003, lr=5.74e-06]Steps:  51%|█████     | 2537/5000 [9:26:53<8:14:44, 12.05s/it, loss=0.5154, lr=5.74e-06]Steps:  51%|█████     | 2538/5000 [9:27:05<8:13:24, 12.02s/it, loss=0.5154, lr=5.74e-06]Steps:  51%|█████     | 2538/5000 [9:27:05<8:13:24, 12.02s/it, loss=0.6608, lr=5.74e-06]Steps:  51%|█████     | 2539/5000 [9:27:17<8:13:05, 12.02s/it, loss=0.6608, lr=5.74e-06]Steps:  51%|█████     | 2539/5000 [9:27:17<8:13:05, 12.02s/it, loss=1.0619, lr=5.73e-06]Steps:  51%|█████     | 2540/5000 [9:27:29<8:12:30, 12.01s/it, loss=1.0619, lr=5.73e-06]Steps:  51%|█████     | 2540/5000 [9:27:29<8:12:30, 12.01s/it, loss=0.6851, lr=5.73e-06]
[Step 2540] Training Debug Info:
  Loss: 0.352695
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0140, std: 0.9414
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0118, std: 1.3750
  Model pred mean: -0.0160, std: 1.2344
  Sigmas: [0.82421875]... (timesteps: [823.0])

[Step 2540] Training Debug Info:
  Loss: 1.087337
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0154, std: 0.9531
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0166, std: 1.3828
  Model pred mean: -0.0164, std: 0.9102
  Sigmas: [0.054931640625]... (timesteps: [55.0])

[Step 2540] Training Debug Info:
  Loss: 0.527060
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0046, std: 0.9219
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0031, std: 1.3594
  Model pred mean: 0.0002, std: 1.1484
  Sigmas: [0.609375]... (timesteps: [608.0])

[Step 2540] Training Debug Info:
  Loss: 0.640860
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0091, std: 0.9453
  Noise mean: 0.0012, std: 0.9961
  Target mean: 0.0103, std: 1.3750
  Model pred mean: 0.0073, std: 1.1250
  Sigmas: [0.51171875]... (timesteps: [510.0])
Steps:  51%|█████     | 2541/5000 [9:27:41<8:11:14, 11.99s/it, loss=0.6851, lr=5.73e-06]Steps:  51%|█████     | 2541/5000 [9:27:41<8:11:14, 11.99s/it, loss=0.6409, lr=5.73e-06]Steps:  51%|█████     | 2542/5000 [9:27:53<8:12:56, 12.03s/it, loss=0.6409, lr=5.73e-06]Steps:  51%|█████     | 2542/5000 [9:27:53<8:12:56, 12.03s/it, loss=0.5724, lr=5.72e-06]Steps:  51%|█████     | 2543/5000 [9:28:05<8:12:12, 12.02s/it, loss=0.5724, lr=5.72e-06]Steps:  51%|█████     | 2543/5000 [9:28:05<8:12:12, 12.02s/it, loss=1.0463, lr=5.72e-06]Steps:  51%|█████     | 2544/5000 [9:28:17<8:11:51, 12.02s/it, loss=1.0463, lr=5.72e-06]Steps:  51%|█████     | 2544/5000 [9:28:17<8:11:51, 12.02s/it, loss=0.5439, lr=5.72e-06]Steps:  51%|█████     | 2545/5000 [9:28:29<8:12:48, 12.04s/it, loss=0.5439, lr=5.72e-06]Steps:  51%|█████     | 2545/5000 [9:28:29<8:12:48, 12.04s/it, loss=1.0199, lr=5.71e-06]Steps:  51%|█████     | 2546/5000 [9:28:41<8:11:26, 12.02s/it, loss=1.0199, lr=5.71e-06]Steps:  51%|█████     | 2546/5000 [9:28:41<8:11:26, 12.02s/it, loss=0.6539, lr=5.71e-06]Steps:  51%|█████     | 2547/5000 [9:28:53<8:11:25, 12.02s/it, loss=0.6539, lr=5.71e-06]Steps:  51%|█████     | 2547/5000 [9:28:53<8:11:25, 12.02s/it, loss=0.3732, lr=5.71e-06]Steps:  51%|█████     | 2548/5000 [9:29:05<8:10:10, 11.99s/it, loss=0.3732, lr=5.71e-06]Steps:  51%|█████     | 2548/5000 [9:29:05<8:10:10, 11.99s/it, loss=0.3869, lr=5.70e-06]Steps:  51%|█████     | 2549/5000 [9:29:17<8:11:08, 12.02s/it, loss=0.3869, lr=5.70e-06]Steps:  51%|█████     | 2549/5000 [9:29:17<8:11:08, 12.02s/it, loss=0.9432, lr=5.70e-06]Steps:  51%|█████     | 2550/5000 [9:29:29<8:09:50, 12.00s/it, loss=0.9432, lr=5.70e-06]Steps:  51%|█████     | 2550/5000 [9:29:29<8:09:50, 12.00s/it, loss=0.4673, lr=5.70e-06]
[Step 2550] Training Debug Info:
  Loss: 1.148533
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0044, std: 0.9258
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0061, std: 1.3594
  Model pred mean: -0.0041, std: 0.8438
  Sigmas: [0.1318359375]... (timesteps: [132.0])

[Step 2550] Training Debug Info:
  Loss: 0.936821
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0128, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0138, std: 1.3438
  Model pred mean: -0.0125, std: 0.9375
  Sigmas: [0.373046875]... (timesteps: [374.0])

[Step 2550] Training Debug Info:
  Loss: 0.459105
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0295, std: 0.9492
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0317, std: 1.3750
  Model pred mean: -0.0288, std: 1.2031
  Sigmas: [0.84765625]... (timesteps: [848.0])

[Step 2550] Training Debug Info:
  Loss: 0.521508
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0432, std: 0.9648
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0417, std: 1.3906
  Model pred mean: -0.0405, std: 1.1875
  Sigmas: [0.6328125]... (timesteps: [631.0])
Steps:  51%|█████     | 2551/5000 [9:29:41<8:08:31, 11.97s/it, loss=0.4673, lr=5.70e-06]Steps:  51%|█████     | 2551/5000 [9:29:41<8:08:31, 11.97s/it, loss=0.5215, lr=5.69e-06]Steps:  51%|█████     | 2552/5000 [9:29:53<8:08:19, 11.97s/it, loss=0.5215, lr=5.69e-06]Steps:  51%|█████     | 2552/5000 [9:29:53<8:08:19, 11.97s/it, loss=0.6557, lr=5.69e-06]Steps:  51%|█████     | 2553/5000 [9:30:05<8:08:03, 11.97s/it, loss=0.6557, lr=5.69e-06]Steps:  51%|█████     | 2553/5000 [9:30:05<8:08:03, 11.97s/it, loss=0.4095, lr=5.69e-06]Steps:  51%|█████     | 2554/5000 [9:30:17<8:09:44, 12.01s/it, loss=0.4095, lr=5.69e-06]Steps:  51%|█████     | 2554/5000 [9:30:17<8:09:44, 12.01s/it, loss=0.4917, lr=5.68e-06]Steps:  51%|█████     | 2555/5000 [9:30:29<8:09:33, 12.01s/it, loss=0.4917, lr=5.68e-06]Steps:  51%|█████     | 2555/5000 [9:30:29<8:09:33, 12.01s/it, loss=0.7336, lr=5.68e-06]Steps:  51%|█████     | 2556/5000 [9:30:41<8:10:54, 12.05s/it, loss=0.7336, lr=5.68e-06]Steps:  51%|█████     | 2556/5000 [9:30:41<8:10:54, 12.05s/it, loss=1.0724, lr=5.68e-06]Steps:  51%|█████     | 2557/5000 [9:30:53<8:10:08, 12.04s/it, loss=1.0724, lr=5.68e-06]Steps:  51%|█████     | 2557/5000 [9:30:53<8:10:08, 12.04s/it, loss=0.3659, lr=5.67e-06]Steps:  51%|█████     | 2558/5000 [9:31:05<8:08:48, 12.01s/it, loss=0.3659, lr=5.67e-06]Steps:  51%|█████     | 2558/5000 [9:31:05<8:08:48, 12.01s/it, loss=0.4408, lr=5.67e-06]Steps:  51%|█████     | 2559/5000 [9:31:17<8:08:23, 12.00s/it, loss=0.4408, lr=5.67e-06]Steps:  51%|█████     | 2559/5000 [9:31:17<8:08:23, 12.00s/it, loss=1.0965, lr=5.66e-06]Steps:  51%|█████     | 2560/5000 [9:31:29<8:08:33, 12.01s/it, loss=1.0965, lr=5.66e-06]Steps:  51%|█████     | 2560/5000 [9:31:29<8:08:33, 12.01s/it, loss=0.4944, lr=5.66e-06]
[Step 2560] Training Debug Info:
  Loss: 1.164196
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0378, std: 0.8594
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0376, std: 1.3203
  Model pred mean: 0.0396, std: 0.7539
  Sigmas: [0.29296875]... (timesteps: [292.0])

[Step 2560] Training Debug Info:
  Loss: 0.497946
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0084, std: 0.9492
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0102, std: 1.3750
  Model pred mean: -0.0037, std: 1.1875
  Sigmas: [0.703125]... (timesteps: [702.0])

[Step 2560] Training Debug Info:
  Loss: 0.509757
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0205, std: 0.9258
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0200, std: 1.3672
  Model pred mean: -0.0220, std: 1.1641
  Sigmas: [0.60546875]... (timesteps: [607.0])

[Step 2560] Training Debug Info:
  Loss: 0.818850
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0378, std: 0.9844
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0388, std: 1.3984
  Model pred mean: -0.0269, std: 1.0703
  Sigmas: [0.99609375]... (timesteps: [996.0])
Steps:  51%|█████     | 2561/5000 [9:31:41<8:10:44, 12.07s/it, loss=0.4944, lr=5.66e-06]Steps:  51%|█████     | 2561/5000 [9:31:41<8:10:44, 12.07s/it, loss=0.8189, lr=5.66e-06]Steps:  51%|█████     | 2562/5000 [9:31:53<8:11:33, 12.10s/it, loss=0.8189, lr=5.66e-06]Steps:  51%|█████     | 2562/5000 [9:31:53<8:11:33, 12.10s/it, loss=0.4011, lr=5.65e-06]Steps:  51%|█████▏    | 2563/5000 [9:32:05<8:10:43, 12.08s/it, loss=0.4011, lr=5.65e-06]Steps:  51%|█████▏    | 2563/5000 [9:32:05<8:10:43, 12.08s/it, loss=0.5021, lr=5.65e-06]Steps:  51%|█████▏    | 2564/5000 [9:32:17<8:08:48, 12.04s/it, loss=0.5021, lr=5.65e-06]Steps:  51%|█████▏    | 2564/5000 [9:32:17<8:08:48, 12.04s/it, loss=0.6191, lr=5.65e-06]Steps:  51%|█████▏    | 2565/5000 [9:32:29<8:08:15, 12.03s/it, loss=0.6191, lr=5.65e-06]Steps:  51%|█████▏    | 2565/5000 [9:32:29<8:08:15, 12.03s/it, loss=0.4322, lr=5.64e-06]Steps:  51%|█████▏    | 2566/5000 [9:32:41<8:08:15, 12.04s/it, loss=0.4322, lr=5.64e-06]Steps:  51%|█████▏    | 2566/5000 [9:32:41<8:08:15, 12.04s/it, loss=1.0063, lr=5.64e-06]Steps:  51%|█████▏    | 2567/5000 [9:32:53<8:07:21, 12.02s/it, loss=1.0063, lr=5.64e-06]Steps:  51%|█████▏    | 2567/5000 [9:32:53<8:07:21, 12.02s/it, loss=0.5335, lr=5.64e-06]Steps:  51%|█████▏    | 2568/5000 [9:33:06<8:10:21, 12.10s/it, loss=0.5335, lr=5.64e-06]Steps:  51%|█████▏    | 2568/5000 [9:33:06<8:10:21, 12.10s/it, loss=1.0964, lr=5.63e-06]Steps:  51%|█████▏    | 2569/5000 [9:33:18<8:11:46, 12.14s/it, loss=1.0964, lr=5.63e-06]Steps:  51%|█████▏    | 2569/5000 [9:33:18<8:11:46, 12.14s/it, loss=1.0939, lr=5.63e-06]Steps:  51%|█████▏    | 2570/5000 [9:33:30<8:08:25, 12.06s/it, loss=1.0939, lr=5.63e-06]Steps:  51%|█████▏    | 2570/5000 [9:33:30<8:08:25, 12.06s/it, loss=0.7907, lr=5.63e-06]
[Step 2570] Training Debug Info:
  Loss: 0.478735
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0150, std: 0.9062
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0134, std: 1.3516
  Model pred mean: 0.0135, std: 1.1641
  Sigmas: [0.71484375]... (timesteps: [715.0])

[Step 2570] Training Debug Info:
  Loss: 0.584087
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0067, std: 0.8867
  Noise mean: 0.0035, std: 1.0000
  Target mean: -0.0032, std: 1.3359
  Model pred mean: -0.0140, std: 1.1016
  Sigmas: [0.984375]... (timesteps: [985.0])

[Step 2570] Training Debug Info:
  Loss: 1.108293
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0280, std: 0.9414
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0297, std: 1.3750
  Model pred mean: -0.0332, std: 0.8906
  Sigmas: [0.080078125]... (timesteps: [80.0])

[Step 2570] Training Debug Info:
  Loss: 0.492694
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0188, std: 0.8125
  Noise mean: 0.0043, std: 1.0000
  Target mean: 0.0232, std: 1.2891
  Model pred mean: -0.0067, std: 1.0938
  Sigmas: [0.98046875]... (timesteps: [979.0])
Steps:  51%|█████▏    | 2571/5000 [9:33:42<8:07:05, 12.03s/it, loss=0.7907, lr=5.63e-06]Steps:  51%|█████▏    | 2571/5000 [9:33:42<8:07:05, 12.03s/it, loss=0.4927, lr=5.62e-06]Steps:  51%|█████▏    | 2572/5000 [9:33:54<8:07:17, 12.04s/it, loss=0.4927, lr=5.62e-06]Steps:  51%|█████▏    | 2572/5000 [9:33:54<8:07:17, 12.04s/it, loss=0.4445, lr=5.62e-06]Steps:  51%|█████▏    | 2573/5000 [9:34:06<8:06:38, 12.03s/it, loss=0.4445, lr=5.62e-06]Steps:  51%|█████▏    | 2573/5000 [9:34:06<8:06:38, 12.03s/it, loss=0.3858, lr=5.62e-06]Steps:  51%|█████▏    | 2574/5000 [9:34:18<8:06:06, 12.02s/it, loss=0.3858, lr=5.62e-06]Steps:  51%|█████▏    | 2574/5000 [9:34:18<8:06:06, 12.02s/it, loss=0.6174, lr=5.61e-06]Steps:  52%|█████▏    | 2575/5000 [9:34:30<8:05:40, 12.02s/it, loss=0.6174, lr=5.61e-06]Steps:  52%|█████▏    | 2575/5000 [9:34:30<8:05:40, 12.02s/it, loss=0.4363, lr=5.61e-06]Steps:  52%|█████▏    | 2576/5000 [9:34:42<8:08:15, 12.09s/it, loss=0.4363, lr=5.61e-06]Steps:  52%|█████▏    | 2576/5000 [9:34:42<8:08:15, 12.09s/it, loss=0.6865, lr=5.61e-06]Steps:  52%|█████▏    | 2577/5000 [9:34:54<8:07:44, 12.08s/it, loss=0.6865, lr=5.61e-06]Steps:  52%|█████▏    | 2577/5000 [9:34:54<8:07:44, 12.08s/it, loss=0.4537, lr=5.60e-06]Steps:  52%|█████▏    | 2578/5000 [9:35:06<8:06:10, 12.04s/it, loss=0.4537, lr=5.60e-06]Steps:  52%|█████▏    | 2578/5000 [9:35:06<8:06:10, 12.04s/it, loss=0.9045, lr=5.60e-06]Steps:  52%|█████▏    | 2579/5000 [9:35:18<8:04:18, 12.00s/it, loss=0.9045, lr=5.60e-06]Steps:  52%|█████▏    | 2579/5000 [9:35:18<8:04:18, 12.00s/it, loss=0.6628, lr=5.60e-06]Steps:  52%|█████▏    | 2580/5000 [9:35:30<8:04:22, 12.01s/it, loss=0.6628, lr=5.60e-06]Steps:  52%|█████▏    | 2580/5000 [9:35:30<8:04:22, 12.01s/it, loss=1.0969, lr=5.59e-06]
[Step 2580] Training Debug Info:
  Loss: 0.436722
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0366, std: 0.9141
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0393, std: 1.3594
  Model pred mean: -0.0369, std: 1.1797
  Sigmas: [0.67578125]... (timesteps: [675.0])

[Step 2580] Training Debug Info:
  Loss: 1.136159
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0058, std: 0.9492
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0062, std: 1.3828
  Model pred mean: -0.0087, std: 0.8750
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 2580] Training Debug Info:
  Loss: 0.758754
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0072, std: 0.8867
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0072, std: 1.3359
  Model pred mean: -0.0095, std: 1.0078
  Sigmas: [0.5]... (timesteps: [501.0])

[Step 2580] Training Debug Info:
  Loss: 0.468594
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0091, std: 0.9258
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0111, std: 1.3672
  Model pred mean: -0.0115, std: 1.1797
  Sigmas: [0.73046875]... (timesteps: [730.0])
Steps:  52%|█████▏    | 2581/5000 [9:35:42<8:04:38, 12.02s/it, loss=1.0969, lr=5.59e-06]Steps:  52%|█████▏    | 2581/5000 [9:35:42<8:04:38, 12.02s/it, loss=0.4686, lr=5.59e-06]Steps:  52%|█████▏    | 2582/5000 [9:35:54<8:02:57, 11.98s/it, loss=0.4686, lr=5.59e-06]Steps:  52%|█████▏    | 2582/5000 [9:35:54<8:02:57, 11.98s/it, loss=0.5295, lr=5.59e-06]Steps:  52%|█████▏    | 2583/5000 [9:36:06<8:04:22, 12.02s/it, loss=0.5295, lr=5.59e-06]Steps:  52%|█████▏    | 2583/5000 [9:36:06<8:04:22, 12.02s/it, loss=1.1384, lr=5.58e-06]Steps:  52%|█████▏    | 2584/5000 [9:36:18<8:04:11, 12.02s/it, loss=1.1384, lr=5.58e-06]Steps:  52%|█████▏    | 2584/5000 [9:36:18<8:04:11, 12.02s/it, loss=0.7429, lr=5.58e-06]Steps:  52%|█████▏    | 2585/5000 [9:36:30<8:02:43, 11.99s/it, loss=0.7429, lr=5.58e-06]Steps:  52%|█████▏    | 2585/5000 [9:36:30<8:02:43, 11.99s/it, loss=0.9593, lr=5.57e-06]Steps:  52%|█████▏    | 2586/5000 [9:36:42<8:02:39, 12.00s/it, loss=0.9593, lr=5.57e-06]Steps:  52%|█████▏    | 2586/5000 [9:36:42<8:02:39, 12.00s/it, loss=0.5111, lr=5.57e-06]Steps:  52%|█████▏    | 2587/5000 [9:36:54<8:01:29, 11.97s/it, loss=0.5111, lr=5.57e-06]Steps:  52%|█████▏    | 2587/5000 [9:36:54<8:01:29, 11.97s/it, loss=1.1812, lr=5.57e-06]Steps:  52%|█████▏    | 2588/5000 [9:37:06<8:01:19, 11.97s/it, loss=1.1812, lr=5.57e-06]Steps:  52%|█████▏    | 2588/5000 [9:37:06<8:01:19, 11.97s/it, loss=0.8380, lr=5.56e-06]Steps:  52%|█████▏    | 2589/5000 [9:37:18<8:02:51, 12.02s/it, loss=0.8380, lr=5.56e-06]Steps:  52%|█████▏    | 2589/5000 [9:37:18<8:02:51, 12.02s/it, loss=0.3713, lr=5.56e-06]Steps:  52%|█████▏    | 2590/5000 [9:37:30<8:03:25, 12.04s/it, loss=0.3713, lr=5.56e-06]Steps:  52%|█████▏    | 2590/5000 [9:37:30<8:03:25, 12.04s/it, loss=0.7219, lr=5.56e-06]
[Step 2590] Training Debug Info:
  Loss: 0.387373
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0544, std: 0.9258
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0571, std: 1.3672
  Model pred mean: -0.0530, std: 1.2109
  Sigmas: [0.6328125]... (timesteps: [632.0])

[Step 2590] Training Debug Info:
  Loss: 1.126316
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0146, std: 0.8906
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0135, std: 1.3359
  Model pred mean: -0.0175, std: 0.8086
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 2590] Training Debug Info:
  Loss: 0.443049
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0415, std: 0.9102
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0391, std: 1.3516
  Model pred mean: -0.0388, std: 1.1719
  Sigmas: [0.7734375]... (timesteps: [774.0])

[Step 2590] Training Debug Info:
  Loss: 0.386803
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0018, std: 0.9219
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0027, std: 1.3594
  Model pred mean: -0.0028, std: 1.2109
  Sigmas: [0.8984375]... (timesteps: [897.0])
Steps:  52%|█████▏    | 2591/5000 [9:37:42<8:02:35, 12.02s/it, loss=0.7219, lr=5.56e-06]Steps:  52%|█████▏    | 2591/5000 [9:37:42<8:02:35, 12.02s/it, loss=0.3868, lr=5.55e-06]Steps:  52%|█████▏    | 2592/5000 [9:37:54<8:01:45, 12.00s/it, loss=0.3868, lr=5.55e-06]Steps:  52%|█████▏    | 2592/5000 [9:37:54<8:01:45, 12.00s/it, loss=1.0203, lr=5.55e-06]Steps:  52%|█████▏    | 2593/5000 [9:38:06<8:02:52, 12.04s/it, loss=1.0203, lr=5.55e-06]Steps:  52%|█████▏    | 2593/5000 [9:38:06<8:02:52, 12.04s/it, loss=0.4860, lr=5.55e-06]Steps:  52%|█████▏    | 2594/5000 [9:38:18<8:00:58, 11.99s/it, loss=0.4860, lr=5.55e-06]Steps:  52%|█████▏    | 2594/5000 [9:38:18<8:00:58, 11.99s/it, loss=1.1494, lr=5.54e-06]Steps:  52%|█████▏    | 2595/5000 [9:38:30<8:01:26, 12.01s/it, loss=1.1494, lr=5.54e-06]Steps:  52%|█████▏    | 2595/5000 [9:38:30<8:01:26, 12.01s/it, loss=0.5340, lr=5.54e-06]Steps:  52%|█████▏    | 2596/5000 [9:38:42<8:02:29, 12.04s/it, loss=0.5340, lr=5.54e-06]Steps:  52%|█████▏    | 2596/5000 [9:38:42<8:02:29, 12.04s/it, loss=0.6103, lr=5.54e-06]Steps:  52%|█████▏    | 2597/5000 [9:38:54<8:00:31, 12.00s/it, loss=0.6103, lr=5.54e-06]Steps:  52%|█████▏    | 2597/5000 [9:38:54<8:00:31, 12.00s/it, loss=0.4921, lr=5.53e-06]Steps:  52%|█████▏    | 2598/5000 [9:39:06<8:00:01, 11.99s/it, loss=0.4921, lr=5.53e-06]Steps:  52%|█████▏    | 2598/5000 [9:39:06<8:00:01, 11.99s/it, loss=0.6428, lr=5.53e-06]Steps:  52%|█████▏    | 2599/5000 [9:39:18<8:00:27, 12.01s/it, loss=0.6428, lr=5.53e-06]Steps:  52%|█████▏    | 2599/5000 [9:39:18<8:00:27, 12.01s/it, loss=0.5354, lr=5.53e-06]Steps:  52%|█████▏    | 2600/5000 [9:39:30<7:59:37, 11.99s/it, loss=0.5354, lr=5.53e-06]Steps:  52%|█████▏    | 2600/5000 [9:39:30<7:59:37, 11.99s/it, loss=0.5120, lr=5.52e-06]01/22/2026 17:25:17 - INFO - __main__ - 
[Step 2600] ✅ Loss in normal range (0.5120)
01/22/2026 17:25:17 - INFO - __main__ -   Loss avg (last 100): 0.6975
01/22/2026 17:25:17 - INFO - __main__ -   Loss range: [0.3659, 1.1812]
01/22/2026 17:25:17 - INFO - __main__ - 
🔍 Running validation at step 2600...
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2600 (parquet mode)...
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2600...
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 17:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.47it/s]
01/22/2026 17:25:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 17:25:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 17:25:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 17:25:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.13it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 17:26:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 17:26:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 17:26:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 17:26:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 17:27:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 17:27:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 17:27:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 17:27:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 17:27:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 17:27:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 17:28:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 17:28:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 17:28:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 17:28:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 17:28:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 17:28:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 17:29:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 17:29:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 17:29:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600/step002600_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 17:29:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 17:29:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 17:29:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002600
01/22/2026 17:29:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 2600] Training Debug Info:
  Loss: 0.945951
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0052, std: 0.9219
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0067, std: 1.3594
  Model pred mean: -0.0030, std: 0.9414
  Sigmas: [0.365234375]... (timesteps: [366.0])

[Step 2600] Training Debug Info:
  Loss: 0.400517
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0077, std: 0.8711
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0085, std: 1.3281
  Model pred mean: -0.0075, std: 1.1641
  Sigmas: [0.859375]... (timesteps: [859.0])

[Step 2600] Training Debug Info:
  Loss: 0.781476
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0029, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0024, std: 1.3672
  Model pred mean: 0.0048, std: 1.0391
  Sigmas: [0.44921875]... (timesteps: [449.0])

[Step 2600] Training Debug Info:
  Loss: 0.600491
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0021, std: 0.9023
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0010, std: 1.3438
  Model pred mean: 0.0076, std: 1.1172
  Sigmas: [0.96875]... (timesteps: [970.0])
Steps:  52%|█████▏    | 2601/5000 [9:43:55<58:29:54, 87.78s/it, loss=0.5120, lr=5.52e-06]Steps:  52%|█████▏    | 2601/5000 [9:43:55<58:29:54, 87.78s/it, loss=0.6005, lr=5.52e-06]Steps:  52%|█████▏    | 2602/5000 [9:44:07<43:18:20, 65.01s/it, loss=0.6005, lr=5.52e-06]Steps:  52%|█████▏    | 2602/5000 [9:44:07<43:18:20, 65.01s/it, loss=0.9868, lr=5.52e-06]Steps:  52%|█████▏    | 2603/5000 [9:44:19<32:43:53, 49.16s/it, loss=0.9868, lr=5.52e-06]Steps:  52%|█████▏    | 2603/5000 [9:44:19<32:43:53, 49.16s/it, loss=1.0201, lr=5.51e-06]Steps:  52%|█████▏    | 2604/5000 [9:44:31<25:17:50, 38.01s/it, loss=1.0201, lr=5.51e-06]Steps:  52%|█████▏    | 2604/5000 [9:44:31<25:17:50, 38.01s/it, loss=1.1056, lr=5.51e-06]Steps:  52%|█████▏    | 2605/5000 [9:44:43<20:05:21, 30.20s/it, loss=1.1056, lr=5.51e-06]Steps:  52%|█████▏    | 2605/5000 [9:44:43<20:05:21, 30.20s/it, loss=1.0636, lr=5.51e-06]Steps:  52%|█████▏    | 2606/5000 [9:44:55<16:27:05, 24.74s/it, loss=1.0636, lr=5.51e-06]Steps:  52%|█████▏    | 2606/5000 [9:44:55<16:27:05, 24.74s/it, loss=0.4216, lr=5.50e-06]Steps:  52%|█████▏    | 2607/5000 [9:45:07<13:53:35, 20.90s/it, loss=0.4216, lr=5.50e-06]Steps:  52%|█████▏    | 2607/5000 [9:45:07<13:53:35, 20.90s/it, loss=0.4123, lr=5.50e-06]Steps:  52%|█████▏    | 2608/5000 [9:45:19<12:06:27, 18.22s/it, loss=0.4123, lr=5.50e-06]Steps:  52%|█████▏    | 2608/5000 [9:45:19<12:06:27, 18.22s/it, loss=0.4139, lr=5.49e-06]Steps:  52%|█████▏    | 2609/5000 [9:45:31<10:52:11, 16.37s/it, loss=0.4139, lr=5.49e-06]Steps:  52%|█████▏    | 2609/5000 [9:45:31<10:52:11, 16.37s/it, loss=0.9791, lr=5.49e-06]Steps:  52%|█████▏    | 2610/5000 [9:45:43<10:00:35, 15.08s/it, loss=0.9791, lr=5.49e-06]Steps:  52%|█████▏    | 2610/5000 [9:45:43<10:00:35, 15.08s/it, loss=0.5950, lr=5.49e-06]
[Step 2610] Training Debug Info:
  Loss: 0.563465
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0070, std: 0.8828
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0092, std: 1.3359
  Model pred mean: -0.0073, std: 1.1016
  Sigmas: [0.578125]... (timesteps: [577.0])

[Step 2610] Training Debug Info:
  Loss: 0.787442
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0299, std: 0.9258
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0302, std: 1.3672
  Model pred mean: -0.0303, std: 1.0391
  Sigmas: [0.4453125]... (timesteps: [446.0])

[Step 2610] Training Debug Info:
  Loss: 0.580560
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0095, std: 0.8789
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0120, std: 1.3281
  Model pred mean: 0.0068, std: 1.0859
  Sigmas: [0.98828125]... (timesteps: [987.0])

[Step 2610] Training Debug Info:
  Loss: 1.123316
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0229, std: 0.8711
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0254, std: 1.3281
  Model pred mean: -0.0250, std: 0.7930
  Sigmas: [0.08203125]... (timesteps: [82.0])
Steps:  52%|█████▏    | 2611/5000 [9:45:55<9:22:56, 14.14s/it, loss=0.5950, lr=5.49e-06] Steps:  52%|█████▏    | 2611/5000 [9:45:55<9:22:56, 14.14s/it, loss=1.1233, lr=5.48e-06]Steps:  52%|█████▏    | 2612/5000 [9:46:07<8:56:25, 13.48s/it, loss=1.1233, lr=5.48e-06]Steps:  52%|█████▏    | 2612/5000 [9:46:07<8:56:25, 13.48s/it, loss=0.3918, lr=5.48e-06]Steps:  52%|█████▏    | 2613/5000 [9:46:19<8:37:25, 13.01s/it, loss=0.3918, lr=5.48e-06]Steps:  52%|█████▏    | 2613/5000 [9:46:19<8:37:25, 13.01s/it, loss=1.0926, lr=5.48e-06]Steps:  52%|█████▏    | 2614/5000 [9:46:31<8:24:48, 12.69s/it, loss=1.0926, lr=5.48e-06]Steps:  52%|█████▏    | 2614/5000 [9:46:31<8:24:48, 12.69s/it, loss=0.4285, lr=5.47e-06]Steps:  52%|█████▏    | 2615/5000 [9:46:43<8:15:54, 12.48s/it, loss=0.4285, lr=5.47e-06]Steps:  52%|█████▏    | 2615/5000 [9:46:43<8:15:54, 12.48s/it, loss=1.0116, lr=5.47e-06]Steps:  52%|█████▏    | 2616/5000 [9:46:55<8:10:33, 12.35s/it, loss=1.0116, lr=5.47e-06]Steps:  52%|█████▏    | 2616/5000 [9:46:55<8:10:33, 12.35s/it, loss=0.4230, lr=5.47e-06]Steps:  52%|█████▏    | 2617/5000 [9:47:07<8:06:16, 12.24s/it, loss=0.4230, lr=5.47e-06]Steps:  52%|█████▏    | 2617/5000 [9:47:07<8:06:16, 12.24s/it, loss=0.8869, lr=5.46e-06]Steps:  52%|█████▏    | 2618/5000 [9:47:19<8:03:00, 12.17s/it, loss=0.8869, lr=5.46e-06]Steps:  52%|█████▏    | 2618/5000 [9:47:19<8:03:00, 12.17s/it, loss=0.7699, lr=5.46e-06]Steps:  52%|█████▏    | 2619/5000 [9:47:30<7:58:42, 12.06s/it, loss=0.7699, lr=5.46e-06]Steps:  52%|█████▏    | 2619/5000 [9:47:30<7:58:42, 12.06s/it, loss=0.5290, lr=5.46e-06]Steps:  52%|█████▏    | 2620/5000 [9:47:42<7:56:31, 12.01s/it, loss=0.5290, lr=5.46e-06]Steps:  52%|█████▏    | 2620/5000 [9:47:42<7:56:31, 12.01s/it, loss=0.7800, lr=5.45e-06]
[Step 2620] Training Debug Info:
  Loss: 1.073486
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0126, std: 0.9492
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0125, std: 1.3750
  Model pred mean: -0.0142, std: 0.9102
  Sigmas: [0.29296875]... (timesteps: [292.0])

[Step 2620] Training Debug Info:
  Loss: 0.995500
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0240, std: 0.9258
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0258, std: 1.3672
  Model pred mean: -0.0247, std: 0.9336
  Sigmas: [0.291015625]... (timesteps: [291.0])

[Step 2620] Training Debug Info:
  Loss: 0.627832
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0403, std: 0.9219
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0405, std: 1.3594
  Model pred mean: -0.0398, std: 1.1016
  Sigmas: [0.50390625]... (timesteps: [501.9999694824219])

[Step 2620] Training Debug Info:
  Loss: 0.408095
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0223, std: 0.9570
  Noise mean: 0.0003, std: 0.9961
  Target mean: -0.0221, std: 1.3828
  Model pred mean: -0.0221, std: 1.2188
  Sigmas: [0.65234375]... (timesteps: [651.0])
Steps:  52%|█████▏    | 2621/5000 [9:47:54<7:56:30, 12.02s/it, loss=0.7800, lr=5.45e-06]Steps:  52%|█████▏    | 2621/5000 [9:47:54<7:56:30, 12.02s/it, loss=0.4081, lr=5.45e-06]Steps:  52%|█████▏    | 2622/5000 [9:48:06<7:55:56, 12.01s/it, loss=0.4081, lr=5.45e-06]Steps:  52%|█████▏    | 2622/5000 [9:48:06<7:55:56, 12.01s/it, loss=0.6436, lr=5.45e-06]Steps:  52%|█████▏    | 2623/5000 [9:48:18<7:56:26, 12.03s/it, loss=0.6436, lr=5.45e-06]Steps:  52%|█████▏    | 2623/5000 [9:48:18<7:56:26, 12.03s/it, loss=1.0245, lr=5.44e-06]Steps:  52%|█████▏    | 2624/5000 [9:48:30<7:57:34, 12.06s/it, loss=1.0245, lr=5.44e-06]Steps:  52%|█████▏    | 2624/5000 [9:48:31<7:57:34, 12.06s/it, loss=0.5103, lr=5.44e-06]Steps:  52%|█████▎    | 2625/5000 [9:48:42<7:55:33, 12.01s/it, loss=0.5103, lr=5.44e-06]Steps:  52%|█████▎    | 2625/5000 [9:48:42<7:55:33, 12.01s/it, loss=1.0261, lr=5.44e-06]Steps:  53%|█████▎    | 2626/5000 [9:48:54<7:55:53, 12.03s/it, loss=1.0261, lr=5.44e-06]Steps:  53%|█████▎    | 2626/5000 [9:48:54<7:55:53, 12.03s/it, loss=0.6058, lr=5.43e-06]Steps:  53%|█████▎    | 2627/5000 [9:49:06<7:55:07, 12.01s/it, loss=0.6058, lr=5.43e-06]Steps:  53%|█████▎    | 2627/5000 [9:49:06<7:55:07, 12.01s/it, loss=0.3577, lr=5.43e-06]Steps:  53%|█████▎    | 2628/5000 [9:49:18<7:54:52, 12.01s/it, loss=0.3577, lr=5.43e-06]Steps:  53%|█████▎    | 2628/5000 [9:49:18<7:54:52, 12.01s/it, loss=0.6345, lr=5.43e-06]Steps:  53%|█████▎    | 2629/5000 [9:49:30<7:53:53, 11.99s/it, loss=0.6345, lr=5.43e-06]Steps:  53%|█████▎    | 2629/5000 [9:49:30<7:53:53, 11.99s/it, loss=0.4740, lr=5.42e-06]Steps:  53%|█████▎    | 2630/5000 [9:49:42<7:54:03, 12.00s/it, loss=0.4740, lr=5.42e-06]Steps:  53%|█████▎    | 2630/5000 [9:49:42<7:54:03, 12.00s/it, loss=0.5731, lr=5.42e-06]
[Step 2630] Training Debug Info:
  Loss: 0.878958
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0051, std: 0.8867
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0057, std: 1.3359
  Model pred mean: 0.0056, std: 0.9609
  Sigmas: [0.42578125]... (timesteps: [426.0])

[Step 2630] Training Debug Info:
  Loss: 0.866120
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0383, std: 0.8828
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0369, std: 1.3359
  Model pred mean: 0.0417, std: 0.9531
  Sigmas: [0.4375]... (timesteps: [438.0])

[Step 2630] Training Debug Info:
  Loss: 1.227194
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0408, std: 0.8203
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0405, std: 1.2891
  Model pred mean: 0.0405, std: 0.6680
  Sigmas: [0.232421875]... (timesteps: [232.0])

[Step 2630] Training Debug Info:
  Loss: 1.100772
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0415, std: 0.9219
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0430, std: 1.3594
  Model pred mean: -0.0388, std: 0.8633
  Sigmas: [0.076171875]... (timesteps: [76.0])
Steps:  53%|█████▎    | 2631/5000 [9:49:54<7:53:47, 12.00s/it, loss=0.5731, lr=5.42e-06]Steps:  53%|█████▎    | 2631/5000 [9:49:54<7:53:47, 12.00s/it, loss=1.1008, lr=5.41e-06]Steps:  53%|█████▎    | 2632/5000 [9:50:06<7:53:03, 11.99s/it, loss=1.1008, lr=5.41e-06]Steps:  53%|█████▎    | 2632/5000 [9:50:06<7:53:03, 11.99s/it, loss=1.0848, lr=5.41e-06]Steps:  53%|█████▎    | 2633/5000 [9:50:18<7:53:57, 12.01s/it, loss=1.0848, lr=5.41e-06]Steps:  53%|█████▎    | 2633/5000 [9:50:18<7:53:57, 12.01s/it, loss=1.0738, lr=5.41e-06]Steps:  53%|█████▎    | 2634/5000 [9:50:30<7:53:25, 12.01s/it, loss=1.0738, lr=5.41e-06]Steps:  53%|█████▎    | 2634/5000 [9:50:30<7:53:25, 12.01s/it, loss=0.9823, lr=5.40e-06]Steps:  53%|█████▎    | 2635/5000 [9:50:42<7:52:59, 12.00s/it, loss=0.9823, lr=5.40e-06]Steps:  53%|█████▎    | 2635/5000 [9:50:42<7:52:59, 12.00s/it, loss=1.0462, lr=5.40e-06]Steps:  53%|█████▎    | 2636/5000 [9:50:54<7:51:34, 11.97s/it, loss=1.0462, lr=5.40e-06]Steps:  53%|█████▎    | 2636/5000 [9:50:54<7:51:34, 11.97s/it, loss=0.3792, lr=5.40e-06]Steps:  53%|█████▎    | 2637/5000 [9:51:06<7:52:36, 12.00s/it, loss=0.3792, lr=5.40e-06]Steps:  53%|█████▎    | 2637/5000 [9:51:06<7:52:36, 12.00s/it, loss=0.8093, lr=5.39e-06]Steps:  53%|█████▎    | 2638/5000 [9:51:18<7:51:48, 11.98s/it, loss=0.8093, lr=5.39e-06]Steps:  53%|█████▎    | 2638/5000 [9:51:18<7:51:48, 11.98s/it, loss=0.4761, lr=5.39e-06]Steps:  53%|█████▎    | 2639/5000 [9:51:30<7:50:04, 11.95s/it, loss=0.4761, lr=5.39e-06]Steps:  53%|█████▎    | 2639/5000 [9:51:30<7:50:04, 11.95s/it, loss=0.5171, lr=5.39e-06]Steps:  53%|█████▎    | 2640/5000 [9:51:42<7:49:42, 11.94s/it, loss=0.5171, lr=5.39e-06]Steps:  53%|█████▎    | 2640/5000 [9:51:42<7:49:42, 11.94s/it, loss=1.0765, lr=5.38e-06]
[Step 2640] Training Debug Info:
  Loss: 0.416556
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0396, std: 0.9844
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0374, std: 1.3984
  Model pred mean: -0.0297, std: 1.2422
  Sigmas: [0.78125]... (timesteps: [782.0])

[Step 2640] Training Debug Info:
  Loss: 0.450932
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0135, std: 0.8984
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0149, std: 1.3438
  Model pred mean: -0.0175, std: 1.1641
  Sigmas: [0.71875]... (timesteps: [717.0])

[Step 2640] Training Debug Info:
  Loss: 1.103703
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0410, std: 0.9531
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0400, std: 1.3828
  Model pred mean: -0.0454, std: 0.8945
  Sigmas: [0.134765625]... (timesteps: [135.0])

[Step 2640] Training Debug Info:
  Loss: 0.594864
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0020, std: 0.9297
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0023, std: 1.3672
  Model pred mean: -0.0022, std: 1.1328
  Sigmas: [0.56640625]... (timesteps: [565.0])
Steps:  53%|█████▎    | 2641/5000 [9:51:54<7:48:45, 11.92s/it, loss=1.0765, lr=5.38e-06]Steps:  53%|█████▎    | 2641/5000 [9:51:54<7:48:45, 11.92s/it, loss=0.5949, lr=5.38e-06]Steps:  53%|█████▎    | 2642/5000 [9:52:06<7:49:19, 11.94s/it, loss=0.5949, lr=5.38e-06]Steps:  53%|█████▎    | 2642/5000 [9:52:06<7:49:19, 11.94s/it, loss=0.3874, lr=5.38e-06]Steps:  53%|█████▎    | 2643/5000 [9:52:18<7:52:53, 12.04s/it, loss=0.3874, lr=5.38e-06]Steps:  53%|█████▎    | 2643/5000 [9:52:18<7:52:53, 12.04s/it, loss=0.9148, lr=5.37e-06]Steps:  53%|█████▎    | 2644/5000 [9:52:30<7:51:50, 12.02s/it, loss=0.9148, lr=5.37e-06]Steps:  53%|█████▎    | 2644/5000 [9:52:30<7:51:50, 12.02s/it, loss=1.1411, lr=5.37e-06]Steps:  53%|█████▎    | 2645/5000 [9:52:42<7:50:17, 11.98s/it, loss=1.1411, lr=5.37e-06]Steps:  53%|█████▎    | 2645/5000 [9:52:42<7:50:17, 11.98s/it, loss=1.1784, lr=5.37e-06]Steps:  53%|█████▎    | 2646/5000 [9:52:54<7:48:44, 11.95s/it, loss=1.1784, lr=5.37e-06]Steps:  53%|█████▎    | 2646/5000 [9:52:54<7:48:44, 11.95s/it, loss=0.5374, lr=5.36e-06]Steps:  53%|█████▎    | 2647/5000 [9:53:06<7:49:18, 11.97s/it, loss=0.5374, lr=5.36e-06]Steps:  53%|█████▎    | 2647/5000 [9:53:06<7:49:18, 11.97s/it, loss=1.0444, lr=5.36e-06]Steps:  53%|█████▎    | 2648/5000 [9:53:18<7:48:44, 11.96s/it, loss=1.0444, lr=5.36e-06]Steps:  53%|█████▎    | 2648/5000 [9:53:18<7:48:44, 11.96s/it, loss=0.3492, lr=5.36e-06]Steps:  53%|█████▎    | 2649/5000 [9:53:30<7:48:18, 11.95s/it, loss=0.3492, lr=5.36e-06]Steps:  53%|█████▎    | 2649/5000 [9:53:30<7:48:18, 11.95s/it, loss=0.6363, lr=5.35e-06]Steps:  53%|█████▎    | 2650/5000 [9:53:42<7:50:49, 12.02s/it, loss=0.6363, lr=5.35e-06]Steps:  53%|█████▎    | 2650/5000 [9:53:42<7:50:49, 12.02s/it, loss=1.1265, lr=5.35e-06]
[Step 2650] Training Debug Info:
  Loss: 1.067385
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0148, std: 0.9102
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0134, std: 1.3516
  Model pred mean: 0.0146, std: 0.8711
  Sigmas: [0.30859375]... (timesteps: [309.0])

[Step 2650] Training Debug Info:
  Loss: 0.877046
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0052, std: 0.9922
  Noise mean: 0.0045, std: 1.0000
  Target mean: 0.0097, std: 1.4062
  Model pred mean: 0.0029, std: 1.0547
  Sigmas: [0.345703125]... (timesteps: [345.0])

[Step 2650] Training Debug Info:
  Loss: 0.612887
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0295, std: 0.8945
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0283, std: 1.3438
  Model pred mean: -0.0204, std: 1.1016
  Sigmas: [0.95703125]... (timesteps: [957.0])

[Step 2650] Training Debug Info:
  Loss: 0.634737
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0042, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0063, std: 1.3438
  Model pred mean: -0.0150, std: 1.0938
  Sigmas: [0.96875]... (timesteps: [967.0])
Steps:  53%|█████▎    | 2651/5000 [9:53:54<7:51:12, 12.04s/it, loss=1.1265, lr=5.35e-06]Steps:  53%|█████▎    | 2651/5000 [9:53:54<7:51:12, 12.04s/it, loss=0.6347, lr=5.35e-06]Steps:  53%|█████▎    | 2652/5000 [9:54:06<7:49:55, 12.01s/it, loss=0.6347, lr=5.35e-06]Steps:  53%|█████▎    | 2652/5000 [9:54:06<7:49:55, 12.01s/it, loss=1.1817, lr=5.34e-06]Steps:  53%|█████▎    | 2653/5000 [9:54:18<7:50:24, 12.03s/it, loss=1.1817, lr=5.34e-06]Steps:  53%|█████▎    | 2653/5000 [9:54:18<7:50:24, 12.03s/it, loss=0.3896, lr=5.34e-06]Steps:  53%|█████▎    | 2654/5000 [9:54:30<7:48:13, 11.97s/it, loss=0.3896, lr=5.34e-06]Steps:  53%|█████▎    | 2654/5000 [9:54:30<7:48:13, 11.97s/it, loss=1.1115, lr=5.33e-06]Steps:  53%|█████▎    | 2655/5000 [9:54:42<7:46:42, 11.94s/it, loss=1.1115, lr=5.33e-06]Steps:  53%|█████▎    | 2655/5000 [9:54:42<7:46:42, 11.94s/it, loss=1.0248, lr=5.33e-06]Steps:  53%|█████▎    | 2656/5000 [9:54:54<7:45:41, 11.92s/it, loss=1.0248, lr=5.33e-06]Steps:  53%|█████▎    | 2656/5000 [9:54:54<7:45:41, 11.92s/it, loss=0.9800, lr=5.33e-06]Steps:  53%|█████▎    | 2657/5000 [9:55:06<7:47:38, 11.98s/it, loss=0.9800, lr=5.33e-06]Steps:  53%|█████▎    | 2657/5000 [9:55:06<7:47:38, 11.98s/it, loss=1.1143, lr=5.32e-06]Steps:  53%|█████▎    | 2658/5000 [9:55:18<7:46:24, 11.95s/it, loss=1.1143, lr=5.32e-06]Steps:  53%|█████▎    | 2658/5000 [9:55:18<7:46:24, 11.95s/it, loss=1.0746, lr=5.32e-06]Steps:  53%|█████▎    | 2659/5000 [9:55:30<7:44:58, 11.92s/it, loss=1.0746, lr=5.32e-06]Steps:  53%|█████▎    | 2659/5000 [9:55:30<7:44:58, 11.92s/it, loss=1.1385, lr=5.32e-06]Steps:  53%|█████▎    | 2660/5000 [9:55:42<7:45:28, 11.94s/it, loss=1.1385, lr=5.32e-06]Steps:  53%|█████▎    | 2660/5000 [9:55:42<7:45:28, 11.94s/it, loss=1.0511, lr=5.31e-06]
[Step 2660] Training Debug Info:
  Loss: 0.605412
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0029, std: 0.9336
  Noise mean: -0.0005, std: 0.9961
  Target mean: 0.0024, std: 1.3672
  Model pred mean: 0.0041, std: 1.1250
  Sigmas: [0.57421875]... (timesteps: [574.0])

[Step 2660] Training Debug Info:
  Loss: 1.164926
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0059, std: 0.8867
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0049, std: 1.3359
  Model pred mean: -0.0073, std: 0.7891
  Sigmas: [0.1474609375]... (timesteps: [147.0])

[Step 2660] Training Debug Info:
  Loss: 1.006722
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0354, std: 0.9922
  Noise mean: -0.0006, std: 0.9961
  Target mean: -0.0359, std: 1.4062
  Model pred mean: -0.0361, std: 0.9922
  Sigmas: [0.328125]... (timesteps: [329.0])

[Step 2660] Training Debug Info:
  Loss: 0.746527
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0050, std: 0.8984
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0053, std: 1.3438
  Model pred mean: 0.0046, std: 1.0312
  Sigmas: [0.49609375]... (timesteps: [496.0])
Steps:  53%|█████▎    | 2661/5000 [9:55:54<7:45:49, 11.95s/it, loss=1.0511, lr=5.31e-06]Steps:  53%|█████▎    | 2661/5000 [9:55:54<7:45:49, 11.95s/it, loss=0.7465, lr=5.31e-06]Steps:  53%|█████▎    | 2662/5000 [9:56:05<7:45:49, 11.95s/it, loss=0.7465, lr=5.31e-06]Steps:  53%|█████▎    | 2662/5000 [9:56:05<7:45:49, 11.95s/it, loss=0.6426, lr=5.31e-06]Steps:  53%|█████▎    | 2663/5000 [9:56:17<7:45:09, 11.94s/it, loss=0.6426, lr=5.31e-06]Steps:  53%|█████▎    | 2663/5000 [9:56:17<7:45:09, 11.94s/it, loss=0.7909, lr=5.30e-06]Steps:  53%|█████▎    | 2664/5000 [9:56:29<7:46:08, 11.97s/it, loss=0.7909, lr=5.30e-06]Steps:  53%|█████▎    | 2664/5000 [9:56:29<7:46:08, 11.97s/it, loss=0.8924, lr=5.30e-06]Steps:  53%|█████▎    | 2665/5000 [9:56:41<7:44:57, 11.95s/it, loss=0.8924, lr=5.30e-06]Steps:  53%|█████▎    | 2665/5000 [9:56:41<7:44:57, 11.95s/it, loss=0.6800, lr=5.30e-06]Steps:  53%|█████▎    | 2666/5000 [9:56:53<7:44:30, 11.94s/it, loss=0.6800, lr=5.30e-06]Steps:  53%|█████▎    | 2666/5000 [9:56:53<7:44:30, 11.94s/it, loss=0.9245, lr=5.29e-06]Steps:  53%|█████▎    | 2667/5000 [9:57:05<7:44:10, 11.94s/it, loss=0.9245, lr=5.29e-06]Steps:  53%|█████▎    | 2667/5000 [9:57:05<7:44:10, 11.94s/it, loss=0.6721, lr=5.29e-06]Steps:  53%|█████▎    | 2668/5000 [9:57:17<7:43:40, 11.93s/it, loss=0.6721, lr=5.29e-06]Steps:  53%|█████▎    | 2668/5000 [9:57:17<7:43:40, 11.93s/it, loss=0.4206, lr=5.29e-06]Steps:  53%|█████▎    | 2669/5000 [9:57:29<7:44:33, 11.96s/it, loss=0.4206, lr=5.29e-06]Steps:  53%|█████▎    | 2669/5000 [9:57:29<7:44:33, 11.96s/it, loss=0.4891, lr=5.28e-06]Steps:  53%|█████▎    | 2670/5000 [9:57:41<7:46:09, 12.00s/it, loss=0.4891, lr=5.28e-06]Steps:  53%|█████▎    | 2670/5000 [9:57:41<7:46:09, 12.00s/it, loss=0.5876, lr=5.28e-06]
[Step 2670] Training Debug Info:
  Loss: 1.213418
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0275, std: 0.8281
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0311, std: 1.2969
  Model pred mean: 0.0253, std: 0.6914
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 2670] Training Debug Info:
  Loss: 0.587749
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0152, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0156, std: 1.3359
  Model pred mean: -0.0175, std: 1.0859
  Sigmas: [0.99609375]... (timesteps: [996.0])

[Step 2670] Training Debug Info:
  Loss: 0.548656
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0308, std: 0.9414
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0330, std: 1.3672
  Model pred mean: -0.0253, std: 1.1562
  Sigmas: [0.62109375]... (timesteps: [621.0])

[Step 2670] Training Debug Info:
  Loss: 1.058196
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0078, std: 0.9375
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0107, std: 1.3672
  Model pred mean: -0.0082, std: 0.9023
  Sigmas: [0.033935546875]... (timesteps: [34.0])
Steps:  53%|█████▎    | 2671/5000 [9:57:53<7:45:46, 12.00s/it, loss=0.5876, lr=5.28e-06]Steps:  53%|█████▎    | 2671/5000 [9:57:53<7:45:46, 12.00s/it, loss=1.0582, lr=5.28e-06]Steps:  53%|█████▎    | 2672/5000 [9:58:05<7:43:51, 11.96s/it, loss=1.0582, lr=5.28e-06]Steps:  53%|█████▎    | 2672/5000 [9:58:05<7:43:51, 11.96s/it, loss=0.4403, lr=5.27e-06]Steps:  53%|█████▎    | 2673/5000 [9:58:17<7:43:06, 11.94s/it, loss=0.4403, lr=5.27e-06]Steps:  53%|█████▎    | 2673/5000 [9:58:17<7:43:06, 11.94s/it, loss=0.3985, lr=5.27e-06]Steps:  53%|█████▎    | 2674/5000 [9:58:29<7:43:33, 11.96s/it, loss=0.3985, lr=5.27e-06]Steps:  53%|█████▎    | 2674/5000 [9:58:29<7:43:33, 11.96s/it, loss=0.4984, lr=5.27e-06]Steps:  54%|█████▎    | 2675/5000 [9:58:41<7:43:26, 11.96s/it, loss=0.4984, lr=5.27e-06]Steps:  54%|█████▎    | 2675/5000 [9:58:41<7:43:26, 11.96s/it, loss=0.8900, lr=5.26e-06]Steps:  54%|█████▎    | 2676/5000 [9:58:53<7:41:53, 11.93s/it, loss=0.8900, lr=5.26e-06]Steps:  54%|█████▎    | 2676/5000 [9:58:53<7:41:53, 11.93s/it, loss=1.0124, lr=5.26e-06]Steps:  54%|█████▎    | 2677/5000 [9:59:05<7:43:37, 11.97s/it, loss=1.0124, lr=5.26e-06]Steps:  54%|█████▎    | 2677/5000 [9:59:05<7:43:37, 11.97s/it, loss=1.0701, lr=5.25e-06]Steps:  54%|█████▎    | 2678/5000 [9:59:17<7:43:41, 11.98s/it, loss=1.0701, lr=5.25e-06]Steps:  54%|█████▎    | 2678/5000 [9:59:17<7:43:41, 11.98s/it, loss=0.4252, lr=5.25e-06]Steps:  54%|█████▎    | 2679/5000 [9:59:29<7:42:45, 11.96s/it, loss=0.4252, lr=5.25e-06]Steps:  54%|█████▎    | 2679/5000 [9:59:29<7:42:45, 11.96s/it, loss=1.1830, lr=5.25e-06]Steps:  54%|█████▎    | 2680/5000 [9:59:41<7:42:29, 11.96s/it, loss=1.1830, lr=5.25e-06]Steps:  54%|█████▎    | 2680/5000 [9:59:41<7:42:29, 11.96s/it, loss=0.5168, lr=5.24e-06]
[Step 2680] Training Debug Info:
  Loss: 0.388030
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0087, std: 0.8945
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0105, std: 1.3438
  Model pred mean: 0.0082, std: 1.1875
  Sigmas: [0.8203125]... (timesteps: [822.0])

[Step 2680] Training Debug Info:
  Loss: 0.818039
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0043, std: 0.8945
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0033, std: 1.3438
  Model pred mean: -0.0041, std: 0.9883
  Sigmas: [0.453125]... (timesteps: [454.0])

[Step 2680] Training Debug Info:
  Loss: 0.393141
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0223, std: 0.9102
  Noise mean: -0.0033, std: 1.0000
  Target mean: 0.0190, std: 1.3516
  Model pred mean: 0.0231, std: 1.1953
  Sigmas: [0.7890625]... (timesteps: [791.0])

[Step 2680] Training Debug Info:
  Loss: 0.839478
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0134, std: 0.8750
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0162, std: 1.3281
  Model pred mean: -0.0130, std: 0.9609
  Sigmas: [0.439453125]... (timesteps: [439.0])
Steps:  54%|█████▎    | 2681/5000 [9:59:53<7:42:51, 11.98s/it, loss=0.5168, lr=5.24e-06]Steps:  54%|█████▎    | 2681/5000 [9:59:53<7:42:51, 11.98s/it, loss=0.8395, lr=5.24e-06]Steps:  54%|█████▎    | 2682/5000 [10:00:05<7:41:21, 11.94s/it, loss=0.8395, lr=5.24e-06]Steps:  54%|█████▎    | 2682/5000 [10:00:05<7:41:21, 11.94s/it, loss=0.4446, lr=5.24e-06]Steps:  54%|█████▎    | 2683/5000 [10:00:17<7:41:09, 11.94s/it, loss=0.4446, lr=5.24e-06]Steps:  54%|█████▎    | 2683/5000 [10:00:17<7:41:09, 11.94s/it, loss=0.4345, lr=5.23e-06]Steps:  54%|█████▎    | 2684/5000 [10:00:29<7:43:17, 12.00s/it, loss=0.4345, lr=5.23e-06]Steps:  54%|█████▎    | 2684/5000 [10:00:29<7:43:17, 12.00s/it, loss=0.4757, lr=5.23e-06]Steps:  54%|█████▎    | 2685/5000 [10:00:41<7:43:02, 12.00s/it, loss=0.4757, lr=5.23e-06]Steps:  54%|█████▎    | 2685/5000 [10:00:41<7:43:02, 12.00s/it, loss=0.4622, lr=5.23e-06]Steps:  54%|█████▎    | 2686/5000 [10:00:53<7:42:37, 12.00s/it, loss=0.4622, lr=5.23e-06]Steps:  54%|█████▎    | 2686/5000 [10:00:53<7:42:37, 12.00s/it, loss=0.4682, lr=5.22e-06]Steps:  54%|█████▎    | 2687/5000 [10:01:05<7:43:18, 12.02s/it, loss=0.4682, lr=5.22e-06]Steps:  54%|█████▎    | 2687/5000 [10:01:05<7:43:18, 12.02s/it, loss=1.0461, lr=5.22e-06]Steps:  54%|█████▍    | 2688/5000 [10:01:17<7:41:59, 11.99s/it, loss=1.0461, lr=5.22e-06]Steps:  54%|█████▍    | 2688/5000 [10:01:17<7:41:59, 11.99s/it, loss=1.1001, lr=5.22e-06]Steps:  54%|█████▍    | 2689/5000 [10:01:29<7:41:26, 11.98s/it, loss=1.1001, lr=5.22e-06]Steps:  54%|█████▍    | 2689/5000 [10:01:29<7:41:26, 11.98s/it, loss=0.9352, lr=5.21e-06]Steps:  54%|█████▍    | 2690/5000 [10:01:41<7:40:36, 11.96s/it, loss=0.9352, lr=5.21e-06]Steps:  54%|█████▍    | 2690/5000 [10:01:41<7:40:36, 11.96s/it, loss=0.3752, lr=5.21e-06]
[Step 2690] Training Debug Info:
  Loss: 0.350537
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0172, std: 0.8945
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0165, std: 1.3438
  Model pred mean: -0.0119, std: 1.2031
  Sigmas: [0.84765625]... (timesteps: [848.0])

[Step 2690] Training Debug Info:
  Loss: 0.553757
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0187, std: 0.9297
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0155, std: 1.3672
  Model pred mean: 0.0220, std: 1.1328
  Sigmas: [0.5859375]... (timesteps: [585.0])

[Step 2690] Training Debug Info:
  Loss: 1.091299
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0060, std: 0.9102
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0064, std: 1.3516
  Model pred mean: -0.0041, std: 0.8633
  Sigmas: [0.22265625]... (timesteps: [223.0])

[Step 2690] Training Debug Info:
  Loss: 1.113319
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0132, std: 0.9023
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0112, std: 1.3438
  Model pred mean: -0.0131, std: 0.8359
  Sigmas: [0.25390625]... (timesteps: [252.99998474121094])
Steps:  54%|█████▍    | 2691/5000 [10:01:53<7:41:39, 12.00s/it, loss=0.3752, lr=5.21e-06]Steps:  54%|█████▍    | 2691/5000 [10:01:53<7:41:39, 12.00s/it, loss=1.1133, lr=5.21e-06]Steps:  54%|█████▍    | 2692/5000 [10:02:05<7:39:57, 11.96s/it, loss=1.1133, lr=5.21e-06]Steps:  54%|█████▍    | 2692/5000 [10:02:05<7:39:57, 11.96s/it, loss=0.9653, lr=5.20e-06]Steps:  54%|█████▍    | 2693/5000 [10:02:16<7:38:40, 11.93s/it, loss=0.9653, lr=5.20e-06]Steps:  54%|█████▍    | 2693/5000 [10:02:16<7:38:40, 11.93s/it, loss=0.3721, lr=5.20e-06]Steps:  54%|█████▍    | 2694/5000 [10:02:28<7:37:24, 11.90s/it, loss=0.3721, lr=5.20e-06]Steps:  54%|█████▍    | 2694/5000 [10:02:28<7:37:24, 11.90s/it, loss=1.0402, lr=5.20e-06]Steps:  54%|█████▍    | 2695/5000 [10:02:40<7:37:36, 11.91s/it, loss=1.0402, lr=5.20e-06]Steps:  54%|█████▍    | 2695/5000 [10:02:40<7:37:36, 11.91s/it, loss=0.5640, lr=5.19e-06]Steps:  54%|█████▍    | 2696/5000 [10:02:52<7:38:07, 11.93s/it, loss=0.5640, lr=5.19e-06]Steps:  54%|█████▍    | 2696/5000 [10:02:52<7:38:07, 11.93s/it, loss=0.4182, lr=5.19e-06]Steps:  54%|█████▍    | 2697/5000 [10:03:04<7:40:40, 12.00s/it, loss=0.4182, lr=5.19e-06]Steps:  54%|█████▍    | 2697/5000 [10:03:04<7:40:40, 12.00s/it, loss=1.0695, lr=5.18e-06]Steps:  54%|█████▍    | 2698/5000 [10:03:16<7:40:05, 11.99s/it, loss=1.0695, lr=5.18e-06]Steps:  54%|█████▍    | 2698/5000 [10:03:16<7:40:05, 11.99s/it, loss=0.9774, lr=5.18e-06]Steps:  54%|█████▍    | 2699/5000 [10:03:28<7:38:54, 11.97s/it, loss=0.9774, lr=5.18e-06]Steps:  54%|█████▍    | 2699/5000 [10:03:28<7:38:54, 11.97s/it, loss=1.2067, lr=5.18e-06]Steps:  54%|█████▍    | 2700/5000 [10:03:40<7:38:10, 11.95s/it, loss=1.2067, lr=5.18e-06]Steps:  54%|█████▍    | 2700/5000 [10:03:40<7:38:10, 11.95s/it, loss=1.2093, lr=5.17e-06]01/22/2026 17:49:27 - INFO - __main__ - 
[Step 2700] ✅ Loss in normal range (1.2093)
01/22/2026 17:49:27 - INFO - __main__ -   Loss avg (last 100): 0.7731
01/22/2026 17:49:27 - INFO - __main__ -   Loss range: [0.3492, 1.2093]

[Step 2700] Training Debug Info:
  Loss: 0.620667
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0388, std: 0.9219
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0410, std: 1.3594
  Model pred mean: -0.0403, std: 1.1094
  Sigmas: [0.515625]... (timesteps: [517.0])

[Step 2700] Training Debug Info:
  Loss: 0.639133
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0311, std: 0.9297
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0327, std: 1.3672
  Model pred mean: -0.0305, std: 1.1094
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 2700] Training Debug Info:
  Loss: 0.413635
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0292, std: 0.9102
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0292, std: 1.3516
  Model pred mean: -0.0315, std: 1.1953
  Sigmas: [0.71875]... (timesteps: [717.0])

[Step 2700] Training Debug Info:
  Loss: 1.075857
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0233, std: 0.9414
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0217, std: 1.3750
  Model pred mean: -0.0260, std: 0.8984
  Sigmas: [0.11083984375]... (timesteps: [111.0])
Steps:  54%|█████▍    | 2701/5000 [10:03:52<7:37:57, 11.95s/it, loss=1.2093, lr=5.17e-06]Steps:  54%|█████▍    | 2701/5000 [10:03:52<7:37:57, 11.95s/it, loss=1.0759, lr=5.17e-06]Steps:  54%|█████▍    | 2702/5000 [10:04:04<7:37:13, 11.94s/it, loss=1.0759, lr=5.17e-06]Steps:  54%|█████▍    | 2702/5000 [10:04:04<7:37:13, 11.94s/it, loss=1.0185, lr=5.17e-06]Steps:  54%|█████▍    | 2703/5000 [10:04:16<7:37:27, 11.95s/it, loss=1.0185, lr=5.17e-06]Steps:  54%|█████▍    | 2703/5000 [10:04:16<7:37:27, 11.95s/it, loss=0.8831, lr=5.16e-06]Steps:  54%|█████▍    | 2704/5000 [10:04:28<7:38:48, 11.99s/it, loss=0.8831, lr=5.16e-06]Steps:  54%|█████▍    | 2704/5000 [10:04:28<7:38:48, 11.99s/it, loss=0.3849, lr=5.16e-06]Steps:  54%|█████▍    | 2705/5000 [10:04:40<7:39:13, 12.01s/it, loss=0.3849, lr=5.16e-06]Steps:  54%|█████▍    | 2705/5000 [10:04:40<7:39:13, 12.01s/it, loss=0.4922, lr=5.16e-06]Steps:  54%|█████▍    | 2706/5000 [10:04:52<7:39:23, 12.02s/it, loss=0.4922, lr=5.16e-06]Steps:  54%|█████▍    | 2706/5000 [10:04:52<7:39:23, 12.02s/it, loss=1.0670, lr=5.15e-06]Steps:  54%|█████▍    | 2707/5000 [10:05:04<7:39:15, 12.02s/it, loss=1.0670, lr=5.15e-06]Steps:  54%|█████▍    | 2707/5000 [10:05:04<7:39:15, 12.02s/it, loss=0.5607, lr=5.15e-06]Steps:  54%|█████▍    | 2708/5000 [10:05:16<7:37:49, 11.98s/it, loss=0.5607, lr=5.15e-06]Steps:  54%|█████▍    | 2708/5000 [10:05:16<7:37:49, 11.98s/it, loss=0.3839, lr=5.15e-06]Steps:  54%|█████▍    | 2709/5000 [10:05:28<7:36:40, 11.96s/it, loss=0.3839, lr=5.15e-06]Steps:  54%|█████▍    | 2709/5000 [10:05:28<7:36:40, 11.96s/it, loss=1.1035, lr=5.14e-06]Steps:  54%|█████▍    | 2710/5000 [10:05:40<7:36:51, 11.97s/it, loss=1.1035, lr=5.14e-06]Steps:  54%|█████▍    | 2710/5000 [10:05:40<7:36:51, 11.97s/it, loss=1.0674, lr=5.14e-06]
[Step 2710] Training Debug Info:
  Loss: 0.411031
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0056, std: 0.8906
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0051, std: 1.3359
  Model pred mean: -0.0056, std: 1.1719
  Sigmas: [0.77734375]... (timesteps: [776.0])

[Step 2710] Training Debug Info:
  Loss: 0.753576
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0097, std: 0.9531
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0082, std: 1.3828
  Model pred mean: -0.0081, std: 1.0781
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 2710] Training Debug Info:
  Loss: 0.908170
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0095, std: 0.8867
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0098, std: 1.3359
  Model pred mean: 0.0091, std: 0.9414
  Sigmas: [0.42578125]... (timesteps: [425.0])

[Step 2710] Training Debug Info:
  Loss: 0.807401
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0172, std: 0.9258
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0175, std: 1.3672
  Model pred mean: -0.0154, std: 1.0312
  Sigmas: [0.396484375]... (timesteps: [396.0])
Steps:  54%|█████▍    | 2711/5000 [10:05:52<7:37:25, 11.99s/it, loss=1.0674, lr=5.14e-06]Steps:  54%|█████▍    | 2711/5000 [10:05:52<7:37:25, 11.99s/it, loss=0.8074, lr=5.14e-06]Steps:  54%|█████▍    | 2712/5000 [10:06:04<7:35:48, 11.95s/it, loss=0.8074, lr=5.14e-06]Steps:  54%|█████▍    | 2712/5000 [10:06:04<7:35:48, 11.95s/it, loss=1.0895, lr=5.13e-06]Steps:  54%|█████▍    | 2713/5000 [10:06:16<7:35:36, 11.95s/it, loss=1.0895, lr=5.13e-06]Steps:  54%|█████▍    | 2713/5000 [10:06:16<7:35:36, 11.95s/it, loss=0.4700, lr=5.13e-06]Steps:  54%|█████▍    | 2714/5000 [10:06:28<7:35:27, 11.95s/it, loss=0.4700, lr=5.13e-06]Steps:  54%|█████▍    | 2714/5000 [10:06:28<7:35:27, 11.95s/it, loss=1.1381, lr=5.13e-06]Steps:  54%|█████▍    | 2715/5000 [10:06:40<7:34:31, 11.93s/it, loss=1.1381, lr=5.13e-06]Steps:  54%|█████▍    | 2715/5000 [10:06:40<7:34:31, 11.93s/it, loss=0.7936, lr=5.12e-06]Steps:  54%|█████▍    | 2716/5000 [10:06:52<7:34:49, 11.95s/it, loss=0.7936, lr=5.12e-06]Steps:  54%|█████▍    | 2716/5000 [10:06:52<7:34:49, 11.95s/it, loss=1.0221, lr=5.12e-06]Steps:  54%|█████▍    | 2717/5000 [10:07:04<7:34:10, 11.94s/it, loss=1.0221, lr=5.12e-06]Steps:  54%|█████▍    | 2717/5000 [10:07:04<7:34:10, 11.94s/it, loss=0.7952, lr=5.12e-06]Steps:  54%|█████▍    | 2718/5000 [10:07:16<7:35:33, 11.98s/it, loss=0.7952, lr=5.12e-06]Steps:  54%|█████▍    | 2718/5000 [10:07:16<7:35:33, 11.98s/it, loss=0.4059, lr=5.11e-06]Steps:  54%|█████▍    | 2719/5000 [10:07:27<7:33:52, 11.94s/it, loss=0.4059, lr=5.11e-06]Steps:  54%|█████▍    | 2719/5000 [10:07:27<7:33:52, 11.94s/it, loss=0.7797, lr=5.11e-06]Steps:  54%|█████▍    | 2720/5000 [10:07:39<7:33:21, 11.93s/it, loss=0.7797, lr=5.11e-06]Steps:  54%|█████▍    | 2720/5000 [10:07:39<7:33:21, 11.93s/it, loss=0.4630, lr=5.10e-06]
[Step 2720] Training Debug Info:
  Loss: 0.929661
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0718, std: 0.9922
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0698, std: 1.4062
  Model pred mean: -0.0732, std: 1.0312
  Sigmas: [0.298828125]... (timesteps: [298.0])

[Step 2720] Training Debug Info:
  Loss: 0.451087
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0021, std: 0.8672
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0019, std: 1.3281
  Model pred mean: 0.0009, std: 1.1641
  Sigmas: [0.91796875]... (timesteps: [917.0])

[Step 2720] Training Debug Info:
  Loss: 0.403854
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0305, std: 0.9375
  Noise mean: -0.0045, std: 1.0000
  Target mean: 0.0260, std: 1.3750
  Model pred mean: 0.0287, std: 1.2188
  Sigmas: [0.75390625]... (timesteps: [753.0])

[Step 2720] Training Debug Info:
  Loss: 0.489596
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0113, std: 0.9219
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0135, std: 1.3594
  Model pred mean: 0.0138, std: 1.1641
  Sigmas: [0.65234375]... (timesteps: [651.0])
Steps:  54%|█████▍    | 2721/5000 [10:07:51<7:32:47, 11.92s/it, loss=0.4630, lr=5.10e-06]Steps:  54%|█████▍    | 2721/5000 [10:07:51<7:32:47, 11.92s/it, loss=0.4896, lr=5.10e-06]Steps:  54%|█████▍    | 2722/5000 [10:08:03<7:31:37, 11.90s/it, loss=0.4896, lr=5.10e-06]Steps:  54%|█████▍    | 2722/5000 [10:08:03<7:31:37, 11.90s/it, loss=0.9871, lr=5.10e-06]Steps:  54%|█████▍    | 2723/5000 [10:08:15<7:32:08, 11.91s/it, loss=0.9871, lr=5.10e-06]Steps:  54%|█████▍    | 2723/5000 [10:08:15<7:32:08, 11.91s/it, loss=0.4623, lr=5.09e-06]Steps:  54%|█████▍    | 2724/5000 [10:08:27<7:33:51, 11.96s/it, loss=0.4623, lr=5.09e-06]Steps:  54%|█████▍    | 2724/5000 [10:08:27<7:33:51, 11.96s/it, loss=1.0381, lr=5.09e-06]Steps:  55%|█████▍    | 2725/5000 [10:08:39<7:33:32, 11.96s/it, loss=1.0381, lr=5.09e-06]Steps:  55%|█████▍    | 2725/5000 [10:08:39<7:33:32, 11.96s/it, loss=0.3765, lr=5.09e-06]Steps:  55%|█████▍    | 2726/5000 [10:08:51<7:32:12, 11.93s/it, loss=0.3765, lr=5.09e-06]Steps:  55%|█████▍    | 2726/5000 [10:08:51<7:32:12, 11.93s/it, loss=0.8266, lr=5.08e-06]Steps:  55%|█████▍    | 2727/5000 [10:09:03<7:31:56, 11.93s/it, loss=0.8266, lr=5.08e-06]Steps:  55%|█████▍    | 2727/5000 [10:09:03<7:31:56, 11.93s/it, loss=1.1536, lr=5.08e-06]Steps:  55%|█████▍    | 2728/5000 [10:09:15<7:32:34, 11.95s/it, loss=1.1536, lr=5.08e-06]Steps:  55%|█████▍    | 2728/5000 [10:09:15<7:32:34, 11.95s/it, loss=0.9685, lr=5.08e-06]Steps:  55%|█████▍    | 2729/5000 [10:09:27<7:31:52, 11.94s/it, loss=0.9685, lr=5.08e-06]Steps:  55%|█████▍    | 2729/5000 [10:09:27<7:31:52, 11.94s/it, loss=0.3996, lr=5.07e-06]Steps:  55%|█████▍    | 2730/5000 [10:09:39<7:31:33, 11.94s/it, loss=0.3996, lr=5.07e-06]Steps:  55%|█████▍    | 2730/5000 [10:09:39<7:31:33, 11.94s/it, loss=1.0837, lr=5.07e-06]
[Step 2730] Training Debug Info:
  Loss: 1.083496
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0403, std: 0.9375
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0403, std: 1.3672
  Model pred mean: -0.0393, std: 0.8867
  Sigmas: [0.1357421875]... (timesteps: [136.0])

[Step 2730] Training Debug Info:
  Loss: 0.934168
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0193, std: 0.9297
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0168, std: 1.3594
  Model pred mean: 0.0167, std: 0.9688
  Sigmas: [0.359375]... (timesteps: [360.0])

[Step 2730] Training Debug Info:
  Loss: 0.595756
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0364, std: 0.9258
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0361, std: 1.3672
  Model pred mean: 0.0371, std: 1.1172
  Sigmas: [0.58203125]... (timesteps: [583.0])

[Step 2730] Training Debug Info:
  Loss: 0.701773
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0026, std: 0.8711
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0005, std: 1.3281
  Model pred mean: -0.0015, std: 1.0312
  Sigmas: [0.55078125]... (timesteps: [549.0])
Steps:  55%|█████▍    | 2731/5000 [10:09:51<7:32:22, 11.96s/it, loss=1.0837, lr=5.07e-06]Steps:  55%|█████▍    | 2731/5000 [10:09:51<7:32:22, 11.96s/it, loss=0.7018, lr=5.07e-06]Steps:  55%|█████▍    | 2732/5000 [10:10:03<7:31:56, 11.96s/it, loss=0.7018, lr=5.07e-06]Steps:  55%|█████▍    | 2732/5000 [10:10:03<7:31:56, 11.96s/it, loss=0.8930, lr=5.06e-06]Steps:  55%|█████▍    | 2733/5000 [10:10:15<7:30:43, 11.93s/it, loss=0.8930, lr=5.06e-06]Steps:  55%|█████▍    | 2733/5000 [10:10:15<7:30:43, 11.93s/it, loss=0.5799, lr=5.06e-06]Steps:  55%|█████▍    | 2734/5000 [10:10:27<7:31:05, 11.94s/it, loss=0.5799, lr=5.06e-06]Steps:  55%|█████▍    | 2734/5000 [10:10:27<7:31:05, 11.94s/it, loss=0.4188, lr=5.06e-06]Steps:  55%|█████▍    | 2735/5000 [10:10:39<7:32:37, 11.99s/it, loss=0.4188, lr=5.06e-06]Steps:  55%|█████▍    | 2735/5000 [10:10:39<7:32:37, 11.99s/it, loss=1.1550, lr=5.05e-06]Steps:  55%|█████▍    | 2736/5000 [10:10:51<7:31:29, 11.97s/it, loss=1.1550, lr=5.05e-06]Steps:  55%|█████▍    | 2736/5000 [10:10:51<7:31:29, 11.97s/it, loss=1.1143, lr=5.05e-06]Steps:  55%|█████▍    | 2737/5000 [10:11:02<7:30:51, 11.95s/it, loss=1.1143, lr=5.05e-06]Steps:  55%|█████▍    | 2737/5000 [10:11:02<7:30:51, 11.95s/it, loss=0.4078, lr=5.05e-06]Steps:  55%|█████▍    | 2738/5000 [10:11:15<7:32:33, 12.00s/it, loss=0.4078, lr=5.05e-06]Steps:  55%|█████▍    | 2738/5000 [10:11:15<7:32:33, 12.00s/it, loss=0.5091, lr=5.04e-06]Steps:  55%|█████▍    | 2739/5000 [10:11:26<7:31:07, 11.97s/it, loss=0.5091, lr=5.04e-06]Steps:  55%|█████▍    | 2739/5000 [10:11:26<7:31:07, 11.97s/it, loss=1.0347, lr=5.04e-06]Steps:  55%|█████▍    | 2740/5000 [10:11:38<7:30:41, 11.97s/it, loss=1.0347, lr=5.04e-06]Steps:  55%|█████▍    | 2740/5000 [10:11:38<7:30:41, 11.97s/it, loss=1.1716, lr=5.03e-06]
[Step 2740] Training Debug Info:
  Loss: 0.455899
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0347, std: 0.8867
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0378, std: 1.3359
  Model pred mean: -0.0332, std: 1.1562
  Sigmas: [0.7578125]... (timesteps: [758.0])

[Step 2740] Training Debug Info:
  Loss: 1.126633
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0083, std: 0.8750
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0080, std: 1.3281
  Model pred mean: 0.0098, std: 0.7969
  Sigmas: [0.0810546875]... (timesteps: [81.0])

[Step 2740] Training Debug Info:
  Loss: 0.425019
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0157, std: 0.9453
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0140, std: 1.3750
  Model pred mean: -0.0131, std: 1.2188
  Sigmas: [0.7421875]... (timesteps: [741.0])

[Step 2740] Training Debug Info:
  Loss: 1.159044
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0006, std: 0.8945
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0002, std: 1.3438
  Model pred mean: 0.0020, std: 0.7969
  Sigmas: [0.1201171875]... (timesteps: [120.0])
Steps:  55%|█████▍    | 2741/5000 [10:11:50<7:28:56, 11.92s/it, loss=1.1716, lr=5.03e-06]Steps:  55%|█████▍    | 2741/5000 [10:11:50<7:28:56, 11.92s/it, loss=1.1590, lr=5.03e-06]Steps:  55%|█████▍    | 2742/5000 [10:12:02<7:31:05, 11.99s/it, loss=1.1590, lr=5.03e-06]Steps:  55%|█████▍    | 2742/5000 [10:12:02<7:31:05, 11.99s/it, loss=0.7042, lr=5.03e-06]Steps:  55%|█████▍    | 2743/5000 [10:12:14<7:29:46, 11.96s/it, loss=0.7042, lr=5.03e-06]Steps:  55%|█████▍    | 2743/5000 [10:12:14<7:29:46, 11.96s/it, loss=1.1243, lr=5.02e-06]Steps:  55%|█████▍    | 2744/5000 [10:12:26<7:29:10, 11.95s/it, loss=1.1243, lr=5.02e-06]Steps:  55%|█████▍    | 2744/5000 [10:12:26<7:29:10, 11.95s/it, loss=0.3930, lr=5.02e-06]Steps:  55%|█████▍    | 2745/5000 [10:12:38<7:29:51, 11.97s/it, loss=0.3930, lr=5.02e-06]Steps:  55%|█████▍    | 2745/5000 [10:12:38<7:29:51, 11.97s/it, loss=0.8698, lr=5.02e-06]Steps:  55%|█████▍    | 2746/5000 [10:12:50<7:28:50, 11.95s/it, loss=0.8698, lr=5.02e-06]Steps:  55%|█████▍    | 2746/5000 [10:12:50<7:28:50, 11.95s/it, loss=0.9195, lr=5.01e-06]Steps:  55%|█████▍    | 2747/5000 [10:13:02<7:28:45, 11.95s/it, loss=0.9195, lr=5.01e-06]Steps:  55%|█████▍    | 2747/5000 [10:13:02<7:28:45, 11.95s/it, loss=0.9913, lr=5.01e-06]Steps:  55%|█████▍    | 2748/5000 [10:13:14<7:28:38, 11.95s/it, loss=0.9913, lr=5.01e-06]Steps:  55%|█████▍    | 2748/5000 [10:13:14<7:28:38, 11.95s/it, loss=1.1614, lr=5.01e-06]Steps:  55%|█████▍    | 2749/5000 [10:13:26<7:30:44, 12.01s/it, loss=1.1614, lr=5.01e-06]Steps:  55%|█████▍    | 2749/5000 [10:13:26<7:30:44, 12.01s/it, loss=0.6618, lr=5.00e-06]Steps:  55%|█████▌    | 2750/5000 [10:13:38<7:29:52, 12.00s/it, loss=0.6618, lr=5.00e-06]Steps:  55%|█████▌    | 2750/5000 [10:13:38<7:29:52, 12.00s/it, loss=1.1457, lr=5.00e-06]
[Step 2750] Training Debug Info:
  Loss: 0.373702
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0061, std: 0.9297
  Noise mean: 0.0035, std: 1.0000
  Target mean: -0.0026, std: 1.3672
  Model pred mean: -0.0022, std: 1.2188
  Sigmas: [0.90234375]... (timesteps: [902.0])

[Step 2750] Training Debug Info:
  Loss: 1.089474
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0032, std: 0.9336
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0035, std: 1.3750
  Model pred mean: 0.0017, std: 0.8867
  Sigmas: [0.06787109375]... (timesteps: [68.0])

[Step 2750] Training Debug Info:
  Loss: 0.850892
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0126, std: 0.9180
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0129, std: 1.3594
  Model pred mean: -0.0129, std: 0.9961
  Sigmas: [0.388671875]... (timesteps: [389.0])

[Step 2750] Training Debug Info:
  Loss: 0.657717
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0045, std: 0.9102
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0022, std: 1.3516
  Model pred mean: 0.0025, std: 1.1016
  Sigmas: [0.98828125]... (timesteps: [988.0])
Steps:  55%|█████▌    | 2751/5000 [10:13:50<7:30:38, 12.02s/it, loss=1.1457, lr=5.00e-06]Steps:  55%|█████▌    | 2751/5000 [10:13:50<7:30:38, 12.02s/it, loss=0.6577, lr=5.00e-06]Steps:  55%|█████▌    | 2752/5000 [10:14:02<7:30:45, 12.03s/it, loss=0.6577, lr=5.00e-06]Steps:  55%|█████▌    | 2752/5000 [10:14:02<7:30:45, 12.03s/it, loss=1.0206, lr=4.99e-06]Steps:  55%|█████▌    | 2753/5000 [10:14:14<7:29:11, 11.99s/it, loss=1.0206, lr=4.99e-06]Steps:  55%|█████▌    | 2753/5000 [10:14:14<7:29:11, 11.99s/it, loss=0.6369, lr=4.99e-06]Steps:  55%|█████▌    | 2754/5000 [10:14:26<7:28:23, 11.98s/it, loss=0.6369, lr=4.99e-06]Steps:  55%|█████▌    | 2754/5000 [10:14:26<7:28:23, 11.98s/it, loss=0.4021, lr=4.99e-06]Steps:  55%|█████▌    | 2755/5000 [10:14:38<7:27:53, 11.97s/it, loss=0.4021, lr=4.99e-06]Steps:  55%|█████▌    | 2755/5000 [10:14:38<7:27:53, 11.97s/it, loss=0.5490, lr=4.98e-06]Steps:  55%|█████▌    | 2756/5000 [10:14:50<7:27:03, 11.95s/it, loss=0.5490, lr=4.98e-06]Steps:  55%|█████▌    | 2756/5000 [10:14:50<7:27:03, 11.95s/it, loss=1.0893, lr=4.98e-06]Steps:  55%|█████▌    | 2757/5000 [10:15:02<7:26:05, 11.93s/it, loss=1.0893, lr=4.98e-06]Steps:  55%|█████▌    | 2757/5000 [10:15:02<7:26:05, 11.93s/it, loss=0.6365, lr=4.98e-06]Steps:  55%|█████▌    | 2758/5000 [10:15:14<7:27:27, 11.97s/it, loss=0.6365, lr=4.98e-06]Steps:  55%|█████▌    | 2758/5000 [10:15:14<7:27:27, 11.97s/it, loss=0.4426, lr=4.97e-06]Steps:  55%|█████▌    | 2759/5000 [10:15:26<7:26:17, 11.95s/it, loss=0.4426, lr=4.97e-06]Steps:  55%|█████▌    | 2759/5000 [10:15:26<7:26:17, 11.95s/it, loss=0.4675, lr=4.97e-06]Steps:  55%|█████▌    | 2760/5000 [10:15:38<7:26:03, 11.95s/it, loss=0.4675, lr=4.97e-06]Steps:  55%|█████▌    | 2760/5000 [10:15:38<7:26:03, 11.95s/it, loss=1.1601, lr=4.97e-06]
[Step 2760] Training Debug Info:
  Loss: 1.090433
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0415, std: 1.0078
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0444, std: 1.4219
  Model pred mean: -0.0388, std: 0.9648
  Sigmas: [0.1982421875]... (timesteps: [198.0])

[Step 2760] Training Debug Info:
  Loss: 1.119551
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0095, std: 0.9062
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0079, std: 1.3516
  Model pred mean: -0.0058, std: 0.8438
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 2760] Training Debug Info:
  Loss: 0.558311
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0354, std: 0.9492
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0361, std: 1.3828
  Model pred mean: -0.0344, std: 1.1562
  Sigmas: [0.51953125]... (timesteps: [520.0])

[Step 2760] Training Debug Info:
  Loss: 1.037607
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0140, std: 0.8789
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0132, std: 1.3359
  Model pred mean: 0.0176, std: 0.8594
  Sigmas: [0.0179443359375]... (timesteps: [18.0])
Steps:  55%|█████▌    | 2761/5000 [10:15:50<7:26:06, 11.95s/it, loss=1.1601, lr=4.97e-06]Steps:  55%|█████▌    | 2761/5000 [10:15:50<7:26:06, 11.95s/it, loss=1.0376, lr=4.96e-06]Steps:  55%|█████▌    | 2762/5000 [10:16:02<7:25:23, 11.94s/it, loss=1.0376, lr=4.96e-06]Steps:  55%|█████▌    | 2762/5000 [10:16:02<7:25:23, 11.94s/it, loss=0.6368, lr=4.96e-06]Steps:  55%|█████▌    | 2763/5000 [10:16:14<7:25:28, 11.95s/it, loss=0.6368, lr=4.96e-06]Steps:  55%|█████▌    | 2763/5000 [10:16:14<7:25:28, 11.95s/it, loss=1.2006, lr=4.95e-06]Steps:  55%|█████▌    | 2764/5000 [10:16:26<7:24:45, 11.93s/it, loss=1.2006, lr=4.95e-06]Steps:  55%|█████▌    | 2764/5000 [10:16:26<7:24:45, 11.93s/it, loss=1.1605, lr=4.95e-06]Steps:  55%|█████▌    | 2765/5000 [10:16:38<7:27:08, 12.00s/it, loss=1.1605, lr=4.95e-06]Steps:  55%|█████▌    | 2765/5000 [10:16:38<7:27:08, 12.00s/it, loss=1.1083, lr=4.95e-06]Steps:  55%|█████▌    | 2766/5000 [10:16:50<7:26:11, 11.98s/it, loss=1.1083, lr=4.95e-06]Steps:  55%|█████▌    | 2766/5000 [10:16:50<7:26:11, 11.98s/it, loss=1.1490, lr=4.94e-06]Steps:  55%|█████▌    | 2767/5000 [10:17:02<7:25:06, 11.96s/it, loss=1.1490, lr=4.94e-06]Steps:  55%|█████▌    | 2767/5000 [10:17:02<7:25:06, 11.96s/it, loss=0.5226, lr=4.94e-06]Steps:  55%|█████▌    | 2768/5000 [10:17:14<7:25:06, 11.97s/it, loss=0.5226, lr=4.94e-06]Steps:  55%|█████▌    | 2768/5000 [10:17:14<7:25:06, 11.97s/it, loss=0.4682, lr=4.94e-06]Steps:  55%|█████▌    | 2769/5000 [10:17:26<7:25:21, 11.98s/it, loss=0.4682, lr=4.94e-06]Steps:  55%|█████▌    | 2769/5000 [10:17:26<7:25:21, 11.98s/it, loss=1.1380, lr=4.93e-06]Steps:  55%|█████▌    | 2770/5000 [10:17:38<7:25:35, 11.99s/it, loss=1.1380, lr=4.93e-06]Steps:  55%|█████▌    | 2770/5000 [10:17:38<7:25:35, 11.99s/it, loss=0.3358, lr=4.93e-06]
[Step 2770] Training Debug Info:
  Loss: 0.448433
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0095, std: 0.9180
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0075, std: 1.3594
  Model pred mean: -0.0071, std: 1.1797
  Sigmas: [0.71484375]... (timesteps: [714.0])

[Step 2770] Training Debug Info:
  Loss: 0.781704
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0155, std: 0.9102
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0173, std: 1.3516
  Model pred mean: -0.0151, std: 1.0234
  Sigmas: [0.46875]... (timesteps: [468.0])

[Step 2770] Training Debug Info:
  Loss: 0.384119
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0182, std: 0.9219
  Noise mean: 0.0005, std: 0.9961
  Target mean: -0.0176, std: 1.3594
  Model pred mean: -0.0195, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 2770] Training Debug Info:
  Loss: 0.718819
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0082, std: 0.9688
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0096, std: 1.3906
  Model pred mean: 0.0068, std: 1.1094
  Sigmas: [0.953125]... (timesteps: [954.0])
Steps:  55%|█████▌    | 2771/5000 [10:17:49<7:24:36, 11.97s/it, loss=0.3358, lr=4.93e-06]Steps:  55%|█████▌    | 2771/5000 [10:17:49<7:24:36, 11.97s/it, loss=0.7188, lr=4.93e-06]Steps:  55%|█████▌    | 2772/5000 [10:18:02<7:26:11, 12.02s/it, loss=0.7188, lr=4.93e-06]Steps:  55%|█████▌    | 2772/5000 [10:18:02<7:26:11, 12.02s/it, loss=0.8712, lr=4.92e-06]Steps:  55%|█████▌    | 2773/5000 [10:18:13<7:24:59, 11.99s/it, loss=0.8712, lr=4.92e-06]Steps:  55%|█████▌    | 2773/5000 [10:18:13<7:24:59, 11.99s/it, loss=0.3878, lr=4.92e-06]Steps:  55%|█████▌    | 2774/5000 [10:18:26<7:25:46, 12.02s/it, loss=0.3878, lr=4.92e-06]Steps:  55%|█████▌    | 2774/5000 [10:18:26<7:25:46, 12.02s/it, loss=1.1518, lr=4.92e-06]Steps:  56%|█████▌    | 2775/5000 [10:18:38<7:25:04, 12.00s/it, loss=1.1518, lr=4.92e-06]Steps:  56%|█████▌    | 2775/5000 [10:18:38<7:25:04, 12.00s/it, loss=0.3731, lr=4.91e-06]Steps:  56%|█████▌    | 2776/5000 [10:18:49<7:23:48, 11.97s/it, loss=0.3731, lr=4.91e-06]Steps:  56%|█████▌    | 2776/5000 [10:18:49<7:23:48, 11.97s/it, loss=0.4152, lr=4.91e-06]Steps:  56%|█████▌    | 2777/5000 [10:19:01<7:22:26, 11.94s/it, loss=0.4152, lr=4.91e-06]Steps:  56%|█████▌    | 2777/5000 [10:19:01<7:22:26, 11.94s/it, loss=0.3625, lr=4.91e-06]Steps:  56%|█████▌    | 2778/5000 [10:19:13<7:23:39, 11.98s/it, loss=0.3625, lr=4.91e-06]Steps:  56%|█████▌    | 2778/5000 [10:19:13<7:23:39, 11.98s/it, loss=0.6858, lr=4.90e-06]Steps:  56%|█████▌    | 2779/5000 [10:19:25<7:23:17, 11.98s/it, loss=0.6858, lr=4.90e-06]Steps:  56%|█████▌    | 2779/5000 [10:19:25<7:23:17, 11.98s/it, loss=0.9290, lr=4.90e-06]Steps:  56%|█████▌    | 2780/5000 [10:19:37<7:22:24, 11.96s/it, loss=0.9290, lr=4.90e-06]Steps:  56%|█████▌    | 2780/5000 [10:19:37<7:22:24, 11.96s/it, loss=1.1547, lr=4.90e-06]
[Step 2780] Training Debug Info:
  Loss: 0.582131
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0003, std: 0.8945
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0018, std: 1.3438
  Model pred mean: 0.0028, std: 1.1094
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 2780] Training Debug Info:
  Loss: 1.100032
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0315, std: 0.9180
  Noise mean: 0.0047, std: 1.0000
  Target mean: 0.0361, std: 1.3516
  Model pred mean: 0.0332, std: 0.8516
  Sigmas: [0.2158203125]... (timesteps: [216.0])

[Step 2780] Training Debug Info:
  Loss: 0.616628
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0110, std: 0.9414
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0089, std: 1.3750
  Model pred mean: -0.0101, std: 1.1250
  Sigmas: [0.53125]... (timesteps: [531.0])

[Step 2780] Training Debug Info:
  Loss: 0.710677
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0021, std: 0.9375
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0000, std: 1.3672
  Model pred mean: -0.0063, std: 1.0859
  Sigmas: [0.9921875]... (timesteps: [992.0])
Steps:  56%|█████▌    | 2781/5000 [10:19:49<7:22:22, 11.96s/it, loss=1.1547, lr=4.90e-06]Steps:  56%|█████▌    | 2781/5000 [10:19:49<7:22:22, 11.96s/it, loss=0.7107, lr=4.89e-06]Steps:  56%|█████▌    | 2782/5000 [10:20:01<7:21:58, 11.96s/it, loss=0.7107, lr=4.89e-06]Steps:  56%|█████▌    | 2782/5000 [10:20:01<7:21:58, 11.96s/it, loss=0.6208, lr=4.89e-06]Steps:  56%|█████▌    | 2783/5000 [10:20:13<7:22:10, 11.97s/it, loss=0.6208, lr=4.89e-06]Steps:  56%|█████▌    | 2783/5000 [10:20:13<7:22:10, 11.97s/it, loss=0.4984, lr=4.88e-06]Steps:  56%|█████▌    | 2784/5000 [10:20:25<7:21:20, 11.95s/it, loss=0.4984, lr=4.88e-06]Steps:  56%|█████▌    | 2784/5000 [10:20:25<7:21:20, 11.95s/it, loss=0.5892, lr=4.88e-06]Steps:  56%|█████▌    | 2785/5000 [10:20:37<7:22:00, 11.97s/it, loss=0.5892, lr=4.88e-06]Steps:  56%|█████▌    | 2785/5000 [10:20:37<7:22:00, 11.97s/it, loss=0.7173, lr=4.88e-06]Steps:  56%|█████▌    | 2786/5000 [10:20:49<7:21:09, 11.96s/it, loss=0.7173, lr=4.88e-06]Steps:  56%|█████▌    | 2786/5000 [10:20:49<7:21:09, 11.96s/it, loss=0.5153, lr=4.87e-06]Steps:  56%|█████▌    | 2787/5000 [10:21:01<7:20:48, 11.95s/it, loss=0.5153, lr=4.87e-06]Steps:  56%|█████▌    | 2787/5000 [10:21:01<7:20:48, 11.95s/it, loss=1.0140, lr=4.87e-06]Steps:  56%|█████▌    | 2788/5000 [10:21:13<7:20:55, 11.96s/it, loss=1.0140, lr=4.87e-06]Steps:  56%|█████▌    | 2788/5000 [10:21:13<7:20:55, 11.96s/it, loss=0.4712, lr=4.87e-06]Steps:  56%|█████▌    | 2789/5000 [10:21:25<7:20:32, 11.95s/it, loss=0.4712, lr=4.87e-06]Steps:  56%|█████▌    | 2789/5000 [10:21:25<7:20:32, 11.95s/it, loss=0.7115, lr=4.86e-06]Steps:  56%|█████▌    | 2790/5000 [10:21:37<7:18:18, 11.90s/it, loss=0.7115, lr=4.86e-06]Steps:  56%|█████▌    | 2790/5000 [10:21:37<7:18:18, 11.90s/it, loss=0.5594, lr=4.86e-06]
[Step 2790] Training Debug Info:
  Loss: 1.151001
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0011, std: 0.9297
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0013, std: 1.3672
  Model pred mean: 0.0031, std: 0.8477
  Sigmas: [0.25390625]... (timesteps: [252.99998474121094])

[Step 2790] Training Debug Info:
  Loss: 1.101954
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0074, std: 0.9219
  Noise mean: 0.0005, std: 0.9961
  Target mean: -0.0068, std: 1.3516
  Model pred mean: -0.0043, std: 0.8672
  Sigmas: [0.1640625]... (timesteps: [164.0])

[Step 2790] Training Debug Info:
  Loss: 0.898520
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0106, std: 0.8555
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0106, std: 1.3125
  Model pred mean: 0.0117, std: 0.9141
  Sigmas: [0.4453125]... (timesteps: [445.0])

[Step 2790] Training Debug Info:
  Loss: 0.616554
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0170, std: 0.8984
  Noise mean: 0.0029, std: 1.0000
  Target mean: -0.0141, std: 1.3438
  Model pred mean: -0.0166, std: 1.0859
  Sigmas: [0.5546875]... (timesteps: [555.0])
Steps:  56%|█████▌    | 2791/5000 [10:21:49<7:19:21, 11.93s/it, loss=0.5594, lr=4.86e-06]Steps:  56%|█████▌    | 2791/5000 [10:21:49<7:19:21, 11.93s/it, loss=0.6166, lr=4.86e-06]Steps:  56%|█████▌    | 2792/5000 [10:22:01<7:20:16, 11.96s/it, loss=0.6166, lr=4.86e-06]Steps:  56%|█████▌    | 2792/5000 [10:22:01<7:20:16, 11.96s/it, loss=0.4427, lr=4.85e-06]Steps:  56%|█████▌    | 2793/5000 [10:22:13<7:19:28, 11.95s/it, loss=0.4427, lr=4.85e-06]Steps:  56%|█████▌    | 2793/5000 [10:22:13<7:19:28, 11.95s/it, loss=0.9131, lr=4.85e-06]Steps:  56%|█████▌    | 2794/5000 [10:22:25<7:18:49, 11.94s/it, loss=0.9131, lr=4.85e-06]Steps:  56%|█████▌    | 2794/5000 [10:22:25<7:18:49, 11.94s/it, loss=0.5839, lr=4.85e-06]Steps:  56%|█████▌    | 2795/5000 [10:22:36<7:18:25, 11.93s/it, loss=0.5839, lr=4.85e-06]Steps:  56%|█████▌    | 2795/5000 [10:22:36<7:18:25, 11.93s/it, loss=1.0849, lr=4.84e-06]Steps:  56%|█████▌    | 2796/5000 [10:22:48<7:19:09, 11.96s/it, loss=1.0849, lr=4.84e-06]Steps:  56%|█████▌    | 2796/5000 [10:22:48<7:19:09, 11.96s/it, loss=0.7731, lr=4.84e-06]Steps:  56%|█████▌    | 2797/5000 [10:23:00<7:19:21, 11.97s/it, loss=0.7731, lr=4.84e-06]Steps:  56%|█████▌    | 2797/5000 [10:23:00<7:19:21, 11.97s/it, loss=0.4081, lr=4.84e-06]Steps:  56%|█████▌    | 2798/5000 [10:23:12<7:19:25, 11.97s/it, loss=0.4081, lr=4.84e-06]Steps:  56%|█████▌    | 2798/5000 [10:23:12<7:19:25, 11.97s/it, loss=0.4001, lr=4.83e-06]Steps:  56%|█████▌    | 2799/5000 [10:23:25<7:22:37, 12.07s/it, loss=0.4001, lr=4.83e-06]Steps:  56%|█████▌    | 2799/5000 [10:23:25<7:22:37, 12.07s/it, loss=0.5636, lr=4.83e-06]Steps:  56%|█████▌    | 2800/5000 [10:23:37<7:20:49, 12.02s/it, loss=0.5636, lr=4.83e-06]Steps:  56%|█████▌    | 2800/5000 [10:23:37<7:20:49, 12.02s/it, loss=0.8087, lr=4.83e-06]01/22/2026 18:09:23 - INFO - __main__ - 
[Step 2800] ✅ Loss in normal range (0.8087)
01/22/2026 18:09:23 - INFO - __main__ -   Loss avg (last 100): 0.7658
01/22/2026 18:09:23 - INFO - __main__ -   Loss range: [0.3358, 1.2006]
01/22/2026 18:09:23 - INFO - __main__ - 
🔍 Running validation at step 2800...
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2800 (parquet mode)...
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 2800...
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 18:09:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.47it/s]
01/22/2026 18:09:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 18:09:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.17it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 18:10:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 18:10:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 18:10:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 18:10:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 18:10:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 18:10:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 18:11:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 18:11:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:11:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 18:11:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:11:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 18:11:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:12:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 18:12:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:13,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.59it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:12:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 18:12:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:12:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 18:12:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.41it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 18:13:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 18:13:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 18:13:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800/step002800_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 18:13:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 18:13:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 18:13:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_002800
01/22/2026 18:13:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 2800] Training Debug Info:
  Loss: 1.187945
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0125, std: 0.8828
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0131, std: 1.3359
  Model pred mean: 0.0067, std: 0.7695
  Sigmas: [0.189453125]... (timesteps: [189.0])

[Step 2800] Training Debug Info:
  Loss: 1.154879
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0239, std: 0.9023
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0237, std: 1.3516
  Model pred mean: -0.0289, std: 0.8086
  Sigmas: [0.1787109375]... (timesteps: [179.0])

[Step 2800] Training Debug Info:
  Loss: 0.505273
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0092, std: 0.9023
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0106, std: 1.3516
  Model pred mean: -0.0166, std: 1.1250
  Sigmas: [0.9375]... (timesteps: [936.0])

[Step 2800] Training Debug Info:
  Loss: 1.075965
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0122, std: 0.9219
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0145, std: 1.3672
  Model pred mean: -0.0160, std: 0.8789
  Sigmas: [0.265625]... (timesteps: [265.0])
Steps:  56%|█████▌    | 2801/5000 [10:28:01<53:38:43, 87.82s/it, loss=0.8087, lr=4.83e-06]Steps:  56%|█████▌    | 2801/5000 [10:28:01<53:38:43, 87.82s/it, loss=1.0760, lr=4.82e-06]Steps:  56%|█████▌    | 2802/5000 [10:28:13<39:42:57, 65.05s/it, loss=1.0760, lr=4.82e-06]Steps:  56%|█████▌    | 2802/5000 [10:28:13<39:42:57, 65.05s/it, loss=0.6722, lr=4.82e-06]Steps:  56%|█████▌    | 2803/5000 [10:28:25<29:58:04, 49.11s/it, loss=0.6722, lr=4.82e-06]Steps:  56%|█████▌    | 2803/5000 [10:28:25<29:58:04, 49.11s/it, loss=0.4036, lr=4.82e-06]Steps:  56%|█████▌    | 2804/5000 [10:28:37<23:09:38, 37.97s/it, loss=0.4036, lr=4.82e-06]Steps:  56%|█████▌    | 2804/5000 [10:28:37<23:09:38, 37.97s/it, loss=0.9387, lr=4.81e-06]Steps:  56%|█████▌    | 2805/5000 [10:28:49<18:25:35, 30.22s/it, loss=0.9387, lr=4.81e-06]Steps:  56%|█████▌    | 2805/5000 [10:28:49<18:25:35, 30.22s/it, loss=0.8919, lr=4.81e-06]Steps:  56%|█████▌    | 2806/5000 [10:29:01<15:05:17, 24.76s/it, loss=0.8919, lr=4.81e-06]Steps:  56%|█████▌    | 2806/5000 [10:29:01<15:05:17, 24.76s/it, loss=0.4425, lr=4.80e-06]Steps:  56%|█████▌    | 2807/5000 [10:29:13<12:43:33, 20.89s/it, loss=0.4425, lr=4.80e-06]Steps:  56%|█████▌    | 2807/5000 [10:29:13<12:43:33, 20.89s/it, loss=0.3974, lr=4.80e-06]Steps:  56%|█████▌    | 2808/5000 [10:29:25<11:04:16, 18.18s/it, loss=0.3974, lr=4.80e-06]Steps:  56%|█████▌    | 2808/5000 [10:29:25<11:04:16, 18.18s/it, loss=0.3654, lr=4.80e-06]Steps:  56%|█████▌    | 2809/5000 [10:29:37<9:56:14, 16.33s/it, loss=0.3654, lr=4.80e-06] Steps:  56%|█████▌    | 2809/5000 [10:29:37<9:56:14, 16.33s/it, loss=1.0710, lr=4.79e-06]Steps:  56%|█████▌    | 2810/5000 [10:29:49<9:08:01, 15.01s/it, loss=1.0710, lr=4.79e-06]Steps:  56%|█████▌    | 2810/5000 [10:29:49<9:08:01, 15.01s/it, loss=0.3841, lr=4.79e-06]
[Step 2810] Training Debug Info:
  Loss: 0.403223
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0417, std: 0.9102
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0417, std: 1.3516
  Model pred mean: -0.0386, std: 1.1953
  Sigmas: [0.75390625]... (timesteps: [754.0])

[Step 2810] Training Debug Info:
  Loss: 0.827880
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0004, std: 0.8633
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0005, std: 1.3203
  Model pred mean: 0.0003, std: 0.9570
  Sigmas: [0.451171875]... (timesteps: [452.0])

[Step 2810] Training Debug Info:
  Loss: 0.378501
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0264, std: 0.9062
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0270, std: 1.3516
  Model pred mean: 0.0259, std: 1.1875
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 2810] Training Debug Info:
  Loss: 0.564616
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0309, std: 0.8633
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0298, std: 1.3203
  Model pred mean: 0.0272, std: 1.0781
  Sigmas: [0.60546875]... (timesteps: [605.0])
Steps:  56%|█████▌    | 2811/5000 [10:30:01<8:33:09, 14.07s/it, loss=0.3841, lr=4.79e-06]Steps:  56%|█████▌    | 2811/5000 [10:30:01<8:33:09, 14.07s/it, loss=0.5646, lr=4.79e-06]Steps:  56%|█████▌    | 2812/5000 [10:30:13<8:10:41, 13.46s/it, loss=0.5646, lr=4.79e-06]Steps:  56%|█████▌    | 2812/5000 [10:30:13<8:10:41, 13.46s/it, loss=0.8596, lr=4.78e-06]Steps:  56%|█████▋    | 2813/5000 [10:30:25<7:54:11, 13.01s/it, loss=0.8596, lr=4.78e-06]Steps:  56%|█████▋    | 2813/5000 [10:30:25<7:54:11, 13.01s/it, loss=1.1728, lr=4.78e-06]Steps:  56%|█████▋    | 2814/5000 [10:30:37<7:42:57, 12.71s/it, loss=1.1728, lr=4.78e-06]Steps:  56%|█████▋    | 2814/5000 [10:30:37<7:42:57, 12.71s/it, loss=0.4037, lr=4.78e-06]Steps:  56%|█████▋    | 2815/5000 [10:30:49<7:35:47, 12.52s/it, loss=0.4037, lr=4.78e-06]Steps:  56%|█████▋    | 2815/5000 [10:30:49<7:35:47, 12.52s/it, loss=1.2086, lr=4.77e-06]Steps:  56%|█████▋    | 2816/5000 [10:31:01<7:28:30, 12.32s/it, loss=1.2086, lr=4.77e-06]Steps:  56%|█████▋    | 2816/5000 [10:31:01<7:28:30, 12.32s/it, loss=0.9287, lr=4.77e-06]Steps:  56%|█████▋    | 2817/5000 [10:31:13<7:23:21, 12.19s/it, loss=0.9287, lr=4.77e-06]Steps:  56%|█████▋    | 2817/5000 [10:31:13<7:23:21, 12.19s/it, loss=1.1169, lr=4.77e-06]Steps:  56%|█████▋    | 2818/5000 [10:31:25<7:20:48, 12.12s/it, loss=1.1169, lr=4.77e-06]Steps:  56%|█████▋    | 2818/5000 [10:31:25<7:20:48, 12.12s/it, loss=0.7625, lr=4.76e-06]Steps:  56%|█████▋    | 2819/5000 [10:31:37<7:20:14, 12.11s/it, loss=0.7625, lr=4.76e-06]Steps:  56%|█████▋    | 2819/5000 [10:31:37<7:20:14, 12.11s/it, loss=0.7058, lr=4.76e-06]Steps:  56%|█████▋    | 2820/5000 [10:31:49<7:17:39, 12.05s/it, loss=0.7058, lr=4.76e-06]Steps:  56%|█████▋    | 2820/5000 [10:31:49<7:17:39, 12.05s/it, loss=1.0796, lr=4.76e-06]
[Step 2820] Training Debug Info:
  Loss: 1.174978
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0114, std: 0.8984
  Noise mean: -0.0019, std: 1.0000
  Target mean: 0.0095, std: 1.3438
  Model pred mean: 0.0117, std: 0.7930
  Sigmas: [0.2099609375]... (timesteps: [210.0])

[Step 2820] Training Debug Info:
  Loss: 0.824447
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0107, std: 0.9414
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0105, std: 1.3750
  Model pred mean: 0.0066, std: 1.0156
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 2820] Training Debug Info:
  Loss: 0.862325
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0500, std: 0.9727
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0518, std: 1.3984
  Model pred mean: -0.0496, std: 1.0391
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 2820] Training Debug Info:
  Loss: 0.766744
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0153, std: 0.9453
  Noise mean: -0.0023, std: 0.9961
  Target mean: -0.0176, std: 1.3750
  Model pred mean: -0.0162, std: 1.0547
  Sigmas: [0.412109375]... (timesteps: [412.0])
Steps:  56%|█████▋    | 2821/5000 [10:32:00<7:16:01, 12.01s/it, loss=1.0796, lr=4.76e-06]Steps:  56%|█████▋    | 2821/5000 [10:32:00<7:16:01, 12.01s/it, loss=0.7667, lr=4.75e-06]Steps:  56%|█████▋    | 2822/5000 [10:32:12<7:14:45, 11.98s/it, loss=0.7667, lr=4.75e-06]Steps:  56%|█████▋    | 2822/5000 [10:32:12<7:14:45, 11.98s/it, loss=0.9464, lr=4.75e-06]Steps:  56%|█████▋    | 2823/5000 [10:32:24<7:13:30, 11.95s/it, loss=0.9464, lr=4.75e-06]Steps:  56%|█████▋    | 2823/5000 [10:32:24<7:13:30, 11.95s/it, loss=1.0953, lr=4.75e-06]Steps:  56%|█████▋    | 2824/5000 [10:32:36<7:15:50, 12.02s/it, loss=1.0953, lr=4.75e-06]Steps:  56%|█████▋    | 2824/5000 [10:32:36<7:15:50, 12.02s/it, loss=1.0046, lr=4.74e-06]Steps:  56%|█████▋    | 2825/5000 [10:32:48<7:14:38, 11.99s/it, loss=1.0046, lr=4.74e-06]Steps:  56%|█████▋    | 2825/5000 [10:32:48<7:14:38, 11.99s/it, loss=1.1712, lr=4.74e-06]Steps:  57%|█████▋    | 2826/5000 [10:33:00<7:15:33, 12.02s/it, loss=1.1712, lr=4.74e-06]Steps:  57%|█████▋    | 2826/5000 [10:33:00<7:15:33, 12.02s/it, loss=0.6719, lr=4.73e-06]Steps:  57%|█████▋    | 2827/5000 [10:33:12<7:13:55, 11.98s/it, loss=0.6719, lr=4.73e-06]Steps:  57%|█████▋    | 2827/5000 [10:33:12<7:13:55, 11.98s/it, loss=0.9482, lr=4.73e-06]Steps:  57%|█████▋    | 2828/5000 [10:33:24<7:12:22, 11.94s/it, loss=0.9482, lr=4.73e-06]Steps:  57%|█████▋    | 2828/5000 [10:33:24<7:12:22, 11.94s/it, loss=0.4582, lr=4.73e-06]Steps:  57%|█████▋    | 2829/5000 [10:33:36<7:11:53, 11.94s/it, loss=0.4582, lr=4.73e-06]Steps:  57%|█████▋    | 2829/5000 [10:33:36<7:11:53, 11.94s/it, loss=1.1935, lr=4.72e-06]Steps:  57%|█████▋    | 2830/5000 [10:33:48<7:11:25, 11.93s/it, loss=1.1935, lr=4.72e-06]Steps:  57%|█████▋    | 2830/5000 [10:33:48<7:11:25, 11.93s/it, loss=1.1452, lr=4.72e-06]
[Step 2830] Training Debug Info:
  Loss: 0.749351
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0264, std: 0.9375
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0264, std: 1.3750
  Model pred mean: 0.0031, std: 1.0781
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 2830] Training Debug Info:
  Loss: 0.357515
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0310, std: 0.9414
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0308, std: 1.3750
  Model pred mean: -0.0304, std: 1.2344
  Sigmas: [0.88671875]... (timesteps: [886.0])

[Step 2830] Training Debug Info:
  Loss: 0.460031
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0200, std: 0.9453
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0195, std: 1.3750
  Model pred mean: -0.0098, std: 1.1953
  Sigmas: [0.91015625]... (timesteps: [911.0])

[Step 2830] Training Debug Info:
  Loss: 0.312479
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0021, std: 0.9570
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0021, std: 1.3906
  Model pred mean: -0.0033, std: 1.2656
  Sigmas: [0.82421875]... (timesteps: [823.0])
Steps:  57%|█████▋    | 2831/5000 [10:34:00<7:11:30, 11.94s/it, loss=1.1452, lr=4.72e-06]Steps:  57%|█████▋    | 2831/5000 [10:34:00<7:11:30, 11.94s/it, loss=0.3125, lr=4.72e-06]Steps:  57%|█████▋    | 2832/5000 [10:34:12<7:13:21, 11.99s/it, loss=0.3125, lr=4.72e-06]Steps:  57%|█████▋    | 2832/5000 [10:34:12<7:13:21, 11.99s/it, loss=1.1479, lr=4.71e-06]Steps:  57%|█████▋    | 2833/5000 [10:34:24<7:13:24, 12.00s/it, loss=1.1479, lr=4.71e-06]Steps:  57%|█████▋    | 2833/5000 [10:34:24<7:13:24, 12.00s/it, loss=0.3908, lr=4.71e-06]Steps:  57%|█████▋    | 2834/5000 [10:34:36<7:12:33, 11.98s/it, loss=0.3908, lr=4.71e-06]Steps:  57%|█████▋    | 2834/5000 [10:34:36<7:12:33, 11.98s/it, loss=0.4156, lr=4.71e-06]Steps:  57%|█████▋    | 2835/5000 [10:34:48<7:11:45, 11.97s/it, loss=0.4156, lr=4.71e-06]Steps:  57%|█████▋    | 2835/5000 [10:34:48<7:11:45, 11.97s/it, loss=0.4552, lr=4.70e-06]Steps:  57%|█████▋    | 2836/5000 [10:35:00<7:10:59, 11.95s/it, loss=0.4552, lr=4.70e-06]Steps:  57%|█████▋    | 2836/5000 [10:35:00<7:10:59, 11.95s/it, loss=1.1267, lr=4.70e-06]Steps:  57%|█████▋    | 2837/5000 [10:35:12<7:10:34, 11.94s/it, loss=1.1267, lr=4.70e-06]Steps:  57%|█████▋    | 2837/5000 [10:35:12<7:10:34, 11.94s/it, loss=0.6598, lr=4.70e-06]Steps:  57%|█████▋    | 2838/5000 [10:35:24<7:10:19, 11.94s/it, loss=0.6598, lr=4.70e-06]Steps:  57%|█████▋    | 2838/5000 [10:35:24<7:10:19, 11.94s/it, loss=1.1209, lr=4.69e-06]Steps:  57%|█████▋    | 2839/5000 [10:35:36<7:11:29, 11.98s/it, loss=1.1209, lr=4.69e-06]Steps:  57%|█████▋    | 2839/5000 [10:35:36<7:11:29, 11.98s/it, loss=0.4743, lr=4.69e-06]Steps:  57%|█████▋    | 2840/5000 [10:35:48<7:11:10, 11.98s/it, loss=0.4743, lr=4.69e-06]Steps:  57%|█████▋    | 2840/5000 [10:35:48<7:11:10, 11.98s/it, loss=0.5716, lr=4.69e-06]
[Step 2840] Training Debug Info:
  Loss: 0.781915
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0079, std: 0.9141
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0072, std: 1.3594
  Model pred mean: 0.0100, std: 1.0234
  Sigmas: [0.44140625]... (timesteps: [442.0])

[Step 2840] Training Debug Info:
  Loss: 0.467666
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0101, std: 0.9141
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0107, std: 1.3594
  Model pred mean: 0.0107, std: 1.1719
  Sigmas: [0.69140625]... (timesteps: [692.0])

[Step 2840] Training Debug Info:
  Loss: 0.394951
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0219, std: 0.8438
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0236, std: 1.3125
  Model pred mean: 0.0250, std: 1.1484
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 2840] Training Debug Info:
  Loss: 1.183681
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0155, std: 0.9141
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0155, std: 1.3516
  Model pred mean: 0.0162, std: 0.8125
  Sigmas: [0.205078125]... (timesteps: [205.0])
Steps:  57%|█████▋    | 2841/5000 [10:36:00<7:09:40, 11.94s/it, loss=0.5716, lr=4.69e-06]Steps:  57%|█████▋    | 2841/5000 [10:36:00<7:09:40, 11.94s/it, loss=1.1837, lr=4.68e-06]Steps:  57%|█████▋    | 2842/5000 [10:36:12<7:10:23, 11.97s/it, loss=1.1837, lr=4.68e-06]Steps:  57%|█████▋    | 2842/5000 [10:36:12<7:10:23, 11.97s/it, loss=1.1070, lr=4.68e-06]Steps:  57%|█████▋    | 2843/5000 [10:36:24<7:08:53, 11.93s/it, loss=1.1070, lr=4.68e-06]Steps:  57%|█████▋    | 2843/5000 [10:36:24<7:08:53, 11.93s/it, loss=1.1304, lr=4.68e-06]Steps:  57%|█████▋    | 2844/5000 [10:36:35<7:07:46, 11.90s/it, loss=1.1304, lr=4.68e-06]Steps:  57%|█████▋    | 2844/5000 [10:36:35<7:07:46, 11.90s/it, loss=1.0707, lr=4.67e-06]Steps:  57%|█████▋    | 2845/5000 [10:36:47<7:07:42, 11.91s/it, loss=1.0707, lr=4.67e-06]Steps:  57%|█████▋    | 2845/5000 [10:36:47<7:07:42, 11.91s/it, loss=0.3283, lr=4.67e-06]Steps:  57%|█████▋    | 2846/5000 [10:36:59<7:08:54, 11.95s/it, loss=0.3283, lr=4.67e-06]Steps:  57%|█████▋    | 2846/5000 [10:36:59<7:08:54, 11.95s/it, loss=1.0920, lr=4.67e-06]Steps:  57%|█████▋    | 2847/5000 [10:37:11<7:09:28, 11.97s/it, loss=1.0920, lr=4.67e-06]Steps:  57%|█████▋    | 2847/5000 [10:37:11<7:09:28, 11.97s/it, loss=0.5109, lr=4.66e-06]Steps:  57%|█████▋    | 2848/5000 [10:37:23<7:07:52, 11.93s/it, loss=0.5109, lr=4.66e-06]Steps:  57%|█████▋    | 2848/5000 [10:37:23<7:07:52, 11.93s/it, loss=0.7927, lr=4.66e-06]Steps:  57%|█████▋    | 2849/5000 [10:37:35<7:06:29, 11.90s/it, loss=0.7927, lr=4.66e-06]Steps:  57%|█████▋    | 2849/5000 [10:37:35<7:06:29, 11.90s/it, loss=0.8555, lr=4.65e-06]Steps:  57%|█████▋    | 2850/5000 [10:37:47<7:07:03, 11.92s/it, loss=0.8555, lr=4.65e-06]Steps:  57%|█████▋    | 2850/5000 [10:37:47<7:07:03, 11.92s/it, loss=1.0504, lr=4.65e-06]
[Step 2850] Training Debug Info:
  Loss: 1.130487
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0066, std: 0.9023
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0060, std: 1.3438
  Model pred mean: 0.0077, std: 0.8281
  Sigmas: [0.236328125]... (timesteps: [236.0])

[Step 2850] Training Debug Info:
  Loss: 0.419361
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0086, std: 0.9414
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0098, std: 1.3750
  Model pred mean: -0.0112, std: 1.2109
  Sigmas: [0.80859375]... (timesteps: [807.0])

[Step 2850] Training Debug Info:
  Loss: 0.791055
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0098, std: 0.9414
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0096, std: 1.3750
  Model pred mean: -0.0064, std: 1.0469
  Sigmas: [0.46484375]... (timesteps: [464.0])

[Step 2850] Training Debug Info:
  Loss: 0.438012
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0201, std: 0.9375
  Noise mean: 0.0001, std: 0.9961
  Target mean: 0.0203, std: 1.3672
  Model pred mean: 0.0214, std: 1.1953
  Sigmas: [0.7421875]... (timesteps: [744.0])
Steps:  57%|█████▋    | 2851/5000 [10:37:59<7:07:39, 11.94s/it, loss=1.0504, lr=4.65e-06]Steps:  57%|█████▋    | 2851/5000 [10:37:59<7:07:39, 11.94s/it, loss=0.4380, lr=4.65e-06]Steps:  57%|█████▋    | 2852/5000 [10:38:11<7:07:36, 11.94s/it, loss=0.4380, lr=4.65e-06]Steps:  57%|█████▋    | 2852/5000 [10:38:11<7:07:36, 11.94s/it, loss=0.4664, lr=4.64e-06]Steps:  57%|█████▋    | 2853/5000 [10:38:23<7:08:20, 11.97s/it, loss=0.4664, lr=4.64e-06]Steps:  57%|█████▋    | 2853/5000 [10:38:23<7:08:20, 11.97s/it, loss=0.5431, lr=4.64e-06]Steps:  57%|█████▋    | 2854/5000 [10:38:35<7:09:09, 12.00s/it, loss=0.5431, lr=4.64e-06]Steps:  57%|█████▋    | 2854/5000 [10:38:35<7:09:09, 12.00s/it, loss=0.9316, lr=4.64e-06]Steps:  57%|█████▋    | 2855/5000 [10:38:47<7:07:14, 11.95s/it, loss=0.9316, lr=4.64e-06]Steps:  57%|█████▋    | 2855/5000 [10:38:47<7:07:14, 11.95s/it, loss=0.3690, lr=4.63e-06]Steps:  57%|█████▋    | 2856/5000 [10:38:59<7:06:29, 11.94s/it, loss=0.3690, lr=4.63e-06]Steps:  57%|█████▋    | 2856/5000 [10:38:59<7:06:29, 11.94s/it, loss=0.5474, lr=4.63e-06]Steps:  57%|█████▋    | 2857/5000 [10:39:11<7:05:38, 11.92s/it, loss=0.5474, lr=4.63e-06]Steps:  57%|█████▋    | 2857/5000 [10:39:11<7:05:38, 11.92s/it, loss=0.3903, lr=4.63e-06]Steps:  57%|█████▋    | 2858/5000 [10:39:23<7:05:12, 11.91s/it, loss=0.3903, lr=4.63e-06]Steps:  57%|█████▋    | 2858/5000 [10:39:23<7:05:12, 11.91s/it, loss=0.4184, lr=4.62e-06]Steps:  57%|█████▋    | 2859/5000 [10:39:35<7:06:21, 11.95s/it, loss=0.4184, lr=4.62e-06]Steps:  57%|█████▋    | 2859/5000 [10:39:35<7:06:21, 11.95s/it, loss=1.0936, lr=4.62e-06]Steps:  57%|█████▋    | 2860/5000 [10:39:47<7:06:29, 11.96s/it, loss=1.0936, lr=4.62e-06]Steps:  57%|█████▋    | 2860/5000 [10:39:47<7:06:29, 11.96s/it, loss=1.0119, lr=4.62e-06]
[Step 2860] Training Debug Info:
  Loss: 0.636747
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0247, std: 1.0469
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0237, std: 1.4453
  Model pred mean: -0.0229, std: 1.2109
  Sigmas: [0.7265625]... (timesteps: [727.0])

[Step 2860] Training Debug Info:
  Loss: 0.607150
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0012, std: 0.8711
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0020, std: 1.3281
  Model pred mean: 0.0009, std: 1.0781
  Sigmas: [0.60546875]... (timesteps: [606.0])

[Step 2860] Training Debug Info:
  Loss: 1.017531
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0325, std: 0.9727
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0315, std: 1.3984
  Model pred mean: -0.0349, std: 0.9648
  Sigmas: [0.33203125]... (timesteps: [332.0])

[Step 2860] Training Debug Info:
  Loss: 0.635226
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0294, std: 0.8906
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0291, std: 1.3359
  Model pred mean: -0.0261, std: 1.0781
  Sigmas: [0.55078125]... (timesteps: [552.0])
Steps:  57%|█████▋    | 2861/5000 [10:39:59<7:08:08, 12.01s/it, loss=1.0119, lr=4.62e-06]Steps:  57%|█████▋    | 2861/5000 [10:39:59<7:08:08, 12.01s/it, loss=0.6352, lr=4.61e-06]Steps:  57%|█████▋    | 2862/5000 [10:40:11<7:08:41, 12.03s/it, loss=0.6352, lr=4.61e-06]Steps:  57%|█████▋    | 2862/5000 [10:40:11<7:08:41, 12.03s/it, loss=1.1230, lr=4.61e-06]Steps:  57%|█████▋    | 2863/5000 [10:40:23<7:07:46, 12.01s/it, loss=1.1230, lr=4.61e-06]Steps:  57%|█████▋    | 2863/5000 [10:40:23<7:07:46, 12.01s/it, loss=0.7250, lr=4.61e-06]Steps:  57%|█████▋    | 2864/5000 [10:40:35<7:06:04, 11.97s/it, loss=0.7250, lr=4.61e-06]Steps:  57%|█████▋    | 2864/5000 [10:40:35<7:06:04, 11.97s/it, loss=0.3960, lr=4.60e-06]Steps:  57%|█████▋    | 2865/5000 [10:40:47<7:06:03, 11.97s/it, loss=0.3960, lr=4.60e-06]Steps:  57%|█████▋    | 2865/5000 [10:40:47<7:06:03, 11.97s/it, loss=0.3895, lr=4.60e-06]Steps:  57%|█████▋    | 2866/5000 [10:40:59<7:06:58, 12.01s/it, loss=0.3895, lr=4.60e-06]Steps:  57%|█████▋    | 2866/5000 [10:40:59<7:06:58, 12.01s/it, loss=0.9557, lr=4.60e-06]Steps:  57%|█████▋    | 2867/5000 [10:41:11<7:06:55, 12.01s/it, loss=0.9557, lr=4.60e-06]Steps:  57%|█████▋    | 2867/5000 [10:41:11<7:06:55, 12.01s/it, loss=1.1511, lr=4.59e-06]Steps:  57%|█████▋    | 2868/5000 [10:41:23<7:06:02, 11.99s/it, loss=1.1511, lr=4.59e-06]Steps:  57%|█████▋    | 2868/5000 [10:41:23<7:06:02, 11.99s/it, loss=0.7072, lr=4.59e-06]Steps:  57%|█████▋    | 2869/5000 [10:41:35<7:05:59, 11.99s/it, loss=0.7072, lr=4.59e-06]Steps:  57%|█████▋    | 2869/5000 [10:41:35<7:05:59, 11.99s/it, loss=0.7745, lr=4.59e-06]Steps:  57%|█████▋    | 2870/5000 [10:41:47<7:04:41, 11.96s/it, loss=0.7745, lr=4.59e-06]Steps:  57%|█████▋    | 2870/5000 [10:41:47<7:04:41, 11.96s/it, loss=1.0376, lr=4.58e-06]
[Step 2870] Training Debug Info:
  Loss: 1.087431
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0151, std: 0.9219
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0129, std: 1.3672
  Model pred mean: -0.0132, std: 0.8750
  Sigmas: [0.208984375]... (timesteps: [209.0])

[Step 2870] Training Debug Info:
  Loss: 1.017923
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0040, std: 0.8906
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0060, std: 1.3359
  Model pred mean: -0.0029, std: 0.8828
  Sigmas: [0.00897216796875]... (timesteps: [9.0])

[Step 2870] Training Debug Info:
  Loss: 0.558013
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0161, std: 0.9375
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0165, std: 1.3672
  Model pred mean: -0.0069, std: 1.1328
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 2870] Training Debug Info:
  Loss: 1.047220
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0137, std: 0.9805
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0159, std: 1.3984
  Model pred mean: -0.0115, std: 0.9531
  Sigmas: [0.255859375]... (timesteps: [256.0])
Steps:  57%|█████▋    | 2871/5000 [10:41:58<7:03:41, 11.94s/it, loss=1.0376, lr=4.58e-06]Steps:  57%|█████▋    | 2871/5000 [10:41:58<7:03:41, 11.94s/it, loss=1.0472, lr=4.58e-06]Steps:  57%|█████▋    | 2872/5000 [10:42:10<7:03:39, 11.95s/it, loss=1.0472, lr=4.58e-06]Steps:  57%|█████▋    | 2872/5000 [10:42:10<7:03:39, 11.95s/it, loss=1.0608, lr=4.57e-06]Steps:  57%|█████▋    | 2873/5000 [10:42:22<7:04:18, 11.97s/it, loss=1.0608, lr=4.57e-06]Steps:  57%|█████▋    | 2873/5000 [10:42:22<7:04:18, 11.97s/it, loss=0.8077, lr=4.57e-06]Steps:  57%|█████▋    | 2874/5000 [10:42:34<7:03:23, 11.95s/it, loss=0.8077, lr=4.57e-06]Steps:  57%|█████▋    | 2874/5000 [10:42:34<7:03:23, 11.95s/it, loss=1.1048, lr=4.57e-06]Steps:  57%|█████▊    | 2875/5000 [10:42:46<7:02:19, 11.92s/it, loss=1.1048, lr=4.57e-06]Steps:  57%|█████▊    | 2875/5000 [10:42:46<7:02:19, 11.92s/it, loss=0.4989, lr=4.56e-06]Steps:  58%|█████▊    | 2876/5000 [10:42:58<7:01:20, 11.90s/it, loss=0.4989, lr=4.56e-06]Steps:  58%|█████▊    | 2876/5000 [10:42:58<7:01:20, 11.90s/it, loss=0.4093, lr=4.56e-06]Steps:  58%|█████▊    | 2877/5000 [10:43:10<7:01:59, 11.93s/it, loss=0.4093, lr=4.56e-06]Steps:  58%|█████▊    | 2877/5000 [10:43:10<7:01:59, 11.93s/it, loss=0.3849, lr=4.56e-06]Steps:  58%|█████▊    | 2878/5000 [10:43:22<7:02:46, 11.95s/it, loss=0.3849, lr=4.56e-06]Steps:  58%|█████▊    | 2878/5000 [10:43:22<7:02:46, 11.95s/it, loss=0.4208, lr=4.55e-06]Steps:  58%|█████▊    | 2879/5000 [10:43:34<7:02:11, 11.94s/it, loss=0.4208, lr=4.55e-06]Steps:  58%|█████▊    | 2879/5000 [10:43:34<7:02:11, 11.94s/it, loss=0.5932, lr=4.55e-06]Steps:  58%|█████▊    | 2880/5000 [10:43:46<7:03:00, 11.97s/it, loss=0.5932, lr=4.55e-06]Steps:  58%|█████▊    | 2880/5000 [10:43:46<7:03:00, 11.97s/it, loss=0.4902, lr=4.55e-06]
[Step 2880] Training Debug Info:
  Loss: 1.044838
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0087, std: 0.8711
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0090, std: 1.3281
  Model pred mean: 0.0092, std: 0.8516
  Sigmas: [0.33984375]... (timesteps: [339.0])

[Step 2880] Training Debug Info:
  Loss: 0.602629
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0156, std: 0.9141
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0166, std: 1.3594
  Model pred mean: 0.0137, std: 1.0938
  Sigmas: [0.984375]... (timesteps: [986.0])

[Step 2880] Training Debug Info:
  Loss: 1.109213
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0283, std: 0.8867
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0262, std: 1.3359
  Model pred mean: -0.0304, std: 0.8242
  Sigmas: [0.16796875]... (timesteps: [168.0])

[Step 2880] Training Debug Info:
  Loss: 1.191885
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0028, std: 0.8672
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0018, std: 1.3281
  Model pred mean: -0.0031, std: 0.7539
  Sigmas: [0.2333984375]... (timesteps: [233.0])
Steps:  58%|█████▊    | 2881/5000 [10:43:58<7:02:23, 11.96s/it, loss=0.4902, lr=4.55e-06]Steps:  58%|█████▊    | 2881/5000 [10:43:58<7:02:23, 11.96s/it, loss=1.1919, lr=4.54e-06]Steps:  58%|█████▊    | 2882/5000 [10:44:10<7:02:30, 11.97s/it, loss=1.1919, lr=4.54e-06]Steps:  58%|█████▊    | 2882/5000 [10:44:10<7:02:30, 11.97s/it, loss=0.4610, lr=4.54e-06]Steps:  58%|█████▊    | 2883/5000 [10:44:22<7:01:57, 11.96s/it, loss=0.4610, lr=4.54e-06]Steps:  58%|█████▊    | 2883/5000 [10:44:22<7:01:57, 11.96s/it, loss=0.5288, lr=4.54e-06]Steps:  58%|█████▊    | 2884/5000 [10:44:34<7:00:43, 11.93s/it, loss=0.5288, lr=4.54e-06]Steps:  58%|█████▊    | 2884/5000 [10:44:34<7:00:43, 11.93s/it, loss=0.6554, lr=4.53e-06]Steps:  58%|█████▊    | 2885/5000 [10:44:46<7:00:20, 11.92s/it, loss=0.6554, lr=4.53e-06]Steps:  58%|█████▊    | 2885/5000 [10:44:46<7:00:20, 11.92s/it, loss=0.9745, lr=4.53e-06]Steps:  58%|█████▊    | 2886/5000 [10:44:58<7:02:01, 11.98s/it, loss=0.9745, lr=4.53e-06]Steps:  58%|█████▊    | 2886/5000 [10:44:58<7:02:01, 11.98s/it, loss=1.1136, lr=4.53e-06]Steps:  58%|█████▊    | 2887/5000 [10:45:10<7:01:23, 11.97s/it, loss=1.1136, lr=4.53e-06]Steps:  58%|█████▊    | 2887/5000 [10:45:10<7:01:23, 11.97s/it, loss=0.4083, lr=4.52e-06]Steps:  58%|█████▊    | 2888/5000 [10:45:22<7:00:12, 11.94s/it, loss=0.4083, lr=4.52e-06]Steps:  58%|█████▊    | 2888/5000 [10:45:22<7:00:12, 11.94s/it, loss=0.3828, lr=4.52e-06]Steps:  58%|█████▊    | 2889/5000 [10:45:33<6:59:32, 11.92s/it, loss=0.3828, lr=4.52e-06]Steps:  58%|█████▊    | 2889/5000 [10:45:33<6:59:32, 11.92s/it, loss=1.1217, lr=4.52e-06]Steps:  58%|█████▊    | 2890/5000 [10:45:45<6:59:19, 11.92s/it, loss=1.1217, lr=4.52e-06]Steps:  58%|█████▊    | 2890/5000 [10:45:45<6:59:19, 11.92s/it, loss=1.1767, lr=4.51e-06]
[Step 2890] Training Debug Info:
  Loss: 1.101759
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0063, std: 0.9102
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0081, std: 1.3516
  Model pred mean: 0.0055, std: 0.8555
  Sigmas: [0.26953125]... (timesteps: [270.0])

[Step 2890] Training Debug Info:
  Loss: 0.499374
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0247, std: 0.9141
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0258, std: 1.3594
  Model pred mean: -0.0248, std: 1.1562
  Sigmas: [0.65234375]... (timesteps: [651.0])

[Step 2890] Training Debug Info:
  Loss: 0.805890
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0322, std: 0.9688
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0337, std: 1.3906
  Model pred mean: -0.0361, std: 1.0625
  Sigmas: [0.412109375]... (timesteps: [413.0])

[Step 2890] Training Debug Info:
  Loss: 0.795497
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0115, std: 0.8906
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0112, std: 1.3359
  Model pred mean: 0.0098, std: 1.0000
  Sigmas: [0.466796875]... (timesteps: [467.0])
Steps:  58%|█████▊    | 2891/5000 [10:45:57<6:59:29, 11.93s/it, loss=1.1767, lr=4.51e-06]Steps:  58%|█████▊    | 2891/5000 [10:45:57<6:59:29, 11.93s/it, loss=0.7955, lr=4.51e-06]Steps:  58%|█████▊    | 2892/5000 [10:46:09<6:59:37, 11.94s/it, loss=0.7955, lr=4.51e-06]Steps:  58%|█████▊    | 2892/5000 [10:46:09<6:59:37, 11.94s/it, loss=0.5406, lr=4.51e-06]Steps:  58%|█████▊    | 2893/5000 [10:46:21<7:00:49, 11.98s/it, loss=0.5406, lr=4.51e-06]Steps:  58%|█████▊    | 2893/5000 [10:46:21<7:00:49, 11.98s/it, loss=0.5611, lr=4.50e-06]Steps:  58%|█████▊    | 2894/5000 [10:46:33<7:00:09, 11.97s/it, loss=0.5611, lr=4.50e-06]Steps:  58%|█████▊    | 2894/5000 [10:46:33<7:00:09, 11.97s/it, loss=0.4243, lr=4.50e-06]Steps:  58%|█████▊    | 2895/5000 [10:46:45<7:00:24, 11.98s/it, loss=0.4243, lr=4.50e-06]Steps:  58%|█████▊    | 2895/5000 [10:46:45<7:00:24, 11.98s/it, loss=1.1172, lr=4.49e-06]Steps:  58%|█████▊    | 2896/5000 [10:46:57<7:00:16, 11.98s/it, loss=1.1172, lr=4.49e-06]Steps:  58%|█████▊    | 2896/5000 [10:46:57<7:00:16, 11.98s/it, loss=0.8758, lr=4.49e-06]Steps:  58%|█████▊    | 2897/5000 [10:47:09<6:58:27, 11.94s/it, loss=0.8758, lr=4.49e-06]Steps:  58%|█████▊    | 2897/5000 [10:47:09<6:58:27, 11.94s/it, loss=0.4760, lr=4.49e-06]Steps:  58%|█████▊    | 2898/5000 [10:47:21<6:57:59, 11.93s/it, loss=0.4760, lr=4.49e-06]Steps:  58%|█████▊    | 2898/5000 [10:47:21<6:57:59, 11.93s/it, loss=0.6215, lr=4.48e-06]Steps:  58%|█████▊    | 2899/5000 [10:47:33<6:57:36, 11.93s/it, loss=0.6215, lr=4.48e-06]Steps:  58%|█████▊    | 2899/5000 [10:47:33<6:57:36, 11.93s/it, loss=1.1165, lr=4.48e-06]Steps:  58%|█████▊    | 2900/5000 [10:47:45<6:59:10, 11.98s/it, loss=1.1165, lr=4.48e-06]Steps:  58%|█████▊    | 2900/5000 [10:47:45<6:59:10, 11.98s/it, loss=0.7494, lr=4.48e-06]01/22/2026 18:33:32 - INFO - __main__ - 
[Step 2900] ✅ Loss in normal range (0.7494)
01/22/2026 18:33:32 - INFO - __main__ -   Loss avg (last 100): 0.7686
01/22/2026 18:33:32 - INFO - __main__ -   Loss range: [0.3125, 1.2086]

[Step 2900] Training Debug Info:
  Loss: 0.939939
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0069, std: 0.9414
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0058, std: 1.3750
  Model pred mean: 0.0070, std: 0.9727
  Sigmas: [0.361328125]... (timesteps: [361.0])

[Step 2900] Training Debug Info:
  Loss: 0.751854
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0289, std: 0.9453
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0262, std: 1.3750
  Model pred mean: -0.0282, std: 1.0625
  Sigmas: [0.419921875]... (timesteps: [420.0])

[Step 2900] Training Debug Info:
  Loss: 0.813361
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0036, std: 0.9570
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0049, std: 1.3828
  Model pred mean: -0.0084, std: 1.0469
  Sigmas: [0.44140625]... (timesteps: [441.0])

[Step 2900] Training Debug Info:
  Loss: 0.473758
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0310, std: 0.9688
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0322, std: 1.3906
  Model pred mean: -0.0391, std: 1.2109
  Sigmas: [0.87890625]... (timesteps: [878.0])
Steps:  58%|█████▊    | 2901/5000 [10:47:57<6:58:13, 11.96s/it, loss=0.7494, lr=4.48e-06]Steps:  58%|█████▊    | 2901/5000 [10:47:57<6:58:13, 11.96s/it, loss=0.4738, lr=4.47e-06]Steps:  58%|█████▊    | 2902/5000 [10:48:09<6:58:03, 11.96s/it, loss=0.4738, lr=4.47e-06]Steps:  58%|█████▊    | 2902/5000 [10:48:09<6:58:03, 11.96s/it, loss=1.1197, lr=4.47e-06]Steps:  58%|█████▊    | 2903/5000 [10:48:21<6:57:42, 11.95s/it, loss=1.1197, lr=4.47e-06]Steps:  58%|█████▊    | 2903/5000 [10:48:21<6:57:42, 11.95s/it, loss=0.4289, lr=4.47e-06]Steps:  58%|█████▊    | 2904/5000 [10:48:33<6:58:51, 11.99s/it, loss=0.4289, lr=4.47e-06]Steps:  58%|█████▊    | 2904/5000 [10:48:33<6:58:51, 11.99s/it, loss=1.0829, lr=4.46e-06]Steps:  58%|█████▊    | 2905/5000 [10:48:45<6:59:23, 12.01s/it, loss=1.0829, lr=4.46e-06]Steps:  58%|█████▊    | 2905/5000 [10:48:45<6:59:23, 12.01s/it, loss=1.0631, lr=4.46e-06]Steps:  58%|█████▊    | 2906/5000 [10:48:57<6:58:45, 12.00s/it, loss=1.0631, lr=4.46e-06]Steps:  58%|█████▊    | 2906/5000 [10:48:57<6:58:45, 12.00s/it, loss=1.1123, lr=4.46e-06]Steps:  58%|█████▊    | 2907/5000 [10:49:09<6:59:08, 12.02s/it, loss=1.1123, lr=4.46e-06]Steps:  58%|█████▊    | 2907/5000 [10:49:09<6:59:08, 12.02s/it, loss=1.1114, lr=4.45e-06]Steps:  58%|█████▊    | 2908/5000 [10:49:21<6:58:26, 12.00s/it, loss=1.1114, lr=4.45e-06]Steps:  58%|█████▊    | 2908/5000 [10:49:21<6:58:26, 12.00s/it, loss=0.4073, lr=4.45e-06]Steps:  58%|█████▊    | 2909/5000 [10:49:33<6:56:42, 11.96s/it, loss=0.4073, lr=4.45e-06]Steps:  58%|█████▊    | 2909/5000 [10:49:33<6:56:42, 11.96s/it, loss=0.5114, lr=4.45e-06]Steps:  58%|█████▊    | 2910/5000 [10:49:45<6:56:07, 11.95s/it, loss=0.5114, lr=4.45e-06]Steps:  58%|█████▊    | 2910/5000 [10:49:45<6:56:07, 11.95s/it, loss=1.0791, lr=4.44e-06]
[Step 2910] Training Debug Info:
  Loss: 0.388003
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0092, std: 0.9023
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0116, std: 1.3516
  Model pred mean: 0.0149, std: 1.1953
  Sigmas: [0.85546875]... (timesteps: [854.0])

[Step 2910] Training Debug Info:
  Loss: 0.390074
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0237, std: 0.9023
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0198, std: 1.3438
  Model pred mean: -0.0217, std: 1.1953
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 2910] Training Debug Info:
  Loss: 0.578940
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0110, std: 0.9062
  Noise mean: 0.0053, std: 1.0000
  Target mean: 0.0162, std: 1.3516
  Model pred mean: 0.0137, std: 1.1172
  Sigmas: [0.6015625]... (timesteps: [603.0])

[Step 2910] Training Debug Info:
  Loss: 0.688065
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0035, std: 0.8672
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0034, std: 1.3203
  Model pred mean: -0.0034, std: 1.0312
  Sigmas: [0.546875]... (timesteps: [548.0])
Steps:  58%|█████▊    | 2911/5000 [10:49:57<6:55:16, 11.93s/it, loss=1.0791, lr=4.44e-06]Steps:  58%|█████▊    | 2911/5000 [10:49:57<6:55:16, 11.93s/it, loss=0.6881, lr=4.44e-06]Steps:  58%|█████▊    | 2912/5000 [10:50:09<6:56:01, 11.95s/it, loss=0.6881, lr=4.44e-06]Steps:  58%|█████▊    | 2912/5000 [10:50:09<6:56:01, 11.95s/it, loss=0.5166, lr=4.44e-06]Steps:  58%|█████▊    | 2913/5000 [10:50:21<6:57:46, 12.01s/it, loss=0.5166, lr=4.44e-06]Steps:  58%|█████▊    | 2913/5000 [10:50:21<6:57:46, 12.01s/it, loss=0.6467, lr=4.43e-06]Steps:  58%|█████▊    | 2914/5000 [10:50:33<6:57:26, 12.01s/it, loss=0.6467, lr=4.43e-06]Steps:  58%|█████▊    | 2914/5000 [10:50:33<6:57:26, 12.01s/it, loss=0.4135, lr=4.43e-06]Steps:  58%|█████▊    | 2915/5000 [10:50:45<6:55:12, 11.95s/it, loss=0.4135, lr=4.43e-06]Steps:  58%|█████▊    | 2915/5000 [10:50:45<6:55:12, 11.95s/it, loss=1.1089, lr=4.43e-06]Steps:  58%|█████▊    | 2916/5000 [10:50:56<6:54:19, 11.93s/it, loss=1.1089, lr=4.43e-06]Steps:  58%|█████▊    | 2916/5000 [10:50:56<6:54:19, 11.93s/it, loss=1.1162, lr=4.42e-06]Steps:  58%|█████▊    | 2917/5000 [10:51:08<6:54:05, 11.93s/it, loss=1.1162, lr=4.42e-06]Steps:  58%|█████▊    | 2917/5000 [10:51:08<6:54:05, 11.93s/it, loss=1.1112, lr=4.42e-06]Steps:  58%|█████▊    | 2918/5000 [10:51:20<6:53:41, 11.92s/it, loss=1.1112, lr=4.42e-06]Steps:  58%|█████▊    | 2918/5000 [10:51:20<6:53:41, 11.92s/it, loss=0.4307, lr=4.41e-06]Steps:  58%|█████▊    | 2919/5000 [10:51:32<6:53:39, 11.93s/it, loss=0.4307, lr=4.41e-06]Steps:  58%|█████▊    | 2919/5000 [10:51:32<6:53:39, 11.93s/it, loss=1.0796, lr=4.41e-06]Steps:  58%|█████▊    | 2920/5000 [10:51:44<6:54:14, 11.95s/it, loss=1.0796, lr=4.41e-06]Steps:  58%|█████▊    | 2920/5000 [10:51:44<6:54:14, 11.95s/it, loss=0.6702, lr=4.41e-06]
[Step 2920] Training Debug Info:
  Loss: 1.072006
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0479, std: 0.9180
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0493, std: 1.3594
  Model pred mean: -0.0459, std: 0.8750
  Sigmas: [0.056884765625]... (timesteps: [57.0])

[Step 2920] Training Debug Info:
  Loss: 0.688330
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0026, std: 0.8906
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0015, std: 1.3438
  Model pred mean: 0.0041, std: 1.0547
  Sigmas: [0.546875]... (timesteps: [547.0])

[Step 2920] Training Debug Info:
  Loss: 1.077142
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0248, std: 0.8906
  Noise mean: 0.0009, std: 0.9961
  Target mean: 0.0258, std: 1.3438
  Model pred mean: 0.0260, std: 0.8438
  Sigmas: [0.049072265625]... (timesteps: [49.0])

[Step 2920] Training Debug Info:
  Loss: 0.568739
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0142, std: 0.8750
  Noise mean: -0.0036, std: 1.0000
  Target mean: 0.0106, std: 1.3281
  Model pred mean: 0.0138, std: 1.0938
  Sigmas: [0.62890625]... (timesteps: [627.0])
Steps:  58%|█████▊    | 2921/5000 [10:51:56<6:53:09, 11.92s/it, loss=0.6702, lr=4.41e-06]Steps:  58%|█████▊    | 2921/5000 [10:51:56<6:53:09, 11.92s/it, loss=0.5687, lr=4.40e-06]Steps:  58%|█████▊    | 2922/5000 [10:52:08<6:54:04, 11.96s/it, loss=0.5687, lr=4.40e-06]Steps:  58%|█████▊    | 2922/5000 [10:52:08<6:54:04, 11.96s/it, loss=1.0763, lr=4.40e-06]Steps:  58%|█████▊    | 2923/5000 [10:52:20<6:53:57, 11.96s/it, loss=1.0763, lr=4.40e-06]Steps:  58%|█████▊    | 2923/5000 [10:52:20<6:53:57, 11.96s/it, loss=0.5906, lr=4.40e-06]Steps:  58%|█████▊    | 2924/5000 [10:52:32<6:53:21, 11.95s/it, loss=0.5906, lr=4.40e-06]Steps:  58%|█████▊    | 2924/5000 [10:52:32<6:53:21, 11.95s/it, loss=0.4470, lr=4.39e-06]Steps:  58%|█████▊    | 2925/5000 [10:52:44<6:52:12, 11.92s/it, loss=0.4470, lr=4.39e-06]Steps:  58%|█████▊    | 2925/5000 [10:52:44<6:52:12, 11.92s/it, loss=0.7742, lr=4.39e-06]Steps:  59%|█████▊    | 2926/5000 [10:52:56<6:52:09, 11.92s/it, loss=0.7742, lr=4.39e-06]Steps:  59%|█████▊    | 2926/5000 [10:52:56<6:52:09, 11.92s/it, loss=0.9443, lr=4.39e-06]Steps:  59%|█████▊    | 2927/5000 [10:53:08<6:53:03, 11.96s/it, loss=0.9443, lr=4.39e-06]Steps:  59%|█████▊    | 2927/5000 [10:53:08<6:53:03, 11.96s/it, loss=1.1176, lr=4.38e-06]Steps:  59%|█████▊    | 2928/5000 [10:53:20<6:52:34, 11.95s/it, loss=1.1176, lr=4.38e-06]Steps:  59%|█████▊    | 2928/5000 [10:53:20<6:52:34, 11.95s/it, loss=0.8159, lr=4.38e-06]Steps:  59%|█████▊    | 2929/5000 [10:53:32<6:52:28, 11.95s/it, loss=0.8159, lr=4.38e-06]Steps:  59%|█████▊    | 2929/5000 [10:53:32<6:52:28, 11.95s/it, loss=1.1760, lr=4.38e-06]Steps:  59%|█████▊    | 2930/5000 [10:53:44<6:51:43, 11.93s/it, loss=1.1760, lr=4.38e-06]Steps:  59%|█████▊    | 2930/5000 [10:53:44<6:51:43, 11.93s/it, loss=0.6712, lr=4.37e-06]
[Step 2930] Training Debug Info:
  Loss: 0.934824
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0151, std: 0.8789
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0155, std: 1.3281
  Model pred mean: -0.0175, std: 0.9102
  Sigmas: [0.388671875]... (timesteps: [389.0])

[Step 2930] Training Debug Info:
  Loss: 0.417587
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0154, std: 0.9336
  Noise mean: 0.0009, std: 0.9961
  Target mean: 0.0162, std: 1.3672
  Model pred mean: 0.0128, std: 1.2109
  Sigmas: [0.89453125]... (timesteps: [896.0])

[Step 2930] Training Debug Info:
  Loss: 1.070332
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0128, std: 0.9492
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0115, std: 1.3750
  Model pred mean: -0.0139, std: 0.9102
  Sigmas: [0.08984375]... (timesteps: [90.0])

[Step 2930] Training Debug Info:
  Loss: 0.397419
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0161, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0150, std: 1.3672
  Model pred mean: -0.0215, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [861.0])
Steps:  59%|█████▊    | 2931/5000 [10:53:56<6:52:24, 11.96s/it, loss=0.6712, lr=4.37e-06]Steps:  59%|█████▊    | 2931/5000 [10:53:56<6:52:24, 11.96s/it, loss=0.3974, lr=4.37e-06]Steps:  59%|█████▊    | 2932/5000 [10:54:08<6:53:47, 12.01s/it, loss=0.3974, lr=4.37e-06]Steps:  59%|█████▊    | 2932/5000 [10:54:08<6:53:47, 12.01s/it, loss=0.3842, lr=4.37e-06]Steps:  59%|█████▊    | 2933/5000 [10:54:20<6:51:56, 11.96s/it, loss=0.3842, lr=4.37e-06]Steps:  59%|█████▊    | 2933/5000 [10:54:20<6:51:56, 11.96s/it, loss=1.1040, lr=4.36e-06]Steps:  59%|█████▊    | 2934/5000 [10:54:32<6:53:06, 12.00s/it, loss=1.1040, lr=4.36e-06]Steps:  59%|█████▊    | 2934/5000 [10:54:32<6:53:06, 12.00s/it, loss=0.5866, lr=4.36e-06]Steps:  59%|█████▊    | 2935/5000 [10:54:44<6:51:56, 11.97s/it, loss=0.5866, lr=4.36e-06]Steps:  59%|█████▊    | 2935/5000 [10:54:44<6:51:56, 11.97s/it, loss=0.6010, lr=4.36e-06]Steps:  59%|█████▊    | 2936/5000 [10:54:56<6:51:10, 11.95s/it, loss=0.6010, lr=4.36e-06]Steps:  59%|█████▊    | 2936/5000 [10:54:56<6:51:10, 11.95s/it, loss=1.0947, lr=4.35e-06]Steps:  59%|█████▊    | 2937/5000 [10:55:07<6:49:38, 11.91s/it, loss=1.0947, lr=4.35e-06]Steps:  59%|█████▊    | 2937/5000 [10:55:07<6:49:38, 11.91s/it, loss=1.0142, lr=4.35e-06]Steps:  59%|█████▉    | 2938/5000 [10:55:19<6:49:29, 11.92s/it, loss=1.0142, lr=4.35e-06]Steps:  59%|█████▉    | 2938/5000 [10:55:19<6:49:29, 11.92s/it, loss=0.7394, lr=4.35e-06]Steps:  59%|█████▉    | 2939/5000 [10:55:31<6:48:44, 11.90s/it, loss=0.7394, lr=4.35e-06]Steps:  59%|█████▉    | 2939/5000 [10:55:31<6:48:44, 11.90s/it, loss=0.7819, lr=4.34e-06]Steps:  59%|█████▉    | 2940/5000 [10:55:43<6:51:58, 12.00s/it, loss=0.7819, lr=4.34e-06]Steps:  59%|█████▉    | 2940/5000 [10:55:43<6:51:58, 12.00s/it, loss=0.3912, lr=4.34e-06]
[Step 2940] Training Debug Info:
  Loss: 0.645629
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0104, std: 0.9453
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0114, std: 1.3750
  Model pred mean: -0.0077, std: 1.1172
  Sigmas: [0.5390625]... (timesteps: [539.0])

[Step 2940] Training Debug Info:
  Loss: 0.529946
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0065, std: 0.9180
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0090, std: 1.3594
  Model pred mean: -0.0079, std: 1.1484
  Sigmas: [0.59765625]... (timesteps: [598.0])

[Step 2940] Training Debug Info:
  Loss: 1.101405
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0339, std: 0.9648
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0352, std: 1.3906
  Model pred mean: -0.0330, std: 0.9141
  Sigmas: [0.162109375]... (timesteps: [162.0])

[Step 2940] Training Debug Info:
  Loss: 1.109379
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0044, std: 0.9062
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0049, std: 1.3516
  Model pred mean: -0.0039, std: 0.8398
  Sigmas: [0.267578125]... (timesteps: [267.0])
Steps:  59%|█████▉    | 2941/5000 [10:55:55<6:51:33, 11.99s/it, loss=0.3912, lr=4.34e-06]Steps:  59%|█████▉    | 2941/5000 [10:55:55<6:51:33, 11.99s/it, loss=1.1094, lr=4.34e-06]Steps:  59%|█████▉    | 2942/5000 [10:56:07<6:50:09, 11.96s/it, loss=1.1094, lr=4.34e-06]Steps:  59%|█████▉    | 2942/5000 [10:56:07<6:50:09, 11.96s/it, loss=0.8304, lr=4.33e-06]Steps:  59%|█████▉    | 2943/5000 [10:56:19<6:49:37, 11.95s/it, loss=0.8304, lr=4.33e-06]Steps:  59%|█████▉    | 2943/5000 [10:56:19<6:49:37, 11.95s/it, loss=0.6712, lr=4.33e-06]Steps:  59%|█████▉    | 2944/5000 [10:56:31<6:48:40, 11.93s/it, loss=0.6712, lr=4.33e-06]Steps:  59%|█████▉    | 2944/5000 [10:56:31<6:48:40, 11.93s/it, loss=0.7287, lr=4.32e-06]Steps:  59%|█████▉    | 2945/5000 [10:56:43<6:48:25, 11.92s/it, loss=0.7287, lr=4.32e-06]Steps:  59%|█████▉    | 2945/5000 [10:56:43<6:48:25, 11.92s/it, loss=0.3545, lr=4.32e-06]Steps:  59%|█████▉    | 2946/5000 [10:56:55<6:48:03, 11.92s/it, loss=0.3545, lr=4.32e-06]Steps:  59%|█████▉    | 2946/5000 [10:56:55<6:48:03, 11.92s/it, loss=0.5322, lr=4.32e-06]Steps:  59%|█████▉    | 2947/5000 [10:57:07<6:49:24, 11.97s/it, loss=0.5322, lr=4.32e-06]Steps:  59%|█████▉    | 2947/5000 [10:57:07<6:49:24, 11.97s/it, loss=0.9859, lr=4.31e-06]Steps:  59%|█████▉    | 2948/5000 [10:57:19<6:49:10, 11.96s/it, loss=0.9859, lr=4.31e-06]Steps:  59%|█████▉    | 2948/5000 [10:57:19<6:49:10, 11.96s/it, loss=1.1358, lr=4.31e-06]Steps:  59%|█████▉    | 2949/5000 [10:57:31<6:48:34, 11.95s/it, loss=1.1358, lr=4.31e-06]Steps:  59%|█████▉    | 2949/5000 [10:57:31<6:48:34, 11.95s/it, loss=0.9047, lr=4.31e-06]Steps:  59%|█████▉    | 2950/5000 [10:57:43<6:48:38, 11.96s/it, loss=0.9047, lr=4.31e-06]Steps:  59%|█████▉    | 2950/5000 [10:57:43<6:48:38, 11.96s/it, loss=0.4556, lr=4.30e-06]
[Step 2950] Training Debug Info:
  Loss: 1.016484
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0009, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0014, std: 1.3516
  Model pred mean: 0.0038, std: 0.9023
  Sigmas: [0.00799560546875]... (timesteps: [8.0])

[Step 2950] Training Debug Info:
  Loss: 0.411451
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0347, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0334, std: 1.3594
  Model pred mean: 0.0352, std: 1.2031
  Sigmas: [0.94140625]... (timesteps: [942.0])

[Step 2950] Training Debug Info:
  Loss: 0.486855
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0396, std: 0.9648
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0415, std: 1.3828
  Model pred mean: -0.0364, std: 1.1953
  Sigmas: [0.87890625]... (timesteps: [879.0])

[Step 2950] Training Debug Info:
  Loss: 1.138330
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0253, std: 0.9180
  Noise mean: -0.0021, std: 1.0000
  Target mean: 0.0232, std: 1.3594
  Model pred mean: 0.0244, std: 0.8438
  Sigmas: [0.1337890625]... (timesteps: [134.0])
Steps:  59%|█████▉    | 2951/5000 [10:57:55<6:48:01, 11.95s/it, loss=0.4556, lr=4.30e-06]Steps:  59%|█████▉    | 2951/5000 [10:57:55<6:48:01, 11.95s/it, loss=1.1383, lr=4.30e-06]Steps:  59%|█████▉    | 2952/5000 [10:58:07<6:47:31, 11.94s/it, loss=1.1383, lr=4.30e-06]Steps:  59%|█████▉    | 2952/5000 [10:58:07<6:47:31, 11.94s/it, loss=0.4848, lr=4.30e-06]Steps:  59%|█████▉    | 2953/5000 [10:58:19<6:48:00, 11.96s/it, loss=0.4848, lr=4.30e-06]Steps:  59%|█████▉    | 2953/5000 [10:58:19<6:48:00, 11.96s/it, loss=0.5805, lr=4.29e-06]Steps:  59%|█████▉    | 2954/5000 [10:58:31<6:48:54, 11.99s/it, loss=0.5805, lr=4.29e-06]Steps:  59%|█████▉    | 2954/5000 [10:58:31<6:48:54, 11.99s/it, loss=0.5840, lr=4.29e-06]Steps:  59%|█████▉    | 2955/5000 [10:58:43<6:47:23, 11.95s/it, loss=0.5840, lr=4.29e-06]Steps:  59%|█████▉    | 2955/5000 [10:58:43<6:47:23, 11.95s/it, loss=0.5845, lr=4.29e-06]Steps:  59%|█████▉    | 2956/5000 [10:58:55<6:48:00, 11.98s/it, loss=0.5845, lr=4.29e-06]Steps:  59%|█████▉    | 2956/5000 [10:58:55<6:48:00, 11.98s/it, loss=1.0446, lr=4.28e-06]Steps:  59%|█████▉    | 2957/5000 [10:59:07<6:47:26, 11.97s/it, loss=1.0446, lr=4.28e-06]Steps:  59%|█████▉    | 2957/5000 [10:59:07<6:47:26, 11.97s/it, loss=1.0092, lr=4.28e-06]Steps:  59%|█████▉    | 2958/5000 [10:59:18<6:46:09, 11.93s/it, loss=1.0092, lr=4.28e-06]Steps:  59%|█████▉    | 2958/5000 [10:59:18<6:46:09, 11.93s/it, loss=1.1184, lr=4.28e-06]Steps:  59%|█████▉    | 2959/5000 [10:59:30<6:46:20, 11.95s/it, loss=1.1184, lr=4.28e-06]Steps:  59%|█████▉    | 2959/5000 [10:59:30<6:46:20, 11.95s/it, loss=0.9017, lr=4.27e-06]Steps:  59%|█████▉    | 2960/5000 [10:59:42<6:46:05, 11.94s/it, loss=0.9017, lr=4.27e-06]Steps:  59%|█████▉    | 2960/5000 [10:59:42<6:46:05, 11.94s/it, loss=0.5768, lr=4.27e-06]
[Step 2960] Training Debug Info:
  Loss: 0.405225
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0139, std: 0.9375
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0151, std: 1.3750
  Model pred mean: -0.0146, std: 1.2188
  Sigmas: [0.74609375]... (timesteps: [746.0])

[Step 2960] Training Debug Info:
  Loss: 0.609379
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0104, std: 0.9375
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0105, std: 1.3672
  Model pred mean: -0.0105, std: 1.1250
  Sigmas: [0.55078125]... (timesteps: [551.0])

[Step 2960] Training Debug Info:
  Loss: 1.119623
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0006, std: 0.8789
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0019, std: 1.3281
  Model pred mean: -0.0001, std: 0.8086
  Sigmas: [0.255859375]... (timesteps: [256.0])

[Step 2960] Training Debug Info:
  Loss: 0.496379
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0103, std: 0.8906
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0112, std: 1.3359
  Model pred mean: -0.0087, std: 1.1406
  Sigmas: [0.67578125]... (timesteps: [674.0])
Steps:  59%|█████▉    | 2961/5000 [10:59:54<6:47:11, 11.98s/it, loss=0.5768, lr=4.27e-06]Steps:  59%|█████▉    | 2961/5000 [10:59:54<6:47:11, 11.98s/it, loss=0.4964, lr=4.27e-06]Steps:  59%|█████▉    | 2962/5000 [11:00:06<6:45:59, 11.95s/it, loss=0.4964, lr=4.27e-06]Steps:  59%|█████▉    | 2962/5000 [11:00:06<6:45:59, 11.95s/it, loss=0.4998, lr=4.26e-06]Steps:  59%|█████▉    | 2963/5000 [11:00:18<6:47:09, 11.99s/it, loss=0.4998, lr=4.26e-06]Steps:  59%|█████▉    | 2963/5000 [11:00:18<6:47:09, 11.99s/it, loss=0.7167, lr=4.26e-06]Steps:  59%|█████▉    | 2964/5000 [11:00:30<6:45:51, 11.96s/it, loss=0.7167, lr=4.26e-06]Steps:  59%|█████▉    | 2964/5000 [11:00:30<6:45:51, 11.96s/it, loss=0.9964, lr=4.26e-06]Steps:  59%|█████▉    | 2965/5000 [11:00:42<6:45:17, 11.95s/it, loss=0.9964, lr=4.26e-06]Steps:  59%|█████▉    | 2965/5000 [11:00:42<6:45:17, 11.95s/it, loss=0.5332, lr=4.25e-06]Steps:  59%|█████▉    | 2966/5000 [11:00:54<6:44:32, 11.93s/it, loss=0.5332, lr=4.25e-06]Steps:  59%|█████▉    | 2966/5000 [11:00:54<6:44:32, 11.93s/it, loss=0.3590, lr=4.25e-06]Steps:  59%|█████▉    | 2967/5000 [11:01:06<6:44:57, 11.95s/it, loss=0.3590, lr=4.25e-06]Steps:  59%|█████▉    | 2967/5000 [11:01:06<6:44:57, 11.95s/it, loss=0.8440, lr=4.25e-06]Steps:  59%|█████▉    | 2968/5000 [11:01:18<6:45:34, 11.98s/it, loss=0.8440, lr=4.25e-06]Steps:  59%|█████▉    | 2968/5000 [11:01:18<6:45:34, 11.98s/it, loss=1.1040, lr=4.24e-06]Steps:  59%|█████▉    | 2969/5000 [11:01:30<6:44:28, 11.95s/it, loss=1.1040, lr=4.24e-06]Steps:  59%|█████▉    | 2969/5000 [11:01:30<6:44:28, 11.95s/it, loss=0.9276, lr=4.24e-06]Steps:  59%|█████▉    | 2970/5000 [11:01:42<6:44:50, 11.97s/it, loss=0.9276, lr=4.24e-06]Steps:  59%|█████▉    | 2970/5000 [11:01:42<6:44:50, 11.97s/it, loss=1.0988, lr=4.24e-06]01/22/2026 18:47:29 - INFO - __main__ - 
==================================================
01/22/2026 18:47:29 - INFO - __main__ - Epoch 0 completed: avg_loss = 0.7593
01/22/2026 18:47:29 - INFO - __main__ - ==================================================


[Step 2970] Training Debug Info:
  Loss: 0.624237
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0016, std: 0.8984
  Noise mean: -0.0032, std: 1.0000
  Target mean: -0.0016, std: 1.3438
  Model pred mean: -0.0160, std: 1.0703
  Sigmas: [0.96875]... (timesteps: [970.0])

[Step 2970] Training Debug Info:
  Loss: 0.943433
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0481, std: 0.9297
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0479, std: 1.3672
  Model pred mean: -0.0483, std: 0.9609
  Sigmas: [0.275390625]... (timesteps: [276.0])

[Step 2970] Training Debug Info:
  Loss: 0.393720
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0056, std: 0.9102
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0045, std: 1.3516
  Model pred mean: 0.0007, std: 1.1953
  Sigmas: [0.875]... (timesteps: [876.0])

[Step 2970] Training Debug Info:
  Loss: 0.830773
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0054, std: 0.8672
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0054, std: 1.3203
  Model pred mean: 0.0036, std: 0.9609
  Sigmas: [0.46875]... (timesteps: [469.0])
Steps:  59%|█████▉    | 2971/5000 [11:01:56<7:04:44, 12.56s/it, loss=1.0988, lr=4.24e-06]Steps:  59%|█████▉    | 2971/5000 [11:01:56<7:04:44, 12.56s/it, loss=0.8308, lr=4.23e-06]Steps:  59%|█████▉    | 2972/5000 [11:02:08<6:58:00, 12.37s/it, loss=0.8308, lr=4.23e-06]Steps:  59%|█████▉    | 2972/5000 [11:02:08<6:58:00, 12.37s/it, loss=0.9607, lr=4.23e-06]Steps:  59%|█████▉    | 2973/5000 [11:02:20<6:57:18, 12.35s/it, loss=0.9607, lr=4.23e-06]Steps:  59%|█████▉    | 2973/5000 [11:02:20<6:57:18, 12.35s/it, loss=0.6267, lr=4.22e-06]Steps:  59%|█████▉    | 2974/5000 [11:02:32<6:56:27, 12.33s/it, loss=0.6267, lr=4.22e-06]Steps:  59%|█████▉    | 2974/5000 [11:02:32<6:56:27, 12.33s/it, loss=0.5322, lr=4.22e-06]Steps:  60%|█████▉    | 2975/5000 [11:02:44<6:52:40, 12.23s/it, loss=0.5322, lr=4.22e-06]Steps:  60%|█████▉    | 2975/5000 [11:02:44<6:52:40, 12.23s/it, loss=0.5857, lr=4.22e-06]Steps:  60%|█████▉    | 2976/5000 [11:02:57<6:51:26, 12.20s/it, loss=0.5857, lr=4.22e-06]Steps:  60%|█████▉    | 2976/5000 [11:02:57<6:51:26, 12.20s/it, loss=0.5876, lr=4.21e-06]Steps:  60%|█████▉    | 2977/5000 [11:03:08<6:48:29, 12.12s/it, loss=0.5876, lr=4.21e-06]Steps:  60%|█████▉    | 2977/5000 [11:03:08<6:48:29, 12.12s/it, loss=0.6050, lr=4.21e-06]Steps:  60%|█████▉    | 2978/5000 [11:03:20<6:46:12, 12.05s/it, loss=0.6050, lr=4.21e-06]Steps:  60%|█████▉    | 2978/5000 [11:03:20<6:46:12, 12.05s/it, loss=1.0016, lr=4.21e-06]Steps:  60%|█████▉    | 2979/5000 [11:03:32<6:44:54, 12.02s/it, loss=1.0016, lr=4.21e-06]Steps:  60%|█████▉    | 2979/5000 [11:03:32<6:44:54, 12.02s/it, loss=0.9581, lr=4.20e-06]Steps:  60%|█████▉    | 2980/5000 [11:03:44<6:45:46, 12.05s/it, loss=0.9581, lr=4.20e-06]Steps:  60%|█████▉    | 2980/5000 [11:03:44<6:45:46, 12.05s/it, loss=0.9857, lr=4.20e-06]
[Step 2980] Training Debug Info:
  Loss: 0.647368
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0161, std: 0.9336
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0145, std: 1.3672
  Model pred mean: -0.0177, std: 1.1094
  Sigmas: [0.9453125]... (timesteps: [946.0])

[Step 2980] Training Debug Info:
  Loss: 0.357002
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0061, std: 0.9297
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0057, std: 1.3672
  Model pred mean: -0.0034, std: 1.2344
  Sigmas: [0.8203125]... (timesteps: [821.0])

[Step 2980] Training Debug Info:
  Loss: 0.922290
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0109, std: 0.8828
  Noise mean: 0.0036, std: 0.9961
  Target mean: 0.0145, std: 1.3359
  Model pred mean: 0.0112, std: 0.9258
  Sigmas: [0.41015625]... (timesteps: [410.0])

[Step 2980] Training Debug Info:
  Loss: 0.601041
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0141, std: 0.9297
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0128, std: 1.3672
  Model pred mean: -0.0115, std: 1.1172
  Sigmas: [0.498046875]... (timesteps: [499.0])
Steps:  60%|█████▉    | 2981/5000 [11:03:56<6:44:23, 12.02s/it, loss=0.9857, lr=4.20e-06]Steps:  60%|█████▉    | 2981/5000 [11:03:56<6:44:23, 12.02s/it, loss=0.6010, lr=4.20e-06]Steps:  60%|█████▉    | 2982/5000 [11:04:08<6:43:40, 12.00s/it, loss=0.6010, lr=4.20e-06]Steps:  60%|█████▉    | 2982/5000 [11:04:08<6:43:40, 12.00s/it, loss=0.3547, lr=4.19e-06]Steps:  60%|█████▉    | 2983/5000 [11:04:20<6:43:35, 12.01s/it, loss=0.3547, lr=4.19e-06]Steps:  60%|█████▉    | 2983/5000 [11:04:20<6:43:35, 12.01s/it, loss=0.5418, lr=4.19e-06]Steps:  60%|█████▉    | 2984/5000 [11:04:32<6:42:47, 11.99s/it, loss=0.5418, lr=4.19e-06]Steps:  60%|█████▉    | 2984/5000 [11:04:32<6:42:47, 11.99s/it, loss=0.4478, lr=4.19e-06]Steps:  60%|█████▉    | 2985/5000 [11:04:44<6:42:25, 11.98s/it, loss=0.4478, lr=4.19e-06]Steps:  60%|█████▉    | 2985/5000 [11:04:44<6:42:25, 11.98s/it, loss=1.1128, lr=4.18e-06]Steps:  60%|█████▉    | 2986/5000 [11:04:56<6:42:02, 11.98s/it, loss=1.1128, lr=4.18e-06]Steps:  60%|█████▉    | 2986/5000 [11:04:56<6:42:02, 11.98s/it, loss=1.1308, lr=4.18e-06]Steps:  60%|█████▉    | 2987/5000 [11:05:08<6:43:36, 12.03s/it, loss=1.1308, lr=4.18e-06]Steps:  60%|█████▉    | 2987/5000 [11:05:08<6:43:36, 12.03s/it, loss=1.1521, lr=4.18e-06]Steps:  60%|█████▉    | 2988/5000 [11:05:20<6:41:57, 11.99s/it, loss=1.1521, lr=4.18e-06]Steps:  60%|█████▉    | 2988/5000 [11:05:20<6:41:57, 11.99s/it, loss=0.7894, lr=4.17e-06]Steps:  60%|█████▉    | 2989/5000 [11:05:32<6:40:43, 11.96s/it, loss=0.7894, lr=4.17e-06]Steps:  60%|█████▉    | 2989/5000 [11:05:32<6:40:43, 11.96s/it, loss=0.7063, lr=4.17e-06]Steps:  60%|█████▉    | 2990/5000 [11:05:44<6:39:37, 11.93s/it, loss=0.7063, lr=4.17e-06]Steps:  60%|█████▉    | 2990/5000 [11:05:44<6:39:37, 11.93s/it, loss=0.9219, lr=4.17e-06]
[Step 2990] Training Debug Info:
  Loss: 1.197622
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0125, std: 0.8477
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0133, std: 1.3125
  Model pred mean: 0.0110, std: 0.7227
  Sigmas: [0.1474609375]... (timesteps: [147.0])

[Step 2990] Training Debug Info:
  Loss: 0.478858
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0133, std: 0.9062
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0126, std: 1.3438
  Model pred mean: -0.0189, std: 1.1484
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 2990] Training Debug Info:
  Loss: 0.600947
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0032, std: 0.8984
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0059, std: 1.3438
  Model pred mean: 0.0048, std: 1.1016
  Sigmas: [0.5859375]... (timesteps: [586.0])

[Step 2990] Training Debug Info:
  Loss: 1.040641
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0347, std: 0.9102
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0366, std: 1.3516
  Model pred mean: -0.0330, std: 0.8945
  Sigmas: [0.326171875]... (timesteps: [327.0])
Steps:  60%|█████▉    | 2991/5000 [11:05:56<6:38:33, 11.90s/it, loss=0.9219, lr=4.17e-06]Steps:  60%|█████▉    | 2991/5000 [11:05:56<6:38:33, 11.90s/it, loss=1.0406, lr=4.16e-06]Steps:  60%|█████▉    | 2992/5000 [11:06:08<6:39:32, 11.94s/it, loss=1.0406, lr=4.16e-06]Steps:  60%|█████▉    | 2992/5000 [11:06:08<6:39:32, 11.94s/it, loss=0.7539, lr=4.16e-06]Steps:  60%|█████▉    | 2993/5000 [11:06:20<6:40:00, 11.96s/it, loss=0.7539, lr=4.16e-06]Steps:  60%|█████▉    | 2993/5000 [11:06:20<6:40:00, 11.96s/it, loss=1.0791, lr=4.16e-06]Steps:  60%|█████▉    | 2994/5000 [11:06:32<6:41:58, 12.02s/it, loss=1.0791, lr=4.16e-06]Steps:  60%|█████▉    | 2994/5000 [11:06:32<6:41:58, 12.02s/it, loss=0.6774, lr=4.15e-06]Steps:  60%|█████▉    | 2995/5000 [11:06:44<6:39:50, 11.97s/it, loss=0.6774, lr=4.15e-06]Steps:  60%|█████▉    | 2995/5000 [11:06:44<6:39:50, 11.97s/it, loss=0.4071, lr=4.15e-06]Steps:  60%|█████▉    | 2996/5000 [11:06:56<6:39:23, 11.96s/it, loss=0.4071, lr=4.15e-06]Steps:  60%|█████▉    | 2996/5000 [11:06:56<6:39:23, 11.96s/it, loss=0.6989, lr=4.15e-06]Steps:  60%|█████▉    | 2997/5000 [11:07:08<6:39:06, 11.96s/it, loss=0.6989, lr=4.15e-06]Steps:  60%|█████▉    | 2997/5000 [11:07:08<6:39:06, 11.96s/it, loss=0.3594, lr=4.14e-06]Steps:  60%|█████▉    | 2998/5000 [11:07:20<6:38:52, 11.95s/it, loss=0.3594, lr=4.14e-06]Steps:  60%|█████▉    | 2998/5000 [11:07:20<6:38:52, 11.95s/it, loss=1.1710, lr=4.14e-06]Steps:  60%|█████▉    | 2999/5000 [11:07:32<6:37:04, 11.91s/it, loss=1.1710, lr=4.14e-06]Steps:  60%|█████▉    | 2999/5000 [11:07:32<6:37:04, 11.91s/it, loss=1.1005, lr=4.14e-06]Steps:  60%|██████    | 3000/5000 [11:07:43<6:37:06, 11.91s/it, loss=1.1005, lr=4.14e-06]Steps:  60%|██████    | 3000/5000 [11:07:43<6:37:06, 11.91s/it, loss=0.4042, lr=4.13e-06]01/22/2026 18:53:30 - INFO - __main__ - 
[Step 3000] ✅ Loss in normal range (0.4042)
01/22/2026 18:53:30 - INFO - __main__ -   Loss avg (last 100): 0.7788
01/22/2026 18:53:30 - INFO - __main__ -   Loss range: [0.3545, 1.1760]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/transformer/diffusion_pytorch_model.safetensors
01/22/2026 18:54:43 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000
01/22/2026 18:54:43 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/accelerator
01/22/2026 18:54:43 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/22/2026 18:56:53 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/accelerator/pytorch_model
01/22/2026 18:56:53 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/accelerator/scheduler.bin
01/22/2026 18:56:53 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/accelerator/sampler.bin
01/22/2026 18:56:53 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-3000/accelerator/random_states_0.pkl
01/22/2026 18:56:53 - INFO - __main__ - Removing 1 old checkpoints
01/22/2026 18:57:39 - INFO - __main__ - 
🔍 Running validation at step 3000...
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3000 (parquet mode)...
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3000...
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 18:57:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.50it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.49it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.46it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.46it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.46it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 18:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 18:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 18:58:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 18:58:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 18:58:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 18:58:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 18:59:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 18:59:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 18:59:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 18:59:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 18:59:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 18:59:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:00:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 19:00:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.41it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:00:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 19:00:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.59it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:00:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 19:00:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 19:01:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 19:01:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.41it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.41it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 19:01:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 19:01:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 19:01:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000/step003000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 19:01:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 19:01:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 19:01:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003000
01/22/2026 19:01:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 3000] Training Debug Info:
  Loss: 0.473721
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0045, std: 0.9023
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0068, std: 1.3438
  Model pred mean: -0.0028, std: 1.1562
  Sigmas: [0.66796875]... (timesteps: [667.0])

[Step 3000] Training Debug Info:
  Loss: 0.753245
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0266, std: 0.9023
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0277, std: 1.3438
  Model pred mean: 0.0238, std: 1.0391
  Sigmas: [0.462890625]... (timesteps: [463.0])

[Step 3000] Training Debug Info:
  Loss: 1.058873
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0231, std: 0.9297
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0250, std: 1.3672
  Model pred mean: -0.0215, std: 0.8945
  Sigmas: [0.04296875]... (timesteps: [43.0])

[Step 3000] Training Debug Info:
  Loss: 0.923877
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0043, std: 0.8945
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0046, std: 1.3438
  Model pred mean: -0.0067, std: 0.9414
  Sigmas: [0.408203125]... (timesteps: [409.0])
Steps:  60%|██████    | 3001/5000 [11:16:24<91:18:40, 164.44s/it, loss=0.4042, lr=4.13e-06]Steps:  60%|██████    | 3001/5000 [11:16:24<91:18:40, 164.44s/it, loss=0.9239, lr=4.13e-06]Steps:  60%|██████    | 3002/5000 [11:16:36<65:52:07, 118.68s/it, loss=0.9239, lr=4.13e-06]Steps:  60%|██████    | 3002/5000 [11:16:36<65:52:07, 118.68s/it, loss=0.9276, lr=4.12e-06]Steps:  60%|██████    | 3003/5000 [11:16:48<48:03:42, 86.64s/it, loss=0.9276, lr=4.12e-06] Steps:  60%|██████    | 3003/5000 [11:16:48<48:03:42, 86.64s/it, loss=1.1696, lr=4.12e-06]Steps:  60%|██████    | 3004/5000 [11:17:00<35:37:26, 64.25s/it, loss=1.1696, lr=4.12e-06]Steps:  60%|██████    | 3004/5000 [11:17:00<35:37:26, 64.25s/it, loss=0.5879, lr=4.12e-06]Steps:  60%|██████    | 3005/5000 [11:17:12<26:54:45, 48.56s/it, loss=0.5879, lr=4.12e-06]Steps:  60%|██████    | 3005/5000 [11:17:12<26:54:45, 48.56s/it, loss=0.4201, lr=4.11e-06]Steps:  60%|██████    | 3006/5000 [11:17:24<20:51:31, 37.66s/it, loss=0.4201, lr=4.11e-06]Steps:  60%|██████    | 3006/5000 [11:17:24<20:51:31, 37.66s/it, loss=1.0906, lr=4.11e-06]Steps:  60%|██████    | 3007/5000 [11:17:36<16:34:47, 29.95s/it, loss=1.0906, lr=4.11e-06]Steps:  60%|██████    | 3007/5000 [11:17:36<16:34:47, 29.95s/it, loss=1.1318, lr=4.11e-06]Steps:  60%|██████    | 3008/5000 [11:17:48<13:34:58, 24.55s/it, loss=1.1318, lr=4.11e-06]Steps:  60%|██████    | 3008/5000 [11:17:48<13:34:58, 24.55s/it, loss=0.4757, lr=4.10e-06]Steps:  60%|██████    | 3009/5000 [11:18:00<11:29:02, 20.76s/it, loss=0.4757, lr=4.10e-06]Steps:  60%|██████    | 3009/5000 [11:18:00<11:29:02, 20.76s/it, loss=1.1366, lr=4.10e-06]Steps:  60%|██████    | 3010/5000 [11:18:12<10:00:56, 18.12s/it, loss=1.1366, lr=4.10e-06]Steps:  60%|██████    | 3010/5000 [11:18:12<10:00:56, 18.12s/it, loss=0.3934, lr=4.10e-06]
[Step 3010] Training Debug Info:
  Loss: 0.458295
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0229, std: 0.9570
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0249, std: 1.3828
  Model pred mean: -0.0288, std: 1.2031
  Sigmas: [0.82421875]... (timesteps: [825.0])

[Step 3010] Training Debug Info:
  Loss: 0.831249
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0142, std: 0.9531
  Noise mean: -0.0031, std: 1.0000
  Target mean: 0.0111, std: 1.3828
  Model pred mean: 0.0132, std: 1.0391
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 3010] Training Debug Info:
  Loss: 0.637802
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0227, std: 0.8594
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0244, std: 1.3203
  Model pred mean: 0.0231, std: 1.0469
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 3010] Training Debug Info:
  Loss: 1.109152
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0354, std: 0.9297
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0361, std: 1.3672
  Model pred mean: -0.0344, std: 0.8672
  Sigmas: [0.10888671875]... (timesteps: [109.0])
Steps:  60%|██████    | 3011/5000 [11:18:23<8:58:53, 16.26s/it, loss=0.3934, lr=4.10e-06] Steps:  60%|██████    | 3011/5000 [11:18:23<8:58:53, 16.26s/it, loss=1.1092, lr=4.09e-06]Steps:  60%|██████    | 3012/5000 [11:18:35<8:15:07, 14.94s/it, loss=1.1092, lr=4.09e-06]Steps:  60%|██████    | 3012/5000 [11:18:35<8:15:07, 14.94s/it, loss=0.3798, lr=4.09e-06]Steps:  60%|██████    | 3013/5000 [11:18:48<7:48:31, 14.15s/it, loss=0.3798, lr=4.09e-06]Steps:  60%|██████    | 3013/5000 [11:18:48<7:48:31, 14.15s/it, loss=0.4873, lr=4.09e-06]Steps:  60%|██████    | 3014/5000 [11:19:00<7:26:31, 13.49s/it, loss=0.4873, lr=4.09e-06]Steps:  60%|██████    | 3014/5000 [11:19:00<7:26:31, 13.49s/it, loss=1.2129, lr=4.08e-06]Steps:  60%|██████    | 3015/5000 [11:19:12<7:11:37, 13.05s/it, loss=1.2129, lr=4.08e-06]Steps:  60%|██████    | 3015/5000 [11:19:12<7:11:37, 13.05s/it, loss=0.3737, lr=4.08e-06]Steps:  60%|██████    | 3016/5000 [11:19:23<6:59:44, 12.69s/it, loss=0.3737, lr=4.08e-06]Steps:  60%|██████    | 3016/5000 [11:19:23<6:59:44, 12.69s/it, loss=1.0327, lr=4.08e-06]Steps:  60%|██████    | 3017/5000 [11:19:35<6:51:42, 12.46s/it, loss=1.0327, lr=4.08e-06]Steps:  60%|██████    | 3017/5000 [11:19:35<6:51:42, 12.46s/it, loss=1.0925, lr=4.07e-06]Steps:  60%|██████    | 3018/5000 [11:19:47<6:46:19, 12.30s/it, loss=1.0925, lr=4.07e-06]Steps:  60%|██████    | 3018/5000 [11:19:47<6:46:19, 12.30s/it, loss=0.5197, lr=4.07e-06]Steps:  60%|██████    | 3019/5000 [11:19:59<6:41:53, 12.17s/it, loss=0.5197, lr=4.07e-06]Steps:  60%|██████    | 3019/5000 [11:19:59<6:41:53, 12.17s/it, loss=1.0395, lr=4.07e-06]Steps:  60%|██████    | 3020/5000 [11:20:11<6:41:18, 12.16s/it, loss=1.0395, lr=4.07e-06]Steps:  60%|██████    | 3020/5000 [11:20:11<6:41:18, 12.16s/it, loss=0.5810, lr=4.06e-06]
[Step 3020] Training Debug Info:
  Loss: 0.652238
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0205, std: 0.8945
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0220, std: 1.3438
  Model pred mean: 0.0197, std: 1.0703
  Sigmas: [0.55078125]... (timesteps: [550.0])

[Step 3020] Training Debug Info:
  Loss: 0.770230
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0145, std: 0.8711
  Noise mean: -0.0003, std: 0.9961
  Target mean: -0.0148, std: 1.3203
  Model pred mean: -0.0139, std: 0.9961
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 3020] Training Debug Info:
  Loss: 0.357799
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0361, std: 0.9336
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0347, std: 1.3672
  Model pred mean: -0.0337, std: 1.2344
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 3020] Training Debug Info:
  Loss: 1.078727
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0152, std: 0.9102
  Noise mean: -0.0004, std: 0.9961
  Target mean: 0.0148, std: 1.3516
  Model pred mean: 0.0171, std: 0.8633
  Sigmas: [0.052978515625]... (timesteps: [53.0])
Steps:  60%|██████    | 3021/5000 [11:20:23<6:38:38, 12.09s/it, loss=0.5810, lr=4.06e-06]Steps:  60%|██████    | 3021/5000 [11:20:23<6:38:38, 12.09s/it, loss=1.0787, lr=4.06e-06]Steps:  60%|██████    | 3022/5000 [11:20:35<6:37:12, 12.05s/it, loss=1.0787, lr=4.06e-06]Steps:  60%|██████    | 3022/5000 [11:20:35<6:37:12, 12.05s/it, loss=0.5522, lr=4.06e-06]Steps:  60%|██████    | 3023/5000 [11:20:47<6:36:02, 12.02s/it, loss=0.5522, lr=4.06e-06]Steps:  60%|██████    | 3023/5000 [11:20:47<6:36:02, 12.02s/it, loss=0.3881, lr=4.05e-06]Steps:  60%|██████    | 3024/5000 [11:20:59<6:35:56, 12.02s/it, loss=0.3881, lr=4.05e-06]Steps:  60%|██████    | 3024/5000 [11:20:59<6:35:56, 12.02s/it, loss=0.7172, lr=4.05e-06]Steps:  60%|██████    | 3025/5000 [11:21:11<6:34:56, 12.00s/it, loss=0.7172, lr=4.05e-06]Steps:  60%|██████    | 3025/5000 [11:21:11<6:34:56, 12.00s/it, loss=1.1991, lr=4.05e-06]Steps:  61%|██████    | 3026/5000 [11:21:23<6:34:40, 12.00s/it, loss=1.1991, lr=4.05e-06]Steps:  61%|██████    | 3026/5000 [11:21:23<6:34:40, 12.00s/it, loss=0.9565, lr=4.04e-06]Steps:  61%|██████    | 3027/5000 [11:21:35<6:36:25, 12.06s/it, loss=0.9565, lr=4.04e-06]Steps:  61%|██████    | 3027/5000 [11:21:35<6:36:25, 12.06s/it, loss=0.4246, lr=4.04e-06]Steps:  61%|██████    | 3028/5000 [11:21:47<6:34:46, 12.01s/it, loss=0.4246, lr=4.04e-06]Steps:  61%|██████    | 3028/5000 [11:21:47<6:34:46, 12.01s/it, loss=0.9222, lr=4.04e-06]Steps:  61%|██████    | 3029/5000 [11:21:59<6:33:56, 11.99s/it, loss=0.9222, lr=4.04e-06]Steps:  61%|██████    | 3029/5000 [11:21:59<6:33:56, 11.99s/it, loss=1.1869, lr=4.03e-06]Steps:  61%|██████    | 3030/5000 [11:22:11<6:33:28, 11.98s/it, loss=1.1869, lr=4.03e-06]Steps:  61%|██████    | 3030/5000 [11:22:11<6:33:28, 11.98s/it, loss=0.4224, lr=4.03e-06]
[Step 3030] Training Debug Info:
  Loss: 1.088426
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0134, std: 0.9180
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0146, std: 1.3594
  Model pred mean: -0.0129, std: 0.8750
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 3030] Training Debug Info:
  Loss: 1.119521
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0070, std: 0.9336
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0053, std: 1.3672
  Model pred mean: -0.0077, std: 0.8672
  Sigmas: [0.12890625]... (timesteps: [129.0])

[Step 3030] Training Debug Info:
  Loss: 0.920199
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0105, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0114, std: 1.3516
  Model pred mean: -0.0109, std: 0.9492
  Sigmas: [0.37109375]... (timesteps: [371.0])

[Step 3030] Training Debug Info:
  Loss: 1.085012
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0255, std: 0.9883
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0261, std: 1.4062
  Model pred mean: -0.0280, std: 0.9453
  Sigmas: [0.051025390625]... (timesteps: [51.0])
Steps:  61%|██████    | 3031/5000 [11:22:23<6:32:38, 11.96s/it, loss=0.4224, lr=4.03e-06]Steps:  61%|██████    | 3031/5000 [11:22:23<6:32:38, 11.96s/it, loss=1.0850, lr=4.03e-06]Steps:  61%|██████    | 3032/5000 [11:22:35<6:31:51, 11.95s/it, loss=1.0850, lr=4.03e-06]Steps:  61%|██████    | 3032/5000 [11:22:35<6:31:51, 11.95s/it, loss=1.2282, lr=4.02e-06]Steps:  61%|██████    | 3033/5000 [11:22:47<6:35:40, 12.07s/it, loss=1.2282, lr=4.02e-06]Steps:  61%|██████    | 3033/5000 [11:22:47<6:35:40, 12.07s/it, loss=1.0931, lr=4.02e-06]Steps:  61%|██████    | 3034/5000 [11:22:59<6:33:53, 12.02s/it, loss=1.0931, lr=4.02e-06]Steps:  61%|██████    | 3034/5000 [11:22:59<6:33:53, 12.02s/it, loss=1.0962, lr=4.02e-06]Steps:  61%|██████    | 3035/5000 [11:23:11<6:32:55, 12.00s/it, loss=1.0962, lr=4.02e-06]Steps:  61%|██████    | 3035/5000 [11:23:11<6:32:55, 12.00s/it, loss=0.4497, lr=4.01e-06]Steps:  61%|██████    | 3036/5000 [11:23:23<6:31:07, 11.95s/it, loss=0.4497, lr=4.01e-06]Steps:  61%|██████    | 3036/5000 [11:23:23<6:31:07, 11.95s/it, loss=0.7127, lr=4.01e-06]Steps:  61%|██████    | 3037/5000 [11:23:35<6:30:54, 11.95s/it, loss=0.7127, lr=4.01e-06]Steps:  61%|██████    | 3037/5000 [11:23:35<6:30:54, 11.95s/it, loss=0.7433, lr=4.00e-06]Steps:  61%|██████    | 3038/5000 [11:23:47<6:30:27, 11.94s/it, loss=0.7433, lr=4.00e-06]Steps:  61%|██████    | 3038/5000 [11:23:47<6:30:27, 11.94s/it, loss=0.4812, lr=4.00e-06]Steps:  61%|██████    | 3039/5000 [11:23:59<6:29:21, 11.91s/it, loss=0.4812, lr=4.00e-06]Steps:  61%|██████    | 3039/5000 [11:23:59<6:29:21, 11.91s/it, loss=0.5355, lr=4.00e-06]Steps:  61%|██████    | 3040/5000 [11:24:11<6:32:11, 12.01s/it, loss=0.5355, lr=4.00e-06]Steps:  61%|██████    | 3040/5000 [11:24:11<6:32:11, 12.01s/it, loss=0.4142, lr=3.99e-06]
[Step 3040] Training Debug Info:
  Loss: 0.850349
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0089, std: 0.9141
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0072, std: 1.3516
  Model pred mean: 0.0106, std: 0.9844
  Sigmas: [0.3984375]... (timesteps: [399.0])

[Step 3040] Training Debug Info:
  Loss: 0.379430
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0261, std: 0.9375
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0250, std: 1.3750
  Model pred mean: -0.0225, std: 1.2344
  Sigmas: [0.8046875]... (timesteps: [804.0])

[Step 3040] Training Debug Info:
  Loss: 0.330898
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0010, std: 0.8828
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0021, std: 1.3359
  Model pred mean: 0.0106, std: 1.1953
  Sigmas: [0.89453125]... (timesteps: [894.0])

[Step 3040] Training Debug Info:
  Loss: 0.421527
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0242, std: 0.9219
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0227, std: 1.3594
  Model pred mean: -0.0233, std: 1.1953
  Sigmas: [0.78515625]... (timesteps: [785.0])
Steps:  61%|██████    | 3041/5000 [11:24:23<6:31:12, 11.98s/it, loss=0.4142, lr=3.99e-06]Steps:  61%|██████    | 3041/5000 [11:24:23<6:31:12, 11.98s/it, loss=0.4215, lr=3.99e-06]Steps:  61%|██████    | 3042/5000 [11:24:35<6:32:16, 12.02s/it, loss=0.4215, lr=3.99e-06]Steps:  61%|██████    | 3042/5000 [11:24:35<6:32:16, 12.02s/it, loss=0.8980, lr=3.99e-06]Steps:  61%|██████    | 3043/5000 [11:24:47<6:31:17, 12.00s/it, loss=0.8980, lr=3.99e-06]Steps:  61%|██████    | 3043/5000 [11:24:47<6:31:17, 12.00s/it, loss=0.8163, lr=3.98e-06]Steps:  61%|██████    | 3044/5000 [11:24:59<6:30:41, 11.98s/it, loss=0.8163, lr=3.98e-06]Steps:  61%|██████    | 3044/5000 [11:24:59<6:30:41, 11.98s/it, loss=1.1956, lr=3.98e-06]Steps:  61%|██████    | 3045/5000 [11:25:11<6:30:20, 11.98s/it, loss=1.1956, lr=3.98e-06]Steps:  61%|██████    | 3045/5000 [11:25:11<6:30:20, 11.98s/it, loss=0.4413, lr=3.98e-06]Steps:  61%|██████    | 3046/5000 [11:25:23<6:29:26, 11.96s/it, loss=0.4413, lr=3.98e-06]Steps:  61%|██████    | 3046/5000 [11:25:23<6:29:26, 11.96s/it, loss=1.0004, lr=3.97e-06]Steps:  61%|██████    | 3047/5000 [11:25:35<6:32:14, 12.05s/it, loss=1.0004, lr=3.97e-06]Steps:  61%|██████    | 3047/5000 [11:25:35<6:32:14, 12.05s/it, loss=0.5137, lr=3.97e-06]Steps:  61%|██████    | 3048/5000 [11:25:47<6:30:02, 11.99s/it, loss=0.5137, lr=3.97e-06]Steps:  61%|██████    | 3048/5000 [11:25:47<6:30:02, 11.99s/it, loss=0.6093, lr=3.97e-06]Steps:  61%|██████    | 3049/5000 [11:25:59<6:29:04, 11.97s/it, loss=0.6093, lr=3.97e-06]Steps:  61%|██████    | 3049/5000 [11:25:59<6:29:04, 11.97s/it, loss=1.0213, lr=3.96e-06]Steps:  61%|██████    | 3050/5000 [11:26:11<6:28:24, 11.95s/it, loss=1.0213, lr=3.96e-06]Steps:  61%|██████    | 3050/5000 [11:26:11<6:28:24, 11.95s/it, loss=1.1519, lr=3.96e-06]
[Step 3050] Training Debug Info:
  Loss: 1.093220
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0031, std: 0.8984
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0014, std: 1.3438
  Model pred mean: -0.0005, std: 0.8477
  Sigmas: [0.279296875]... (timesteps: [279.0])

[Step 3050] Training Debug Info:
  Loss: 0.503831
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0310, std: 0.9062
  Noise mean: -0.0037, std: 1.0000
  Target mean: -0.0347, std: 1.3516
  Model pred mean: -0.0344, std: 1.1484
  Sigmas: [0.62109375]... (timesteps: [620.0])

[Step 3050] Training Debug Info:
  Loss: 1.127412
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0009, std: 0.8906
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0026, std: 1.3359
  Model pred mean: 0.0037, std: 0.8086
  Sigmas: [0.0869140625]... (timesteps: [87.0])

[Step 3050] Training Debug Info:
  Loss: 0.451385
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0227, std: 0.8867
  Noise mean: -0.0038, std: 1.0000
  Target mean: 0.0189, std: 1.3359
  Model pred mean: 0.0160, std: 1.1562
  Sigmas: [0.859375]... (timesteps: [860.0])
Steps:  61%|██████    | 3051/5000 [11:26:23<6:29:12, 11.98s/it, loss=1.1519, lr=3.96e-06]Steps:  61%|██████    | 3051/5000 [11:26:23<6:29:12, 11.98s/it, loss=0.4514, lr=3.96e-06]Steps:  61%|██████    | 3052/5000 [11:26:35<6:28:49, 11.98s/it, loss=0.4514, lr=3.96e-06]Steps:  61%|██████    | 3052/5000 [11:26:35<6:28:49, 11.98s/it, loss=1.1110, lr=3.95e-06]Steps:  61%|██████    | 3053/5000 [11:26:47<6:27:51, 11.95s/it, loss=1.1110, lr=3.95e-06]Steps:  61%|██████    | 3053/5000 [11:26:47<6:27:51, 11.95s/it, loss=0.7422, lr=3.95e-06]Steps:  61%|██████    | 3054/5000 [11:26:59<6:29:55, 12.02s/it, loss=0.7422, lr=3.95e-06]Steps:  61%|██████    | 3054/5000 [11:26:59<6:29:55, 12.02s/it, loss=0.4054, lr=3.95e-06]Steps:  61%|██████    | 3055/5000 [11:27:11<6:29:03, 12.00s/it, loss=0.4054, lr=3.95e-06]Steps:  61%|██████    | 3055/5000 [11:27:11<6:29:03, 12.00s/it, loss=0.3456, lr=3.94e-06]Steps:  61%|██████    | 3056/5000 [11:27:23<6:28:06, 11.98s/it, loss=0.3456, lr=3.94e-06]Steps:  61%|██████    | 3056/5000 [11:27:23<6:28:06, 11.98s/it, loss=0.8295, lr=3.94e-06]Steps:  61%|██████    | 3057/5000 [11:27:35<6:26:40, 11.94s/it, loss=0.8295, lr=3.94e-06]Steps:  61%|██████    | 3057/5000 [11:27:35<6:26:40, 11.94s/it, loss=0.5130, lr=3.94e-06]Steps:  61%|██████    | 3058/5000 [11:27:46<6:26:36, 11.94s/it, loss=0.5130, lr=3.94e-06]Steps:  61%|██████    | 3058/5000 [11:27:46<6:26:36, 11.94s/it, loss=1.1402, lr=3.93e-06]Steps:  61%|██████    | 3059/5000 [11:27:58<6:26:57, 11.96s/it, loss=1.1402, lr=3.93e-06]Steps:  61%|██████    | 3059/5000 [11:27:58<6:26:57, 11.96s/it, loss=0.4844, lr=3.93e-06]Steps:  61%|██████    | 3060/5000 [11:28:11<6:28:56, 12.03s/it, loss=0.4844, lr=3.93e-06]Steps:  61%|██████    | 3060/5000 [11:28:11<6:28:56, 12.03s/it, loss=0.3725, lr=3.93e-06]
[Step 3060] Training Debug Info:
  Loss: 0.637170
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0201, std: 0.8867
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0212, std: 1.3359
  Model pred mean: -0.0032, std: 1.0781
  Sigmas: [0.99609375]... (timesteps: [997.0])

[Step 3060] Training Debug Info:
  Loss: 0.375906
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0059, std: 0.9258
  Noise mean: 0.0040, std: 1.0000
  Target mean: -0.0019, std: 1.3594
  Model pred mean: -0.0058, std: 1.2266
  Sigmas: [0.8515625]... (timesteps: [853.0])

[Step 3060] Training Debug Info:
  Loss: 1.089770
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0366, std: 0.9414
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0383, std: 1.3750
  Model pred mean: -0.0361, std: 0.8906
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 3060] Training Debug Info:
  Loss: 0.497197
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0050, std: 0.8594
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0063, std: 1.3203
  Model pred mean: -0.0036, std: 1.1094
  Sigmas: [0.6875]... (timesteps: [687.0])
Steps:  61%|██████    | 3061/5000 [11:28:23<6:27:54, 12.00s/it, loss=0.3725, lr=3.93e-06]Steps:  61%|██████    | 3061/5000 [11:28:23<6:27:54, 12.00s/it, loss=0.4972, lr=3.92e-06]Steps:  61%|██████    | 3062/5000 [11:28:35<6:27:11, 11.99s/it, loss=0.4972, lr=3.92e-06]Steps:  61%|██████    | 3062/5000 [11:28:35<6:27:11, 11.99s/it, loss=0.4206, lr=3.92e-06]Steps:  61%|██████▏   | 3063/5000 [11:28:47<6:26:43, 11.98s/it, loss=0.4206, lr=3.92e-06]Steps:  61%|██████▏   | 3063/5000 [11:28:47<6:26:43, 11.98s/it, loss=0.6538, lr=3.92e-06]Steps:  61%|██████▏   | 3064/5000 [11:28:58<6:26:12, 11.97s/it, loss=0.6538, lr=3.92e-06]Steps:  61%|██████▏   | 3064/5000 [11:28:58<6:26:12, 11.97s/it, loss=1.1061, lr=3.91e-06]Steps:  61%|██████▏   | 3065/5000 [11:29:10<6:24:38, 11.93s/it, loss=1.1061, lr=3.91e-06]Steps:  61%|██████▏   | 3065/5000 [11:29:10<6:24:38, 11.93s/it, loss=0.3918, lr=3.91e-06]Steps:  61%|██████▏   | 3066/5000 [11:29:22<6:24:00, 11.91s/it, loss=0.3918, lr=3.91e-06]Steps:  61%|██████▏   | 3066/5000 [11:29:22<6:24:00, 11.91s/it, loss=0.3755, lr=3.91e-06]Steps:  61%|██████▏   | 3067/5000 [11:29:34<6:25:57, 11.98s/it, loss=0.3755, lr=3.91e-06]Steps:  61%|██████▏   | 3067/5000 [11:29:34<6:25:57, 11.98s/it, loss=0.6029, lr=3.90e-06]Steps:  61%|██████▏   | 3068/5000 [11:29:46<6:25:37, 11.98s/it, loss=0.6029, lr=3.90e-06]Steps:  61%|██████▏   | 3068/5000 [11:29:46<6:25:37, 11.98s/it, loss=1.0706, lr=3.90e-06]Steps:  61%|██████▏   | 3069/5000 [11:29:58<6:25:36, 11.98s/it, loss=1.0706, lr=3.90e-06]Steps:  61%|██████▏   | 3069/5000 [11:29:58<6:25:36, 11.98s/it, loss=0.4813, lr=3.90e-06]Steps:  61%|██████▏   | 3070/5000 [11:30:10<6:25:36, 11.99s/it, loss=0.4813, lr=3.90e-06]Steps:  61%|██████▏   | 3070/5000 [11:30:10<6:25:36, 11.99s/it, loss=0.3776, lr=3.89e-06]
[Step 3070] Training Debug Info:
  Loss: 1.019822
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0334, std: 0.9297
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0344, std: 1.3594
  Model pred mean: -0.0342, std: 0.9141
  Sigmas: [0.25]... (timesteps: [250.0])

[Step 3070] Training Debug Info:
  Loss: 0.781822
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0059, std: 0.9180
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0065, std: 1.3594
  Model pred mean: -0.0080, std: 1.0312
  Sigmas: [0.46484375]... (timesteps: [464.0])

[Step 3070] Training Debug Info:
  Loss: 0.379114
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0021, std: 0.9688
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0035, std: 1.3906
  Model pred mean: 0.0015, std: 1.2500
  Sigmas: [0.76171875]... (timesteps: [762.0])

[Step 3070] Training Debug Info:
  Loss: 0.499574
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0198, std: 0.9883
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0217, std: 1.4062
  Model pred mean: -0.0231, std: 1.2109
  Sigmas: [0.7890625]... (timesteps: [791.0])
Steps:  61%|██████▏   | 3071/5000 [11:30:22<6:25:25, 11.99s/it, loss=0.3776, lr=3.89e-06]Steps:  61%|██████▏   | 3071/5000 [11:30:22<6:25:25, 11.99s/it, loss=0.4996, lr=3.89e-06]Steps:  61%|██████▏   | 3072/5000 [11:30:34<6:25:05, 11.98s/it, loss=0.4996, lr=3.89e-06]Steps:  61%|██████▏   | 3072/5000 [11:30:34<6:25:05, 11.98s/it, loss=0.5630, lr=3.89e-06]Steps:  61%|██████▏   | 3073/5000 [11:30:46<6:25:00, 11.99s/it, loss=0.5630, lr=3.89e-06]Steps:  61%|██████▏   | 3073/5000 [11:30:46<6:25:00, 11.99s/it, loss=0.3552, lr=3.88e-06]Steps:  61%|██████▏   | 3074/5000 [11:30:58<6:26:39, 12.05s/it, loss=0.3552, lr=3.88e-06]Steps:  61%|██████▏   | 3074/5000 [11:30:58<6:26:39, 12.05s/it, loss=1.1985, lr=3.88e-06]Steps:  62%|██████▏   | 3075/5000 [11:31:10<6:25:36, 12.02s/it, loss=1.1985, lr=3.88e-06]Steps:  62%|██████▏   | 3075/5000 [11:31:10<6:25:36, 12.02s/it, loss=0.5458, lr=3.88e-06]Steps:  62%|██████▏   | 3076/5000 [11:31:22<6:25:09, 12.01s/it, loss=0.5458, lr=3.88e-06]Steps:  62%|██████▏   | 3076/5000 [11:31:22<6:25:09, 12.01s/it, loss=0.5211, lr=3.87e-06]Steps:  62%|██████▏   | 3077/5000 [11:31:34<6:23:58, 11.98s/it, loss=0.5211, lr=3.87e-06]Steps:  62%|██████▏   | 3077/5000 [11:31:34<6:23:58, 11.98s/it, loss=1.0891, lr=3.87e-06]Steps:  62%|██████▏   | 3078/5000 [11:31:46<6:25:06, 12.02s/it, loss=1.0891, lr=3.87e-06]Steps:  62%|██████▏   | 3078/5000 [11:31:46<6:25:06, 12.02s/it, loss=1.1129, lr=3.87e-06]Steps:  62%|██████▏   | 3079/5000 [11:31:58<6:23:39, 11.98s/it, loss=1.1129, lr=3.87e-06]Steps:  62%|██████▏   | 3079/5000 [11:31:58<6:23:39, 11.98s/it, loss=0.4630, lr=3.86e-06]Steps:  62%|██████▏   | 3080/5000 [11:32:10<6:21:59, 11.94s/it, loss=0.4630, lr=3.86e-06]Steps:  62%|██████▏   | 3080/5000 [11:32:10<6:21:59, 11.94s/it, loss=0.3896, lr=3.86e-06]
[Step 3080] Training Debug Info:
  Loss: 0.922687
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0496, std: 0.9531
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0522, std: 1.3828
  Model pred mean: -0.0476, std: 0.9922
  Sigmas: [0.26171875]... (timesteps: [262.0])

[Step 3080] Training Debug Info:
  Loss: 1.182402
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0017, std: 0.8750
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0012, std: 1.3359
  Model pred mean: 0.0007, std: 0.7656
  Sigmas: [0.1396484375]... (timesteps: [140.0])

[Step 3080] Training Debug Info:
  Loss: 0.403619
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0212, std: 0.9375
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0209, std: 1.3750
  Model pred mean: 0.0188, std: 1.2188
  Sigmas: [0.69140625]... (timesteps: [690.0])

[Step 3080] Training Debug Info:
  Loss: 0.707192
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0069, std: 0.9375
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0096, std: 1.3750
  Model pred mean: 0.0080, std: 1.0781
  Sigmas: [0.48046875]... (timesteps: [481.0])
Steps:  62%|██████▏   | 3081/5000 [11:32:22<6:24:11, 12.01s/it, loss=0.3896, lr=3.86e-06]Steps:  62%|██████▏   | 3081/5000 [11:32:22<6:24:11, 12.01s/it, loss=0.7072, lr=3.85e-06]Steps:  62%|██████▏   | 3082/5000 [11:32:34<6:23:05, 11.98s/it, loss=0.7072, lr=3.85e-06]Steps:  62%|██████▏   | 3082/5000 [11:32:34<6:23:05, 11.98s/it, loss=0.4070, lr=3.85e-06]Steps:  62%|██████▏   | 3083/5000 [11:32:46<6:22:49, 11.98s/it, loss=0.4070, lr=3.85e-06]Steps:  62%|██████▏   | 3083/5000 [11:32:46<6:22:49, 11.98s/it, loss=0.6726, lr=3.85e-06]Steps:  62%|██████▏   | 3084/5000 [11:32:58<6:21:58, 11.96s/it, loss=0.6726, lr=3.85e-06]Steps:  62%|██████▏   | 3084/5000 [11:32:58<6:21:58, 11.96s/it, loss=0.7284, lr=3.84e-06]Steps:  62%|██████▏   | 3085/5000 [11:33:10<6:21:13, 11.94s/it, loss=0.7284, lr=3.84e-06]Steps:  62%|██████▏   | 3085/5000 [11:33:10<6:21:13, 11.94s/it, loss=0.6853, lr=3.84e-06]Steps:  62%|██████▏   | 3086/5000 [11:33:22<6:20:36, 11.93s/it, loss=0.6853, lr=3.84e-06]Steps:  62%|██████▏   | 3086/5000 [11:33:22<6:20:36, 11.93s/it, loss=1.1791, lr=3.84e-06]Steps:  62%|██████▏   | 3087/5000 [11:33:34<6:23:52, 12.04s/it, loss=1.1791, lr=3.84e-06]Steps:  62%|██████▏   | 3087/5000 [11:33:34<6:23:52, 12.04s/it, loss=0.7307, lr=3.83e-06]Steps:  62%|██████▏   | 3088/5000 [11:33:46<6:22:23, 12.00s/it, loss=0.7307, lr=3.83e-06]Steps:  62%|██████▏   | 3088/5000 [11:33:46<6:22:23, 12.00s/it, loss=0.5246, lr=3.83e-06]Steps:  62%|██████▏   | 3089/5000 [11:33:58<6:21:39, 11.98s/it, loss=0.5246, lr=3.83e-06]Steps:  62%|██████▏   | 3089/5000 [11:33:58<6:21:39, 11.98s/it, loss=0.4071, lr=3.83e-06]Steps:  62%|██████▏   | 3090/5000 [11:34:10<6:21:27, 11.98s/it, loss=0.4071, lr=3.83e-06]Steps:  62%|██████▏   | 3090/5000 [11:34:10<6:21:27, 11.98s/it, loss=1.0054, lr=3.82e-06]
[Step 3090] Training Debug Info:
  Loss: 0.932942
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0140, std: 0.9648
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0127, std: 1.3906
  Model pred mean: -0.0089, std: 0.9961
  Sigmas: [0.2197265625]... (timesteps: [220.0])

[Step 3090] Training Debug Info:
  Loss: 0.392833
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0030, std: 0.8594
  Noise mean: 0.0011, std: 0.9961
  Target mean: -0.0019, std: 1.3203
  Model pred mean: 0.0013, std: 1.1562
  Sigmas: [0.8046875]... (timesteps: [804.0])

[Step 3090] Training Debug Info:
  Loss: 0.499687
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0276, std: 0.9297
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0294, std: 1.3672
  Model pred mean: 0.0315, std: 1.1641
  Sigmas: [0.65234375]... (timesteps: [651.0])

[Step 3090] Training Debug Info:
  Loss: 1.099342
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0072, std: 0.8906
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0063, std: 1.3359
  Model pred mean: -0.0059, std: 0.8320
  Sigmas: [0.283203125]... (timesteps: [284.0])
Steps:  62%|██████▏   | 3091/5000 [11:34:22<6:20:55, 11.97s/it, loss=1.0054, lr=3.82e-06]Steps:  62%|██████▏   | 3091/5000 [11:34:22<6:20:55, 11.97s/it, loss=1.0993, lr=3.82e-06]Steps:  62%|██████▏   | 3092/5000 [11:34:34<6:20:14, 11.96s/it, loss=1.0993, lr=3.82e-06]Steps:  62%|██████▏   | 3092/5000 [11:34:34<6:20:14, 11.96s/it, loss=0.5552, lr=3.82e-06]Steps:  62%|██████▏   | 3093/5000 [11:34:46<6:20:01, 11.96s/it, loss=0.5552, lr=3.82e-06]Steps:  62%|██████▏   | 3093/5000 [11:34:46<6:20:01, 11.96s/it, loss=1.0103, lr=3.81e-06]Steps:  62%|██████▏   | 3094/5000 [11:34:58<6:22:23, 12.04s/it, loss=1.0103, lr=3.81e-06]Steps:  62%|██████▏   | 3094/5000 [11:34:58<6:22:23, 12.04s/it, loss=0.9642, lr=3.81e-06]Steps:  62%|██████▏   | 3095/5000 [11:35:10<6:21:25, 12.01s/it, loss=0.9642, lr=3.81e-06]Steps:  62%|██████▏   | 3095/5000 [11:35:10<6:21:25, 12.01s/it, loss=1.0894, lr=3.81e-06]Steps:  62%|██████▏   | 3096/5000 [11:35:22<6:22:09, 12.04s/it, loss=1.0894, lr=3.81e-06]Steps:  62%|██████▏   | 3096/5000 [11:35:22<6:22:09, 12.04s/it, loss=0.8658, lr=3.80e-06]Steps:  62%|██████▏   | 3097/5000 [11:35:34<6:20:59, 12.01s/it, loss=0.8658, lr=3.80e-06]Steps:  62%|██████▏   | 3097/5000 [11:35:34<6:20:59, 12.01s/it, loss=0.4130, lr=3.80e-06]Steps:  62%|██████▏   | 3098/5000 [11:35:46<6:20:04, 11.99s/it, loss=0.4130, lr=3.80e-06]Steps:  62%|██████▏   | 3098/5000 [11:35:46<6:20:04, 11.99s/it, loss=1.0546, lr=3.80e-06]Steps:  62%|██████▏   | 3099/5000 [11:35:58<6:19:27, 11.98s/it, loss=1.0546, lr=3.80e-06]Steps:  62%|██████▏   | 3099/5000 [11:35:58<6:19:27, 11.98s/it, loss=0.5902, lr=3.79e-06]Steps:  62%|██████▏   | 3100/5000 [11:36:10<6:18:31, 11.95s/it, loss=0.5902, lr=3.79e-06]Steps:  62%|██████▏   | 3100/5000 [11:36:10<6:18:31, 11.95s/it, loss=1.1077, lr=3.79e-06]01/22/2026 19:21:57 - INFO - __main__ - 
[Step 3100] ✅ Loss in normal range (1.1077)
01/22/2026 19:21:57 - INFO - __main__ -   Loss avg (last 100): 0.7475
01/22/2026 19:21:57 - INFO - __main__ -   Loss range: [0.3456, 1.2282]

[Step 3100] Training Debug Info:
  Loss: 0.803894
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0297, std: 0.8711
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0312, std: 1.3203
  Model pred mean: -0.0289, std: 0.9766
  Sigmas: [0.470703125]... (timesteps: [470.0])

[Step 3100] Training Debug Info:
  Loss: 0.819501
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0342, std: 0.9023
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0330, std: 1.3438
  Model pred mean: 0.0325, std: 1.0000
  Sigmas: [0.44140625]... (timesteps: [442.0])

[Step 3100] Training Debug Info:
  Loss: 0.658515
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0023, std: 0.9023
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0009, std: 1.3516
  Model pred mean: -0.0017, std: 1.0781
  Sigmas: [0.53515625]... (timesteps: [535.0])

[Step 3100] Training Debug Info:
  Loss: 0.394101
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.9219
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0042, std: 1.3594
  Model pred mean: -0.0014, std: 1.2031
  Sigmas: [0.7578125]... (timesteps: [757.0])
Steps:  62%|██████▏   | 3101/5000 [11:36:22<6:20:41, 12.03s/it, loss=1.1077, lr=3.79e-06]Steps:  62%|██████▏   | 3101/5000 [11:36:22<6:20:41, 12.03s/it, loss=0.3941, lr=3.79e-06]Steps:  62%|██████▏   | 3102/5000 [11:36:34<6:19:59, 12.01s/it, loss=0.3941, lr=3.79e-06]Steps:  62%|██████▏   | 3102/5000 [11:36:34<6:19:59, 12.01s/it, loss=0.4611, lr=3.78e-06]Steps:  62%|██████▏   | 3103/5000 [11:36:46<6:18:45, 11.98s/it, loss=0.4611, lr=3.78e-06]Steps:  62%|██████▏   | 3103/5000 [11:36:46<6:18:45, 11.98s/it, loss=1.0792, lr=3.78e-06]Steps:  62%|██████▏   | 3104/5000 [11:36:58<6:19:39, 12.01s/it, loss=1.0792, lr=3.78e-06]Steps:  62%|██████▏   | 3104/5000 [11:36:58<6:19:39, 12.01s/it, loss=0.7852, lr=3.78e-06]Steps:  62%|██████▏   | 3105/5000 [11:37:10<6:18:49, 11.99s/it, loss=0.7852, lr=3.78e-06]Steps:  62%|██████▏   | 3105/5000 [11:37:10<6:18:49, 11.99s/it, loss=0.4710, lr=3.77e-06]Steps:  62%|██████▏   | 3106/5000 [11:37:22<6:17:16, 11.95s/it, loss=0.4710, lr=3.77e-06]Steps:  62%|██████▏   | 3106/5000 [11:37:22<6:17:16, 11.95s/it, loss=0.6753, lr=3.77e-06]Steps:  62%|██████▏   | 3107/5000 [11:37:34<6:16:47, 11.94s/it, loss=0.6753, lr=3.77e-06]Steps:  62%|██████▏   | 3107/5000 [11:37:34<6:16:47, 11.94s/it, loss=0.8942, lr=3.77e-06]Steps:  62%|██████▏   | 3108/5000 [11:37:46<6:19:02, 12.02s/it, loss=0.8942, lr=3.77e-06]Steps:  62%|██████▏   | 3108/5000 [11:37:46<6:19:02, 12.02s/it, loss=1.1788, lr=3.76e-06]Steps:  62%|██████▏   | 3109/5000 [11:37:58<6:17:42, 11.98s/it, loss=1.1788, lr=3.76e-06]Steps:  62%|██████▏   | 3109/5000 [11:37:58<6:17:42, 11.98s/it, loss=1.1599, lr=3.76e-06]Steps:  62%|██████▏   | 3110/5000 [11:38:10<6:17:23, 11.98s/it, loss=1.1599, lr=3.76e-06]Steps:  62%|██████▏   | 3110/5000 [11:38:10<6:17:23, 11.98s/it, loss=0.5999, lr=3.76e-06]
[Step 3110] Training Debug Info:
  Loss: 1.123298
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0016, std: 0.9180
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0019, std: 1.3594
  Model pred mean: -0.0021, std: 0.8438
  Sigmas: [0.263671875]... (timesteps: [263.0])

[Step 3110] Training Debug Info:
  Loss: 0.374889
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0097, std: 0.9062
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0121, std: 1.3438
  Model pred mean: 0.0126, std: 1.2031
  Sigmas: [0.80078125]... (timesteps: [802.0])

[Step 3110] Training Debug Info:
  Loss: 1.146238
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0027, std: 0.9062
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0052, std: 1.3516
  Model pred mean: 0.0037, std: 0.8242
  Sigmas: [0.1201171875]... (timesteps: [120.0])

[Step 3110] Training Debug Info:
  Loss: 0.378510
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0222, std: 0.9219
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0229, std: 1.3594
  Model pred mean: -0.0269, std: 1.2266
  Sigmas: [0.90234375]... (timesteps: [904.0])
Steps:  62%|██████▏   | 3111/5000 [11:38:22<6:16:24, 11.96s/it, loss=0.5999, lr=3.76e-06]Steps:  62%|██████▏   | 3111/5000 [11:38:22<6:16:24, 11.96s/it, loss=0.3785, lr=3.75e-06]Steps:  62%|██████▏   | 3112/5000 [11:38:34<6:17:17, 11.99s/it, loss=0.3785, lr=3.75e-06]Steps:  62%|██████▏   | 3112/5000 [11:38:34<6:17:17, 11.99s/it, loss=0.3623, lr=3.75e-06]Steps:  62%|██████▏   | 3113/5000 [11:38:46<6:16:34, 11.97s/it, loss=0.3623, lr=3.75e-06]Steps:  62%|██████▏   | 3113/5000 [11:38:46<6:16:34, 11.97s/it, loss=0.5837, lr=3.75e-06]Steps:  62%|██████▏   | 3114/5000 [11:38:58<6:18:43, 12.05s/it, loss=0.5837, lr=3.75e-06]Steps:  62%|██████▏   | 3114/5000 [11:38:58<6:18:43, 12.05s/it, loss=1.1387, lr=3.74e-06]Steps:  62%|██████▏   | 3115/5000 [11:39:10<6:17:15, 12.01s/it, loss=1.1387, lr=3.74e-06]Steps:  62%|██████▏   | 3115/5000 [11:39:10<6:17:15, 12.01s/it, loss=0.7182, lr=3.74e-06]Steps:  62%|██████▏   | 3116/5000 [11:39:22<6:15:22, 11.95s/it, loss=0.7182, lr=3.74e-06]Steps:  62%|██████▏   | 3116/5000 [11:39:22<6:15:22, 11.95s/it, loss=0.3988, lr=3.74e-06]Steps:  62%|██████▏   | 3117/5000 [11:39:34<6:14:30, 11.93s/it, loss=0.3988, lr=3.74e-06]Steps:  62%|██████▏   | 3117/5000 [11:39:34<6:14:30, 11.93s/it, loss=0.9820, lr=3.73e-06]Steps:  62%|██████▏   | 3118/5000 [11:39:46<6:14:08, 11.93s/it, loss=0.9820, lr=3.73e-06]Steps:  62%|██████▏   | 3118/5000 [11:39:46<6:14:08, 11.93s/it, loss=0.5213, lr=3.73e-06]Steps:  62%|██████▏   | 3119/5000 [11:39:58<6:15:44, 11.99s/it, loss=0.5213, lr=3.73e-06]Steps:  62%|██████▏   | 3119/5000 [11:39:58<6:15:44, 11.99s/it, loss=0.5906, lr=3.73e-06]Steps:  62%|██████▏   | 3120/5000 [11:40:10<6:15:00, 11.97s/it, loss=0.5906, lr=3.73e-06]Steps:  62%|██████▏   | 3120/5000 [11:40:10<6:15:00, 11.97s/it, loss=0.8861, lr=3.72e-06]
[Step 3120] Training Debug Info:
  Loss: 0.472244
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0134, std: 0.8906
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0135, std: 1.3359
  Model pred mean: 0.0115, std: 1.1484
  Sigmas: [0.703125]... (timesteps: [704.0])

[Step 3120] Training Debug Info:
  Loss: 0.839587
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0527, std: 0.9219
  Noise mean: -0.0008, std: 0.9961
  Target mean: -0.0537, std: 1.3594
  Model pred mean: -0.0540, std: 1.0078
  Sigmas: [0.322265625]... (timesteps: [322.0])

[Step 3120] Training Debug Info:
  Loss: 0.845430
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0161, std: 0.8945
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0143, std: 1.3438
  Model pred mean: -0.0161, std: 0.9766
  Sigmas: [0.4296875]... (timesteps: [430.0])

[Step 3120] Training Debug Info:
  Loss: 0.421632
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0103, std: 0.8750
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0112, std: 1.3281
  Model pred mean: 0.0096, std: 1.1562
  Sigmas: [0.92578125]... (timesteps: [926.0])
Steps:  62%|██████▏   | 3121/5000 [11:40:22<6:15:37, 11.99s/it, loss=0.8861, lr=3.72e-06]Steps:  62%|██████▏   | 3121/5000 [11:40:22<6:15:37, 11.99s/it, loss=0.4216, lr=3.72e-06]Steps:  62%|██████▏   | 3122/5000 [11:40:34<6:15:32, 12.00s/it, loss=0.4216, lr=3.72e-06]Steps:  62%|██████▏   | 3122/5000 [11:40:34<6:15:32, 12.00s/it, loss=0.4776, lr=3.72e-06]Steps:  62%|██████▏   | 3123/5000 [11:40:46<6:14:49, 11.98s/it, loss=0.4776, lr=3.72e-06]Steps:  62%|██████▏   | 3123/5000 [11:40:46<6:14:49, 11.98s/it, loss=1.0514, lr=3.71e-06]Steps:  62%|██████▏   | 3124/5000 [11:40:57<6:13:30, 11.95s/it, loss=1.0514, lr=3.71e-06]Steps:  62%|██████▏   | 3124/5000 [11:40:57<6:13:30, 11.95s/it, loss=0.8852, lr=3.71e-06]Steps:  62%|██████▎   | 3125/5000 [11:41:09<6:12:38, 11.92s/it, loss=0.8852, lr=3.71e-06]Steps:  62%|██████▎   | 3125/5000 [11:41:09<6:12:38, 11.92s/it, loss=0.7493, lr=3.71e-06]Steps:  63%|██████▎   | 3126/5000 [11:41:21<6:14:31, 11.99s/it, loss=0.7493, lr=3.71e-06]Steps:  63%|██████▎   | 3126/5000 [11:41:21<6:14:31, 11.99s/it, loss=0.9324, lr=3.70e-06]Steps:  63%|██████▎   | 3127/5000 [11:41:33<6:13:25, 11.96s/it, loss=0.9324, lr=3.70e-06]Steps:  63%|██████▎   | 3127/5000 [11:41:33<6:13:25, 11.96s/it, loss=0.6924, lr=3.70e-06]Steps:  63%|██████▎   | 3128/5000 [11:41:46<6:15:07, 12.02s/it, loss=0.6924, lr=3.70e-06]Steps:  63%|██████▎   | 3128/5000 [11:41:46<6:15:07, 12.02s/it, loss=0.5034, lr=3.70e-06]Steps:  63%|██████▎   | 3129/5000 [11:41:57<6:13:53, 11.99s/it, loss=0.5034, lr=3.70e-06]Steps:  63%|██████▎   | 3129/5000 [11:41:57<6:13:53, 11.99s/it, loss=0.7315, lr=3.69e-06]Steps:  63%|██████▎   | 3130/5000 [11:42:09<6:13:55, 12.00s/it, loss=0.7315, lr=3.69e-06]Steps:  63%|██████▎   | 3130/5000 [11:42:09<6:13:55, 12.00s/it, loss=0.5914, lr=3.69e-06]
[Step 3130] Training Debug Info:
  Loss: 0.442306
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0078, std: 0.8672
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0060, std: 1.3281
  Model pred mean: 0.0109, std: 1.1484
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 3130] Training Debug Info:
  Loss: 1.044010
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0586, std: 0.9375
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0581, std: 1.3750
  Model pred mean: -0.0566, std: 0.9102
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 3130] Training Debug Info:
  Loss: 0.789925
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0047, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0041, std: 1.3438
  Model pred mean: 0.0029, std: 1.0078
  Sigmas: [0.462890625]... (timesteps: [462.0])

[Step 3130] Training Debug Info:
  Loss: 0.426145
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0269, std: 0.9023
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0293, std: 1.3438
  Model pred mean: -0.0258, std: 1.1797
  Sigmas: [0.71875]... (timesteps: [718.0])
Steps:  63%|██████▎   | 3131/5000 [11:42:21<6:13:21, 11.99s/it, loss=0.5914, lr=3.69e-06]Steps:  63%|██████▎   | 3131/5000 [11:42:21<6:13:21, 11.99s/it, loss=0.4261, lr=3.69e-06]Steps:  63%|██████▎   | 3132/5000 [11:42:33<6:13:04, 11.98s/it, loss=0.4261, lr=3.69e-06]Steps:  63%|██████▎   | 3132/5000 [11:42:33<6:13:04, 11.98s/it, loss=0.6878, lr=3.68e-06]Steps:  63%|██████▎   | 3133/5000 [11:42:46<6:15:06, 12.05s/it, loss=0.6878, lr=3.68e-06]Steps:  63%|██████▎   | 3133/5000 [11:42:46<6:15:06, 12.05s/it, loss=0.3705, lr=3.68e-06]Steps:  63%|██████▎   | 3134/5000 [11:42:58<6:13:35, 12.01s/it, loss=0.3705, lr=3.68e-06]Steps:  63%|██████▎   | 3134/5000 [11:42:58<6:13:35, 12.01s/it, loss=1.0711, lr=3.68e-06]Steps:  63%|██████▎   | 3135/5000 [11:43:10<6:14:33, 12.05s/it, loss=1.0711, lr=3.68e-06]Steps:  63%|██████▎   | 3135/5000 [11:43:10<6:14:33, 12.05s/it, loss=0.4315, lr=3.67e-06]Steps:  63%|██████▎   | 3136/5000 [11:43:22<6:14:00, 12.04s/it, loss=0.4315, lr=3.67e-06]Steps:  63%|██████▎   | 3136/5000 [11:43:22<6:14:00, 12.04s/it, loss=1.1382, lr=3.67e-06]Steps:  63%|██████▎   | 3137/5000 [11:43:34<6:13:08, 12.02s/it, loss=1.1382, lr=3.67e-06]Steps:  63%|██████▎   | 3137/5000 [11:43:34<6:13:08, 12.02s/it, loss=0.5475, lr=3.67e-06]Steps:  63%|██████▎   | 3138/5000 [11:43:46<6:12:02, 11.99s/it, loss=0.5475, lr=3.67e-06]Steps:  63%|██████▎   | 3138/5000 [11:43:46<6:12:02, 11.99s/it, loss=0.4862, lr=3.66e-06]Steps:  63%|██████▎   | 3139/5000 [11:43:58<6:11:59, 11.99s/it, loss=0.4862, lr=3.66e-06]Steps:  63%|██████▎   | 3139/5000 [11:43:58<6:11:59, 11.99s/it, loss=0.7890, lr=3.66e-06]Steps:  63%|██████▎   | 3140/5000 [11:44:10<6:13:46, 12.06s/it, loss=0.7890, lr=3.66e-06]Steps:  63%|██████▎   | 3140/5000 [11:44:10<6:13:46, 12.06s/it, loss=0.4384, lr=3.66e-06]
[Step 3140] Training Debug Info:
  Loss: 0.461367
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0339, std: 0.9023
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0322, std: 1.3516
  Model pred mean: -0.0359, std: 1.1641
  Sigmas: [0.87890625]... (timesteps: [880.0])

[Step 3140] Training Debug Info:
  Loss: 1.026731
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0055, std: 0.9141
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0037, std: 1.3594
  Model pred mean: -0.0030, std: 0.8984
  Sigmas: [0.0150146484375]... (timesteps: [15.0])

[Step 3140] Training Debug Info:
  Loss: 1.068902
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0325, std: 0.9062
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0304, std: 1.3516
  Model pred mean: 0.0347, std: 0.8711
  Sigmas: [0.31640625]... (timesteps: [317.0])

[Step 3140] Training Debug Info:
  Loss: 0.438730
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0133, std: 0.9219
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0132, std: 1.3594
  Model pred mean: -0.0131, std: 1.1953
  Sigmas: [0.7109375]... (timesteps: [710.0])
Steps:  63%|██████▎   | 3141/5000 [11:44:22<6:14:49, 12.10s/it, loss=0.4384, lr=3.66e-06]Steps:  63%|██████▎   | 3141/5000 [11:44:22<6:14:49, 12.10s/it, loss=0.4387, lr=3.65e-06]Steps:  63%|██████▎   | 3142/5000 [11:44:34<6:13:16, 12.05s/it, loss=0.4387, lr=3.65e-06]Steps:  63%|██████▎   | 3142/5000 [11:44:34<6:13:16, 12.05s/it, loss=0.4141, lr=3.65e-06]Steps:  63%|██████▎   | 3143/5000 [11:44:46<6:12:12, 12.03s/it, loss=0.4141, lr=3.65e-06]Steps:  63%|██████▎   | 3143/5000 [11:44:46<6:12:12, 12.03s/it, loss=0.3698, lr=3.65e-06]Steps:  63%|██████▎   | 3144/5000 [11:44:58<6:11:18, 12.00s/it, loss=0.3698, lr=3.65e-06]Steps:  63%|██████▎   | 3144/5000 [11:44:58<6:11:18, 12.00s/it, loss=0.7779, lr=3.64e-06]Steps:  63%|██████▎   | 3145/5000 [11:45:10<6:09:24, 11.95s/it, loss=0.7779, lr=3.64e-06]Steps:  63%|██████▎   | 3145/5000 [11:45:10<6:09:24, 11.95s/it, loss=1.1418, lr=3.64e-06]Steps:  63%|██████▎   | 3146/5000 [11:45:22<6:08:34, 11.93s/it, loss=1.1418, lr=3.64e-06]Steps:  63%|██████▎   | 3146/5000 [11:45:22<6:08:34, 11.93s/it, loss=0.3485, lr=3.64e-06]Steps:  63%|██████▎   | 3147/5000 [11:45:34<6:11:11, 12.02s/it, loss=0.3485, lr=3.64e-06]Steps:  63%|██████▎   | 3147/5000 [11:45:34<6:11:11, 12.02s/it, loss=0.3935, lr=3.63e-06]Steps:  63%|██████▎   | 3148/5000 [11:45:46<6:12:27, 12.07s/it, loss=0.3935, lr=3.63e-06]Steps:  63%|██████▎   | 3148/5000 [11:45:46<6:12:27, 12.07s/it, loss=1.1419, lr=3.63e-06]Steps:  63%|██████▎   | 3149/5000 [11:45:58<6:11:10, 12.03s/it, loss=1.1419, lr=3.63e-06]Steps:  63%|██████▎   | 3149/5000 [11:45:58<6:11:10, 12.03s/it, loss=0.8238, lr=3.63e-06]Steps:  63%|██████▎   | 3150/5000 [11:46:10<6:10:06, 12.00s/it, loss=0.8238, lr=3.63e-06]Steps:  63%|██████▎   | 3150/5000 [11:46:10<6:10:06, 12.00s/it, loss=0.8295, lr=3.62e-06]
[Step 3150] Training Debug Info:
  Loss: 0.444437
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0128, std: 0.8789
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0143, std: 1.3281
  Model pred mean: 0.0153, std: 1.1484
  Sigmas: [0.7734375]... (timesteps: [772.0])

[Step 3150] Training Debug Info:
  Loss: 0.950917
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0146, std: 0.8906
  Noise mean: -0.0005, std: 0.9961
  Target mean: 0.0142, std: 1.3359
  Model pred mean: 0.0134, std: 0.9219
  Sigmas: [0.416015625]... (timesteps: [416.0])

[Step 3150] Training Debug Info:
  Loss: 0.355679
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0364, std: 0.9414
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0374, std: 1.3750
  Model pred mean: -0.0347, std: 1.2422
  Sigmas: [0.85546875]... (timesteps: [856.0])

[Step 3150] Training Debug Info:
  Loss: 1.175467
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0089, std: 0.8398
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0087, std: 1.3047
  Model pred mean: 0.0099, std: 0.7188
  Sigmas: [0.115234375]... (timesteps: [115.0])
Steps:  63%|██████▎   | 3151/5000 [11:46:22<6:09:35, 11.99s/it, loss=0.8295, lr=3.62e-06]Steps:  63%|██████▎   | 3151/5000 [11:46:22<6:09:35, 11.99s/it, loss=1.1755, lr=3.62e-06]Steps:  63%|██████▎   | 3152/5000 [11:46:34<6:09:25, 11.99s/it, loss=1.1755, lr=3.62e-06]Steps:  63%|██████▎   | 3152/5000 [11:46:34<6:09:25, 11.99s/it, loss=0.5833, lr=3.62e-06]Steps:  63%|██████▎   | 3153/5000 [11:46:46<6:09:27, 12.00s/it, loss=0.5833, lr=3.62e-06]Steps:  63%|██████▎   | 3153/5000 [11:46:46<6:09:27, 12.00s/it, loss=1.1555, lr=3.61e-06]Steps:  63%|██████▎   | 3154/5000 [11:46:58<6:11:08, 12.06s/it, loss=1.1555, lr=3.61e-06]Steps:  63%|██████▎   | 3154/5000 [11:46:58<6:11:08, 12.06s/it, loss=0.4184, lr=3.61e-06]Steps:  63%|██████▎   | 3155/5000 [11:47:10<6:11:06, 12.07s/it, loss=0.4184, lr=3.61e-06]Steps:  63%|██████▎   | 3155/5000 [11:47:10<6:11:06, 12.07s/it, loss=1.1813, lr=3.61e-06]Steps:  63%|██████▎   | 3156/5000 [11:47:22<6:09:34, 12.03s/it, loss=1.1813, lr=3.61e-06]Steps:  63%|██████▎   | 3156/5000 [11:47:22<6:09:34, 12.03s/it, loss=0.5853, lr=3.60e-06]Steps:  63%|██████▎   | 3157/5000 [11:47:34<6:08:37, 12.00s/it, loss=0.5853, lr=3.60e-06]Steps:  63%|██████▎   | 3157/5000 [11:47:34<6:08:37, 12.00s/it, loss=1.1000, lr=3.60e-06]Steps:  63%|██████▎   | 3158/5000 [11:47:46<6:07:30, 11.97s/it, loss=1.1000, lr=3.60e-06]Steps:  63%|██████▎   | 3158/5000 [11:47:46<6:07:30, 11.97s/it, loss=0.6935, lr=3.59e-06]Steps:  63%|██████▎   | 3159/5000 [11:47:58<6:07:10, 11.97s/it, loss=0.6935, lr=3.59e-06]Steps:  63%|██████▎   | 3159/5000 [11:47:58<6:07:10, 11.97s/it, loss=0.5289, lr=3.59e-06]Steps:  63%|██████▎   | 3160/5000 [11:48:10<6:06:41, 11.96s/it, loss=0.5289, lr=3.59e-06]Steps:  63%|██████▎   | 3160/5000 [11:48:10<6:06:41, 11.96s/it, loss=0.3537, lr=3.59e-06]
[Step 3160] Training Debug Info:
  Loss: 0.995221
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0145, std: 0.9648
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0134, std: 1.3906
  Model pred mean: -0.0131, std: 0.9766
  Sigmas: [0.2890625]... (timesteps: [289.0])

[Step 3160] Training Debug Info:
  Loss: 0.988271
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0032, std: 0.8945
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0042, std: 1.3438
  Model pred mean: -0.0053, std: 0.8984
  Sigmas: [0.359375]... (timesteps: [359.0])

[Step 3160] Training Debug Info:
  Loss: 0.564113
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0098, std: 0.8945
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0083, std: 1.3438
  Model pred mean: -0.0143, std: 1.1016
  Sigmas: [0.98828125]... (timesteps: [988.0])

[Step 3160] Training Debug Info:
  Loss: 0.403900
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.9023
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0013, std: 1.3516
  Model pred mean: -0.0011, std: 1.1797
  Sigmas: [0.8671875]... (timesteps: [868.0])
Steps:  63%|██████▎   | 3161/5000 [11:48:22<6:08:48, 12.03s/it, loss=0.3537, lr=3.59e-06]Steps:  63%|██████▎   | 3161/5000 [11:48:22<6:08:48, 12.03s/it, loss=0.4039, lr=3.58e-06]Steps:  63%|██████▎   | 3162/5000 [11:48:34<6:09:56, 12.08s/it, loss=0.4039, lr=3.58e-06]Steps:  63%|██████▎   | 3162/5000 [11:48:34<6:09:56, 12.08s/it, loss=0.3744, lr=3.58e-06]Steps:  63%|██████▎   | 3163/5000 [11:48:46<6:09:51, 12.08s/it, loss=0.3744, lr=3.58e-06]Steps:  63%|██████▎   | 3163/5000 [11:48:46<6:09:51, 12.08s/it, loss=1.0919, lr=3.58e-06]Steps:  63%|██████▎   | 3164/5000 [11:48:58<6:07:53, 12.02s/it, loss=1.0919, lr=3.58e-06]Steps:  63%|██████▎   | 3164/5000 [11:48:58<6:07:53, 12.02s/it, loss=1.0958, lr=3.57e-06]Steps:  63%|██████▎   | 3165/5000 [11:49:10<6:06:39, 11.99s/it, loss=1.0958, lr=3.57e-06]Steps:  63%|██████▎   | 3165/5000 [11:49:10<6:06:39, 11.99s/it, loss=1.1242, lr=3.57e-06]Steps:  63%|██████▎   | 3166/5000 [11:49:22<6:05:45, 11.97s/it, loss=1.1242, lr=3.57e-06]Steps:  63%|██████▎   | 3166/5000 [11:49:22<6:05:45, 11.97s/it, loss=1.1357, lr=3.57e-06]Steps:  63%|██████▎   | 3167/5000 [11:49:34<6:06:07, 11.98s/it, loss=1.1357, lr=3.57e-06]Steps:  63%|██████▎   | 3167/5000 [11:49:34<6:06:07, 11.98s/it, loss=0.3902, lr=3.56e-06]Steps:  63%|██████▎   | 3168/5000 [11:49:46<6:07:54, 12.05s/it, loss=0.3902, lr=3.56e-06]Steps:  63%|██████▎   | 3168/5000 [11:49:46<6:07:54, 12.05s/it, loss=0.4007, lr=3.56e-06]Steps:  63%|██████▎   | 3169/5000 [11:49:58<6:06:08, 12.00s/it, loss=0.4007, lr=3.56e-06]Steps:  63%|██████▎   | 3169/5000 [11:49:58<6:06:08, 12.00s/it, loss=0.4079, lr=3.56e-06]Steps:  63%|██████▎   | 3170/5000 [11:50:10<6:05:26, 11.98s/it, loss=0.4079, lr=3.56e-06]Steps:  63%|██████▎   | 3170/5000 [11:50:10<6:05:26, 11.98s/it, loss=0.6779, lr=3.55e-06]
[Step 3170] Training Debug Info:
  Loss: 0.932807
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0231, std: 0.9219
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0219, std: 1.3594
  Model pred mean: -0.0242, std: 0.9570
  Sigmas: [0.3515625]... (timesteps: [352.0])

[Step 3170] Training Debug Info:
  Loss: 1.007511
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0038, std: 0.9141
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0064, std: 1.3594
  Model pred mean: 0.0033, std: 0.9102
  Sigmas: [0.330078125]... (timesteps: [331.0])

[Step 3170] Training Debug Info:
  Loss: 0.546231
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0023, std: 0.9062
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0030, std: 1.3516
  Model pred mean: 0.0008, std: 1.1484
  Sigmas: [0.92578125]... (timesteps: [924.0])

[Step 3170] Training Debug Info:
  Loss: 0.458960
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0537, std: 0.9219
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0562, std: 1.3594
  Model pred mean: -0.0544, std: 1.1719
  Sigmas: [0.7265625]... (timesteps: [725.0])
Steps:  63%|██████▎   | 3171/5000 [11:50:22<6:04:35, 11.96s/it, loss=0.6779, lr=3.55e-06]Steps:  63%|██████▎   | 3171/5000 [11:50:22<6:04:35, 11.96s/it, loss=0.4590, lr=3.55e-06]Steps:  63%|██████▎   | 3172/5000 [11:50:34<6:03:24, 11.93s/it, loss=0.4590, lr=3.55e-06]Steps:  63%|██████▎   | 3172/5000 [11:50:34<6:03:24, 11.93s/it, loss=0.4579, lr=3.55e-06]Steps:  63%|██████▎   | 3173/5000 [11:50:46<6:02:47, 11.91s/it, loss=0.4579, lr=3.55e-06]Steps:  63%|██████▎   | 3173/5000 [11:50:46<6:02:47, 11.91s/it, loss=0.9617, lr=3.54e-06]Steps:  63%|██████▎   | 3174/5000 [11:50:58<6:02:41, 11.92s/it, loss=0.9617, lr=3.54e-06]Steps:  63%|██████▎   | 3174/5000 [11:50:58<6:02:41, 11.92s/it, loss=1.1478, lr=3.54e-06]Steps:  64%|██████▎   | 3175/5000 [11:51:10<6:04:58, 12.00s/it, loss=1.1478, lr=3.54e-06]Steps:  64%|██████▎   | 3175/5000 [11:51:10<6:04:58, 12.00s/it, loss=0.8500, lr=3.54e-06]Steps:  64%|██████▎   | 3176/5000 [11:51:22<6:04:11, 11.98s/it, loss=0.8500, lr=3.54e-06]Steps:  64%|██████▎   | 3176/5000 [11:51:22<6:04:11, 11.98s/it, loss=0.7712, lr=3.53e-06]Steps:  64%|██████▎   | 3177/5000 [11:51:34<6:04:56, 12.01s/it, loss=0.7712, lr=3.53e-06]Steps:  64%|██████▎   | 3177/5000 [11:51:34<6:04:56, 12.01s/it, loss=0.6706, lr=3.53e-06]Steps:  64%|██████▎   | 3178/5000 [11:51:46<6:03:47, 11.98s/it, loss=0.6706, lr=3.53e-06]Steps:  64%|██████▎   | 3178/5000 [11:51:46<6:03:47, 11.98s/it, loss=0.5682, lr=3.53e-06]Steps:  64%|██████▎   | 3179/5000 [11:51:58<6:03:46, 11.99s/it, loss=0.5682, lr=3.53e-06]Steps:  64%|██████▎   | 3179/5000 [11:51:58<6:03:46, 11.99s/it, loss=0.7567, lr=3.52e-06]Steps:  64%|██████▎   | 3180/5000 [11:52:10<6:02:58, 11.97s/it, loss=0.7567, lr=3.52e-06]Steps:  64%|██████▎   | 3180/5000 [11:52:10<6:02:58, 11.97s/it, loss=1.0913, lr=3.52e-06]
[Step 3180] Training Debug Info:
  Loss: 0.753506
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0020, std: 0.8984
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0011, std: 1.3438
  Model pred mean: 0.0029, std: 1.0312
  Sigmas: [0.498046875]... (timesteps: [498.0])

[Step 3180] Training Debug Info:
  Loss: 0.993964
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0002, std: 0.8984
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0021, std: 1.3438
  Model pred mean: 0.0011, std: 0.9023
  Sigmas: [0.3515625]... (timesteps: [352.0])

[Step 3180] Training Debug Info:
  Loss: 0.392996
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0181, std: 0.9375
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0190, std: 1.3750
  Model pred mean: -0.0173, std: 1.2188
  Sigmas: [0.73046875]... (timesteps: [731.0])

[Step 3180] Training Debug Info:
  Loss: 0.414730
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0031, std: 0.9141
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0026, std: 1.3594
  Model pred mean: 0.0019, std: 1.1875
  Sigmas: [0.8671875]... (timesteps: [868.0])
Steps:  64%|██████▎   | 3181/5000 [11:52:21<6:01:43, 11.93s/it, loss=1.0913, lr=3.52e-06]Steps:  64%|██████▎   | 3181/5000 [11:52:21<6:01:43, 11.93s/it, loss=0.4147, lr=3.52e-06]Steps:  64%|██████▎   | 3182/5000 [11:52:34<6:03:25, 11.99s/it, loss=0.4147, lr=3.52e-06]Steps:  64%|██████▎   | 3182/5000 [11:52:34<6:03:25, 11.99s/it, loss=0.7894, lr=3.51e-06]Steps:  64%|██████▎   | 3183/5000 [11:52:46<6:02:48, 11.98s/it, loss=0.7894, lr=3.51e-06]Steps:  64%|██████▎   | 3183/5000 [11:52:46<6:02:48, 11.98s/it, loss=1.0887, lr=3.51e-06]Steps:  64%|██████▎   | 3184/5000 [11:52:57<6:01:21, 11.94s/it, loss=1.0887, lr=3.51e-06]Steps:  64%|██████▎   | 3184/5000 [11:52:57<6:01:21, 11.94s/it, loss=0.6676, lr=3.51e-06]Steps:  64%|██████▎   | 3185/5000 [11:53:09<5:59:39, 11.89s/it, loss=0.6676, lr=3.51e-06]Steps:  64%|██████▎   | 3185/5000 [11:53:09<5:59:39, 11.89s/it, loss=0.4464, lr=3.50e-06]Steps:  64%|██████▎   | 3186/5000 [11:53:21<6:02:02, 11.97s/it, loss=0.4464, lr=3.50e-06]Steps:  64%|██████▎   | 3186/5000 [11:53:21<6:02:02, 11.97s/it, loss=0.5613, lr=3.50e-06]Steps:  64%|██████▎   | 3187/5000 [11:53:33<6:01:29, 11.96s/it, loss=0.5613, lr=3.50e-06]Steps:  64%|██████▎   | 3187/5000 [11:53:33<6:01:29, 11.96s/it, loss=1.1177, lr=3.50e-06]Steps:  64%|██████▍   | 3188/5000 [11:53:45<6:01:00, 11.95s/it, loss=1.1177, lr=3.50e-06]Steps:  64%|██████▍   | 3188/5000 [11:53:45<6:01:00, 11.95s/it, loss=0.8943, lr=3.49e-06]Steps:  64%|██████▍   | 3189/5000 [11:53:57<6:02:49, 12.02s/it, loss=0.8943, lr=3.49e-06]Steps:  64%|██████▍   | 3189/5000 [11:53:57<6:02:49, 12.02s/it, loss=0.3846, lr=3.49e-06]Steps:  64%|██████▍   | 3190/5000 [11:54:09<6:01:22, 11.98s/it, loss=0.3846, lr=3.49e-06]Steps:  64%|██████▍   | 3190/5000 [11:54:09<6:01:22, 11.98s/it, loss=1.0582, lr=3.49e-06]
[Step 3190] Training Debug Info:
  Loss: 0.474539
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0186, std: 0.9375
  Noise mean: 0.0009, std: 0.9961
  Target mean: -0.0177, std: 1.3672
  Model pred mean: -0.0175, std: 1.1875
  Sigmas: [0.87109375]... (timesteps: [873.0])

[Step 3190] Training Debug Info:
  Loss: 0.438921
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0073, std: 0.9062
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0107, std: 1.3516
  Model pred mean: -0.0072, std: 1.1797
  Sigmas: [0.7265625]... (timesteps: [728.0])

[Step 3190] Training Debug Info:
  Loss: 0.409385
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0066, std: 0.8828
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0050, std: 1.3359
  Model pred mean: 0.0006, std: 1.1641
  Sigmas: [0.85546875]... (timesteps: [856.0])

[Step 3190] Training Debug Info:
  Loss: 0.447505
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0530, std: 0.9648
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0518, std: 1.3906
  Model pred mean: -0.0479, std: 1.2188
  Sigmas: [0.6328125]... (timesteps: [633.0])
Steps:  64%|██████▍   | 3191/5000 [11:54:21<6:01:03, 11.98s/it, loss=1.0582, lr=3.49e-06]Steps:  64%|██████▍   | 3191/5000 [11:54:21<6:01:03, 11.98s/it, loss=0.4475, lr=3.48e-06]Steps:  64%|██████▍   | 3192/5000 [11:54:33<6:00:24, 11.96s/it, loss=0.4475, lr=3.48e-06]Steps:  64%|██████▍   | 3192/5000 [11:54:33<6:00:24, 11.96s/it, loss=0.3838, lr=3.48e-06]Steps:  64%|██████▍   | 3193/5000 [11:54:45<6:00:07, 11.96s/it, loss=0.3838, lr=3.48e-06]Steps:  64%|██████▍   | 3193/5000 [11:54:45<6:00:07, 11.96s/it, loss=0.3798, lr=3.48e-06]Steps:  64%|██████▍   | 3194/5000 [11:54:57<5:59:20, 11.94s/it, loss=0.3798, lr=3.48e-06]Steps:  64%|██████▍   | 3194/5000 [11:54:57<5:59:20, 11.94s/it, loss=0.4576, lr=3.47e-06]Steps:  64%|██████▍   | 3195/5000 [11:55:09<6:02:12, 12.04s/it, loss=0.4576, lr=3.47e-06]Steps:  64%|██████▍   | 3195/5000 [11:55:09<6:02:12, 12.04s/it, loss=0.3800, lr=3.47e-06]Steps:  64%|██████▍   | 3196/5000 [11:55:21<6:00:48, 12.00s/it, loss=0.3800, lr=3.47e-06]Steps:  64%|██████▍   | 3196/5000 [11:55:21<6:00:48, 12.00s/it, loss=1.0585, lr=3.47e-06]Steps:  64%|██████▍   | 3197/5000 [11:55:33<5:59:41, 11.97s/it, loss=1.0585, lr=3.47e-06]Steps:  64%|██████▍   | 3197/5000 [11:55:33<5:59:41, 11.97s/it, loss=1.0043, lr=3.46e-06]Steps:  64%|██████▍   | 3198/5000 [11:55:45<5:59:15, 11.96s/it, loss=1.0043, lr=3.46e-06]Steps:  64%|██████▍   | 3198/5000 [11:55:45<5:59:15, 11.96s/it, loss=0.9042, lr=3.46e-06]Steps:  64%|██████▍   | 3199/5000 [11:55:57<5:58:40, 11.95s/it, loss=0.9042, lr=3.46e-06]Steps:  64%|██████▍   | 3199/5000 [11:55:57<5:58:40, 11.95s/it, loss=0.9052, lr=3.46e-06]Steps:  64%|██████▍   | 3200/5000 [11:56:09<5:57:56, 11.93s/it, loss=0.9052, lr=3.46e-06]Steps:  64%|██████▍   | 3200/5000 [11:56:09<5:57:56, 11.93s/it, loss=1.1914, lr=3.45e-06]01/22/2026 19:41:56 - INFO - __main__ - 
[Step 3200] ✅ Loss in normal range (1.1914)
01/22/2026 19:41:56 - INFO - __main__ -   Loss avg (last 100): 0.7151
01/22/2026 19:41:56 - INFO - __main__ -   Loss range: [0.3485, 1.1914]
01/22/2026 19:41:56 - INFO - __main__ - 
🔍 Running validation at step 3200...
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3200 (parquet mode)...
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3200...
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 19:42:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.47it/s]
01/22/2026 19:42:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 19:42:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.47it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.46it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.44it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 19:42:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 19:42:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 19:43:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 19:43:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 19:43:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 19:43:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 19:43:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 19:43:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 19:44:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 19:44:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:44:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 19:44:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:44:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 19:44:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:45:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 19:45:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 19:45:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 19:45:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:05<00:14,  1.43it/s][A
 29%|██▊       | 8/28 [00:05<00:15,  1.28it/s][A
 32%|███▏      | 9/28 [00:06<00:14,  1.32it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.35it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.36it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.41it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.41it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.41it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.41it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.41it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.41it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.41it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 19:45:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 19:45:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 19:46:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200/step003200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 19:46:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 19:46:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 19:46:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003200
01/22/2026 19:46:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 3200] Training Debug Info:
  Loss: 0.444955
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0195, std: 0.9453
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0206, std: 1.3750
  Model pred mean: 0.0240, std: 1.2031
  Sigmas: [0.90234375]... (timesteps: [902.0])

[Step 3200] Training Debug Info:
  Loss: 0.413025
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0396, std: 0.9531
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0391, std: 1.3750
  Model pred mean: -0.0356, std: 1.2266
  Sigmas: [0.734375]... (timesteps: [735.0])

[Step 3200] Training Debug Info:
  Loss: 0.896573
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0065, std: 0.9531
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0051, std: 1.3828
  Model pred mean: -0.0082, std: 1.0078
  Sigmas: [0.419921875]... (timesteps: [420.0])

[Step 3200] Training Debug Info:
  Loss: 1.185840
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0004, std: 0.8750
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0028, std: 1.3281
  Model pred mean: 0.0019, std: 0.7617
  Sigmas: [0.1845703125]... (timesteps: [185.0])
Steps:  64%|██████▍   | 3201/5000 [12:00:44<45:28:41, 91.01s/it, loss=1.1914, lr=3.45e-06]Steps:  64%|██████▍   | 3201/5000 [12:00:44<45:28:41, 91.01s/it, loss=1.1858, lr=3.45e-06]Steps:  64%|██████▍   | 3202/5000 [12:00:57<33:38:31, 67.36s/it, loss=1.1858, lr=3.45e-06]Steps:  64%|██████▍   | 3202/5000 [12:00:57<33:38:31, 67.36s/it, loss=1.0819, lr=3.45e-06]Steps:  64%|██████▍   | 3203/5000 [12:01:09<25:19:52, 50.75s/it, loss=1.0819, lr=3.45e-06]Steps:  64%|██████▍   | 3203/5000 [12:01:09<25:19:52, 50.75s/it, loss=1.1151, lr=3.44e-06]Steps:  64%|██████▍   | 3204/5000 [12:01:20<19:30:38, 39.11s/it, loss=1.1151, lr=3.44e-06]Steps:  64%|██████▍   | 3204/5000 [12:01:20<19:30:38, 39.11s/it, loss=0.6905, lr=3.44e-06]Steps:  64%|██████▍   | 3205/5000 [12:01:32<15:25:43, 30.94s/it, loss=0.6905, lr=3.44e-06]Steps:  64%|██████▍   | 3205/5000 [12:01:32<15:25:43, 30.94s/it, loss=0.8141, lr=3.44e-06]Steps:  64%|██████▍   | 3206/5000 [12:01:44<12:34:57, 25.25s/it, loss=0.8141, lr=3.44e-06]Steps:  64%|██████▍   | 3206/5000 [12:01:44<12:34:57, 25.25s/it, loss=0.4042, lr=3.44e-06]Steps:  64%|██████▍   | 3207/5000 [12:01:56<10:35:28, 21.27s/it, loss=0.4042, lr=3.44e-06]Steps:  64%|██████▍   | 3207/5000 [12:01:56<10:35:28, 21.27s/it, loss=1.1501, lr=3.43e-06]Steps:  64%|██████▍   | 3208/5000 [12:02:08<9:13:36, 18.54s/it, loss=1.1501, lr=3.43e-06] Steps:  64%|██████▍   | 3208/5000 [12:02:08<9:13:36, 18.54s/it, loss=0.4121, lr=3.43e-06]Steps:  64%|██████▍   | 3209/5000 [12:02:21<8:16:21, 16.63s/it, loss=0.4121, lr=3.43e-06]Steps:  64%|██████▍   | 3209/5000 [12:02:21<8:16:21, 16.63s/it, loss=1.0511, lr=3.43e-06]Steps:  64%|██████▍   | 3210/5000 [12:02:32<7:33:14, 15.19s/it, loss=1.0511, lr=3.43e-06]Steps:  64%|██████▍   | 3210/5000 [12:02:32<7:33:14, 15.19s/it, loss=0.4379, lr=3.42e-06]
[Step 3210] Training Debug Info:
  Loss: 1.124329
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0082, std: 0.9219
  Noise mean: 0.0016, std: 1.0000
  Target mean: 0.0099, std: 1.3594
  Model pred mean: 0.0061, std: 0.8516
  Sigmas: [0.091796875]... (timesteps: [92.0])

[Step 3210] Training Debug Info:
  Loss: 0.426619
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0022, std: 0.9492
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0057, std: 1.3750
  Model pred mean: -0.0078, std: 1.2266
  Sigmas: [0.89453125]... (timesteps: [896.0])

[Step 3210] Training Debug Info:
  Loss: 0.415720
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0141, std: 0.9688
  Noise mean: 0.0037, std: 1.0000
  Target mean: -0.0104, std: 1.3906
  Model pred mean: -0.0164, std: 1.2344
  Sigmas: [0.859375]... (timesteps: [858.0])

[Step 3210] Training Debug Info:
  Loss: 0.390064
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0050, std: 0.9102
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0085, std: 1.3516
  Model pred mean: -0.0044, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [793.0])
Steps:  64%|██████▍   | 3211/5000 [12:02:44<7:03:39, 14.21s/it, loss=0.4379, lr=3.42e-06]Steps:  64%|██████▍   | 3211/5000 [12:02:44<7:03:39, 14.21s/it, loss=0.3901, lr=3.42e-06]Steps:  64%|██████▍   | 3212/5000 [12:02:56<6:44:00, 13.56s/it, loss=0.3901, lr=3.42e-06]Steps:  64%|██████▍   | 3212/5000 [12:02:56<6:44:00, 13.56s/it, loss=1.0686, lr=3.42e-06]Steps:  64%|██████▍   | 3213/5000 [12:03:08<6:29:49, 13.09s/it, loss=1.0686, lr=3.42e-06]Steps:  64%|██████▍   | 3213/5000 [12:03:08<6:29:49, 13.09s/it, loss=1.1428, lr=3.41e-06]Steps:  64%|██████▍   | 3214/5000 [12:03:20<6:19:05, 12.74s/it, loss=1.1428, lr=3.41e-06]Steps:  64%|██████▍   | 3214/5000 [12:03:20<6:19:05, 12.74s/it, loss=0.4919, lr=3.41e-06]Steps:  64%|██████▍   | 3215/5000 [12:03:32<6:11:48, 12.50s/it, loss=0.4919, lr=3.41e-06]Steps:  64%|██████▍   | 3215/5000 [12:03:32<6:11:48, 12.50s/it, loss=0.8020, lr=3.41e-06]Steps:  64%|██████▍   | 3216/5000 [12:03:44<6:08:46, 12.40s/it, loss=0.8020, lr=3.41e-06]Steps:  64%|██████▍   | 3216/5000 [12:03:44<6:08:46, 12.40s/it, loss=0.4657, lr=3.40e-06]Steps:  64%|██████▍   | 3217/5000 [12:03:56<6:04:24, 12.26s/it, loss=0.4657, lr=3.40e-06]Steps:  64%|██████▍   | 3217/5000 [12:03:56<6:04:24, 12.26s/it, loss=0.7140, lr=3.40e-06]Steps:  64%|██████▍   | 3218/5000 [12:04:08<6:01:22, 12.17s/it, loss=0.7140, lr=3.40e-06]Steps:  64%|██████▍   | 3218/5000 [12:04:08<6:01:22, 12.17s/it, loss=0.5173, lr=3.40e-06]Steps:  64%|██████▍   | 3219/5000 [12:04:20<5:58:44, 12.09s/it, loss=0.5173, lr=3.40e-06]Steps:  64%|██████▍   | 3219/5000 [12:04:20<5:58:44, 12.09s/it, loss=0.4035, lr=3.39e-06]Steps:  64%|██████▍   | 3220/5000 [12:04:32<5:56:55, 12.03s/it, loss=0.4035, lr=3.39e-06]Steps:  64%|██████▍   | 3220/5000 [12:04:32<5:56:55, 12.03s/it, loss=0.9299, lr=3.39e-06]
[Step 3220] Training Debug Info:
  Loss: 0.719958
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0090, std: 0.9609
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0107, std: 1.3906
  Model pred mean: -0.0009, std: 1.1172
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 3220] Training Debug Info:
  Loss: 0.348978
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0454, std: 0.9023
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0447, std: 1.3438
  Model pred mean: 0.0474, std: 1.2031
  Sigmas: [0.85546875]... (timesteps: [856.0])

[Step 3220] Training Debug Info:
  Loss: 0.489159
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0054, std: 0.8906
  Noise mean: -0.0019, std: 1.0000
  Target mean: 0.0035, std: 1.3359
  Model pred mean: 0.0059, std: 1.1406
  Sigmas: [0.68359375]... (timesteps: [684.0])

[Step 3220] Training Debug Info:
  Loss: 1.100519
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0229, std: 0.8945
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0242, std: 1.3438
  Model pred mean: -0.0221, std: 0.8359
  Sigmas: [0.259765625]... (timesteps: [260.0])
Steps:  64%|██████▍   | 3221/5000 [12:04:44<5:55:23, 11.99s/it, loss=0.9299, lr=3.39e-06]Steps:  64%|██████▍   | 3221/5000 [12:04:44<5:55:23, 11.99s/it, loss=1.1005, lr=3.39e-06]Steps:  64%|██████▍   | 3222/5000 [12:04:56<5:58:54, 12.11s/it, loss=1.1005, lr=3.39e-06]Steps:  64%|██████▍   | 3222/5000 [12:04:56<5:58:54, 12.11s/it, loss=1.1645, lr=3.38e-06]Steps:  64%|██████▍   | 3223/5000 [12:05:08<5:57:13, 12.06s/it, loss=1.1645, lr=3.38e-06]Steps:  64%|██████▍   | 3223/5000 [12:05:08<5:57:13, 12.06s/it, loss=0.4826, lr=3.38e-06]Steps:  64%|██████▍   | 3224/5000 [12:05:20<5:55:10, 12.00s/it, loss=0.4826, lr=3.38e-06]Steps:  64%|██████▍   | 3224/5000 [12:05:20<5:55:10, 12.00s/it, loss=0.9334, lr=3.38e-06]Steps:  64%|██████▍   | 3225/5000 [12:05:32<5:55:08, 12.01s/it, loss=0.9334, lr=3.38e-06]Steps:  64%|██████▍   | 3225/5000 [12:05:32<5:55:08, 12.01s/it, loss=0.4159, lr=3.37e-06]Steps:  65%|██████▍   | 3226/5000 [12:05:44<5:54:36, 11.99s/it, loss=0.4159, lr=3.37e-06]Steps:  65%|██████▍   | 3226/5000 [12:05:44<5:54:36, 11.99s/it, loss=1.1559, lr=3.37e-06]Steps:  65%|██████▍   | 3227/5000 [12:05:56<5:53:51, 11.97s/it, loss=1.1559, lr=3.37e-06]Steps:  65%|██████▍   | 3227/5000 [12:05:56<5:53:51, 11.97s/it, loss=1.0124, lr=3.37e-06]Steps:  65%|██████▍   | 3228/5000 [12:06:08<5:53:32, 11.97s/it, loss=1.0124, lr=3.37e-06]Steps:  65%|██████▍   | 3228/5000 [12:06:08<5:53:32, 11.97s/it, loss=1.0344, lr=3.36e-06]Steps:  65%|██████▍   | 3229/5000 [12:06:21<5:57:47, 12.12s/it, loss=1.0344, lr=3.36e-06]Steps:  65%|██████▍   | 3229/5000 [12:06:21<5:57:47, 12.12s/it, loss=0.4951, lr=3.36e-06]Steps:  65%|██████▍   | 3230/5000 [12:06:32<5:55:39, 12.06s/it, loss=0.4951, lr=3.36e-06]Steps:  65%|██████▍   | 3230/5000 [12:06:32<5:55:39, 12.06s/it, loss=0.3408, lr=3.36e-06]
[Step 3230] Training Debug Info:
  Loss: 1.132527
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0062, std: 0.9062
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0059, std: 1.3516
  Model pred mean: 0.0042, std: 0.8320
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 3230] Training Debug Info:
  Loss: 1.019013
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0177, std: 0.9336
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0204, std: 1.3672
  Model pred mean: -0.0192, std: 0.9297
  Sigmas: [0.26171875]... (timesteps: [262.0])

[Step 3230] Training Debug Info:
  Loss: 0.924916
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0059, std: 0.8672
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0063, std: 1.3281
  Model pred mean: -0.0068, std: 0.9141
  Sigmas: [0.380859375]... (timesteps: [380.0])

[Step 3230] Training Debug Info:
  Loss: 1.004603
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0212, std: 0.8398
  Noise mean: -0.0007, std: 0.9961
  Target mean: 0.0205, std: 1.3047
  Model pred mean: 0.0203, std: 0.8359
  Sigmas: [0.392578125]... (timesteps: [392.0])
Steps:  65%|██████▍   | 3231/5000 [12:06:44<5:53:38, 11.99s/it, loss=0.3408, lr=3.36e-06]Steps:  65%|██████▍   | 3231/5000 [12:06:44<5:53:38, 11.99s/it, loss=1.0046, lr=3.35e-06]Steps:  65%|██████▍   | 3232/5000 [12:06:56<5:52:26, 11.96s/it, loss=1.0046, lr=3.35e-06]Steps:  65%|██████▍   | 3232/5000 [12:06:56<5:52:26, 11.96s/it, loss=0.5593, lr=3.35e-06]Steps:  65%|██████▍   | 3233/5000 [12:07:08<5:51:32, 11.94s/it, loss=0.5593, lr=3.35e-06]Steps:  65%|██████▍   | 3233/5000 [12:07:08<5:51:32, 11.94s/it, loss=1.1245, lr=3.35e-06]Steps:  65%|██████▍   | 3234/5000 [12:07:20<5:51:24, 11.94s/it, loss=1.1245, lr=3.35e-06]Steps:  65%|██████▍   | 3234/5000 [12:07:20<5:51:24, 11.94s/it, loss=1.1073, lr=3.34e-06]Steps:  65%|██████▍   | 3235/5000 [12:07:32<5:51:03, 11.93s/it, loss=1.1073, lr=3.34e-06]Steps:  65%|██████▍   | 3235/5000 [12:07:32<5:51:03, 11.93s/it, loss=1.0611, lr=3.34e-06]Steps:  65%|██████▍   | 3236/5000 [12:07:44<5:53:39, 12.03s/it, loss=1.0611, lr=3.34e-06]Steps:  65%|██████▍   | 3236/5000 [12:07:44<5:53:39, 12.03s/it, loss=0.6510, lr=3.34e-06]Steps:  65%|██████▍   | 3237/5000 [12:07:56<5:51:27, 11.96s/it, loss=0.6510, lr=3.34e-06]Steps:  65%|██████▍   | 3237/5000 [12:07:56<5:51:27, 11.96s/it, loss=1.0599, lr=3.33e-06]Steps:  65%|██████▍   | 3238/5000 [12:08:08<5:50:52, 11.95s/it, loss=1.0599, lr=3.33e-06]Steps:  65%|██████▍   | 3238/5000 [12:08:08<5:50:52, 11.95s/it, loss=0.4113, lr=3.33e-06]Steps:  65%|██████▍   | 3239/5000 [12:08:20<5:50:38, 11.95s/it, loss=0.4113, lr=3.33e-06]Steps:  65%|██████▍   | 3239/5000 [12:08:20<5:50:38, 11.95s/it, loss=0.4699, lr=3.33e-06]Steps:  65%|██████▍   | 3240/5000 [12:08:32<5:49:59, 11.93s/it, loss=0.4699, lr=3.33e-06]Steps:  65%|██████▍   | 3240/5000 [12:08:32<5:49:59, 11.93s/it, loss=0.3810, lr=3.32e-06]
[Step 3240] Training Debug Info:
  Loss: 0.521851
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0259, std: 0.9648
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0237, std: 1.3906
  Model pred mean: -0.0283, std: 1.1797
  Sigmas: [0.62109375]... (timesteps: [621.0])

[Step 3240] Training Debug Info:
  Loss: 1.149231
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.8906
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0039, std: 1.3359
  Model pred mean: 0.0026, std: 0.7969
  Sigmas: [0.11279296875]... (timesteps: [113.0])

[Step 3240] Training Debug Info:
  Loss: 0.750570
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0381, std: 1.0000
  Noise mean: -0.0041, std: 1.0000
  Target mean: -0.0422, std: 1.4141
  Model pred mean: -0.0378, std: 1.1172
  Sigmas: [0.427734375]... (timesteps: [428.0])

[Step 3240] Training Debug Info:
  Loss: 0.519315
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0400, std: 0.9141
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0415, std: 1.3516
  Model pred mean: -0.0354, std: 1.1484
  Sigmas: [0.56640625]... (timesteps: [568.0])
Steps:  65%|██████▍   | 3241/5000 [12:08:44<5:49:22, 11.92s/it, loss=0.3810, lr=3.32e-06]Steps:  65%|██████▍   | 3241/5000 [12:08:44<5:49:22, 11.92s/it, loss=0.5193, lr=3.32e-06]Steps:  65%|██████▍   | 3242/5000 [12:08:56<5:50:04, 11.95s/it, loss=0.5193, lr=3.32e-06]Steps:  65%|██████▍   | 3242/5000 [12:08:56<5:50:04, 11.95s/it, loss=1.1669, lr=3.32e-06]Steps:  65%|██████▍   | 3243/5000 [12:09:08<5:51:52, 12.02s/it, loss=1.1669, lr=3.32e-06]Steps:  65%|██████▍   | 3243/5000 [12:09:08<5:51:52, 12.02s/it, loss=0.3967, lr=3.31e-06]Steps:  65%|██████▍   | 3244/5000 [12:09:20<5:50:40, 11.98s/it, loss=0.3967, lr=3.31e-06]Steps:  65%|██████▍   | 3244/5000 [12:09:20<5:50:40, 11.98s/it, loss=1.0902, lr=3.31e-06]Steps:  65%|██████▍   | 3245/5000 [12:09:32<5:50:27, 11.98s/it, loss=1.0902, lr=3.31e-06]Steps:  65%|██████▍   | 3245/5000 [12:09:32<5:50:27, 11.98s/it, loss=0.9768, lr=3.31e-06]Steps:  65%|██████▍   | 3246/5000 [12:09:44<5:49:55, 11.97s/it, loss=0.9768, lr=3.31e-06]Steps:  65%|██████▍   | 3246/5000 [12:09:44<5:49:55, 11.97s/it, loss=0.7110, lr=3.30e-06]Steps:  65%|██████▍   | 3247/5000 [12:09:56<5:49:50, 11.97s/it, loss=0.7110, lr=3.30e-06]Steps:  65%|██████▍   | 3247/5000 [12:09:56<5:49:50, 11.97s/it, loss=0.4006, lr=3.30e-06]Steps:  65%|██████▍   | 3248/5000 [12:10:08<5:49:15, 11.96s/it, loss=0.4006, lr=3.30e-06]Steps:  65%|██████▍   | 3248/5000 [12:10:08<5:49:15, 11.96s/it, loss=0.4876, lr=3.30e-06]Steps:  65%|██████▍   | 3249/5000 [12:10:20<5:51:04, 12.03s/it, loss=0.4876, lr=3.30e-06]Steps:  65%|██████▍   | 3249/5000 [12:10:20<5:51:04, 12.03s/it, loss=0.6736, lr=3.29e-06]Steps:  65%|██████▌   | 3250/5000 [12:10:32<5:50:31, 12.02s/it, loss=0.6736, lr=3.29e-06]Steps:  65%|██████▌   | 3250/5000 [12:10:32<5:50:31, 12.02s/it, loss=1.0573, lr=3.29e-06]
[Step 3250] Training Debug Info:
  Loss: 0.670983
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0051, std: 0.9023
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0048, std: 1.3438
  Model pred mean: 0.0069, std: 1.0703
  Sigmas: [0.5390625]... (timesteps: [540.0])

[Step 3250] Training Debug Info:
  Loss: 0.507294
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0289, std: 0.8633
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0283, std: 1.3281
  Model pred mean: 0.0275, std: 1.1172
  Sigmas: [0.67578125]... (timesteps: [677.0])

[Step 3250] Training Debug Info:
  Loss: 0.843209
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0137, std: 0.9297
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0160, std: 1.3672
  Model pred mean: -0.0118, std: 1.0156
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 3250] Training Debug Info:
  Loss: 0.374755
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0134, std: 0.9062
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0139, std: 1.3516
  Model pred mean: 0.0132, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [793.0])
Steps:  65%|██████▌   | 3251/5000 [12:10:44<5:49:31, 11.99s/it, loss=1.0573, lr=3.29e-06]Steps:  65%|██████▌   | 3251/5000 [12:10:44<5:49:31, 11.99s/it, loss=0.3748, lr=3.29e-06]Steps:  65%|██████▌   | 3252/5000 [12:10:56<5:50:28, 12.03s/it, loss=0.3748, lr=3.29e-06]Steps:  65%|██████▌   | 3252/5000 [12:10:56<5:50:28, 12.03s/it, loss=0.5142, lr=3.28e-06]Steps:  65%|██████▌   | 3253/5000 [12:11:08<5:49:43, 12.01s/it, loss=0.5142, lr=3.28e-06]Steps:  65%|██████▌   | 3253/5000 [12:11:08<5:49:43, 12.01s/it, loss=0.6067, lr=3.28e-06]Steps:  65%|██████▌   | 3254/5000 [12:11:20<5:49:04, 12.00s/it, loss=0.6067, lr=3.28e-06]Steps:  65%|██████▌   | 3254/5000 [12:11:20<5:49:04, 12.00s/it, loss=0.5121, lr=3.28e-06]Steps:  65%|██████▌   | 3255/5000 [12:11:32<5:47:45, 11.96s/it, loss=0.5121, lr=3.28e-06]Steps:  65%|██████▌   | 3255/5000 [12:11:32<5:47:45, 11.96s/it, loss=1.0161, lr=3.27e-06]Steps:  65%|██████▌   | 3256/5000 [12:11:44<5:49:23, 12.02s/it, loss=1.0161, lr=3.27e-06]Steps:  65%|██████▌   | 3256/5000 [12:11:44<5:49:23, 12.02s/it, loss=0.4289, lr=3.27e-06]Steps:  65%|██████▌   | 3257/5000 [12:11:56<5:47:50, 11.97s/it, loss=0.4289, lr=3.27e-06]Steps:  65%|██████▌   | 3257/5000 [12:11:56<5:47:50, 11.97s/it, loss=0.5785, lr=3.27e-06]Steps:  65%|██████▌   | 3258/5000 [12:12:08<5:46:35, 11.94s/it, loss=0.5785, lr=3.27e-06]Steps:  65%|██████▌   | 3258/5000 [12:12:08<5:46:35, 11.94s/it, loss=0.9205, lr=3.26e-06]Steps:  65%|██████▌   | 3259/5000 [12:12:19<5:46:04, 11.93s/it, loss=0.9205, lr=3.26e-06]Steps:  65%|██████▌   | 3259/5000 [12:12:19<5:46:04, 11.93s/it, loss=1.1055, lr=3.26e-06]Steps:  65%|██████▌   | 3260/5000 [12:12:31<5:45:29, 11.91s/it, loss=1.1055, lr=3.26e-06]Steps:  65%|██████▌   | 3260/5000 [12:12:31<5:45:29, 11.91s/it, loss=1.1857, lr=3.26e-06]
[Step 3260] Training Debug Info:
  Loss: 1.113865
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0359, std: 0.9453
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0361, std: 1.3750
  Model pred mean: 0.0332, std: 0.8828
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 3260] Training Debug Info:
  Loss: 1.020856
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0234, std: 0.9180
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0226, std: 1.3594
  Model pred mean: 0.0258, std: 0.9023
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 3260] Training Debug Info:
  Loss: 1.198222
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0135, std: 0.8633
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0126, std: 1.3203
  Model pred mean: 0.0108, std: 0.7383
  Sigmas: [0.15234375]... (timesteps: [152.0])

[Step 3260] Training Debug Info:
  Loss: 0.439358
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0122, std: 0.8984
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0102, std: 1.3438
  Model pred mean: 0.0177, std: 1.1797
  Sigmas: [0.90234375]... (timesteps: [904.0])
Steps:  65%|██████▌   | 3261/5000 [12:12:43<5:46:15, 11.95s/it, loss=1.1857, lr=3.26e-06]Steps:  65%|██████▌   | 3261/5000 [12:12:43<5:46:15, 11.95s/it, loss=0.4394, lr=3.25e-06]Steps:  65%|██████▌   | 3262/5000 [12:12:55<5:46:33, 11.96s/it, loss=0.4394, lr=3.25e-06]Steps:  65%|██████▌   | 3262/5000 [12:12:55<5:46:33, 11.96s/it, loss=1.0874, lr=3.25e-06]Steps:  65%|██████▌   | 3263/5000 [12:13:08<5:48:47, 12.05s/it, loss=1.0874, lr=3.25e-06]Steps:  65%|██████▌   | 3263/5000 [12:13:08<5:48:47, 12.05s/it, loss=0.6608, lr=3.25e-06]Steps:  65%|██████▌   | 3264/5000 [12:13:19<5:47:26, 12.01s/it, loss=0.6608, lr=3.25e-06]Steps:  65%|██████▌   | 3264/5000 [12:13:19<5:47:26, 12.01s/it, loss=1.1337, lr=3.24e-06]Steps:  65%|██████▌   | 3265/5000 [12:13:31<5:46:47, 11.99s/it, loss=1.1337, lr=3.24e-06]Steps:  65%|██████▌   | 3265/5000 [12:13:31<5:46:47, 11.99s/it, loss=0.8157, lr=3.24e-06]Steps:  65%|██████▌   | 3266/5000 [12:13:43<5:46:42, 12.00s/it, loss=0.8157, lr=3.24e-06]Steps:  65%|██████▌   | 3266/5000 [12:13:43<5:46:42, 12.00s/it, loss=0.6358, lr=3.24e-06]Steps:  65%|██████▌   | 3267/5000 [12:13:55<5:45:20, 11.96s/it, loss=0.6358, lr=3.24e-06]Steps:  65%|██████▌   | 3267/5000 [12:13:55<5:45:20, 11.96s/it, loss=0.4054, lr=3.23e-06]Steps:  65%|██████▌   | 3268/5000 [12:14:07<5:45:08, 11.96s/it, loss=0.4054, lr=3.23e-06]Steps:  65%|██████▌   | 3268/5000 [12:14:07<5:45:08, 11.96s/it, loss=1.0163, lr=3.23e-06]Steps:  65%|██████▌   | 3269/5000 [12:14:19<5:44:42, 11.95s/it, loss=1.0163, lr=3.23e-06]Steps:  65%|██████▌   | 3269/5000 [12:14:19<5:44:42, 11.95s/it, loss=0.8299, lr=3.23e-06]Steps:  65%|██████▌   | 3270/5000 [12:14:31<5:47:32, 12.05s/it, loss=0.8299, lr=3.23e-06]Steps:  65%|██████▌   | 3270/5000 [12:14:31<5:47:32, 12.05s/it, loss=0.3818, lr=3.22e-06]
[Step 3270] Training Debug Info:
  Loss: 0.955249
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0109, std: 0.9062
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0093, std: 1.3516
  Model pred mean: -0.0083, std: 0.9297
  Sigmas: [0.365234375]... (timesteps: [365.0])

[Step 3270] Training Debug Info:
  Loss: 0.358372
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0393, std: 0.8594
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0381, std: 1.3203
  Model pred mean: 0.0374, std: 1.1797
  Sigmas: [0.8828125]... (timesteps: [884.0])

[Step 3270] Training Debug Info:
  Loss: 1.163280
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0080, std: 0.8828
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0086, std: 1.3359
  Model pred mean: -0.0058, std: 0.7891
  Sigmas: [0.2392578125]... (timesteps: [239.0])

[Step 3270] Training Debug Info:
  Loss: 1.147738
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0006, std: 0.8984
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0040, std: 1.3438
  Model pred mean: 0.0036, std: 0.8125
  Sigmas: [0.130859375]... (timesteps: [131.0])
Steps:  65%|██████▌   | 3271/5000 [12:14:43<5:46:24, 12.02s/it, loss=0.3818, lr=3.22e-06]Steps:  65%|██████▌   | 3271/5000 [12:14:43<5:46:24, 12.02s/it, loss=1.1477, lr=3.22e-06]Steps:  65%|██████▌   | 3272/5000 [12:14:55<5:45:33, 12.00s/it, loss=1.1477, lr=3.22e-06]Steps:  65%|██████▌   | 3272/5000 [12:14:55<5:45:33, 12.00s/it, loss=0.4515, lr=3.22e-06]Steps:  65%|██████▌   | 3273/5000 [12:15:07<5:44:48, 11.98s/it, loss=0.4515, lr=3.22e-06]Steps:  65%|██████▌   | 3273/5000 [12:15:07<5:44:48, 11.98s/it, loss=0.9140, lr=3.21e-06]Steps:  65%|██████▌   | 3274/5000 [12:15:19<5:44:13, 11.97s/it, loss=0.9140, lr=3.21e-06]Steps:  65%|██████▌   | 3274/5000 [12:15:19<5:44:13, 11.97s/it, loss=0.5260, lr=3.21e-06]Steps:  66%|██████▌   | 3275/5000 [12:15:31<5:43:30, 11.95s/it, loss=0.5260, lr=3.21e-06]Steps:  66%|██████▌   | 3275/5000 [12:15:31<5:43:30, 11.95s/it, loss=1.1112, lr=3.21e-06]Steps:  66%|██████▌   | 3276/5000 [12:15:43<5:45:05, 12.01s/it, loss=1.1112, lr=3.21e-06]Steps:  66%|██████▌   | 3276/5000 [12:15:43<5:45:05, 12.01s/it, loss=0.4143, lr=3.20e-06]Steps:  66%|██████▌   | 3277/5000 [12:15:55<5:43:46, 11.97s/it, loss=0.4143, lr=3.20e-06]Steps:  66%|██████▌   | 3277/5000 [12:15:55<5:43:46, 11.97s/it, loss=0.7205, lr=3.20e-06]Steps:  66%|██████▌   | 3278/5000 [12:16:07<5:43:08, 11.96s/it, loss=0.7205, lr=3.20e-06]Steps:  66%|██████▌   | 3278/5000 [12:16:07<5:43:08, 11.96s/it, loss=0.6055, lr=3.20e-06]Steps:  66%|██████▌   | 3279/5000 [12:16:19<5:44:23, 12.01s/it, loss=0.6055, lr=3.20e-06]Steps:  66%|██████▌   | 3279/5000 [12:16:19<5:44:23, 12.01s/it, loss=0.8201, lr=3.20e-06]Steps:  66%|██████▌   | 3280/5000 [12:16:31<5:43:25, 11.98s/it, loss=0.8201, lr=3.20e-06]Steps:  66%|██████▌   | 3280/5000 [12:16:31<5:43:25, 11.98s/it, loss=0.9670, lr=3.19e-06]
[Step 3280] Training Debug Info:
  Loss: 0.506102
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0013, std: 0.9180
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0019, std: 1.3594
  Model pred mean: 0.0008, std: 1.1484
  Sigmas: [0.9453125]... (timesteps: [944.0])

[Step 3280] Training Debug Info:
  Loss: 0.487289
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0217, std: 0.9609
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0198, std: 1.3906
  Model pred mean: -0.0269, std: 1.1953
  Sigmas: [0.73828125]... (timesteps: [739.0])

[Step 3280] Training Debug Info:
  Loss: 1.015772
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0155, std: 0.8945
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0164, std: 1.3359
  Model pred mean: -0.0168, std: 0.8828
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 3280] Training Debug Info:
  Loss: 0.420461
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0041, std: 0.8945
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0026, std: 1.3438
  Model pred mean: 0.0054, std: 1.1797
  Sigmas: [0.82421875]... (timesteps: [824.0])
Steps:  66%|██████▌   | 3281/5000 [12:16:43<5:42:28, 11.95s/it, loss=0.9670, lr=3.19e-06]Steps:  66%|██████▌   | 3281/5000 [12:16:43<5:42:28, 11.95s/it, loss=0.4205, lr=3.19e-06]Steps:  66%|██████▌   | 3282/5000 [12:16:55<5:42:23, 11.96s/it, loss=0.4205, lr=3.19e-06]Steps:  66%|██████▌   | 3282/5000 [12:16:55<5:42:23, 11.96s/it, loss=0.8109, lr=3.19e-06]Steps:  66%|██████▌   | 3283/5000 [12:17:07<5:44:48, 12.05s/it, loss=0.8109, lr=3.19e-06]Steps:  66%|██████▌   | 3283/5000 [12:17:07<5:44:48, 12.05s/it, loss=1.1057, lr=3.18e-06]Steps:  66%|██████▌   | 3284/5000 [12:17:19<5:44:01, 12.03s/it, loss=1.1057, lr=3.18e-06]Steps:  66%|██████▌   | 3284/5000 [12:17:19<5:44:01, 12.03s/it, loss=0.5216, lr=3.18e-06]Steps:  66%|██████▌   | 3285/5000 [12:17:31<5:43:06, 12.00s/it, loss=0.5216, lr=3.18e-06]Steps:  66%|██████▌   | 3285/5000 [12:17:31<5:43:06, 12.00s/it, loss=1.1902, lr=3.18e-06]Steps:  66%|██████▌   | 3286/5000 [12:17:43<5:42:34, 11.99s/it, loss=1.1902, lr=3.18e-06]Steps:  66%|██████▌   | 3286/5000 [12:17:43<5:42:34, 11.99s/it, loss=0.6109, lr=3.17e-06]Steps:  66%|██████▌   | 3287/5000 [12:17:55<5:42:06, 11.98s/it, loss=0.6109, lr=3.17e-06]Steps:  66%|██████▌   | 3287/5000 [12:17:55<5:42:06, 11.98s/it, loss=0.5465, lr=3.17e-06]Steps:  66%|██████▌   | 3288/5000 [12:18:07<5:42:17, 12.00s/it, loss=0.5465, lr=3.17e-06]Steps:  66%|██████▌   | 3288/5000 [12:18:07<5:42:17, 12.00s/it, loss=0.4254, lr=3.17e-06]Steps:  66%|██████▌   | 3289/5000 [12:18:19<5:41:23, 11.97s/it, loss=0.4254, lr=3.17e-06]Steps:  66%|██████▌   | 3289/5000 [12:18:19<5:41:23, 11.97s/it, loss=1.0994, lr=3.16e-06]Steps:  66%|██████▌   | 3290/5000 [12:18:31<5:43:13, 12.04s/it, loss=1.0994, lr=3.16e-06]Steps:  66%|██████▌   | 3290/5000 [12:18:31<5:43:13, 12.04s/it, loss=0.8705, lr=3.16e-06]
[Step 3290] Training Debug Info:
  Loss: 0.517103
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0034, std: 0.9219
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0078, std: 1.3594
  Model pred mean: -0.0062, std: 1.1562
  Sigmas: [0.671875]... (timesteps: [672.0])

[Step 3290] Training Debug Info:
  Loss: 0.997056
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0201, std: 0.9141
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0231, std: 1.3594
  Model pred mean: -0.0188, std: 0.9141
  Sigmas: [0.30859375]... (timesteps: [309.0])

[Step 3290] Training Debug Info:
  Loss: 0.451898
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0200, std: 0.9727
  Noise mean: -0.0041, std: 1.0000
  Target mean: -0.0242, std: 1.3984
  Model pred mean: -0.0231, std: 1.2188
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 3290] Training Debug Info:
  Loss: 0.644081
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0038, std: 0.9062
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0026, std: 1.3516
  Model pred mean: 0.0033, std: 1.0859
  Sigmas: [0.53515625]... (timesteps: [534.0])
Steps:  66%|██████▌   | 3291/5000 [12:18:43<5:41:59, 12.01s/it, loss=0.8705, lr=3.16e-06]Steps:  66%|██████▌   | 3291/5000 [12:18:43<5:41:59, 12.01s/it, loss=0.6441, lr=3.16e-06]Steps:  66%|██████▌   | 3292/5000 [12:18:55<5:41:22, 11.99s/it, loss=0.6441, lr=3.16e-06]Steps:  66%|██████▌   | 3292/5000 [12:18:55<5:41:22, 11.99s/it, loss=1.0626, lr=3.15e-06]Steps:  66%|██████▌   | 3293/5000 [12:19:07<5:40:39, 11.97s/it, loss=1.0626, lr=3.15e-06]Steps:  66%|██████▌   | 3293/5000 [12:19:07<5:40:39, 11.97s/it, loss=0.6822, lr=3.15e-06]Steps:  66%|██████▌   | 3294/5000 [12:19:19<5:39:34, 11.94s/it, loss=0.6822, lr=3.15e-06]Steps:  66%|██████▌   | 3294/5000 [12:19:19<5:39:34, 11.94s/it, loss=0.3986, lr=3.15e-06]Steps:  66%|██████▌   | 3295/5000 [12:19:31<5:39:39, 11.95s/it, loss=0.3986, lr=3.15e-06]Steps:  66%|██████▌   | 3295/5000 [12:19:31<5:39:39, 11.95s/it, loss=1.0730, lr=3.14e-06]Steps:  66%|██████▌   | 3296/5000 [12:19:43<5:38:58, 11.94s/it, loss=1.0730, lr=3.14e-06]Steps:  66%|██████▌   | 3296/5000 [12:19:43<5:38:58, 11.94s/it, loss=0.8817, lr=3.14e-06]Steps:  66%|██████▌   | 3297/5000 [12:19:55<5:42:26, 12.06s/it, loss=0.8817, lr=3.14e-06]Steps:  66%|██████▌   | 3297/5000 [12:19:55<5:42:26, 12.06s/it, loss=1.0003, lr=3.14e-06]Steps:  66%|██████▌   | 3298/5000 [12:20:07<5:41:21, 12.03s/it, loss=1.0003, lr=3.14e-06]Steps:  66%|██████▌   | 3298/5000 [12:20:07<5:41:21, 12.03s/it, loss=1.1309, lr=3.13e-06]Steps:  66%|██████▌   | 3299/5000 [12:20:19<5:39:21, 11.97s/it, loss=1.1309, lr=3.13e-06]Steps:  66%|██████▌   | 3299/5000 [12:20:19<5:39:21, 11.97s/it, loss=0.4403, lr=3.13e-06]Steps:  66%|██████▌   | 3300/5000 [12:20:31<5:38:31, 11.95s/it, loss=0.4403, lr=3.13e-06]Steps:  66%|██████▌   | 3300/5000 [12:20:31<5:38:31, 11.95s/it, loss=1.1065, lr=3.13e-06]01/22/2026 20:06:18 - INFO - __main__ - 
[Step 3300] ✅ Loss in normal range (1.1065)
01/22/2026 20:06:18 - INFO - __main__ -   Loss avg (last 100): 0.7706
01/22/2026 20:06:18 - INFO - __main__ -   Loss range: [0.3408, 1.1902]

[Step 3300] Training Debug Info:
  Loss: 1.054564
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0064, std: 0.9180
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0089, std: 1.3594
  Model pred mean: -0.0043, std: 0.8906
  Sigmas: [0.296875]... (timesteps: [297.0])

[Step 3300] Training Debug Info:
  Loss: 0.560594
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0178, std: 0.9688
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0170, std: 1.3906
  Model pred mean: -0.0127, std: 1.1797
  Sigmas: [0.65625]... (timesteps: [657.0])

[Step 3300] Training Debug Info:
  Loss: 0.808368
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0271, std: 0.9375
  Noise mean: -0.0053, std: 1.0000
  Target mean: -0.0325, std: 1.3672
  Model pred mean: -0.0232, std: 1.0312
  Sigmas: [0.380859375]... (timesteps: [381.0])

[Step 3300] Training Debug Info:
  Loss: 0.368356
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0198, std: 0.8828
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0203, std: 1.3359
  Model pred mean: 0.0162, std: 1.1875
  Sigmas: [0.84765625]... (timesteps: [846.0])
Steps:  66%|██████▌   | 3301/5000 [12:20:43<5:38:01, 11.94s/it, loss=1.1065, lr=3.13e-06]Steps:  66%|██████▌   | 3301/5000 [12:20:43<5:38:01, 11.94s/it, loss=0.3684, lr=3.12e-06]Steps:  66%|██████▌   | 3302/5000 [12:20:55<5:37:09, 11.91s/it, loss=0.3684, lr=3.12e-06]Steps:  66%|██████▌   | 3302/5000 [12:20:55<5:37:09, 11.91s/it, loss=0.3557, lr=3.12e-06]Steps:  66%|██████▌   | 3303/5000 [12:21:07<5:39:24, 12.00s/it, loss=0.3557, lr=3.12e-06]Steps:  66%|██████▌   | 3303/5000 [12:21:07<5:39:24, 12.00s/it, loss=0.4911, lr=3.12e-06]Steps:  66%|██████▌   | 3304/5000 [12:21:19<5:38:43, 11.98s/it, loss=0.4911, lr=3.12e-06]Steps:  66%|██████▌   | 3304/5000 [12:21:19<5:38:43, 11.98s/it, loss=0.5896, lr=3.11e-06]Steps:  66%|██████▌   | 3305/5000 [12:21:31<5:39:01, 12.00s/it, loss=0.5896, lr=3.11e-06]Steps:  66%|██████▌   | 3305/5000 [12:21:31<5:39:01, 12.00s/it, loss=1.0160, lr=3.11e-06]Steps:  66%|██████▌   | 3306/5000 [12:21:43<5:38:13, 11.98s/it, loss=1.0160, lr=3.11e-06]Steps:  66%|██████▌   | 3306/5000 [12:21:43<5:38:13, 11.98s/it, loss=0.4060, lr=3.11e-06]Steps:  66%|██████▌   | 3307/5000 [12:21:55<5:38:07, 11.98s/it, loss=0.4060, lr=3.11e-06]Steps:  66%|██████▌   | 3307/5000 [12:21:55<5:38:07, 11.98s/it, loss=1.0109, lr=3.10e-06]Steps:  66%|██████▌   | 3308/5000 [12:22:07<5:37:31, 11.97s/it, loss=1.0109, lr=3.10e-06]Steps:  66%|██████▌   | 3308/5000 [12:22:07<5:37:31, 11.97s/it, loss=0.4011, lr=3.10e-06]Steps:  66%|██████▌   | 3309/5000 [12:22:19<5:36:48, 11.95s/it, loss=0.4011, lr=3.10e-06]Steps:  66%|██████▌   | 3309/5000 [12:22:19<5:36:48, 11.95s/it, loss=0.4098, lr=3.10e-06]Steps:  66%|██████▌   | 3310/5000 [12:22:31<5:38:31, 12.02s/it, loss=0.4098, lr=3.10e-06]Steps:  66%|██████▌   | 3310/5000 [12:22:31<5:38:31, 12.02s/it, loss=1.1263, lr=3.09e-06]
[Step 3310] Training Debug Info:
  Loss: 0.366717
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.9258
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0070, std: 1.3672
  Model pred mean: -0.0139, std: 1.2188
  Sigmas: [0.8203125]... (timesteps: [822.0])

[Step 3310] Training Debug Info:
  Loss: 0.839963
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0004, std: 0.8672
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0018, std: 1.3281
  Model pred mean: -0.0020, std: 0.9531
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 3310] Training Debug Info:
  Loss: 0.657448
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0072, std: 0.8945
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0067, std: 1.3438
  Model pred mean: -0.0096, std: 1.0703
  Sigmas: [0.55078125]... (timesteps: [549.0])

[Step 3310] Training Debug Info:
  Loss: 0.535292
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0031, std: 0.9141
  Noise mean: 0.0018, std: 0.9961
  Target mean: -0.0014, std: 1.3594
  Model pred mean: -0.0047, std: 1.1406
  Sigmas: [0.60546875]... (timesteps: [605.0])
Steps:  66%|██████▌   | 3311/5000 [12:22:43<5:37:59, 12.01s/it, loss=1.1263, lr=3.09e-06]Steps:  66%|██████▌   | 3311/5000 [12:22:43<5:37:59, 12.01s/it, loss=0.5353, lr=3.09e-06]Steps:  66%|██████▌   | 3312/5000 [12:22:55<5:37:27, 12.00s/it, loss=0.5353, lr=3.09e-06]Steps:  66%|██████▌   | 3312/5000 [12:22:55<5:37:27, 12.00s/it, loss=0.3799, lr=3.09e-06]Steps:  66%|██████▋   | 3313/5000 [12:23:07<5:37:10, 11.99s/it, loss=0.3799, lr=3.09e-06]Steps:  66%|██████▋   | 3313/5000 [12:23:07<5:37:10, 11.99s/it, loss=0.7197, lr=3.08e-06]Steps:  66%|██████▋   | 3314/5000 [12:23:19<5:36:48, 11.99s/it, loss=0.7197, lr=3.08e-06]Steps:  66%|██████▋   | 3314/5000 [12:23:19<5:36:48, 11.99s/it, loss=0.3623, lr=3.08e-06]Steps:  66%|██████▋   | 3315/5000 [12:23:31<5:35:23, 11.94s/it, loss=0.3623, lr=3.08e-06]Steps:  66%|██████▋   | 3315/5000 [12:23:31<5:35:23, 11.94s/it, loss=0.9840, lr=3.08e-06]Steps:  66%|██████▋   | 3316/5000 [12:23:42<5:35:17, 11.95s/it, loss=0.9840, lr=3.08e-06]Steps:  66%|██████▋   | 3316/5000 [12:23:42<5:35:17, 11.95s/it, loss=0.9469, lr=3.08e-06]Steps:  66%|██████▋   | 3317/5000 [12:23:55<5:36:40, 12.00s/it, loss=0.9469, lr=3.08e-06]Steps:  66%|██████▋   | 3317/5000 [12:23:55<5:36:40, 12.00s/it, loss=1.0952, lr=3.07e-06]Steps:  66%|██████▋   | 3318/5000 [12:24:07<5:35:29, 11.97s/it, loss=1.0952, lr=3.07e-06]Steps:  66%|██████▋   | 3318/5000 [12:24:07<5:35:29, 11.97s/it, loss=0.7207, lr=3.07e-06]Steps:  66%|██████▋   | 3319/5000 [12:24:18<5:34:31, 11.94s/it, loss=0.7207, lr=3.07e-06]Steps:  66%|██████▋   | 3319/5000 [12:24:18<5:34:31, 11.94s/it, loss=0.6226, lr=3.07e-06]Steps:  66%|██████▋   | 3320/5000 [12:24:30<5:34:56, 11.96s/it, loss=0.6226, lr=3.07e-06]Steps:  66%|██████▋   | 3320/5000 [12:24:30<5:34:56, 11.96s/it, loss=0.4032, lr=3.06e-06]
[Step 3320] Training Debug Info:
  Loss: 0.929759
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0068, std: 0.8945
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0089, std: 1.3359
  Model pred mean: 0.0079, std: 0.9297
  Sigmas: [0.384765625]... (timesteps: [384.0])

[Step 3320] Training Debug Info:
  Loss: 0.800749
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0060, std: 0.8945
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0034, std: 1.3359
  Model pred mean: 0.0059, std: 0.9922
  Sigmas: [0.453125]... (timesteps: [454.0])

[Step 3320] Training Debug Info:
  Loss: 0.462600
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0087, std: 0.8945
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0090, std: 1.3438
  Model pred mean: 0.0037, std: 1.1328
  Sigmas: [0.9453125]... (timesteps: [945.0])

[Step 3320] Training Debug Info:
  Loss: 0.447611
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0089, std: 0.9375
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0121, std: 1.3672
  Model pred mean: -0.0081, std: 1.1953
  Sigmas: [0.83203125]... (timesteps: [833.0])
Steps:  66%|██████▋   | 3321/5000 [12:24:42<5:34:32, 11.96s/it, loss=0.4032, lr=3.06e-06]Steps:  66%|██████▋   | 3321/5000 [12:24:42<5:34:32, 11.96s/it, loss=0.4476, lr=3.06e-06]Steps:  66%|██████▋   | 3322/5000 [12:24:54<5:34:24, 11.96s/it, loss=0.4476, lr=3.06e-06]Steps:  66%|██████▋   | 3322/5000 [12:24:54<5:34:24, 11.96s/it, loss=0.5272, lr=3.06e-06]Steps:  66%|██████▋   | 3323/5000 [12:25:06<5:35:02, 11.99s/it, loss=0.5272, lr=3.06e-06]Steps:  66%|██████▋   | 3323/5000 [12:25:06<5:35:02, 11.99s/it, loss=0.7111, lr=3.05e-06]Steps:  66%|██████▋   | 3324/5000 [12:25:19<5:37:03, 12.07s/it, loss=0.7111, lr=3.05e-06]Steps:  66%|██████▋   | 3324/5000 [12:25:19<5:37:03, 12.07s/it, loss=0.4193, lr=3.05e-06]Steps:  66%|██████▋   | 3325/5000 [12:25:31<5:35:54, 12.03s/it, loss=0.4193, lr=3.05e-06]Steps:  66%|██████▋   | 3325/5000 [12:25:31<5:35:54, 12.03s/it, loss=0.4370, lr=3.05e-06]Steps:  67%|██████▋   | 3326/5000 [12:25:42<5:34:53, 12.00s/it, loss=0.4370, lr=3.05e-06]Steps:  67%|██████▋   | 3326/5000 [12:25:42<5:34:53, 12.00s/it, loss=1.0215, lr=3.04e-06]Steps:  67%|██████▋   | 3327/5000 [12:25:54<5:34:20, 11.99s/it, loss=1.0215, lr=3.04e-06]Steps:  67%|██████▋   | 3327/5000 [12:25:54<5:34:20, 11.99s/it, loss=0.5210, lr=3.04e-06]Steps:  67%|██████▋   | 3328/5000 [12:26:06<5:34:21, 12.00s/it, loss=0.5210, lr=3.04e-06]Steps:  67%|██████▋   | 3328/5000 [12:26:06<5:34:21, 12.00s/it, loss=1.1463, lr=3.04e-06]Steps:  67%|██████▋   | 3329/5000 [12:26:18<5:33:38, 11.98s/it, loss=1.1463, lr=3.04e-06]Steps:  67%|██████▋   | 3329/5000 [12:26:18<5:33:38, 11.98s/it, loss=0.5122, lr=3.03e-06]Steps:  67%|██████▋   | 3330/5000 [12:26:31<5:35:14, 12.04s/it, loss=0.5122, lr=3.03e-06]Steps:  67%|██████▋   | 3330/5000 [12:26:31<5:35:14, 12.04s/it, loss=1.1002, lr=3.03e-06]
[Step 3330] Training Debug Info:
  Loss: 0.876606
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0615, std: 0.9609
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0623, std: 1.3828
  Model pred mean: -0.0625, std: 1.0234
  Sigmas: [0.240234375]... (timesteps: [240.0])

[Step 3330] Training Debug Info:
  Loss: 0.534760
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0227, std: 0.8711
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0203, std: 1.3203
  Model pred mean: 0.0249, std: 1.1016
  Sigmas: [0.65625]... (timesteps: [658.0])

[Step 3330] Training Debug Info:
  Loss: 0.437724
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0171, std: 1.3438
  Model pred mean: -0.0165, std: 1.1797
  Sigmas: [0.91015625]... (timesteps: [909.0])

[Step 3330] Training Debug Info:
  Loss: 1.110569
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0058, std: 0.9180
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0063, std: 1.3594
  Model pred mean: -0.0062, std: 0.8516
  Sigmas: [0.2333984375]... (timesteps: [233.0])
Steps:  67%|██████▋   | 3331/5000 [12:26:43<5:33:49, 12.00s/it, loss=1.1002, lr=3.03e-06]Steps:  67%|██████▋   | 3331/5000 [12:26:43<5:33:49, 12.00s/it, loss=1.1106, lr=3.03e-06]Steps:  67%|██████▋   | 3332/5000 [12:26:54<5:32:59, 11.98s/it, loss=1.1106, lr=3.03e-06]Steps:  67%|██████▋   | 3332/5000 [12:26:54<5:32:59, 11.98s/it, loss=0.8922, lr=3.02e-06]Steps:  67%|██████▋   | 3333/5000 [12:27:06<5:33:00, 11.99s/it, loss=0.8922, lr=3.02e-06]Steps:  67%|██████▋   | 3333/5000 [12:27:06<5:33:00, 11.99s/it, loss=0.4572, lr=3.02e-06]Steps:  67%|██████▋   | 3334/5000 [12:27:18<5:31:21, 11.93s/it, loss=0.4572, lr=3.02e-06]Steps:  67%|██████▋   | 3334/5000 [12:27:18<5:31:21, 11.93s/it, loss=0.6839, lr=3.02e-06]Steps:  67%|██████▋   | 3335/5000 [12:27:30<5:31:37, 11.95s/it, loss=0.6839, lr=3.02e-06]Steps:  67%|██████▋   | 3335/5000 [12:27:30<5:31:37, 11.95s/it, loss=0.8120, lr=3.01e-06]Steps:  67%|██████▋   | 3336/5000 [12:27:42<5:31:03, 11.94s/it, loss=0.8120, lr=3.01e-06]Steps:  67%|██████▋   | 3336/5000 [12:27:42<5:31:03, 11.94s/it, loss=0.8367, lr=3.01e-06]Steps:  67%|██████▋   | 3337/5000 [12:27:54<5:32:05, 11.98s/it, loss=0.8367, lr=3.01e-06]Steps:  67%|██████▋   | 3337/5000 [12:27:54<5:32:05, 11.98s/it, loss=0.7209, lr=3.01e-06]Steps:  67%|██████▋   | 3338/5000 [12:28:06<5:31:38, 11.97s/it, loss=0.7209, lr=3.01e-06]Steps:  67%|██████▋   | 3338/5000 [12:28:06<5:31:38, 11.97s/it, loss=1.1675, lr=3.00e-06]Steps:  67%|██████▋   | 3339/5000 [12:28:18<5:30:53, 11.95s/it, loss=1.1675, lr=3.00e-06]Steps:  67%|██████▋   | 3339/5000 [12:28:18<5:30:53, 11.95s/it, loss=1.1648, lr=3.00e-06]Steps:  67%|██████▋   | 3340/5000 [12:28:30<5:30:14, 11.94s/it, loss=1.1648, lr=3.00e-06]Steps:  67%|██████▋   | 3340/5000 [12:28:30<5:30:14, 11.94s/it, loss=0.7498, lr=3.00e-06]
[Step 3340] Training Debug Info:
  Loss: 0.443290
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0125, std: 0.9062
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0146, std: 1.3516
  Model pred mean: -0.0153, std: 1.1719
  Sigmas: [0.71484375]... (timesteps: [713.0])

[Step 3340] Training Debug Info:
  Loss: 0.708705
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0623, std: 0.9219
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0615, std: 1.3594
  Model pred mean: 0.0620, std: 1.0703
  Sigmas: [0.482421875]... (timesteps: [483.0])

[Step 3340] Training Debug Info:
  Loss: 0.405026
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0066, std: 0.9336
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0085, std: 1.3672
  Model pred mean: -0.0091, std: 1.2109
  Sigmas: [0.80078125]... (timesteps: [802.0])

[Step 3340] Training Debug Info:
  Loss: 0.527841
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0125, std: 0.8945
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0127, std: 1.3438
  Model pred mean: 0.0122, std: 1.1328
  Sigmas: [0.6484375]... (timesteps: [647.0])
Steps:  67%|██████▋   | 3341/5000 [12:28:42<5:29:49, 11.93s/it, loss=0.7498, lr=3.00e-06]Steps:  67%|██████▋   | 3341/5000 [12:28:42<5:29:49, 11.93s/it, loss=0.5278, lr=3.00e-06]Steps:  67%|██████▋   | 3342/5000 [12:28:54<5:31:56, 12.01s/it, loss=0.5278, lr=3.00e-06]Steps:  67%|██████▋   | 3342/5000 [12:28:54<5:31:56, 12.01s/it, loss=0.9145, lr=2.99e-06]Steps:  67%|██████▋   | 3343/5000 [12:29:06<5:31:21, 12.00s/it, loss=0.9145, lr=2.99e-06]Steps:  67%|██████▋   | 3343/5000 [12:29:06<5:31:21, 12.00s/it, loss=0.7042, lr=2.99e-06]Steps:  67%|██████▋   | 3344/5000 [12:29:18<5:33:08, 12.07s/it, loss=0.7042, lr=2.99e-06]Steps:  67%|██████▋   | 3344/5000 [12:29:18<5:33:08, 12.07s/it, loss=0.7898, lr=2.99e-06]Steps:  67%|██████▋   | 3345/5000 [12:29:30<5:32:10, 12.04s/it, loss=0.7898, lr=2.99e-06]Steps:  67%|██████▋   | 3345/5000 [12:29:30<5:32:10, 12.04s/it, loss=0.4751, lr=2.98e-06]Steps:  67%|██████▋   | 3346/5000 [12:29:42<5:30:58, 12.01s/it, loss=0.4751, lr=2.98e-06]Steps:  67%|██████▋   | 3346/5000 [12:29:42<5:30:58, 12.01s/it, loss=0.9760, lr=2.98e-06]Steps:  67%|██████▋   | 3347/5000 [12:29:54<5:30:31, 12.00s/it, loss=0.9760, lr=2.98e-06]Steps:  67%|██████▋   | 3347/5000 [12:29:54<5:30:31, 12.00s/it, loss=0.3634, lr=2.98e-06]Steps:  67%|██████▋   | 3348/5000 [12:30:06<5:29:52, 11.98s/it, loss=0.3634, lr=2.98e-06]Steps:  67%|██████▋   | 3348/5000 [12:30:06<5:29:52, 11.98s/it, loss=0.3996, lr=2.97e-06]Steps:  67%|██████▋   | 3349/5000 [12:30:18<5:30:41, 12.02s/it, loss=0.3996, lr=2.97e-06]Steps:  67%|██████▋   | 3349/5000 [12:30:18<5:30:41, 12.02s/it, loss=1.0642, lr=2.97e-06]Steps:  67%|██████▋   | 3350/5000 [12:30:30<5:29:09, 11.97s/it, loss=1.0642, lr=2.97e-06]Steps:  67%|██████▋   | 3350/5000 [12:30:30<5:29:09, 11.97s/it, loss=0.5889, lr=2.97e-06]
[Step 3350] Training Debug Info:
  Loss: 0.717834
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0552, std: 0.9492
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0564, std: 1.3750
  Model pred mean: -0.0271, std: 1.0859
  Sigmas: [0.98828125]... (timesteps: [988.0])

[Step 3350] Training Debug Info:
  Loss: 0.476328
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0136, std: 0.9531
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0141, std: 1.3828
  Model pred mean: -0.0103, std: 1.2031
  Sigmas: [0.8359375]... (timesteps: [835.0])

[Step 3350] Training Debug Info:
  Loss: 0.737325
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0164, std: 0.9883
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0172, std: 1.4062
  Model pred mean: -0.0159, std: 1.1172
  Sigmas: [0.4921875]... (timesteps: [492.0])

[Step 3350] Training Debug Info:
  Loss: 0.595091
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0045, std: 0.9180
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0075, std: 1.3594
  Model pred mean: 0.0009, std: 1.1250
  Sigmas: [0.9609375]... (timesteps: [960.0])
Steps:  67%|██████▋   | 3351/5000 [12:30:42<5:30:49, 12.04s/it, loss=0.5889, lr=2.97e-06]Steps:  67%|██████▋   | 3351/5000 [12:30:42<5:30:49, 12.04s/it, loss=0.5951, lr=2.96e-06]Steps:  67%|██████▋   | 3352/5000 [12:30:54<5:30:02, 12.02s/it, loss=0.5951, lr=2.96e-06]Steps:  67%|██████▋   | 3352/5000 [12:30:54<5:30:02, 12.02s/it, loss=0.6147, lr=2.96e-06]Steps:  67%|██████▋   | 3353/5000 [12:31:06<5:29:50, 12.02s/it, loss=0.6147, lr=2.96e-06]Steps:  67%|██████▋   | 3353/5000 [12:31:06<5:29:50, 12.02s/it, loss=0.8116, lr=2.96e-06]Steps:  67%|██████▋   | 3354/5000 [12:31:18<5:28:49, 11.99s/it, loss=0.8116, lr=2.96e-06]Steps:  67%|██████▋   | 3354/5000 [12:31:18<5:28:49, 11.99s/it, loss=1.1555, lr=2.95e-06]Steps:  67%|██████▋   | 3355/5000 [12:31:30<5:28:40, 11.99s/it, loss=1.1555, lr=2.95e-06]Steps:  67%|██████▋   | 3355/5000 [12:31:30<5:28:40, 11.99s/it, loss=0.3855, lr=2.95e-06]Steps:  67%|██████▋   | 3356/5000 [12:31:42<5:31:09, 12.09s/it, loss=0.3855, lr=2.95e-06]Steps:  67%|██████▋   | 3356/5000 [12:31:42<5:31:09, 12.09s/it, loss=0.5547, lr=2.95e-06]Steps:  67%|██████▋   | 3357/5000 [12:31:55<5:31:44, 12.11s/it, loss=0.5547, lr=2.95e-06]Steps:  67%|██████▋   | 3357/5000 [12:31:55<5:31:44, 12.11s/it, loss=0.5653, lr=2.94e-06]Steps:  67%|██████▋   | 3358/5000 [12:32:07<5:30:12, 12.07s/it, loss=0.5653, lr=2.94e-06]Steps:  67%|██████▋   | 3358/5000 [12:32:07<5:30:12, 12.07s/it, loss=0.5887, lr=2.94e-06]Steps:  67%|██████▋   | 3359/5000 [12:32:19<5:29:25, 12.04s/it, loss=0.5887, lr=2.94e-06]Steps:  67%|██████▋   | 3359/5000 [12:32:19<5:29:25, 12.04s/it, loss=0.3986, lr=2.94e-06]Steps:  67%|██████▋   | 3360/5000 [12:32:31<5:28:41, 12.03s/it, loss=0.3986, lr=2.94e-06]Steps:  67%|██████▋   | 3360/5000 [12:32:31<5:28:41, 12.03s/it, loss=0.7078, lr=2.93e-06]
[Step 3360] Training Debug Info:
  Loss: 1.115241
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0238, std: 0.9297
  Noise mean: -0.0049, std: 1.0000
  Target mean: -0.0287, std: 1.3672
  Model pred mean: -0.0243, std: 0.8711
  Sigmas: [0.1396484375]... (timesteps: [140.0])

[Step 3360] Training Debug Info:
  Loss: 1.104161
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0238, std: 0.9180
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0261, std: 1.3516
  Model pred mean: -0.0247, std: 0.8555
  Sigmas: [0.0927734375]... (timesteps: [93.0])

[Step 3360] Training Debug Info:
  Loss: 0.751161
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0022, std: 0.9062
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0002, std: 1.3516
  Model pred mean: 0.0020, std: 1.0312
  Sigmas: [0.515625]... (timesteps: [517.0])

[Step 3360] Training Debug Info:
  Loss: 0.792767
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0245, std: 0.9727
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0239, std: 1.3984
  Model pred mean: -0.0304, std: 1.0625
  Sigmas: [1.0]... (timesteps: [1000.0])
Steps:  67%|██████▋   | 3361/5000 [12:32:43<5:27:55, 12.00s/it, loss=0.7078, lr=2.93e-06]Steps:  67%|██████▋   | 3361/5000 [12:32:43<5:27:55, 12.00s/it, loss=0.7928, lr=2.93e-06]Steps:  67%|██████▋   | 3362/5000 [12:32:55<5:27:37, 12.00s/it, loss=0.7928, lr=2.93e-06]Steps:  67%|██████▋   | 3362/5000 [12:32:55<5:27:37, 12.00s/it, loss=0.5236, lr=2.93e-06]Steps:  67%|██████▋   | 3363/5000 [12:33:07<5:27:05, 11.99s/it, loss=0.5236, lr=2.93e-06]Steps:  67%|██████▋   | 3363/5000 [12:33:07<5:27:05, 11.99s/it, loss=1.0039, lr=2.92e-06]Steps:  67%|██████▋   | 3364/5000 [12:33:19<5:28:22, 12.04s/it, loss=1.0039, lr=2.92e-06]Steps:  67%|██████▋   | 3364/5000 [12:33:19<5:28:22, 12.04s/it, loss=0.4736, lr=2.92e-06]Steps:  67%|██████▋   | 3365/5000 [12:33:31<5:27:23, 12.01s/it, loss=0.4736, lr=2.92e-06]Steps:  67%|██████▋   | 3365/5000 [12:33:31<5:27:23, 12.01s/it, loss=1.2050, lr=2.92e-06]Steps:  67%|██████▋   | 3366/5000 [12:33:43<5:26:29, 11.99s/it, loss=1.2050, lr=2.92e-06]Steps:  67%|██████▋   | 3366/5000 [12:33:43<5:26:29, 11.99s/it, loss=1.0434, lr=2.92e-06]Steps:  67%|██████▋   | 3367/5000 [12:33:54<5:25:51, 11.97s/it, loss=1.0434, lr=2.92e-06]Steps:  67%|██████▋   | 3367/5000 [12:33:54<5:25:51, 11.97s/it, loss=0.6653, lr=2.91e-06]Steps:  67%|██████▋   | 3368/5000 [12:34:06<5:24:31, 11.93s/it, loss=0.6653, lr=2.91e-06]Steps:  67%|██████▋   | 3368/5000 [12:34:06<5:24:31, 11.93s/it, loss=0.7056, lr=2.91e-06]Steps:  67%|██████▋   | 3369/5000 [12:34:18<5:24:40, 11.94s/it, loss=0.7056, lr=2.91e-06]Steps:  67%|██████▋   | 3369/5000 [12:34:18<5:24:40, 11.94s/it, loss=0.7457, lr=2.91e-06]Steps:  67%|██████▋   | 3370/5000 [12:34:30<5:24:22, 11.94s/it, loss=0.7457, lr=2.91e-06]Steps:  67%|██████▋   | 3370/5000 [12:34:30<5:24:22, 11.94s/it, loss=0.4118, lr=2.90e-06]
[Step 3370] Training Debug Info:
  Loss: 1.052085
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0188, std: 0.9180
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0186, std: 1.3516
  Model pred mean: -0.0217, std: 0.8867
  Sigmas: [0.032958984375]... (timesteps: [33.0])

[Step 3370] Training Debug Info:
  Loss: 1.075701
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0093, std: 0.8555
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0112, std: 1.3203
  Model pred mean: 0.0086, std: 0.8203
  Sigmas: [0.341796875]... (timesteps: [341.0])

[Step 3370] Training Debug Info:
  Loss: 0.997536
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0021, std: 0.8711
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0006, std: 1.3281
  Model pred mean: -0.0019, std: 0.8750
  Sigmas: [0.3671875]... (timesteps: [368.0])

[Step 3370] Training Debug Info:
  Loss: 0.665703
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0197, std: 0.9023
  Noise mean: -0.0011, std: 0.9961
  Target mean: -0.0209, std: 1.3438
  Model pred mean: -0.0199, std: 1.0781
  Sigmas: [0.51171875]... (timesteps: [513.0])
Steps:  67%|██████▋   | 3371/5000 [12:34:42<5:25:48, 12.00s/it, loss=0.4118, lr=2.90e-06]Steps:  67%|██████▋   | 3371/5000 [12:34:42<5:25:48, 12.00s/it, loss=0.6657, lr=2.90e-06]Steps:  67%|██████▋   | 3372/5000 [12:34:54<5:26:28, 12.03s/it, loss=0.6657, lr=2.90e-06]Steps:  67%|██████▋   | 3372/5000 [12:34:54<5:26:28, 12.03s/it, loss=1.1500, lr=2.90e-06]Steps:  67%|██████▋   | 3373/5000 [12:35:06<5:25:25, 12.00s/it, loss=1.1500, lr=2.90e-06]Steps:  67%|██████▋   | 3373/5000 [12:35:06<5:25:25, 12.00s/it, loss=0.5582, lr=2.89e-06]Steps:  67%|██████▋   | 3374/5000 [12:35:18<5:25:03, 12.00s/it, loss=0.5582, lr=2.89e-06]Steps:  67%|██████▋   | 3374/5000 [12:35:18<5:25:03, 12.00s/it, loss=0.7482, lr=2.89e-06]Steps:  68%|██████▊   | 3375/5000 [12:35:30<5:24:33, 11.98s/it, loss=0.7482, lr=2.89e-06]Steps:  68%|██████▊   | 3375/5000 [12:35:30<5:24:33, 11.98s/it, loss=1.0351, lr=2.89e-06]Steps:  68%|██████▊   | 3376/5000 [12:35:42<5:23:51, 11.97s/it, loss=1.0351, lr=2.89e-06]Steps:  68%|██████▊   | 3376/5000 [12:35:42<5:23:51, 11.97s/it, loss=0.9579, lr=2.88e-06]Steps:  68%|██████▊   | 3377/5000 [12:35:54<5:23:42, 11.97s/it, loss=0.9579, lr=2.88e-06]Steps:  68%|██████▊   | 3377/5000 [12:35:54<5:23:42, 11.97s/it, loss=1.0866, lr=2.88e-06]Steps:  68%|██████▊   | 3378/5000 [12:36:06<5:25:33, 12.04s/it, loss=1.0866, lr=2.88e-06]Steps:  68%|██████▊   | 3378/5000 [12:36:06<5:25:33, 12.04s/it, loss=0.4452, lr=2.88e-06]Steps:  68%|██████▊   | 3379/5000 [12:36:18<5:24:47, 12.02s/it, loss=0.4452, lr=2.88e-06]Steps:  68%|██████▊   | 3379/5000 [12:36:18<5:24:47, 12.02s/it, loss=0.4044, lr=2.87e-06]Steps:  68%|██████▊   | 3380/5000 [12:36:30<5:23:03, 11.97s/it, loss=0.4044, lr=2.87e-06]Steps:  68%|██████▊   | 3380/5000 [12:36:30<5:23:03, 11.97s/it, loss=0.4505, lr=2.87e-06]
[Step 3380] Training Debug Info:
  Loss: 0.525297
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0001, std: 0.8555
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0025, std: 1.3203
  Model pred mean: -0.0094, std: 1.1172
  Sigmas: [1.0]... (timesteps: [1000.0])

[Step 3380] Training Debug Info:
  Loss: 0.624040
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0427, std: 0.9258
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0432, std: 1.3594
  Model pred mean: -0.0442, std: 1.1094
  Sigmas: [0.48828125]... (timesteps: [488.0])

[Step 3380] Training Debug Info:
  Loss: 0.623233
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0166, std: 0.9219
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0189, std: 1.3594
  Model pred mean: -0.0041, std: 1.1016
  Sigmas: [0.9921875]... (timesteps: [993.0])

[Step 3380] Training Debug Info:
  Loss: 1.060206
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0166, std: 0.8984
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0157, std: 1.3438
  Model pred mean: 0.0210, std: 0.8672
  Sigmas: [0.034912109375]... (timesteps: [35.0])
Steps:  68%|██████▊   | 3381/5000 [12:36:42<5:24:02, 12.01s/it, loss=0.4505, lr=2.87e-06]Steps:  68%|██████▊   | 3381/5000 [12:36:42<5:24:02, 12.01s/it, loss=1.0602, lr=2.87e-06]Steps:  68%|██████▊   | 3382/5000 [12:36:54<5:22:55, 11.98s/it, loss=1.0602, lr=2.87e-06]Steps:  68%|██████▊   | 3382/5000 [12:36:54<5:22:55, 11.98s/it, loss=0.4858, lr=2.86e-06]Steps:  68%|██████▊   | 3383/5000 [12:37:06<5:22:40, 11.97s/it, loss=0.4858, lr=2.86e-06]Steps:  68%|██████▊   | 3383/5000 [12:37:06<5:22:40, 11.97s/it, loss=0.5480, lr=2.86e-06]Steps:  68%|██████▊   | 3384/5000 [12:37:18<5:24:49, 12.06s/it, loss=0.5480, lr=2.86e-06]Steps:  68%|██████▊   | 3384/5000 [12:37:18<5:24:49, 12.06s/it, loss=0.8164, lr=2.86e-06]Steps:  68%|██████▊   | 3385/5000 [12:37:30<5:23:43, 12.03s/it, loss=0.8164, lr=2.86e-06]Steps:  68%|██████▊   | 3385/5000 [12:37:30<5:23:43, 12.03s/it, loss=0.7872, lr=2.86e-06]Steps:  68%|██████▊   | 3386/5000 [12:37:42<5:23:06, 12.01s/it, loss=0.7872, lr=2.86e-06]Steps:  68%|██████▊   | 3386/5000 [12:37:42<5:23:06, 12.01s/it, loss=0.7248, lr=2.85e-06]Steps:  68%|██████▊   | 3387/5000 [12:37:54<5:21:28, 11.96s/it, loss=0.7248, lr=2.85e-06]Steps:  68%|██████▊   | 3387/5000 [12:37:54<5:21:28, 11.96s/it, loss=0.3776, lr=2.85e-06]Steps:  68%|██████▊   | 3388/5000 [12:38:06<5:20:30, 11.93s/it, loss=0.3776, lr=2.85e-06]Steps:  68%|██████▊   | 3388/5000 [12:38:06<5:20:30, 11.93s/it, loss=0.4123, lr=2.85e-06]Steps:  68%|██████▊   | 3389/5000 [12:38:18<5:20:15, 11.93s/it, loss=0.4123, lr=2.85e-06]Steps:  68%|██████▊   | 3389/5000 [12:38:18<5:20:15, 11.93s/it, loss=0.5549, lr=2.84e-06]Steps:  68%|██████▊   | 3390/5000 [12:38:30<5:20:50, 11.96s/it, loss=0.5549, lr=2.84e-06]Steps:  68%|██████▊   | 3390/5000 [12:38:30<5:20:50, 11.96s/it, loss=0.5636, lr=2.84e-06]
[Step 3390] Training Debug Info:
  Loss: 1.089073
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0031, std: 0.9297
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0037, std: 1.3594
  Model pred mean: -0.0081, std: 0.8750
  Sigmas: [0.1982421875]... (timesteps: [198.0])

[Step 3390] Training Debug Info:
  Loss: 0.446919
  Latent shape: torch.Size([1, 32, 150, 60]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0309, std: 0.8945
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0289, std: 1.3359
  Model pred mean: -0.0300, std: 1.1641
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 3390] Training Debug Info:
  Loss: 1.119621
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0251, std: 0.9531
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0276, std: 1.3828
  Model pred mean: -0.0293, std: 0.8828
  Sigmas: [0.12109375]... (timesteps: [121.0])

[Step 3390] Training Debug Info:
  Loss: 0.442555
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0349, std: 0.9141
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0344, std: 1.3516
  Model pred mean: -0.0383, std: 1.1797
  Sigmas: [0.75]... (timesteps: [751.0])
Steps:  68%|██████▊   | 3391/5000 [12:38:42<5:22:00, 12.01s/it, loss=0.5636, lr=2.84e-06]Steps:  68%|██████▊   | 3391/5000 [12:38:42<5:22:00, 12.01s/it, loss=0.4426, lr=2.84e-06]Steps:  68%|██████▊   | 3392/5000 [12:38:54<5:21:14, 11.99s/it, loss=0.4426, lr=2.84e-06]Steps:  68%|██████▊   | 3392/5000 [12:38:54<5:21:14, 11.99s/it, loss=0.4255, lr=2.83e-06]Steps:  68%|██████▊   | 3393/5000 [12:39:06<5:20:42, 11.97s/it, loss=0.4255, lr=2.83e-06]Steps:  68%|██████▊   | 3393/5000 [12:39:06<5:20:42, 11.97s/it, loss=0.9096, lr=2.83e-06]Steps:  68%|██████▊   | 3394/5000 [12:39:18<5:20:09, 11.96s/it, loss=0.9096, lr=2.83e-06]Steps:  68%|██████▊   | 3394/5000 [12:39:18<5:20:09, 11.96s/it, loss=0.6293, lr=2.83e-06]Steps:  68%|██████▊   | 3395/5000 [12:39:30<5:19:49, 11.96s/it, loss=0.6293, lr=2.83e-06]Steps:  68%|██████▊   | 3395/5000 [12:39:30<5:19:49, 11.96s/it, loss=1.0197, lr=2.82e-06]Steps:  68%|██████▊   | 3396/5000 [12:39:42<5:19:28, 11.95s/it, loss=1.0197, lr=2.82e-06]Steps:  68%|██████▊   | 3396/5000 [12:39:42<5:19:28, 11.95s/it, loss=0.3683, lr=2.82e-06]Steps:  68%|██████▊   | 3397/5000 [12:39:54<5:19:07, 11.95s/it, loss=0.3683, lr=2.82e-06]Steps:  68%|██████▊   | 3397/5000 [12:39:54<5:19:07, 11.95s/it, loss=0.3799, lr=2.82e-06]Steps:  68%|██████▊   | 3398/5000 [12:40:06<5:20:41, 12.01s/it, loss=0.3799, lr=2.82e-06]Steps:  68%|██████▊   | 3398/5000 [12:40:06<5:20:41, 12.01s/it, loss=0.3721, lr=2.81e-06]Steps:  68%|██████▊   | 3399/5000 [12:40:18<5:21:15, 12.04s/it, loss=0.3721, lr=2.81e-06]Steps:  68%|██████▊   | 3399/5000 [12:40:18<5:21:15, 12.04s/it, loss=0.4370, lr=2.81e-06]Steps:  68%|██████▊   | 3400/5000 [12:40:30<5:19:33, 11.98s/it, loss=0.4370, lr=2.81e-06]Steps:  68%|██████▊   | 3400/5000 [12:40:30<5:19:33, 11.98s/it, loss=1.1260, lr=2.81e-06]01/22/2026 20:26:17 - INFO - __main__ - 
[Step 3400] ✅ Loss in normal range (1.1260)
01/22/2026 20:26:17 - INFO - __main__ -   Loss avg (last 100): 0.6908
01/22/2026 20:26:17 - INFO - __main__ -   Loss range: [0.3557, 1.2050]
01/22/2026 20:26:17 - INFO - __main__ - 
🔍 Running validation at step 3400...
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3400 (parquet mode)...
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3400...
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 20:26:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.47it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.46it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.46it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.46it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.46it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.46it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 20:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 20:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 20:27:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 20:27:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 20:27:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 20:27:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 20:27:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 20:27:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 20:28:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 20:28:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.31it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 20:28:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 20:28:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.59it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.41it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 20:28:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 20:28:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 20:29:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 20:29:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 20:29:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 20:29:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 20:29:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 20:29:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.43it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 20:30:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 20:30:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 20:30:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400/step003400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 20:30:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 20:30:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 20:30:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003400
01/22/2026 20:30:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 3400] Training Debug Info:
  Loss: 0.397001
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0002, std: 0.8828
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0025, std: 1.3359
  Model pred mean: 0.0013, std: 1.1797
  Sigmas: [0.8359375]... (timesteps: [837.0])

[Step 3400] Training Debug Info:
  Loss: 0.769210
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0073, std: 0.8867
  Noise mean: 0.0009, std: 0.9961
  Target mean: -0.0063, std: 1.3359
  Model pred mean: -0.0048, std: 1.0078
  Sigmas: [0.50390625]... (timesteps: [501.9999694824219])

[Step 3400] Training Debug Info:
  Loss: 1.133304
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0115, std: 0.9258
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0128, std: 1.3672
  Model pred mean: -0.0098, std: 0.8516
  Sigmas: [0.126953125]... (timesteps: [127.00000762939453])

[Step 3400] Training Debug Info:
  Loss: 0.518504
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0122, std: 0.9023
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0126, std: 1.3438
  Model pred mean: 0.0256, std: 1.1484
  Sigmas: [0.93359375]... (timesteps: [935.0])
Steps:  68%|██████▊   | 3401/5000 [12:45:01<39:50:43, 89.71s/it, loss=1.1260, lr=2.81e-06]Steps:  68%|██████▊   | 3401/5000 [12:45:01<39:50:43, 89.71s/it, loss=0.5185, lr=2.81e-06]Steps:  68%|██████▊   | 3402/5000 [12:45:13<29:26:46, 66.34s/it, loss=0.5185, lr=2.81e-06]Steps:  68%|██████▊   | 3402/5000 [12:45:13<29:26:46, 66.34s/it, loss=0.6338, lr=2.80e-06]Steps:  68%|██████▊   | 3403/5000 [12:45:25<22:11:38, 50.03s/it, loss=0.6338, lr=2.80e-06]Steps:  68%|██████▊   | 3403/5000 [12:45:25<22:11:38, 50.03s/it, loss=0.5636, lr=2.80e-06]Steps:  68%|██████▊   | 3404/5000 [12:45:37<17:06:52, 38.60s/it, loss=0.5636, lr=2.80e-06]Steps:  68%|██████▊   | 3404/5000 [12:45:37<17:06:52, 38.60s/it, loss=1.0186, lr=2.80e-06]Steps:  68%|██████▊   | 3405/5000 [12:45:49<13:35:34, 30.68s/it, loss=1.0186, lr=2.80e-06]Steps:  68%|██████▊   | 3405/5000 [12:45:49<13:35:34, 30.68s/it, loss=1.0814, lr=2.79e-06]Steps:  68%|██████▊   | 3406/5000 [12:46:01<11:05:37, 25.05s/it, loss=1.0814, lr=2.79e-06]Steps:  68%|██████▊   | 3406/5000 [12:46:01<11:05:37, 25.05s/it, loss=1.0320, lr=2.79e-06]Steps:  68%|██████▊   | 3407/5000 [12:46:13<9:20:33, 21.11s/it, loss=1.0320, lr=2.79e-06] Steps:  68%|██████▊   | 3407/5000 [12:46:13<9:20:33, 21.11s/it, loss=0.6817, lr=2.79e-06]Steps:  68%|██████▊   | 3408/5000 [12:46:25<8:08:17, 18.40s/it, loss=0.6817, lr=2.79e-06]Steps:  68%|██████▊   | 3408/5000 [12:46:25<8:08:17, 18.40s/it, loss=0.8827, lr=2.78e-06]Steps:  68%|██████▊   | 3409/5000 [12:46:37<7:15:54, 16.44s/it, loss=0.8827, lr=2.78e-06]Steps:  68%|██████▊   | 3409/5000 [12:46:37<7:15:54, 16.44s/it, loss=0.4036, lr=2.78e-06]Steps:  68%|██████▊   | 3410/5000 [12:46:49<6:39:31, 15.08s/it, loss=0.4036, lr=2.78e-06]Steps:  68%|██████▊   | 3410/5000 [12:46:49<6:39:31, 15.08s/it, loss=0.9005, lr=2.78e-06]
[Step 3410] Training Debug Info:
  Loss: 0.880026
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0195, std: 0.9414
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0188, std: 1.3750
  Model pred mean: -0.0192, std: 1.0000
  Sigmas: [0.337890625]... (timesteps: [338.0])

[Step 3410] Training Debug Info:
  Loss: 0.391360
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0040, std: 0.8438
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0063, std: 1.3047
  Model pred mean: -0.0146, std: 1.1484
  Sigmas: [0.8203125]... (timesteps: [822.0])

[Step 3410] Training Debug Info:
  Loss: 0.413640
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0259, std: 0.9023
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0265, std: 1.3438
  Model pred mean: -0.0280, std: 1.1875
  Sigmas: [0.76171875]... (timesteps: [763.0])

[Step 3410] Training Debug Info:
  Loss: 0.600646
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0082, std: 1.0078
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0066, std: 1.4219
  Model pred mean: -0.0088, std: 1.1953
  Sigmas: [0.58984375]... (timesteps: [589.0])
Steps:  68%|██████▊   | 3411/5000 [12:47:01<6:16:49, 14.23s/it, loss=0.9005, lr=2.78e-06]Steps:  68%|██████▊   | 3411/5000 [12:47:01<6:16:49, 14.23s/it, loss=0.6006, lr=2.77e-06]Steps:  68%|██████▊   | 3412/5000 [12:47:13<5:58:24, 13.54s/it, loss=0.6006, lr=2.77e-06]Steps:  68%|██████▊   | 3412/5000 [12:47:13<5:58:24, 13.54s/it, loss=0.5231, lr=2.77e-06]Steps:  68%|██████▊   | 3413/5000 [12:47:25<5:45:04, 13.05s/it, loss=0.5231, lr=2.77e-06]Steps:  68%|██████▊   | 3413/5000 [12:47:25<5:45:04, 13.05s/it, loss=1.0970, lr=2.77e-06]Steps:  68%|██████▊   | 3414/5000 [12:47:37<5:35:20, 12.69s/it, loss=1.0970, lr=2.77e-06]Steps:  68%|██████▊   | 3414/5000 [12:47:37<5:35:20, 12.69s/it, loss=0.4279, lr=2.76e-06]Steps:  68%|██████▊   | 3415/5000 [12:47:49<5:29:47, 12.48s/it, loss=0.4279, lr=2.76e-06]Steps:  68%|██████▊   | 3415/5000 [12:47:49<5:29:47, 12.48s/it, loss=0.4287, lr=2.76e-06]Steps:  68%|██████▊   | 3416/5000 [12:48:00<5:24:29, 12.29s/it, loss=0.4287, lr=2.76e-06]Steps:  68%|██████▊   | 3416/5000 [12:48:00<5:24:29, 12.29s/it, loss=0.5890, lr=2.76e-06]Steps:  68%|██████▊   | 3417/5000 [12:48:12<5:22:11, 12.21s/it, loss=0.5890, lr=2.76e-06]Steps:  68%|██████▊   | 3417/5000 [12:48:12<5:22:11, 12.21s/it, loss=1.1162, lr=2.75e-06]Steps:  68%|██████▊   | 3418/5000 [12:48:25<5:21:36, 12.20s/it, loss=1.1162, lr=2.75e-06]Steps:  68%|██████▊   | 3418/5000 [12:48:25<5:21:36, 12.20s/it, loss=0.8228, lr=2.75e-06]Steps:  68%|██████▊   | 3419/5000 [12:48:37<5:19:22, 12.12s/it, loss=0.8228, lr=2.75e-06]Steps:  68%|██████▊   | 3419/5000 [12:48:37<5:19:22, 12.12s/it, loss=1.1039, lr=2.75e-06]Steps:  68%|██████▊   | 3420/5000 [12:48:48<5:17:23, 12.05s/it, loss=1.1039, lr=2.75e-06]Steps:  68%|██████▊   | 3420/5000 [12:48:48<5:17:23, 12.05s/it, loss=0.3478, lr=2.75e-06]
[Step 3420] Training Debug Info:
  Loss: 0.582605
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0518, std: 0.8828
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0505, std: 1.3359
  Model pred mean: 0.0422, std: 1.1172
  Sigmas: [0.984375]... (timesteps: [985.0])

[Step 3420] Training Debug Info:
  Loss: 1.081578
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0009, std: 0.9297
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0040, std: 1.3672
  Model pred mean: -0.0003, std: 0.8867
  Sigmas: [0.21875]... (timesteps: [219.0])

[Step 3420] Training Debug Info:
  Loss: 1.147051
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: 0.0079, std: 0.9141
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0098, std: 1.3594
  Model pred mean: -0.0062, std: 0.8359
  Sigmas: [0.1357421875]... (timesteps: [136.0])

[Step 3420] Training Debug Info:
  Loss: 1.070276
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0042, std: 0.8789
  Noise mean: 0.0017, std: 0.9961
  Target mean: -0.0025, std: 1.3281
  Model pred mean: -0.0016, std: 0.8359
  Sigmas: [0.30078125]... (timesteps: [301.0])
Steps:  68%|██████▊   | 3421/5000 [12:49:00<5:16:38, 12.03s/it, loss=0.3478, lr=2.75e-06]Steps:  68%|██████▊   | 3421/5000 [12:49:00<5:16:38, 12.03s/it, loss=1.0703, lr=2.74e-06]Steps:  68%|██████▊   | 3422/5000 [12:49:12<5:16:09, 12.02s/it, loss=1.0703, lr=2.74e-06]Steps:  68%|██████▊   | 3422/5000 [12:49:12<5:16:09, 12.02s/it, loss=0.5028, lr=2.74e-06]Steps:  68%|██████▊   | 3423/5000 [12:49:24<5:15:39, 12.01s/it, loss=0.5028, lr=2.74e-06]Steps:  68%|██████▊   | 3423/5000 [12:49:24<5:15:39, 12.01s/it, loss=1.1167, lr=2.74e-06]Steps:  68%|██████▊   | 3424/5000 [12:49:36<5:15:07, 12.00s/it, loss=1.1167, lr=2.74e-06]Steps:  68%|██████▊   | 3424/5000 [12:49:36<5:15:07, 12.00s/it, loss=1.1314, lr=2.73e-06]Steps:  68%|██████▊   | 3425/5000 [12:49:49<5:16:27, 12.06s/it, loss=1.1314, lr=2.73e-06]Steps:  68%|██████▊   | 3425/5000 [12:49:49<5:16:27, 12.06s/it, loss=1.1080, lr=2.73e-06]Steps:  69%|██████▊   | 3426/5000 [12:50:00<5:15:01, 12.01s/it, loss=1.1080, lr=2.73e-06]Steps:  69%|██████▊   | 3426/5000 [12:50:00<5:15:01, 12.01s/it, loss=0.4405, lr=2.73e-06]Steps:  69%|██████▊   | 3427/5000 [12:50:12<5:14:28, 12.00s/it, loss=0.4405, lr=2.73e-06]Steps:  69%|██████▊   | 3427/5000 [12:50:12<5:14:28, 12.00s/it, loss=0.4927, lr=2.72e-06]Steps:  69%|██████▊   | 3428/5000 [12:50:24<5:14:08, 11.99s/it, loss=0.4927, lr=2.72e-06]Steps:  69%|██████▊   | 3428/5000 [12:50:24<5:14:08, 11.99s/it, loss=1.0594, lr=2.72e-06]Steps:  69%|██████▊   | 3429/5000 [12:50:36<5:13:25, 11.97s/it, loss=1.0594, lr=2.72e-06]Steps:  69%|██████▊   | 3429/5000 [12:50:36<5:13:25, 11.97s/it, loss=1.0812, lr=2.72e-06]Steps:  69%|██████▊   | 3430/5000 [12:50:48<5:12:23, 11.94s/it, loss=1.0812, lr=2.72e-06]Steps:  69%|██████▊   | 3430/5000 [12:50:48<5:12:23, 11.94s/it, loss=0.5739, lr=2.71e-06]
[Step 3430] Training Debug Info:
  Loss: 0.417253
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0141, std: 0.9023
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0117, std: 1.3438
  Model pred mean: -0.0165, std: 1.1797
  Sigmas: [0.8125]... (timesteps: [812.0])

[Step 3430] Training Debug Info:
  Loss: 0.727124
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0183, std: 0.9258
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0186, std: 1.3594
  Model pred mean: 0.0188, std: 1.0625
  Sigmas: [0.47265625]... (timesteps: [472.0])

[Step 3430] Training Debug Info:
  Loss: 1.151799
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0116, std: 0.8672
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0098, std: 1.3203
  Model pred mean: 0.0121, std: 0.7734
  Sigmas: [0.10595703125]... (timesteps: [106.0])

[Step 3430] Training Debug Info:
  Loss: 1.185829
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0117, std: 0.8203
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0115, std: 1.2969
  Model pred mean: 0.0123, std: 0.7031
  Sigmas: [0.1162109375]... (timesteps: [116.0])
Steps:  69%|██████▊   | 3431/5000 [12:51:00<5:11:40, 11.92s/it, loss=0.5739, lr=2.71e-06]Steps:  69%|██████▊   | 3431/5000 [12:51:00<5:11:40, 11.92s/it, loss=1.1858, lr=2.71e-06]Steps:  69%|██████▊   | 3432/5000 [12:51:12<5:13:21, 11.99s/it, loss=1.1858, lr=2.71e-06]Steps:  69%|██████▊   | 3432/5000 [12:51:12<5:13:21, 11.99s/it, loss=0.4587, lr=2.71e-06]Steps:  69%|██████▊   | 3433/5000 [12:51:24<5:13:45, 12.01s/it, loss=0.4587, lr=2.71e-06]Steps:  69%|██████▊   | 3433/5000 [12:51:24<5:13:45, 12.01s/it, loss=0.5753, lr=2.71e-06]Steps:  69%|██████▊   | 3434/5000 [12:51:36<5:12:17, 11.97s/it, loss=0.5753, lr=2.71e-06]Steps:  69%|██████▊   | 3434/5000 [12:51:36<5:12:17, 11.97s/it, loss=0.8179, lr=2.70e-06]Steps:  69%|██████▊   | 3435/5000 [12:51:48<5:11:54, 11.96s/it, loss=0.8179, lr=2.70e-06]Steps:  69%|██████▊   | 3435/5000 [12:51:48<5:11:54, 11.96s/it, loss=0.9907, lr=2.70e-06]Steps:  69%|██████▊   | 3436/5000 [12:52:00<5:10:55, 11.93s/it, loss=0.9907, lr=2.70e-06]Steps:  69%|██████▊   | 3436/5000 [12:52:00<5:10:55, 11.93s/it, loss=0.4899, lr=2.70e-06]Steps:  69%|██████▊   | 3437/5000 [12:52:12<5:10:38, 11.93s/it, loss=0.4899, lr=2.70e-06]Steps:  69%|██████▊   | 3437/5000 [12:52:12<5:10:38, 11.93s/it, loss=0.7031, lr=2.69e-06]Steps:  69%|██████▉   | 3438/5000 [12:52:24<5:11:59, 11.98s/it, loss=0.7031, lr=2.69e-06]Steps:  69%|██████▉   | 3438/5000 [12:52:24<5:11:59, 11.98s/it, loss=0.5754, lr=2.69e-06]Steps:  69%|██████▉   | 3439/5000 [12:52:36<5:11:01, 11.95s/it, loss=0.5754, lr=2.69e-06]Steps:  69%|██████▉   | 3439/5000 [12:52:36<5:11:01, 11.95s/it, loss=0.9483, lr=2.69e-06]Steps:  69%|██████▉   | 3440/5000 [12:52:48<5:10:42, 11.95s/it, loss=0.9483, lr=2.69e-06]Steps:  69%|██████▉   | 3440/5000 [12:52:48<5:10:42, 11.95s/it, loss=0.4041, lr=2.68e-06]
[Step 3440] Training Debug Info:
  Loss: 0.494179
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0079, std: 0.9258
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0072, std: 1.3672
  Model pred mean: -0.0070, std: 1.1719
  Sigmas: [0.6484375]... (timesteps: [649.0])

[Step 3440] Training Debug Info:
  Loss: 0.438107
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0471, std: 0.9258
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0452, std: 1.3672
  Model pred mean: -0.0471, std: 1.1875
  Sigmas: [0.87109375]... (timesteps: [872.0])

[Step 3440] Training Debug Info:
  Loss: 0.356994
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0018, std: 0.8906
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0048, std: 1.3359
  Model pred mean: -0.0003, std: 1.1953
  Sigmas: [0.8359375]... (timesteps: [836.0])

[Step 3440] Training Debug Info:
  Loss: 1.106792
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0022, std: 0.9180
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0001, std: 1.3594
  Model pred mean: -0.0013, std: 0.8555
  Sigmas: [0.259765625]... (timesteps: [260.0])
Steps:  69%|██████▉   | 3441/5000 [12:53:00<5:10:16, 11.94s/it, loss=0.4041, lr=2.68e-06]Steps:  69%|██████▉   | 3441/5000 [12:53:00<5:10:16, 11.94s/it, loss=1.1068, lr=2.68e-06]Steps:  69%|██████▉   | 3442/5000 [12:53:12<5:11:12, 11.99s/it, loss=1.1068, lr=2.68e-06]Steps:  69%|██████▉   | 3442/5000 [12:53:12<5:11:12, 11.99s/it, loss=1.0726, lr=2.68e-06]Steps:  69%|██████▉   | 3443/5000 [12:53:24<5:10:42, 11.97s/it, loss=1.0726, lr=2.68e-06]Steps:  69%|██████▉   | 3443/5000 [12:53:24<5:10:42, 11.97s/it, loss=0.7361, lr=2.67e-06]Steps:  69%|██████▉   | 3444/5000 [12:53:36<5:09:32, 11.94s/it, loss=0.7361, lr=2.67e-06]Steps:  69%|██████▉   | 3444/5000 [12:53:36<5:09:32, 11.94s/it, loss=1.0322, lr=2.67e-06]Steps:  69%|██████▉   | 3445/5000 [12:53:48<5:10:43, 11.99s/it, loss=1.0322, lr=2.67e-06]Steps:  69%|██████▉   | 3445/5000 [12:53:48<5:10:43, 11.99s/it, loss=0.3777, lr=2.67e-06]Steps:  69%|██████▉   | 3446/5000 [12:54:00<5:09:30, 11.95s/it, loss=0.3777, lr=2.67e-06]Steps:  69%|██████▉   | 3446/5000 [12:54:00<5:09:30, 11.95s/it, loss=0.7803, lr=2.66e-06]Steps:  69%|██████▉   | 3447/5000 [12:54:12<5:09:32, 11.96s/it, loss=0.7803, lr=2.66e-06]Steps:  69%|██████▉   | 3447/5000 [12:54:12<5:09:32, 11.96s/it, loss=0.8777, lr=2.66e-06]Steps:  69%|██████▉   | 3448/5000 [12:54:23<5:09:15, 11.96s/it, loss=0.8777, lr=2.66e-06]Steps:  69%|██████▉   | 3448/5000 [12:54:23<5:09:15, 11.96s/it, loss=0.3916, lr=2.66e-06]Steps:  69%|██████▉   | 3449/5000 [12:54:35<5:08:11, 11.92s/it, loss=0.3916, lr=2.66e-06]Steps:  69%|██████▉   | 3449/5000 [12:54:35<5:08:11, 11.92s/it, loss=0.4545, lr=2.66e-06]Steps:  69%|██████▉   | 3450/5000 [12:54:47<5:07:40, 11.91s/it, loss=0.4545, lr=2.66e-06]Steps:  69%|██████▉   | 3450/5000 [12:54:47<5:07:40, 11.91s/it, loss=1.0359, lr=2.65e-06]
[Step 3450] Training Debug Info:
  Loss: 0.878977
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0140, std: 0.9883
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0117, std: 1.4062
  Model pred mean: -0.0123, std: 1.0469
  Sigmas: [0.328125]... (timesteps: [328.0])

[Step 3450] Training Debug Info:
  Loss: 1.020326
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0094, std: 0.8828
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0114, std: 1.3359
  Model pred mean: -0.0106, std: 0.8750
  Sigmas: [0.00897216796875]... (timesteps: [9.0])

[Step 3450] Training Debug Info:
  Loss: 1.074255
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0122, std: 0.9219
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0132, std: 1.3594
  Model pred mean: 0.0117, std: 0.8828
  Sigmas: [0.298828125]... (timesteps: [298.0])

[Step 3450] Training Debug Info:
  Loss: 0.459908
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0109, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0112, std: 1.3438
  Model pred mean: -0.0101, std: 1.1641
  Sigmas: [0.7109375]... (timesteps: [711.0])
Steps:  69%|██████▉   | 3451/5000 [12:54:59<5:09:03, 11.97s/it, loss=1.0359, lr=2.65e-06]Steps:  69%|██████▉   | 3451/5000 [12:54:59<5:09:03, 11.97s/it, loss=0.4599, lr=2.65e-06]Steps:  69%|██████▉   | 3452/5000 [12:55:11<5:09:53, 12.01s/it, loss=0.4599, lr=2.65e-06]Steps:  69%|██████▉   | 3452/5000 [12:55:11<5:09:53, 12.01s/it, loss=0.3140, lr=2.65e-06]Steps:  69%|██████▉   | 3453/5000 [12:55:23<5:09:43, 12.01s/it, loss=0.3140, lr=2.65e-06]Steps:  69%|██████▉   | 3453/5000 [12:55:23<5:09:43, 12.01s/it, loss=0.4272, lr=2.64e-06]Steps:  69%|██████▉   | 3454/5000 [12:55:35<5:09:00, 11.99s/it, loss=0.4272, lr=2.64e-06]Steps:  69%|██████▉   | 3454/5000 [12:55:35<5:09:00, 11.99s/it, loss=0.4913, lr=2.64e-06]Steps:  69%|██████▉   | 3455/5000 [12:55:47<5:08:10, 11.97s/it, loss=0.4913, lr=2.64e-06]Steps:  69%|██████▉   | 3455/5000 [12:55:47<5:08:10, 11.97s/it, loss=1.1253, lr=2.64e-06]Steps:  69%|██████▉   | 3456/5000 [12:55:59<5:08:18, 11.98s/it, loss=1.1253, lr=2.64e-06]Steps:  69%|██████▉   | 3456/5000 [12:55:59<5:08:18, 11.98s/it, loss=0.7168, lr=2.63e-06]Steps:  69%|██████▉   | 3457/5000 [12:56:11<5:08:21, 11.99s/it, loss=0.7168, lr=2.63e-06]Steps:  69%|██████▉   | 3457/5000 [12:56:11<5:08:21, 11.99s/it, loss=0.4690, lr=2.63e-06]Steps:  69%|██████▉   | 3458/5000 [12:56:23<5:07:29, 11.96s/it, loss=0.4690, lr=2.63e-06]Steps:  69%|██████▉   | 3458/5000 [12:56:23<5:07:29, 11.96s/it, loss=1.0251, lr=2.63e-06]Steps:  69%|██████▉   | 3459/5000 [12:56:35<5:09:09, 12.04s/it, loss=1.0251, lr=2.63e-06]Steps:  69%|██████▉   | 3459/5000 [12:56:35<5:09:09, 12.04s/it, loss=1.1006, lr=2.62e-06]Steps:  69%|██████▉   | 3460/5000 [12:56:47<5:09:01, 12.04s/it, loss=1.1006, lr=2.62e-06]Steps:  69%|██████▉   | 3460/5000 [12:56:47<5:09:01, 12.04s/it, loss=0.3988, lr=2.62e-06]
[Step 3460] Training Debug Info:
  Loss: 1.208745
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0106, std: 0.8438
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0106, std: 1.3125
  Model pred mean: 0.0108, std: 0.7070
  Sigmas: [0.169921875]... (timesteps: [170.0])

[Step 3460] Training Debug Info:
  Loss: 1.056427
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0278, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0273, std: 1.3594
  Model pred mean: -0.0310, std: 0.8906
  Sigmas: [0.26953125]... (timesteps: [270.0])

[Step 3460] Training Debug Info:
  Loss: 1.144172
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0136, std: 0.9102
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0134, std: 1.3516
  Model pred mean: -0.0156, std: 0.8281
  Sigmas: [0.1328125]... (timesteps: [133.0])

[Step 3460] Training Debug Info:
  Loss: 1.038648
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0325, std: 0.8906
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0332, std: 1.3438
  Model pred mean: -0.0322, std: 0.8789
  Sigmas: [0.271484375]... (timesteps: [272.0])
Steps:  69%|██████▉   | 3461/5000 [12:56:59<5:08:15, 12.02s/it, loss=0.3988, lr=2.62e-06]Steps:  69%|██████▉   | 3461/5000 [12:56:59<5:08:15, 12.02s/it, loss=1.0386, lr=2.62e-06]Steps:  69%|██████▉   | 3462/5000 [12:57:11<5:06:45, 11.97s/it, loss=1.0386, lr=2.62e-06]Steps:  69%|██████▉   | 3462/5000 [12:57:11<5:06:45, 11.97s/it, loss=1.0328, lr=2.62e-06]Steps:  69%|██████▉   | 3463/5000 [12:57:23<5:05:47, 11.94s/it, loss=1.0328, lr=2.62e-06]Steps:  69%|██████▉   | 3463/5000 [12:57:23<5:05:47, 11.94s/it, loss=0.3581, lr=2.61e-06]Steps:  69%|██████▉   | 3464/5000 [12:57:35<5:05:21, 11.93s/it, loss=0.3581, lr=2.61e-06]Steps:  69%|██████▉   | 3464/5000 [12:57:35<5:05:21, 11.93s/it, loss=0.9593, lr=2.61e-06]Steps:  69%|██████▉   | 3465/5000 [12:57:47<5:06:45, 11.99s/it, loss=0.9593, lr=2.61e-06]Steps:  69%|██████▉   | 3465/5000 [12:57:47<5:06:45, 11.99s/it, loss=1.0610, lr=2.61e-06]Steps:  69%|██████▉   | 3466/5000 [12:57:59<5:06:12, 11.98s/it, loss=1.0610, lr=2.61e-06]Steps:  69%|██████▉   | 3466/5000 [12:57:59<5:06:12, 11.98s/it, loss=1.0899, lr=2.60e-06]Steps:  69%|██████▉   | 3467/5000 [12:58:11<5:05:20, 11.95s/it, loss=1.0899, lr=2.60e-06]Steps:  69%|██████▉   | 3467/5000 [12:58:11<5:05:20, 11.95s/it, loss=1.0141, lr=2.60e-06]Steps:  69%|██████▉   | 3468/5000 [12:58:23<5:04:31, 11.93s/it, loss=1.0141, lr=2.60e-06]Steps:  69%|██████▉   | 3468/5000 [12:58:23<5:04:31, 11.93s/it, loss=1.0425, lr=2.60e-06]Steps:  69%|██████▉   | 3469/5000 [12:58:35<5:04:38, 11.94s/it, loss=1.0425, lr=2.60e-06]Steps:  69%|██████▉   | 3469/5000 [12:58:35<5:04:38, 11.94s/it, loss=0.4467, lr=2.59e-06]Steps:  69%|██████▉   | 3470/5000 [12:58:47<5:03:50, 11.92s/it, loss=0.4467, lr=2.59e-06]Steps:  69%|██████▉   | 3470/5000 [12:58:47<5:03:50, 11.92s/it, loss=0.7911, lr=2.59e-06]
[Step 3470] Training Debug Info:
  Loss: 0.479964
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0011, std: 0.8711
  Noise mean: -0.0010, std: 0.9961
  Target mean: -0.0021, std: 1.3203
  Model pred mean: -0.0023, std: 1.1328
  Sigmas: [0.7109375]... (timesteps: [710.0])

[Step 3470] Training Debug Info:
  Loss: 0.355358
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0151, std: 0.9414
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0156, std: 1.3750
  Model pred mean: -0.0198, std: 1.2344
  Sigmas: [0.79296875]... (timesteps: [794.0])

[Step 3470] Training Debug Info:
  Loss: 0.705696
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0122, std: 0.9336
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0149, std: 1.3672
  Model pred mean: -0.0016, std: 1.0703
  Sigmas: [0.9765625]... (timesteps: [978.0])

[Step 3470] Training Debug Info:
  Loss: 0.729204
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0026, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0016, std: 1.3594
  Model pred mean: 0.0025, std: 1.0547
  Sigmas: [0.46875]... (timesteps: [469.0])
Steps:  69%|██████▉   | 3471/5000 [12:58:59<5:03:23, 11.91s/it, loss=0.7911, lr=2.59e-06]Steps:  69%|██████▉   | 3471/5000 [12:58:59<5:03:23, 11.91s/it, loss=0.7292, lr=2.59e-06]Steps:  69%|██████▉   | 3472/5000 [12:59:11<5:05:01, 11.98s/it, loss=0.7292, lr=2.59e-06]Steps:  69%|██████▉   | 3472/5000 [12:59:11<5:05:01, 11.98s/it, loss=1.1306, lr=2.59e-06]Steps:  69%|██████▉   | 3473/5000 [12:59:23<5:03:45, 11.94s/it, loss=1.1306, lr=2.59e-06]Steps:  69%|██████▉   | 3473/5000 [12:59:23<5:03:45, 11.94s/it, loss=1.0255, lr=2.58e-06]Steps:  69%|██████▉   | 3474/5000 [12:59:34<5:03:07, 11.92s/it, loss=1.0255, lr=2.58e-06]Steps:  69%|██████▉   | 3474/5000 [12:59:34<5:03:07, 11.92s/it, loss=0.5286, lr=2.58e-06]Steps:  70%|██████▉   | 3475/5000 [12:59:46<5:03:11, 11.93s/it, loss=0.5286, lr=2.58e-06]Steps:  70%|██████▉   | 3475/5000 [12:59:46<5:03:11, 11.93s/it, loss=0.7742, lr=2.58e-06]Steps:  70%|██████▉   | 3476/5000 [12:59:58<5:03:02, 11.93s/it, loss=0.7742, lr=2.58e-06]Steps:  70%|██████▉   | 3476/5000 [12:59:58<5:03:02, 11.93s/it, loss=1.1312, lr=2.57e-06]Steps:  70%|██████▉   | 3477/5000 [13:00:10<5:02:49, 11.93s/it, loss=1.1312, lr=2.57e-06]Steps:  70%|██████▉   | 3477/5000 [13:00:10<5:02:49, 11.93s/it, loss=0.3939, lr=2.57e-06]Steps:  70%|██████▉   | 3478/5000 [13:00:22<5:03:21, 11.96s/it, loss=0.3939, lr=2.57e-06]Steps:  70%|██████▉   | 3478/5000 [13:00:22<5:03:21, 11.96s/it, loss=1.0655, lr=2.57e-06]Steps:  70%|██████▉   | 3479/5000 [13:00:34<5:04:12, 12.00s/it, loss=1.0655, lr=2.57e-06]Steps:  70%|██████▉   | 3479/5000 [13:00:34<5:04:12, 12.00s/it, loss=0.4259, lr=2.56e-06]Steps:  70%|██████▉   | 3480/5000 [13:00:46<5:03:10, 11.97s/it, loss=0.4259, lr=2.56e-06]Steps:  70%|██████▉   | 3480/5000 [13:00:46<5:03:10, 11.97s/it, loss=0.4789, lr=2.56e-06]
[Step 3480] Training Debug Info:
  Loss: 0.394598
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0016, std: 0.9570
  Noise mean: 0.0004, std: 0.9961
  Target mean: -0.0012, std: 1.3828
  Model pred mean: 0.0013, std: 1.2266
  Sigmas: [0.8515625]... (timesteps: [852.0])

[Step 3480] Training Debug Info:
  Loss: 1.149004
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0007, std: 0.9258
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0002, std: 1.3594
  Model pred mean: 0.0010, std: 0.8398
  Sigmas: [0.1328125]... (timesteps: [133.0])

[Step 3480] Training Debug Info:
  Loss: 0.542763
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0010, std: 0.9023
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0010, std: 1.3438
  Model pred mean: 0.0057, std: 1.1250
  Sigmas: [0.62109375]... (timesteps: [620.0])

[Step 3480] Training Debug Info:
  Loss: 1.134445
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0006, std: 0.8984
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0011, std: 1.3438
  Model pred mean: 0.0007, std: 0.8203
  Sigmas: [0.10888671875]... (timesteps: [109.0])
Steps:  70%|██████▉   | 3481/5000 [13:00:58<5:02:55, 11.97s/it, loss=0.4789, lr=2.56e-06]Steps:  70%|██████▉   | 3481/5000 [13:00:58<5:02:55, 11.97s/it, loss=1.1344, lr=2.56e-06]Steps:  70%|██████▉   | 3482/5000 [13:01:10<5:02:33, 11.96s/it, loss=1.1344, lr=2.56e-06]Steps:  70%|██████▉   | 3482/5000 [13:01:10<5:02:33, 11.96s/it, loss=1.0502, lr=2.55e-06]Steps:  70%|██████▉   | 3483/5000 [13:01:22<5:01:53, 11.94s/it, loss=1.0502, lr=2.55e-06]Steps:  70%|██████▉   | 3483/5000 [13:01:22<5:01:53, 11.94s/it, loss=0.9093, lr=2.55e-06]Steps:  70%|██████▉   | 3484/5000 [13:01:34<5:01:28, 11.93s/it, loss=0.9093, lr=2.55e-06]Steps:  70%|██████▉   | 3484/5000 [13:01:34<5:01:28, 11.93s/it, loss=1.1260, lr=2.55e-06]Steps:  70%|██████▉   | 3485/5000 [13:01:46<5:01:07, 11.93s/it, loss=1.1260, lr=2.55e-06]Steps:  70%|██████▉   | 3485/5000 [13:01:46<5:01:07, 11.93s/it, loss=1.0117, lr=2.55e-06]Steps:  70%|██████▉   | 3486/5000 [13:01:58<5:02:41, 12.00s/it, loss=1.0117, lr=2.55e-06]Steps:  70%|██████▉   | 3486/5000 [13:01:58<5:02:41, 12.00s/it, loss=0.8368, lr=2.54e-06]Steps:  70%|██████▉   | 3487/5000 [13:02:10<5:02:47, 12.01s/it, loss=0.8368, lr=2.54e-06]Steps:  70%|██████▉   | 3487/5000 [13:02:10<5:02:47, 12.01s/it, loss=1.1361, lr=2.54e-06]Steps:  70%|██████▉   | 3488/5000 [13:02:22<5:01:59, 11.98s/it, loss=1.1361, lr=2.54e-06]Steps:  70%|██████▉   | 3488/5000 [13:02:22<5:01:59, 11.98s/it, loss=0.7075, lr=2.54e-06]Steps:  70%|██████▉   | 3489/5000 [13:02:34<5:00:52, 11.95s/it, loss=0.7075, lr=2.54e-06]Steps:  70%|██████▉   | 3489/5000 [13:02:34<5:00:52, 11.95s/it, loss=0.4256, lr=2.53e-06]Steps:  70%|██████▉   | 3490/5000 [13:02:46<5:00:34, 11.94s/it, loss=0.4256, lr=2.53e-06]Steps:  70%|██████▉   | 3490/5000 [13:02:46<5:00:34, 11.94s/it, loss=0.9276, lr=2.53e-06]
[Step 3490] Training Debug Info:
  Loss: 0.474026
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0067, std: 0.9023
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0052, std: 1.3438
  Model pred mean: -0.0087, std: 1.1562
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 3490] Training Debug Info:
  Loss: 0.419511
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0126, std: 0.9727
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0118, std: 1.3984
  Model pred mean: -0.0155, std: 1.2422
  Sigmas: [0.7109375]... (timesteps: [712.0])

[Step 3490] Training Debug Info:
  Loss: 0.917353
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0566, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0566, std: 1.3672
  Model pred mean: -0.0564, std: 0.9805
  Sigmas: [0.251953125]... (timesteps: [252.0])

[Step 3490] Training Debug Info:
  Loss: 0.534356
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0041, std: 0.9219
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0041, std: 1.3594
  Model pred mean: -0.0019, std: 1.1484
  Sigmas: [0.62109375]... (timesteps: [621.0])
Steps:  70%|██████▉   | 3491/5000 [13:02:58<5:00:19, 11.94s/it, loss=0.9276, lr=2.53e-06]Steps:  70%|██████▉   | 3491/5000 [13:02:58<5:00:19, 11.94s/it, loss=0.5344, lr=2.53e-06]Steps:  70%|██████▉   | 3492/5000 [13:03:10<5:02:00, 12.02s/it, loss=0.5344, lr=2.53e-06]Steps:  70%|██████▉   | 3492/5000 [13:03:10<5:02:00, 12.02s/it, loss=1.0093, lr=2.52e-06]Steps:  70%|██████▉   | 3493/5000 [13:03:22<5:01:02, 11.99s/it, loss=1.0093, lr=2.52e-06]Steps:  70%|██████▉   | 3493/5000 [13:03:22<5:01:02, 11.99s/it, loss=0.6238, lr=2.52e-06]Steps:  70%|██████▉   | 3494/5000 [13:03:34<5:00:33, 11.97s/it, loss=0.6238, lr=2.52e-06]Steps:  70%|██████▉   | 3494/5000 [13:03:34<5:00:33, 11.97s/it, loss=1.1666, lr=2.52e-06]Steps:  70%|██████▉   | 3495/5000 [13:03:46<5:00:12, 11.97s/it, loss=1.1666, lr=2.52e-06]Steps:  70%|██████▉   | 3495/5000 [13:03:46<5:00:12, 11.97s/it, loss=0.4189, lr=2.52e-06]Steps:  70%|██████▉   | 3496/5000 [13:03:58<5:00:50, 12.00s/it, loss=0.4189, lr=2.52e-06]Steps:  70%|██████▉   | 3496/5000 [13:03:58<5:00:50, 12.00s/it, loss=1.1283, lr=2.51e-06]Steps:  70%|██████▉   | 3497/5000 [13:04:10<4:59:31, 11.96s/it, loss=1.1283, lr=2.51e-06]Steps:  70%|██████▉   | 3497/5000 [13:04:10<4:59:31, 11.96s/it, loss=0.7196, lr=2.51e-06]Steps:  70%|██████▉   | 3498/5000 [13:04:22<4:58:39, 11.93s/it, loss=0.7196, lr=2.51e-06]Steps:  70%|██████▉   | 3498/5000 [13:04:22<4:58:39, 11.93s/it, loss=1.0112, lr=2.51e-06]Steps:  70%|██████▉   | 3499/5000 [13:04:34<4:59:50, 11.99s/it, loss=1.0112, lr=2.51e-06]Steps:  70%|██████▉   | 3499/5000 [13:04:34<4:59:50, 11.99s/it, loss=0.6978, lr=2.50e-06]Steps:  70%|███████   | 3500/5000 [13:04:46<4:59:24, 11.98s/it, loss=0.6978, lr=2.50e-06]Steps:  70%|███████   | 3500/5000 [13:04:46<4:59:24, 11.98s/it, loss=0.5974, lr=2.50e-06]01/22/2026 20:50:32 - INFO - __main__ - 
[Step 3500] ✅ Loss in normal range (0.5974)
01/22/2026 20:50:32 - INFO - __main__ -   Loss avg (last 100): 0.7858
01/22/2026 20:50:32 - INFO - __main__ -   Loss range: [0.3140, 1.1858]

[Step 3500] Training Debug Info:
  Loss: 1.020086
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 0.9492
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0366, std: 1.3750
  Model pred mean: -0.0359, std: 0.9414
  Sigmas: [0.2021484375]... (timesteps: [202.0])

[Step 3500] Training Debug Info:
  Loss: 0.601035
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0009, std: 0.8477
  Noise mean: -0.0036, std: 1.0000
  Target mean: -0.0027, std: 1.3125
  Model pred mean: 0.0004, std: 1.0547
  Sigmas: [0.61328125]... (timesteps: [613.0])

[Step 3500] Training Debug Info:
  Loss: 0.463433
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0001, std: 0.9062
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0021, std: 1.3516
  Model pred mean: 0.0049, std: 1.1641
  Sigmas: [0.70703125]... (timesteps: [708.0])

[Step 3500] Training Debug Info:
  Loss: 1.063855
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0306, std: 0.8242
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0344, std: 1.2969
  Model pred mean: 0.0298, std: 0.7773
  Sigmas: [0.353515625]... (timesteps: [354.0])
Steps:  70%|███████   | 3501/5000 [13:04:57<4:58:00, 11.93s/it, loss=0.5974, lr=2.50e-06]Steps:  70%|███████   | 3501/5000 [13:04:57<4:58:00, 11.93s/it, loss=1.0639, lr=2.50e-06]Steps:  70%|███████   | 3502/5000 [13:05:09<4:57:27, 11.91s/it, loss=1.0639, lr=2.50e-06]Steps:  70%|███████   | 3502/5000 [13:05:09<4:57:27, 11.91s/it, loss=0.9382, lr=2.49e-06]Steps:  70%|███████   | 3503/5000 [13:05:21<4:58:00, 11.94s/it, loss=0.9382, lr=2.49e-06]Steps:  70%|███████   | 3503/5000 [13:05:21<4:58:00, 11.94s/it, loss=1.0804, lr=2.49e-06]Steps:  70%|███████   | 3504/5000 [13:05:33<4:57:33, 11.93s/it, loss=1.0804, lr=2.49e-06]Steps:  70%|███████   | 3504/5000 [13:05:33<4:57:33, 11.93s/it, loss=0.9261, lr=2.49e-06]Steps:  70%|███████   | 3505/5000 [13:05:45<4:58:04, 11.96s/it, loss=0.9261, lr=2.49e-06]Steps:  70%|███████   | 3505/5000 [13:05:45<4:58:04, 11.96s/it, loss=1.0216, lr=2.48e-06]Steps:  70%|███████   | 3506/5000 [13:05:58<4:59:49, 12.04s/it, loss=1.0216, lr=2.48e-06]Steps:  70%|███████   | 3506/5000 [13:05:58<4:59:49, 12.04s/it, loss=0.7595, lr=2.48e-06]Steps:  70%|███████   | 3507/5000 [13:06:09<4:58:55, 12.01s/it, loss=0.7595, lr=2.48e-06]Steps:  70%|███████   | 3507/5000 [13:06:09<4:58:55, 12.01s/it, loss=0.3920, lr=2.48e-06]Steps:  70%|███████   | 3508/5000 [13:06:21<4:58:25, 12.00s/it, loss=0.3920, lr=2.48e-06]Steps:  70%|███████   | 3508/5000 [13:06:21<4:58:25, 12.00s/it, loss=1.1064, lr=2.48e-06]Steps:  70%|███████   | 3509/5000 [13:06:33<4:57:46, 11.98s/it, loss=1.1064, lr=2.48e-06]Steps:  70%|███████   | 3509/5000 [13:06:33<4:57:46, 11.98s/it, loss=0.5566, lr=2.47e-06]Steps:  70%|███████   | 3510/5000 [13:06:45<4:57:31, 11.98s/it, loss=0.5566, lr=2.47e-06]Steps:  70%|███████   | 3510/5000 [13:06:45<4:57:31, 11.98s/it, loss=0.4544, lr=2.47e-06]
[Step 3510] Training Debug Info:
  Loss: 0.851619
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0165, std: 0.9180
  Noise mean: 0.0002, std: 0.9961
  Target mean: -0.0162, std: 1.3594
  Model pred mean: -0.0149, std: 0.9922
  Sigmas: [0.345703125]... (timesteps: [345.0])

[Step 3510] Training Debug Info:
  Loss: 1.179448
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0273, std: 0.9688
  Noise mean: 0.0028, std: 1.0000
  Target mean: 0.0302, std: 1.3906
  Model pred mean: 0.0258, std: 0.8750
  Sigmas: [0.16015625]... (timesteps: [160.0])

[Step 3510] Training Debug Info:
  Loss: 1.070423
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0581, std: 0.9414
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0579, std: 1.3750
  Model pred mean: -0.0610, std: 0.9023
  Sigmas: [0.0791015625]... (timesteps: [79.0])

[Step 3510] Training Debug Info:
  Loss: 0.441604
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.9141
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0001, std: 1.3516
  Model pred mean: -0.0020, std: 1.1797
  Sigmas: [0.68359375]... (timesteps: [684.0])
Steps:  70%|███████   | 3511/5000 [13:06:57<4:57:21, 11.98s/it, loss=0.4544, lr=2.47e-06]Steps:  70%|███████   | 3511/5000 [13:06:57<4:57:21, 11.98s/it, loss=0.4416, lr=2.47e-06]Steps:  70%|███████   | 3512/5000 [13:07:09<4:56:49, 11.97s/it, loss=0.4416, lr=2.47e-06]Steps:  70%|███████   | 3512/5000 [13:07:09<4:56:49, 11.97s/it, loss=0.7910, lr=2.46e-06]Steps:  70%|███████   | 3513/5000 [13:07:21<4:58:09, 12.03s/it, loss=0.7910, lr=2.46e-06]Steps:  70%|███████   | 3513/5000 [13:07:21<4:58:09, 12.03s/it, loss=1.0674, lr=2.46e-06]Steps:  70%|███████   | 3514/5000 [13:07:33<4:57:44, 12.02s/it, loss=1.0674, lr=2.46e-06]Steps:  70%|███████   | 3514/5000 [13:07:33<4:57:44, 12.02s/it, loss=0.6391, lr=2.46e-06]Steps:  70%|███████   | 3515/5000 [13:07:45<4:57:10, 12.01s/it, loss=0.6391, lr=2.46e-06]Steps:  70%|███████   | 3515/5000 [13:07:45<4:57:10, 12.01s/it, loss=0.5700, lr=2.45e-06]Steps:  70%|███████   | 3516/5000 [13:07:57<4:56:25, 11.98s/it, loss=0.5700, lr=2.45e-06]Steps:  70%|███████   | 3516/5000 [13:07:57<4:56:25, 11.98s/it, loss=0.4315, lr=2.45e-06]Steps:  70%|███████   | 3517/5000 [13:08:09<4:55:44, 11.97s/it, loss=0.4315, lr=2.45e-06]Steps:  70%|███████   | 3517/5000 [13:08:09<4:55:44, 11.97s/it, loss=1.0153, lr=2.45e-06]Steps:  70%|███████   | 3518/5000 [13:08:21<4:54:50, 11.94s/it, loss=1.0153, lr=2.45e-06]Steps:  70%|███████   | 3518/5000 [13:08:21<4:54:50, 11.94s/it, loss=0.4801, lr=2.45e-06]Steps:  70%|███████   | 3519/5000 [13:08:33<4:56:38, 12.02s/it, loss=0.4801, lr=2.45e-06]Steps:  70%|███████   | 3519/5000 [13:08:33<4:56:38, 12.02s/it, loss=0.4931, lr=2.44e-06]Steps:  70%|███████   | 3520/5000 [13:08:45<4:55:48, 11.99s/it, loss=0.4931, lr=2.44e-06]Steps:  70%|███████   | 3520/5000 [13:08:45<4:55:48, 11.99s/it, loss=0.6309, lr=2.44e-06]
[Step 3520] Training Debug Info:
  Loss: 0.537314
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0262, std: 0.9102
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0282, std: 1.3516
  Model pred mean: 0.0259, std: 1.1328
  Sigmas: [0.61328125]... (timesteps: [612.0])

[Step 3520] Training Debug Info:
  Loss: 0.858862
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0025, std: 0.9453
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0043, std: 1.3750
  Model pred mean: 0.0006, std: 1.0078
  Sigmas: [0.396484375]... (timesteps: [396.0])

[Step 3520] Training Debug Info:
  Loss: 0.528686
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0762, std: 0.9336
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0767, std: 1.3750
  Model pred mean: -0.0762, std: 1.1641
  Sigmas: [0.443359375]... (timesteps: [444.0])

[Step 3520] Training Debug Info:
  Loss: 1.168668
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0199, std: 0.8867
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0233, std: 1.3359
  Model pred mean: -0.0194, std: 0.7852
  Sigmas: [0.2109375]... (timesteps: [211.0])
Steps:  70%|███████   | 3521/5000 [13:08:57<4:55:12, 11.98s/it, loss=0.6309, lr=2.44e-06]Steps:  70%|███████   | 3521/5000 [13:08:57<4:55:12, 11.98s/it, loss=1.1687, lr=2.44e-06]Steps:  70%|███████   | 3522/5000 [13:09:09<4:54:19, 11.95s/it, loss=1.1687, lr=2.44e-06]Steps:  70%|███████   | 3522/5000 [13:09:09<4:54:19, 11.95s/it, loss=0.3488, lr=2.43e-06]Steps:  70%|███████   | 3523/5000 [13:09:21<4:54:48, 11.98s/it, loss=0.3488, lr=2.43e-06]Steps:  70%|███████   | 3523/5000 [13:09:21<4:54:48, 11.98s/it, loss=0.8185, lr=2.43e-06]Steps:  70%|███████   | 3524/5000 [13:09:33<4:54:01, 11.95s/it, loss=0.8185, lr=2.43e-06]Steps:  70%|███████   | 3524/5000 [13:09:33<4:54:01, 11.95s/it, loss=0.7572, lr=2.43e-06]Steps:  70%|███████   | 3525/5000 [13:09:45<4:53:28, 11.94s/it, loss=0.7572, lr=2.43e-06]Steps:  70%|███████   | 3525/5000 [13:09:45<4:53:28, 11.94s/it, loss=0.7344, lr=2.42e-06]Steps:  71%|███████   | 3526/5000 [13:09:57<4:54:48, 12.00s/it, loss=0.7344, lr=2.42e-06]Steps:  71%|███████   | 3526/5000 [13:09:57<4:54:48, 12.00s/it, loss=1.0987, lr=2.42e-06]Steps:  71%|███████   | 3527/5000 [13:10:09<4:53:24, 11.95s/it, loss=1.0987, lr=2.42e-06]Steps:  71%|███████   | 3527/5000 [13:10:09<4:53:24, 11.95s/it, loss=0.4695, lr=2.42e-06]Steps:  71%|███████   | 3528/5000 [13:10:21<4:52:30, 11.92s/it, loss=0.4695, lr=2.42e-06]Steps:  71%|███████   | 3528/5000 [13:10:21<4:52:30, 11.92s/it, loss=0.4104, lr=2.42e-06]Steps:  71%|███████   | 3529/5000 [13:10:33<4:51:56, 11.91s/it, loss=0.4104, lr=2.42e-06]Steps:  71%|███████   | 3529/5000 [13:10:33<4:51:56, 11.91s/it, loss=1.1443, lr=2.41e-06]Steps:  71%|███████   | 3530/5000 [13:10:45<4:51:43, 11.91s/it, loss=1.1443, lr=2.41e-06]Steps:  71%|███████   | 3530/5000 [13:10:45<4:51:43, 11.91s/it, loss=0.9307, lr=2.41e-06]
[Step 3530] Training Debug Info:
  Loss: 0.520181
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0091, std: 0.8750
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0092, std: 1.3281
  Model pred mean: -0.0079, std: 1.1172
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 3530] Training Debug Info:
  Loss: 1.053927
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0120, std: 0.9414
  Noise mean: 0.0030, std: 1.0000
  Target mean: -0.0091, std: 1.3750
  Model pred mean: -0.0121, std: 0.9141
  Sigmas: [0.236328125]... (timesteps: [236.0])

[Step 3530] Training Debug Info:
  Loss: 0.433861
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0069, std: 0.9570
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0091, std: 1.3828
  Model pred mean: -0.0052, std: 1.2109
  Sigmas: [0.69921875]... (timesteps: [700.0])

[Step 3530] Training Debug Info:
  Loss: 0.382892
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0079, std: 0.9023
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0064, std: 1.3438
  Model pred mean: -0.0112, std: 1.1953
  Sigmas: [0.74609375]... (timesteps: [748.0])
Steps:  71%|███████   | 3531/5000 [13:10:57<4:51:36, 11.91s/it, loss=0.9307, lr=2.41e-06]Steps:  71%|███████   | 3531/5000 [13:10:57<4:51:36, 11.91s/it, loss=0.3829, lr=2.41e-06]Steps:  71%|███████   | 3532/5000 [13:11:09<4:52:07, 11.94s/it, loss=0.3829, lr=2.41e-06]Steps:  71%|███████   | 3532/5000 [13:11:09<4:52:07, 11.94s/it, loss=0.6249, lr=2.40e-06]Steps:  71%|███████   | 3533/5000 [13:11:21<4:53:29, 12.00s/it, loss=0.6249, lr=2.40e-06]Steps:  71%|███████   | 3533/5000 [13:11:21<4:53:29, 12.00s/it, loss=0.7385, lr=2.40e-06]Steps:  71%|███████   | 3534/5000 [13:11:33<4:52:10, 11.96s/it, loss=0.7385, lr=2.40e-06]Steps:  71%|███████   | 3534/5000 [13:11:33<4:52:10, 11.96s/it, loss=0.7250, lr=2.40e-06]Steps:  71%|███████   | 3535/5000 [13:11:44<4:51:46, 11.95s/it, loss=0.7250, lr=2.40e-06]Steps:  71%|███████   | 3535/5000 [13:11:44<4:51:46, 11.95s/it, loss=1.0351, lr=2.39e-06]Steps:  71%|███████   | 3536/5000 [13:11:56<4:51:09, 11.93s/it, loss=1.0351, lr=2.39e-06]Steps:  71%|███████   | 3536/5000 [13:11:56<4:51:09, 11.93s/it, loss=1.0555, lr=2.39e-06]Steps:  71%|███████   | 3537/5000 [13:12:08<4:50:26, 11.91s/it, loss=1.0555, lr=2.39e-06]Steps:  71%|███████   | 3537/5000 [13:12:08<4:50:26, 11.91s/it, loss=1.1109, lr=2.39e-06]Steps:  71%|███████   | 3538/5000 [13:12:20<4:50:25, 11.92s/it, loss=1.1109, lr=2.39e-06]Steps:  71%|███████   | 3538/5000 [13:12:20<4:50:25, 11.92s/it, loss=1.0590, lr=2.39e-06]Steps:  71%|███████   | 3539/5000 [13:12:32<4:49:56, 11.91s/it, loss=1.0590, lr=2.39e-06]Steps:  71%|███████   | 3539/5000 [13:12:32<4:49:56, 11.91s/it, loss=0.4469, lr=2.38e-06]Steps:  71%|███████   | 3540/5000 [13:12:44<4:51:06, 11.96s/it, loss=0.4469, lr=2.38e-06]Steps:  71%|███████   | 3540/5000 [13:12:44<4:51:06, 11.96s/it, loss=0.3700, lr=2.38e-06]
[Step 3540] Training Debug Info:
  Loss: 1.072762
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0223, std: 0.9375
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0226, std: 1.3672
  Model pred mean: -0.0214, std: 0.8945
  Sigmas: [0.2119140625]... (timesteps: [212.0])

[Step 3540] Training Debug Info:
  Loss: 1.123178
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0109, std: 0.9258
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0137, std: 1.3594
  Model pred mean: -0.0112, std: 0.8516
  Sigmas: [0.2236328125]... (timesteps: [224.0])

[Step 3540] Training Debug Info:
  Loss: 1.062817
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0505, std: 0.9727
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0496, std: 1.3906
  Model pred mean: -0.0491, std: 0.9375
  Sigmas: [0.049072265625]... (timesteps: [49.0])

[Step 3540] Training Debug Info:
  Loss: 0.440416
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0309, std: 0.8828
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0308, std: 1.3359
  Model pred mean: -0.0374, std: 1.1562
  Sigmas: [0.796875]... (timesteps: [795.0])
Steps:  71%|███████   | 3541/5000 [13:12:56<4:51:37, 11.99s/it, loss=0.3700, lr=2.38e-06]Steps:  71%|███████   | 3541/5000 [13:12:56<4:51:37, 11.99s/it, loss=0.4404, lr=2.38e-06]Steps:  71%|███████   | 3542/5000 [13:13:08<4:50:31, 11.96s/it, loss=0.4404, lr=2.38e-06]Steps:  71%|███████   | 3542/5000 [13:13:08<4:50:31, 11.96s/it, loss=0.4677, lr=2.37e-06]Steps:  71%|███████   | 3543/5000 [13:13:20<4:49:39, 11.93s/it, loss=0.4677, lr=2.37e-06]Steps:  71%|███████   | 3543/5000 [13:13:20<4:49:39, 11.93s/it, loss=0.6176, lr=2.37e-06]Steps:  71%|███████   | 3544/5000 [13:13:32<4:49:44, 11.94s/it, loss=0.6176, lr=2.37e-06]Steps:  71%|███████   | 3544/5000 [13:13:32<4:49:44, 11.94s/it, loss=0.9392, lr=2.37e-06]Steps:  71%|███████   | 3545/5000 [13:13:44<4:49:05, 11.92s/it, loss=0.9392, lr=2.37e-06]Steps:  71%|███████   | 3545/5000 [13:13:44<4:49:05, 11.92s/it, loss=0.7534, lr=2.37e-06]Steps:  71%|███████   | 3546/5000 [13:13:56<4:50:42, 12.00s/it, loss=0.7534, lr=2.37e-06]Steps:  71%|███████   | 3546/5000 [13:13:56<4:50:42, 12.00s/it, loss=0.6179, lr=2.36e-06]Steps:  71%|███████   | 3547/5000 [13:14:08<4:49:57, 11.97s/it, loss=0.6179, lr=2.36e-06]Steps:  71%|███████   | 3547/5000 [13:14:08<4:49:57, 11.97s/it, loss=1.0721, lr=2.36e-06]Steps:  71%|███████   | 3548/5000 [13:14:20<4:48:58, 11.94s/it, loss=1.0721, lr=2.36e-06]Steps:  71%|███████   | 3548/5000 [13:14:20<4:48:58, 11.94s/it, loss=0.5509, lr=2.36e-06]Steps:  71%|███████   | 3549/5000 [13:14:32<4:49:00, 11.95s/it, loss=0.5509, lr=2.36e-06]Steps:  71%|███████   | 3549/5000 [13:14:32<4:49:00, 11.95s/it, loss=1.0583, lr=2.35e-06]Steps:  71%|███████   | 3550/5000 [13:14:44<4:49:37, 11.98s/it, loss=1.0583, lr=2.35e-06]Steps:  71%|███████   | 3550/5000 [13:14:44<4:49:37, 11.98s/it, loss=0.7074, lr=2.35e-06]
[Step 3550] Training Debug Info:
  Loss: 0.682384
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0053, std: 0.9297
  Noise mean: 0.0055, std: 1.0000
  Target mean: 0.0002, std: 1.3672
  Model pred mean: -0.0013, std: 1.0859
  Sigmas: [0.490234375]... (timesteps: [490.0])

[Step 3550] Training Debug Info:
  Loss: 0.646433
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0092, std: 0.9141
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0084, std: 1.3516
  Model pred mean: -0.0182, std: 1.0781
  Sigmas: [0.984375]... (timesteps: [983.0])

[Step 3550] Training Debug Info:
  Loss: 0.574901
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0025, std: 0.8711
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0021, std: 1.3281
  Model pred mean: 0.0112, std: 1.0859
  Sigmas: [0.96875]... (timesteps: [970.0])

[Step 3550] Training Debug Info:
  Loss: 1.077851
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0033, std: 0.9219
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0027, std: 1.3594
  Model pred mean: -0.0030, std: 0.8789
  Sigmas: [0.051025390625]... (timesteps: [51.0])
Steps:  71%|███████   | 3551/5000 [13:14:56<4:48:57, 11.96s/it, loss=0.7074, lr=2.35e-06]Steps:  71%|███████   | 3551/5000 [13:14:56<4:48:57, 11.96s/it, loss=1.0779, lr=2.35e-06]Steps:  71%|███████   | 3552/5000 [13:15:08<4:48:51, 11.97s/it, loss=1.0779, lr=2.35e-06]Steps:  71%|███████   | 3552/5000 [13:15:08<4:48:51, 11.97s/it, loss=0.6467, lr=2.34e-06]Steps:  71%|███████   | 3553/5000 [13:15:20<4:50:42, 12.05s/it, loss=0.6467, lr=2.34e-06]Steps:  71%|███████   | 3553/5000 [13:15:20<4:50:42, 12.05s/it, loss=0.3739, lr=2.34e-06]Steps:  71%|███████   | 3554/5000 [13:15:32<4:50:05, 12.04s/it, loss=0.3739, lr=2.34e-06]Steps:  71%|███████   | 3554/5000 [13:15:32<4:50:05, 12.04s/it, loss=0.5248, lr=2.34e-06]Steps:  71%|███████   | 3555/5000 [13:15:44<4:49:25, 12.02s/it, loss=0.5248, lr=2.34e-06]Steps:  71%|███████   | 3555/5000 [13:15:44<4:49:25, 12.02s/it, loss=1.1550, lr=2.34e-06]Steps:  71%|███████   | 3556/5000 [13:15:56<4:48:32, 11.99s/it, loss=1.1550, lr=2.34e-06]Steps:  71%|███████   | 3556/5000 [13:15:56<4:48:32, 11.99s/it, loss=0.8156, lr=2.33e-06]Steps:  71%|███████   | 3557/5000 [13:16:08<4:47:35, 11.96s/it, loss=0.8156, lr=2.33e-06]Steps:  71%|███████   | 3557/5000 [13:16:08<4:47:35, 11.96s/it, loss=1.0278, lr=2.33e-06]Steps:  71%|███████   | 3558/5000 [13:16:20<4:46:55, 11.94s/it, loss=1.0278, lr=2.33e-06]Steps:  71%|███████   | 3558/5000 [13:16:20<4:46:55, 11.94s/it, loss=1.2126, lr=2.33e-06]Steps:  71%|███████   | 3559/5000 [13:16:32<4:47:07, 11.96s/it, loss=1.2126, lr=2.33e-06]Steps:  71%|███████   | 3559/5000 [13:16:32<4:47:07, 11.96s/it, loss=1.0092, lr=2.32e-06]Steps:  71%|███████   | 3560/5000 [13:16:44<4:48:46, 12.03s/it, loss=1.0092, lr=2.32e-06]Steps:  71%|███████   | 3560/5000 [13:16:44<4:48:46, 12.03s/it, loss=1.1248, lr=2.32e-06]
[Step 3560] Training Debug Info:
  Loss: 1.103839
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0074, std: 0.8906
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0076, std: 1.3359
  Model pred mean: 0.0085, std: 0.8281
  Sigmas: [0.287109375]... (timesteps: [287.0])

[Step 3560] Training Debug Info:
  Loss: 1.136210
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0173, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0167, std: 1.3516
  Model pred mean: -0.0167, std: 0.8320
  Sigmas: [0.224609375]... (timesteps: [225.0])

[Step 3560] Training Debug Info:
  Loss: 0.346017
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0074, std: 0.8984
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0047, std: 1.3438
  Model pred mean: 0.0067, std: 1.2109
  Sigmas: [0.859375]... (timesteps: [858.0])

[Step 3560] Training Debug Info:
  Loss: 0.760268
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0211, std: 0.8750
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0210, std: 1.3281
  Model pred mean: 0.0186, std: 1.0078
  Sigmas: [0.515625]... (timesteps: [515.0])
Steps:  71%|███████   | 3561/5000 [13:16:56<4:47:30, 11.99s/it, loss=1.1248, lr=2.32e-06]Steps:  71%|███████   | 3561/5000 [13:16:56<4:47:30, 11.99s/it, loss=0.7603, lr=2.32e-06]Steps:  71%|███████   | 3562/5000 [13:17:08<4:46:46, 11.97s/it, loss=0.7603, lr=2.32e-06]Steps:  71%|███████   | 3562/5000 [13:17:08<4:46:46, 11.97s/it, loss=0.5883, lr=2.31e-06]Steps:  71%|███████▏  | 3563/5000 [13:17:19<4:46:07, 11.95s/it, loss=0.5883, lr=2.31e-06]Steps:  71%|███████▏  | 3563/5000 [13:17:19<4:46:07, 11.95s/it, loss=0.7148, lr=2.31e-06]Steps:  71%|███████▏  | 3564/5000 [13:17:31<4:45:41, 11.94s/it, loss=0.7148, lr=2.31e-06]Steps:  71%|███████▏  | 3564/5000 [13:17:31<4:45:41, 11.94s/it, loss=0.8955, lr=2.31e-06]Steps:  71%|███████▏  | 3565/5000 [13:17:43<4:44:50, 11.91s/it, loss=0.8955, lr=2.31e-06]Steps:  71%|███████▏  | 3565/5000 [13:17:43<4:44:50, 11.91s/it, loss=1.1784, lr=2.31e-06]Steps:  71%|███████▏  | 3566/5000 [13:17:55<4:44:04, 11.89s/it, loss=1.1784, lr=2.31e-06]Steps:  71%|███████▏  | 3566/5000 [13:17:55<4:44:04, 11.89s/it, loss=0.9249, lr=2.30e-06]Steps:  71%|███████▏  | 3567/5000 [13:18:07<4:45:55, 11.97s/it, loss=0.9249, lr=2.30e-06]Steps:  71%|███████▏  | 3567/5000 [13:18:07<4:45:55, 11.97s/it, loss=1.0674, lr=2.30e-06]Steps:  71%|███████▏  | 3568/5000 [13:18:19<4:46:04, 11.99s/it, loss=1.0674, lr=2.30e-06]Steps:  71%|███████▏  | 3568/5000 [13:18:19<4:46:04, 11.99s/it, loss=1.0963, lr=2.30e-06]Steps:  71%|███████▏  | 3569/5000 [13:18:31<4:45:28, 11.97s/it, loss=1.0963, lr=2.30e-06]Steps:  71%|███████▏  | 3569/5000 [13:18:31<4:45:28, 11.97s/it, loss=0.3830, lr=2.29e-06]Steps:  71%|███████▏  | 3570/5000 [13:18:43<4:45:02, 11.96s/it, loss=0.3830, lr=2.29e-06]Steps:  71%|███████▏  | 3570/5000 [13:18:43<4:45:02, 11.96s/it, loss=1.1293, lr=2.29e-06]
[Step 3570] Training Debug Info:
  Loss: 0.399943
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0347, std: 0.9297
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0354, std: 1.3672
  Model pred mean: -0.0381, std: 1.2109
  Sigmas: [0.68359375]... (timesteps: [684.0])

[Step 3570] Training Debug Info:
  Loss: 0.515243
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0128, std: 0.8672
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0139, std: 1.3203
  Model pred mean: -0.0116, std: 1.1094
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 3570] Training Debug Info:
  Loss: 1.116681
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0110, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0100, std: 1.3594
  Model pred mean: 0.0089, std: 0.8555
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 3570] Training Debug Info:
  Loss: 1.144752
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0204, std: 0.8945
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0238, std: 1.3359
  Model pred mean: 0.0186, std: 0.8125
  Sigmas: [0.12109375]... (timesteps: [121.0])
Steps:  71%|███████▏  | 3571/5000 [13:18:55<4:44:27, 11.94s/it, loss=1.1293, lr=2.29e-06]Steps:  71%|███████▏  | 3571/5000 [13:18:55<4:44:27, 11.94s/it, loss=1.1448, lr=2.29e-06]Steps:  71%|███████▏  | 3572/5000 [13:19:07<4:43:47, 11.92s/it, loss=1.1448, lr=2.29e-06]Steps:  71%|███████▏  | 3572/5000 [13:19:07<4:43:47, 11.92s/it, loss=0.4029, lr=2.29e-06]Steps:  71%|███████▏  | 3573/5000 [13:19:19<4:45:06, 11.99s/it, loss=0.4029, lr=2.29e-06]Steps:  71%|███████▏  | 3573/5000 [13:19:19<4:45:06, 11.99s/it, loss=0.6506, lr=2.28e-06]Steps:  71%|███████▏  | 3574/5000 [13:19:31<4:44:41, 11.98s/it, loss=0.6506, lr=2.28e-06]Steps:  71%|███████▏  | 3574/5000 [13:19:31<4:44:41, 11.98s/it, loss=0.5921, lr=2.28e-06]Steps:  72%|███████▏  | 3575/5000 [13:19:43<4:43:43, 11.95s/it, loss=0.5921, lr=2.28e-06]Steps:  72%|███████▏  | 3575/5000 [13:19:43<4:43:43, 11.95s/it, loss=0.4244, lr=2.28e-06]Steps:  72%|███████▏  | 3576/5000 [13:19:55<4:43:08, 11.93s/it, loss=0.4244, lr=2.28e-06]Steps:  72%|███████▏  | 3576/5000 [13:19:55<4:43:08, 11.93s/it, loss=0.6624, lr=2.27e-06]Steps:  72%|███████▏  | 3577/5000 [13:20:07<4:43:31, 11.95s/it, loss=0.6624, lr=2.27e-06]Steps:  72%|███████▏  | 3577/5000 [13:20:07<4:43:31, 11.95s/it, loss=0.3768, lr=2.27e-06]Steps:  72%|███████▏  | 3578/5000 [13:20:19<4:43:12, 11.95s/it, loss=0.3768, lr=2.27e-06]Steps:  72%|███████▏  | 3578/5000 [13:20:19<4:43:12, 11.95s/it, loss=0.4069, lr=2.27e-06]Steps:  72%|███████▏  | 3579/5000 [13:20:31<4:42:43, 11.94s/it, loss=0.4069, lr=2.27e-06]Steps:  72%|███████▏  | 3579/5000 [13:20:31<4:42:43, 11.94s/it, loss=0.9979, lr=2.27e-06]Steps:  72%|███████▏  | 3580/5000 [13:20:43<4:44:06, 12.00s/it, loss=0.9979, lr=2.27e-06]Steps:  72%|███████▏  | 3580/5000 [13:20:43<4:44:06, 12.00s/it, loss=0.5339, lr=2.26e-06]
[Step 3580] Training Debug Info:
  Loss: 0.377576
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0027, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0028, std: 1.3672
  Model pred mean: 0.0177, std: 1.2266
  Sigmas: [0.921875]... (timesteps: [920.0])

[Step 3580] Training Debug Info:
  Loss: 1.113577
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0092, std: 0.9375
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0068, std: 1.3672
  Model pred mean: 0.0113, std: 0.8711
  Sigmas: [0.11083984375]... (timesteps: [111.0])

[Step 3580] Training Debug Info:
  Loss: 0.604334
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0007, std: 0.9023
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0022, std: 1.3516
  Model pred mean: -0.0134, std: 1.0938
  Sigmas: [0.9765625]... (timesteps: [976.0])

[Step 3580] Training Debug Info:
  Loss: 0.425480
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0098, std: 0.8789
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0084, std: 1.3281
  Model pred mean: 0.0079, std: 1.1562
  Sigmas: [0.7421875]... (timesteps: [742.0])
Steps:  72%|███████▏  | 3581/5000 [13:20:55<4:43:29, 11.99s/it, loss=0.5339, lr=2.26e-06]Steps:  72%|███████▏  | 3581/5000 [13:20:55<4:43:29, 11.99s/it, loss=0.4255, lr=2.26e-06]Steps:  72%|███████▏  | 3582/5000 [13:21:07<4:42:36, 11.96s/it, loss=0.4255, lr=2.26e-06]Steps:  72%|███████▏  | 3582/5000 [13:21:07<4:42:36, 11.96s/it, loss=1.1968, lr=2.26e-06]Steps:  72%|███████▏  | 3583/5000 [13:21:19<4:41:48, 11.93s/it, loss=1.1968, lr=2.26e-06]Steps:  72%|███████▏  | 3583/5000 [13:21:19<4:41:48, 11.93s/it, loss=0.7601, lr=2.25e-06]Steps:  72%|███████▏  | 3584/5000 [13:21:30<4:41:45, 11.94s/it, loss=0.7601, lr=2.25e-06]Steps:  72%|███████▏  | 3584/5000 [13:21:30<4:41:45, 11.94s/it, loss=0.9132, lr=2.25e-06]Steps:  72%|███████▏  | 3585/5000 [13:21:42<4:40:56, 11.91s/it, loss=0.9132, lr=2.25e-06]Steps:  72%|███████▏  | 3585/5000 [13:21:42<4:40:56, 11.91s/it, loss=0.8557, lr=2.25e-06]Steps:  72%|███████▏  | 3586/5000 [13:21:54<4:41:38, 11.95s/it, loss=0.8557, lr=2.25e-06]Steps:  72%|███████▏  | 3586/5000 [13:21:54<4:41:38, 11.95s/it, loss=0.4297, lr=2.24e-06]Steps:  72%|███████▏  | 3587/5000 [13:22:06<4:42:43, 12.01s/it, loss=0.4297, lr=2.24e-06]Steps:  72%|███████▏  | 3587/5000 [13:22:06<4:42:43, 12.01s/it, loss=0.4095, lr=2.24e-06]Steps:  72%|███████▏  | 3588/5000 [13:22:18<4:41:51, 11.98s/it, loss=0.4095, lr=2.24e-06]Steps:  72%|███████▏  | 3588/5000 [13:22:18<4:41:51, 11.98s/it, loss=1.1024, lr=2.24e-06]Steps:  72%|███████▏  | 3589/5000 [13:22:30<4:41:00, 11.95s/it, loss=1.1024, lr=2.24e-06]Steps:  72%|███████▏  | 3589/5000 [13:22:30<4:41:00, 11.95s/it, loss=0.4269, lr=2.24e-06]Steps:  72%|███████▏  | 3590/5000 [13:22:42<4:40:47, 11.95s/it, loss=0.4269, lr=2.24e-06]Steps:  72%|███████▏  | 3590/5000 [13:22:42<4:40:47, 11.95s/it, loss=0.6653, lr=2.23e-06]
[Step 3590] Training Debug Info:
  Loss: 0.989473
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0170, std: 0.9258
  Noise mean: 0.0010, std: 0.9961
  Target mean: -0.0159, std: 1.3594
  Model pred mean: -0.0156, std: 0.9297
  Sigmas: [0.298828125]... (timesteps: [299.0])

[Step 3590] Training Debug Info:
  Loss: 0.852894
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0182, std: 0.9297
  Noise mean: 0.0007, std: 0.9961
  Target mean: -0.0175, std: 1.3672
  Model pred mean: -0.0175, std: 1.0078
  Sigmas: [0.41015625]... (timesteps: [410.0])

[Step 3590] Training Debug Info:
  Loss: 0.450755
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0583, std: 0.9414
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0581, std: 1.3750
  Model pred mean: -0.0588, std: 1.1953
  Sigmas: [0.56640625]... (timesteps: [567.0])

[Step 3590] Training Debug Info:
  Loss: 0.450795
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0130, std: 0.8984
  Noise mean: 0.0004, std: 0.9961
  Target mean: -0.0126, std: 1.3438
  Model pred mean: -0.0117, std: 1.1641
  Sigmas: [0.71484375]... (timesteps: [713.0])
Steps:  72%|███████▏  | 3591/5000 [13:22:54<4:40:54, 11.96s/it, loss=0.6653, lr=2.23e-06]Steps:  72%|███████▏  | 3591/5000 [13:22:54<4:40:54, 11.96s/it, loss=0.4508, lr=2.23e-06]Steps:  72%|███████▏  | 3592/5000 [13:23:06<4:40:53, 11.97s/it, loss=0.4508, lr=2.23e-06]Steps:  72%|███████▏  | 3592/5000 [13:23:06<4:40:53, 11.97s/it, loss=1.0025, lr=2.23e-06]Steps:  72%|███████▏  | 3593/5000 [13:23:18<4:40:43, 11.97s/it, loss=1.0025, lr=2.23e-06]Steps:  72%|███████▏  | 3593/5000 [13:23:18<4:40:43, 11.97s/it, loss=0.3800, lr=2.22e-06]Steps:  72%|███████▏  | 3594/5000 [13:23:30<4:41:44, 12.02s/it, loss=0.3800, lr=2.22e-06]Steps:  72%|███████▏  | 3594/5000 [13:23:30<4:41:44, 12.02s/it, loss=0.4077, lr=2.22e-06]Steps:  72%|███████▏  | 3595/5000 [13:23:42<4:41:18, 12.01s/it, loss=0.4077, lr=2.22e-06]Steps:  72%|███████▏  | 3595/5000 [13:23:42<4:41:18, 12.01s/it, loss=1.0969, lr=2.22e-06]Steps:  72%|███████▏  | 3596/5000 [13:23:54<4:40:56, 12.01s/it, loss=1.0969, lr=2.22e-06]Steps:  72%|███████▏  | 3596/5000 [13:23:54<4:40:56, 12.01s/it, loss=0.4576, lr=2.22e-06]Steps:  72%|███████▏  | 3597/5000 [13:24:06<4:40:29, 12.00s/it, loss=0.4576, lr=2.22e-06]Steps:  72%|███████▏  | 3597/5000 [13:24:06<4:40:29, 12.00s/it, loss=0.4902, lr=2.21e-06]Steps:  72%|███████▏  | 3598/5000 [13:24:18<4:39:36, 11.97s/it, loss=0.4902, lr=2.21e-06]Steps:  72%|███████▏  | 3598/5000 [13:24:18<4:39:36, 11.97s/it, loss=0.3866, lr=2.21e-06]Steps:  72%|███████▏  | 3599/5000 [13:24:30<4:38:51, 11.94s/it, loss=0.3866, lr=2.21e-06]Steps:  72%|███████▏  | 3599/5000 [13:24:30<4:38:51, 11.94s/it, loss=1.0339, lr=2.21e-06]Steps:  72%|███████▏  | 3600/5000 [13:24:42<4:40:19, 12.01s/it, loss=1.0339, lr=2.21e-06]Steps:  72%|███████▏  | 3600/5000 [13:24:42<4:40:19, 12.01s/it, loss=1.0111, lr=2.20e-06]01/22/2026 21:10:29 - INFO - __main__ - 
[Step 3600] ✅ Loss in normal range (1.0111)
01/22/2026 21:10:29 - INFO - __main__ -   Loss avg (last 100): 0.7532
01/22/2026 21:10:29 - INFO - __main__ -   Loss range: [0.3488, 1.2126]
01/22/2026 21:10:29 - INFO - __main__ - 
🔍 Running validation at step 3600...
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3600 (parquet mode)...
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3600...
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 21:10:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 21:10:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 21:10:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.36it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.41it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.43it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.43it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.43it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.45it/s]
01/22/2026 21:11:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 21:11:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 21:11:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 21:11:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 21:11:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 21:11:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 21:12:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 21:12:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 21:12:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 21:12:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.37it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.37it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:12:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 21:12:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:13:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 21:13:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.41it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.38it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:13:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 21:13:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 21:13:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 21:13:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.48it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.45it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.43it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 21:14:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 21:14:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.47it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.44it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.43it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 21:14:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600/step003600_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 21:14:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 21:14:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 21:14:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003600
01/22/2026 21:14:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 3600] Training Debug Info:
  Loss: 0.858984
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0461, std: 0.9727
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0469, std: 1.3984
  Model pred mean: -0.0461, std: 1.0469
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 3600] Training Debug Info:
  Loss: 0.323437
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0075, std: 0.9375
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0078, std: 1.3750
  Model pred mean: 0.0103, std: 1.2500
  Sigmas: [0.8203125]... (timesteps: [819.0])

[Step 3600] Training Debug Info:
  Loss: 1.090619
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0234, std: 0.9688
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0195, std: 1.3906
  Model pred mean: -0.0209, std: 0.9258
  Sigmas: [0.1728515625]... (timesteps: [173.0])

[Step 3600] Training Debug Info:
  Loss: 0.394292
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0250, std: 0.9219
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0270, std: 1.3594
  Model pred mean: -0.0220, std: 1.2109
  Sigmas: [0.73828125]... (timesteps: [739.0])
Steps:  72%|███████▏  | 3601/5000 [13:29:15<35:03:38, 90.22s/it, loss=1.0111, lr=2.20e-06]Steps:  72%|███████▏  | 3601/5000 [13:29:15<35:03:38, 90.22s/it, loss=0.3943, lr=2.20e-06]Steps:  72%|███████▏  | 3602/5000 [13:29:27<25:54:54, 66.73s/it, loss=0.3943, lr=2.20e-06]Steps:  72%|███████▏  | 3602/5000 [13:29:27<25:54:54, 66.73s/it, loss=0.8017, lr=2.20e-06]Steps:  72%|███████▏  | 3603/5000 [13:29:39<19:30:43, 50.28s/it, loss=0.8017, lr=2.20e-06]Steps:  72%|███████▏  | 3603/5000 [13:29:39<19:30:43, 50.28s/it, loss=0.9148, lr=2.20e-06]Steps:  72%|███████▏  | 3604/5000 [13:29:51<15:02:07, 38.77s/it, loss=0.9148, lr=2.20e-06]Steps:  72%|███████▏  | 3604/5000 [13:29:51<15:02:07, 38.77s/it, loss=0.8587, lr=2.19e-06]Steps:  72%|███████▏  | 3605/5000 [13:30:03<11:54:17, 30.72s/it, loss=0.8587, lr=2.19e-06]Steps:  72%|███████▏  | 3605/5000 [13:30:03<11:54:17, 30.72s/it, loss=0.4326, lr=2.19e-06]Steps:  72%|███████▏  | 3606/5000 [13:30:15<9:42:47, 25.08s/it, loss=0.4326, lr=2.19e-06] Steps:  72%|███████▏  | 3606/5000 [13:30:15<9:42:47, 25.08s/it, loss=1.0433, lr=2.19e-06]Steps:  72%|███████▏  | 3607/5000 [13:30:27<8:12:38, 21.22s/it, loss=1.0433, lr=2.19e-06]Steps:  72%|███████▏  | 3607/5000 [13:30:27<8:12:38, 21.22s/it, loss=0.6534, lr=2.18e-06]Steps:  72%|███████▏  | 3608/5000 [13:30:39<7:07:22, 18.42s/it, loss=0.6534, lr=2.18e-06]Steps:  72%|███████▏  | 3608/5000 [13:30:39<7:07:22, 18.42s/it, loss=1.1113, lr=2.18e-06]Steps:  72%|███████▏  | 3609/5000 [13:30:51<6:22:23, 16.49s/it, loss=1.1113, lr=2.18e-06]Steps:  72%|███████▏  | 3609/5000 [13:30:51<6:22:23, 16.49s/it, loss=0.6579, lr=2.18e-06]Steps:  72%|███████▏  | 3610/5000 [13:31:03<5:50:44, 15.14s/it, loss=0.6579, lr=2.18e-06]Steps:  72%|███████▏  | 3610/5000 [13:31:03<5:50:44, 15.14s/it, loss=0.4795, lr=2.18e-06]
[Step 3610] Training Debug Info:
  Loss: 1.036778
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0109, std: 0.9844
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0099, std: 1.3984
  Model pred mean: -0.0123, std: 0.9648
  Sigmas: [0.3203125]... (timesteps: [320.0])

[Step 3610] Training Debug Info:
  Loss: 0.522385
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0298, std: 0.9062
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0325, std: 1.3516
  Model pred mean: -0.0269, std: 1.1406
  Sigmas: [0.56640625]... (timesteps: [567.0])

[Step 3610] Training Debug Info:
  Loss: 0.576461
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0240, std: 0.8945
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0234, std: 1.3438
  Model pred mean: 0.0237, std: 1.1016
  Sigmas: [0.6171875]... (timesteps: [618.0])

[Step 3610] Training Debug Info:
  Loss: 1.174558
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0020, std: 0.8906
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0032, std: 1.3359
  Model pred mean: 0.0034, std: 0.7852
  Sigmas: [0.2001953125]... (timesteps: [200.0])
Steps:  72%|███████▏  | 3611/5000 [13:31:14<5:27:28, 14.15s/it, loss=0.4795, lr=2.18e-06]Steps:  72%|███████▏  | 3611/5000 [13:31:14<5:27:28, 14.15s/it, loss=1.1746, lr=2.17e-06]Steps:  72%|███████▏  | 3612/5000 [13:31:26<5:12:05, 13.49s/it, loss=1.1746, lr=2.17e-06]Steps:  72%|███████▏  | 3612/5000 [13:31:26<5:12:05, 13.49s/it, loss=1.1133, lr=2.17e-06]Steps:  72%|███████▏  | 3613/5000 [13:31:38<5:00:40, 13.01s/it, loss=1.1133, lr=2.17e-06]Steps:  72%|███████▏  | 3613/5000 [13:31:38<5:00:40, 13.01s/it, loss=1.0927, lr=2.17e-06]Steps:  72%|███████▏  | 3614/5000 [13:31:51<4:54:56, 12.77s/it, loss=1.0927, lr=2.17e-06]Steps:  72%|███████▏  | 3614/5000 [13:31:51<4:54:56, 12.77s/it, loss=0.9464, lr=2.16e-06]Steps:  72%|███████▏  | 3615/5000 [13:32:02<4:48:59, 12.52s/it, loss=0.9464, lr=2.16e-06]Steps:  72%|███████▏  | 3615/5000 [13:32:02<4:48:59, 12.52s/it, loss=1.0434, lr=2.16e-06]Steps:  72%|███████▏  | 3616/5000 [13:32:14<4:44:29, 12.33s/it, loss=1.0434, lr=2.16e-06]Steps:  72%|███████▏  | 3616/5000 [13:32:14<4:44:29, 12.33s/it, loss=0.4036, lr=2.16e-06]Steps:  72%|███████▏  | 3617/5000 [13:32:26<4:40:56, 12.19s/it, loss=0.4036, lr=2.16e-06]Steps:  72%|███████▏  | 3617/5000 [13:32:26<4:40:56, 12.19s/it, loss=0.7223, lr=2.16e-06]Steps:  72%|███████▏  | 3618/5000 [13:32:38<4:39:00, 12.11s/it, loss=0.7223, lr=2.16e-06]Steps:  72%|███████▏  | 3618/5000 [13:32:38<4:39:00, 12.11s/it, loss=0.4105, lr=2.15e-06]Steps:  72%|███████▏  | 3619/5000 [13:32:50<4:37:37, 12.06s/it, loss=0.4105, lr=2.15e-06]Steps:  72%|███████▏  | 3619/5000 [13:32:50<4:37:37, 12.06s/it, loss=1.1763, lr=2.15e-06]Steps:  72%|███████▏  | 3620/5000 [13:33:02<4:36:41, 12.03s/it, loss=1.1763, lr=2.15e-06]Steps:  72%|███████▏  | 3620/5000 [13:33:02<4:36:41, 12.03s/it, loss=1.1645, lr=2.15e-06]
[Step 3620] Training Debug Info:
  Loss: 0.853982
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0493, std: 0.9336
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0471, std: 1.3672
  Model pred mean: -0.0493, std: 1.0078
  Sigmas: [0.341796875]... (timesteps: [342.0])

[Step 3620] Training Debug Info:
  Loss: 0.804976
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0170, std: 0.9023
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0179, std: 1.3438
  Model pred mean: -0.0178, std: 1.0078
  Sigmas: [0.4296875]... (timesteps: [430.0])

[Step 3620] Training Debug Info:
  Loss: 0.454904
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0131, std: 0.9336
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0117, std: 1.3672
  Model pred mean: -0.0170, std: 1.1953
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 3620] Training Debug Info:
  Loss: 0.522466
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0055, std: 0.8828
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0068, std: 1.3281
  Model pred mean: 0.0032, std: 1.1172
  Sigmas: [0.9765625]... (timesteps: [975.0])
Steps:  72%|███████▏  | 3621/5000 [13:33:14<4:37:29, 12.07s/it, loss=1.1645, lr=2.15e-06]Steps:  72%|███████▏  | 3621/5000 [13:33:14<4:37:29, 12.07s/it, loss=0.5225, lr=2.14e-06]Steps:  72%|███████▏  | 3622/5000 [13:33:26<4:35:54, 12.01s/it, loss=0.5225, lr=2.14e-06]Steps:  72%|███████▏  | 3622/5000 [13:33:26<4:35:54, 12.01s/it, loss=0.4522, lr=2.14e-06]Steps:  72%|███████▏  | 3623/5000 [13:33:38<4:34:55, 11.98s/it, loss=0.4522, lr=2.14e-06]Steps:  72%|███████▏  | 3623/5000 [13:33:38<4:34:55, 11.98s/it, loss=0.5185, lr=2.14e-06]Steps:  72%|███████▏  | 3624/5000 [13:33:50<4:35:15, 12.00s/it, loss=0.5185, lr=2.14e-06]Steps:  72%|███████▏  | 3624/5000 [13:33:50<4:35:15, 12.00s/it, loss=0.6354, lr=2.13e-06]Steps:  72%|███████▎  | 3625/5000 [13:34:02<4:34:10, 11.96s/it, loss=0.6354, lr=2.13e-06]Steps:  72%|███████▎  | 3625/5000 [13:34:02<4:34:10, 11.96s/it, loss=0.4974, lr=2.13e-06]Steps:  73%|███████▎  | 3626/5000 [13:34:14<4:33:25, 11.94s/it, loss=0.4974, lr=2.13e-06]Steps:  73%|███████▎  | 3626/5000 [13:34:14<4:33:25, 11.94s/it, loss=1.1531, lr=2.13e-06]Steps:  73%|███████▎  | 3627/5000 [13:34:26<4:34:49, 12.01s/it, loss=1.1531, lr=2.13e-06]Steps:  73%|███████▎  | 3627/5000 [13:34:26<4:34:49, 12.01s/it, loss=0.3572, lr=2.13e-06]Steps:  73%|███████▎  | 3628/5000 [13:34:38<4:33:37, 11.97s/it, loss=0.3572, lr=2.13e-06]Steps:  73%|███████▎  | 3628/5000 [13:34:38<4:33:37, 11.97s/it, loss=0.9740, lr=2.12e-06]Steps:  73%|███████▎  | 3629/5000 [13:34:50<4:33:17, 11.96s/it, loss=0.9740, lr=2.12e-06]Steps:  73%|███████▎  | 3629/5000 [13:34:50<4:33:17, 11.96s/it, loss=0.3471, lr=2.12e-06]Steps:  73%|███████▎  | 3630/5000 [13:35:02<4:32:58, 11.95s/it, loss=0.3471, lr=2.12e-06]Steps:  73%|███████▎  | 3630/5000 [13:35:02<4:32:58, 11.95s/it, loss=0.3828, lr=2.12e-06]
[Step 3630] Training Debug Info:
  Loss: 0.831004
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0214, std: 0.8398
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0240, std: 1.3047
  Model pred mean: 0.0215, std: 0.9336
  Sigmas: [0.4921875]... (timesteps: [492.0])

[Step 3630] Training Debug Info:
  Loss: 1.011564
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0057, std: 0.8984
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0046, std: 1.3438
  Model pred mean: -0.0060, std: 0.8906
  Sigmas: [0.349609375]... (timesteps: [349.0])

[Step 3630] Training Debug Info:
  Loss: 0.420464
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0073, std: 0.9062
  Noise mean: 0.0042, std: 0.9961
  Target mean: -0.0031, std: 1.3516
  Model pred mean: -0.0032, std: 1.1875
  Sigmas: [0.8984375]... (timesteps: [898.0])

[Step 3630] Training Debug Info:
  Loss: 0.792809
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0435, std: 0.9062
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0449, std: 1.3516
  Model pred mean: -0.0442, std: 1.0156
  Sigmas: [0.34765625]... (timesteps: [347.0])
Steps:  73%|███████▎  | 3631/5000 [13:35:14<4:32:15, 11.93s/it, loss=0.3828, lr=2.12e-06]Steps:  73%|███████▎  | 3631/5000 [13:35:14<4:32:15, 11.93s/it, loss=0.7928, lr=2.11e-06]Steps:  73%|███████▎  | 3632/5000 [13:35:25<4:31:34, 11.91s/it, loss=0.7928, lr=2.11e-06]Steps:  73%|███████▎  | 3632/5000 [13:35:25<4:31:34, 11.91s/it, loss=0.4802, lr=2.11e-06]Steps:  73%|███████▎  | 3633/5000 [13:35:38<4:33:04, 11.99s/it, loss=0.4802, lr=2.11e-06]Steps:  73%|███████▎  | 3633/5000 [13:35:38<4:33:04, 11.99s/it, loss=1.0063, lr=2.11e-06]Steps:  73%|███████▎  | 3634/5000 [13:35:50<4:33:59, 12.04s/it, loss=1.0063, lr=2.11e-06]Steps:  73%|███████▎  | 3634/5000 [13:35:50<4:33:59, 12.04s/it, loss=0.3612, lr=2.11e-06]Steps:  73%|███████▎  | 3635/5000 [13:36:02<4:32:45, 11.99s/it, loss=0.3612, lr=2.11e-06]Steps:  73%|███████▎  | 3635/5000 [13:36:02<4:32:45, 11.99s/it, loss=0.8135, lr=2.10e-06]Steps:  73%|███████▎  | 3636/5000 [13:36:14<4:32:10, 11.97s/it, loss=0.8135, lr=2.10e-06]Steps:  73%|███████▎  | 3636/5000 [13:36:14<4:32:10, 11.97s/it, loss=0.8785, lr=2.10e-06]Steps:  73%|███████▎  | 3637/5000 [13:36:26<4:31:41, 11.96s/it, loss=0.8785, lr=2.10e-06]Steps:  73%|███████▎  | 3637/5000 [13:36:26<4:31:41, 11.96s/it, loss=1.0982, lr=2.10e-06]Steps:  73%|███████▎  | 3638/5000 [13:36:37<4:30:47, 11.93s/it, loss=1.0982, lr=2.10e-06]Steps:  73%|███████▎  | 3638/5000 [13:36:37<4:30:47, 11.93s/it, loss=0.6198, lr=2.10e-06]Steps:  73%|███████▎  | 3639/5000 [13:36:49<4:30:51, 11.94s/it, loss=0.6198, lr=2.10e-06]Steps:  73%|███████▎  | 3639/5000 [13:36:49<4:30:51, 11.94s/it, loss=0.9594, lr=2.09e-06]Steps:  73%|███████▎  | 3640/5000 [13:37:01<4:30:37, 11.94s/it, loss=0.9594, lr=2.09e-06]Steps:  73%|███████▎  | 3640/5000 [13:37:01<4:30:37, 11.94s/it, loss=1.0382, lr=2.09e-06]
[Step 3640] Training Debug Info:
  Loss: 1.046647
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0150, std: 0.9141
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0123, std: 1.3516
  Model pred mean: 0.0157, std: 0.8906
  Sigmas: [0.032958984375]... (timesteps: [33.0])

[Step 3640] Training Debug Info:
  Loss: 0.876005
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0105, std: 0.9531
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0117, std: 1.3828
  Model pred mean: -0.0122, std: 1.0156
  Sigmas: [0.462890625]... (timesteps: [463.0])

[Step 3640] Training Debug Info:
  Loss: 0.534248
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0236, std: 0.9023
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0233, std: 1.3438
  Model pred mean: -0.0229, std: 1.1250
  Sigmas: [0.62890625]... (timesteps: [628.0])

[Step 3640] Training Debug Info:
  Loss: 0.686684
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0130, std: 0.9609
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0118, std: 1.3828
  Model pred mean: 0.0061, std: 1.1016
  Sigmas: [0.9609375]... (timesteps: [962.0])
Steps:  73%|███████▎  | 3641/5000 [13:37:14<4:32:46, 12.04s/it, loss=1.0382, lr=2.09e-06]Steps:  73%|███████▎  | 3641/5000 [13:37:14<4:32:46, 12.04s/it, loss=0.6867, lr=2.09e-06]Steps:  73%|███████▎  | 3642/5000 [13:37:25<4:31:34, 12.00s/it, loss=0.6867, lr=2.09e-06]Steps:  73%|███████▎  | 3642/5000 [13:37:25<4:31:34, 12.00s/it, loss=0.4570, lr=2.08e-06]Steps:  73%|███████▎  | 3643/5000 [13:37:37<4:30:36, 11.96s/it, loss=0.4570, lr=2.08e-06]Steps:  73%|███████▎  | 3643/5000 [13:37:37<4:30:36, 11.96s/it, loss=0.4189, lr=2.08e-06]Steps:  73%|███████▎  | 3644/5000 [13:37:49<4:30:19, 11.96s/it, loss=0.4189, lr=2.08e-06]Steps:  73%|███████▎  | 3644/5000 [13:37:49<4:30:19, 11.96s/it, loss=0.5061, lr=2.08e-06]Steps:  73%|███████▎  | 3645/5000 [13:38:01<4:29:40, 11.94s/it, loss=0.5061, lr=2.08e-06]Steps:  73%|███████▎  | 3645/5000 [13:38:01<4:29:40, 11.94s/it, loss=0.4524, lr=2.08e-06]Steps:  73%|███████▎  | 3646/5000 [13:38:13<4:29:49, 11.96s/it, loss=0.4524, lr=2.08e-06]Steps:  73%|███████▎  | 3646/5000 [13:38:13<4:29:49, 11.96s/it, loss=0.8304, lr=2.07e-06]Steps:  73%|███████▎  | 3647/5000 [13:38:25<4:28:59, 11.93s/it, loss=0.8304, lr=2.07e-06]Steps:  73%|███████▎  | 3647/5000 [13:38:25<4:28:59, 11.93s/it, loss=0.5100, lr=2.07e-06]Steps:  73%|███████▎  | 3648/5000 [13:38:37<4:30:51, 12.02s/it, loss=0.5100, lr=2.07e-06]Steps:  73%|███████▎  | 3648/5000 [13:38:37<4:30:51, 12.02s/it, loss=0.4257, lr=2.07e-06]Steps:  73%|███████▎  | 3649/5000 [13:38:49<4:30:00, 11.99s/it, loss=0.4257, lr=2.07e-06]Steps:  73%|███████▎  | 3649/5000 [13:38:49<4:30:00, 11.99s/it, loss=0.4425, lr=2.06e-06]Steps:  73%|███████▎  | 3650/5000 [13:39:01<4:28:53, 11.95s/it, loss=0.4425, lr=2.06e-06]Steps:  73%|███████▎  | 3650/5000 [13:39:01<4:28:53, 11.95s/it, loss=1.0266, lr=2.06e-06]
[Step 3650] Training Debug Info:
  Loss: 0.469941
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0052, std: 0.9297
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0068, std: 1.3672
  Model pred mean: -0.0046, std: 1.1797
  Sigmas: [0.67578125]... (timesteps: [676.0])

[Step 3650] Training Debug Info:
  Loss: 0.917069
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0240, std: 0.9219
  Noise mean: 0.0062, std: 1.0000
  Target mean: 0.0303, std: 1.3594
  Model pred mean: 0.0228, std: 0.9609
  Sigmas: [0.373046875]... (timesteps: [374.0])

[Step 3650] Training Debug Info:
  Loss: 0.448858
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0072, std: 0.8672
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0070, std: 1.3203
  Model pred mean: -0.0093, std: 1.1406
  Sigmas: [0.734375]... (timesteps: [736.0])

[Step 3650] Training Debug Info:
  Loss: 0.685488
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0091, std: 0.9336
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0118, std: 1.3672
  Model pred mean: 0.0067, std: 1.0859
  Sigmas: [0.48828125]... (timesteps: [488.0])
Steps:  73%|███████▎  | 3651/5000 [13:39:13<4:28:26, 11.94s/it, loss=1.0266, lr=2.06e-06]Steps:  73%|███████▎  | 3651/5000 [13:39:13<4:28:26, 11.94s/it, loss=0.6855, lr=2.06e-06]Steps:  73%|███████▎  | 3652/5000 [13:39:25<4:27:38, 11.91s/it, loss=0.6855, lr=2.06e-06]Steps:  73%|███████▎  | 3652/5000 [13:39:25<4:27:38, 11.91s/it, loss=1.0866, lr=2.06e-06]Steps:  73%|███████▎  | 3653/5000 [13:39:37<4:27:39, 11.92s/it, loss=1.0866, lr=2.06e-06]Steps:  73%|███████▎  | 3653/5000 [13:39:37<4:27:39, 11.92s/it, loss=1.1343, lr=2.05e-06]Steps:  73%|███████▎  | 3654/5000 [13:39:49<4:28:30, 11.97s/it, loss=1.1343, lr=2.05e-06]Steps:  73%|███████▎  | 3654/5000 [13:39:49<4:28:30, 11.97s/it, loss=1.0937, lr=2.05e-06]Steps:  73%|███████▎  | 3655/5000 [13:40:01<4:28:02, 11.96s/it, loss=1.0937, lr=2.05e-06]Steps:  73%|███████▎  | 3655/5000 [13:40:01<4:28:02, 11.96s/it, loss=0.4603, lr=2.05e-06]Steps:  73%|███████▎  | 3656/5000 [13:40:13<4:28:45, 12.00s/it, loss=0.4603, lr=2.05e-06]Steps:  73%|███████▎  | 3656/5000 [13:40:13<4:28:45, 12.00s/it, loss=0.4251, lr=2.04e-06]Steps:  73%|███████▎  | 3657/5000 [13:40:25<4:28:09, 11.98s/it, loss=0.4251, lr=2.04e-06]Steps:  73%|███████▎  | 3657/5000 [13:40:25<4:28:09, 11.98s/it, loss=1.0166, lr=2.04e-06]Steps:  73%|███████▎  | 3658/5000 [13:40:37<4:27:14, 11.95s/it, loss=1.0166, lr=2.04e-06]Steps:  73%|███████▎  | 3658/5000 [13:40:37<4:27:14, 11.95s/it, loss=0.9324, lr=2.04e-06]Steps:  73%|███████▎  | 3659/5000 [13:40:49<4:26:39, 11.93s/it, loss=0.9324, lr=2.04e-06]Steps:  73%|███████▎  | 3659/5000 [13:40:49<4:26:39, 11.93s/it, loss=0.4573, lr=2.04e-06]Steps:  73%|███████▎  | 3660/5000 [13:41:00<4:26:03, 11.91s/it, loss=0.4573, lr=2.04e-06]Steps:  73%|███████▎  | 3660/5000 [13:41:00<4:26:03, 11.91s/it, loss=0.7781, lr=2.03e-06]
[Step 3660] Training Debug Info:
  Loss: 0.597306
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0542, std: 0.9023
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0518, std: 1.3438
  Model pred mean: -0.0535, std: 1.1016
  Sigmas: [0.515625]... (timesteps: [517.0])

[Step 3660] Training Debug Info:
  Loss: 0.475139
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0557, std: 0.9414
  Noise mean: 0.0006, std: 0.9961
  Target mean: -0.0552, std: 1.3672
  Model pred mean: -0.0381, std: 1.1719
  Sigmas: [0.91796875]... (timesteps: [917.0])

[Step 3660] Training Debug Info:
  Loss: 1.115510
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0117, std: 0.8750
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0121, std: 1.3359
  Model pred mean: 0.0135, std: 0.8125
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 3660] Training Debug Info:
  Loss: 0.351768
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0603, std: 0.9570
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0625, std: 1.3828
  Model pred mean: -0.0618, std: 1.2500
  Sigmas: [0.79296875]... (timesteps: [793.0])
Steps:  73%|███████▎  | 3661/5000 [13:41:13<4:27:05, 11.97s/it, loss=0.7781, lr=2.03e-06]Steps:  73%|███████▎  | 3661/5000 [13:41:13<4:27:05, 11.97s/it, loss=0.3518, lr=2.03e-06]Steps:  73%|███████▎  | 3662/5000 [13:41:25<4:27:12, 11.98s/it, loss=0.3518, lr=2.03e-06]Steps:  73%|███████▎  | 3662/5000 [13:41:25<4:27:12, 11.98s/it, loss=0.3623, lr=2.03e-06]Steps:  73%|███████▎  | 3663/5000 [13:41:37<4:28:26, 12.05s/it, loss=0.3623, lr=2.03e-06]Steps:  73%|███████▎  | 3663/5000 [13:41:37<4:28:26, 12.05s/it, loss=0.7653, lr=2.02e-06]Steps:  73%|███████▎  | 3664/5000 [13:41:49<4:27:08, 12.00s/it, loss=0.7653, lr=2.02e-06]Steps:  73%|███████▎  | 3664/5000 [13:41:49<4:27:08, 12.00s/it, loss=0.5811, lr=2.02e-06]Steps:  73%|███████▎  | 3665/5000 [13:42:01<4:26:39, 11.98s/it, loss=0.5811, lr=2.02e-06]Steps:  73%|███████▎  | 3665/5000 [13:42:01<4:26:39, 11.98s/it, loss=0.3825, lr=2.02e-06]Steps:  73%|███████▎  | 3666/5000 [13:42:12<4:25:55, 11.96s/it, loss=0.3825, lr=2.02e-06]Steps:  73%|███████▎  | 3666/5000 [13:42:12<4:25:55, 11.96s/it, loss=1.0286, lr=2.02e-06]Steps:  73%|███████▎  | 3667/5000 [13:42:24<4:25:08, 11.93s/it, loss=1.0286, lr=2.02e-06]Steps:  73%|███████▎  | 3667/5000 [13:42:24<4:25:08, 11.93s/it, loss=0.8607, lr=2.01e-06]Steps:  73%|███████▎  | 3668/5000 [13:42:37<4:26:16, 11.99s/it, loss=0.8607, lr=2.01e-06]Steps:  73%|███████▎  | 3668/5000 [13:42:37<4:26:16, 11.99s/it, loss=1.0868, lr=2.01e-06]Steps:  73%|███████▎  | 3669/5000 [13:42:48<4:25:54, 11.99s/it, loss=1.0868, lr=2.01e-06]Steps:  73%|███████▎  | 3669/5000 [13:42:48<4:25:54, 11.99s/it, loss=0.7534, lr=2.01e-06]Steps:  73%|███████▎  | 3670/5000 [13:43:01<4:26:58, 12.04s/it, loss=0.7534, lr=2.01e-06]Steps:  73%|███████▎  | 3670/5000 [13:43:01<4:26:58, 12.04s/it, loss=0.5980, lr=2.00e-06]
[Step 3670] Training Debug Info:
  Loss: 0.999246
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0347, std: 0.9141
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0344, std: 1.3516
  Model pred mean: 0.0356, std: 0.9180
  Sigmas: [0.37109375]... (timesteps: [371.0])

[Step 3670] Training Debug Info:
  Loss: 0.754133
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0398, std: 0.9453
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0396, std: 1.3750
  Model pred mean: 0.0408, std: 1.0703
  Sigmas: [0.451171875]... (timesteps: [451.0])

[Step 3670] Training Debug Info:
  Loss: 0.399831
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0178, std: 0.9375
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0193, std: 1.3750
  Model pred mean: -0.0199, std: 1.2188
  Sigmas: [0.734375]... (timesteps: [734.0])

[Step 3670] Training Debug Info:
  Loss: 1.074467
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0220, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0221, std: 1.3672
  Model pred mean: -0.0216, std: 0.8945
  Sigmas: [0.244140625]... (timesteps: [244.0])
Steps:  73%|███████▎  | 3671/5000 [13:43:13<4:26:09, 12.02s/it, loss=0.5980, lr=2.00e-06]Steps:  73%|███████▎  | 3671/5000 [13:43:13<4:26:09, 12.02s/it, loss=1.0745, lr=2.00e-06]Steps:  73%|███████▎  | 3672/5000 [13:43:25<4:25:30, 12.00s/it, loss=1.0745, lr=2.00e-06]Steps:  73%|███████▎  | 3672/5000 [13:43:25<4:25:30, 12.00s/it, loss=0.7220, lr=2.00e-06]Steps:  73%|███████▎  | 3673/5000 [13:43:37<4:25:09, 11.99s/it, loss=0.7220, lr=2.00e-06]Steps:  73%|███████▎  | 3673/5000 [13:43:37<4:25:09, 11.99s/it, loss=1.0786, lr=2.00e-06]Steps:  73%|███████▎  | 3674/5000 [13:43:48<4:24:24, 11.96s/it, loss=1.0786, lr=2.00e-06]Steps:  73%|███████▎  | 3674/5000 [13:43:48<4:24:24, 11.96s/it, loss=0.6111, lr=1.99e-06]Steps:  74%|███████▎  | 3675/5000 [13:44:01<4:25:28, 12.02s/it, loss=0.6111, lr=1.99e-06]Steps:  74%|███████▎  | 3675/5000 [13:44:01<4:25:28, 12.02s/it, loss=0.7028, lr=1.99e-06]Steps:  74%|███████▎  | 3676/5000 [13:44:13<4:24:41, 11.99s/it, loss=0.7028, lr=1.99e-06]Steps:  74%|███████▎  | 3676/5000 [13:44:13<4:24:41, 11.99s/it, loss=0.3474, lr=1.99e-06]Steps:  74%|███████▎  | 3677/5000 [13:44:24<4:24:17, 11.99s/it, loss=0.3474, lr=1.99e-06]Steps:  74%|███████▎  | 3677/5000 [13:44:24<4:24:17, 11.99s/it, loss=1.0879, lr=1.99e-06]Steps:  74%|███████▎  | 3678/5000 [13:44:36<4:23:46, 11.97s/it, loss=1.0879, lr=1.99e-06]Steps:  74%|███████▎  | 3678/5000 [13:44:36<4:23:46, 11.97s/it, loss=0.7078, lr=1.98e-06]Steps:  74%|███████▎  | 3679/5000 [13:44:48<4:23:26, 11.97s/it, loss=0.7078, lr=1.98e-06]Steps:  74%|███████▎  | 3679/5000 [13:44:48<4:23:26, 11.97s/it, loss=1.0806, lr=1.98e-06]Steps:  74%|███████▎  | 3680/5000 [13:45:00<4:22:32, 11.93s/it, loss=1.0806, lr=1.98e-06]Steps:  74%|███████▎  | 3680/5000 [13:45:00<4:22:32, 11.93s/it, loss=0.9170, lr=1.98e-06]
[Step 3680] Training Debug Info:
  Loss: 0.547285
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0084, std: 0.9375
  Noise mean: 0.0000, std: 0.9961
  Target mean: 0.0085, std: 1.3672
  Model pred mean: 0.0086, std: 1.1562
  Sigmas: [0.60546875]... (timesteps: [604.0])

[Step 3680] Training Debug Info:
  Loss: 1.143985
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0067, std: 0.8945
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0068, std: 1.3438
  Model pred mean: -0.0075, std: 0.8086
  Sigmas: [0.1376953125]... (timesteps: [138.0])

[Step 3680] Training Debug Info:
  Loss: 0.609727
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0369, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0359, std: 1.3672
  Model pred mean: -0.0325, std: 1.1172
  Sigmas: [0.50390625]... (timesteps: [503.0000305175781])

[Step 3680] Training Debug Info:
  Loss: 1.158073
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0020, std: 0.9062
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0055, std: 1.3516
  Model pred mean: -0.0038, std: 0.8164
  Sigmas: [0.1962890625]... (timesteps: [196.0])
Steps:  74%|███████▎  | 3681/5000 [13:45:12<4:24:12, 12.02s/it, loss=0.9170, lr=1.98e-06]Steps:  74%|███████▎  | 3681/5000 [13:45:12<4:24:12, 12.02s/it, loss=1.1581, lr=1.97e-06]Steps:  74%|███████▎  | 3682/5000 [13:45:24<4:23:16, 11.99s/it, loss=1.1581, lr=1.97e-06]Steps:  74%|███████▎  | 3682/5000 [13:45:24<4:23:16, 11.99s/it, loss=0.6044, lr=1.97e-06]Steps:  74%|███████▎  | 3683/5000 [13:45:36<4:22:35, 11.96s/it, loss=0.6044, lr=1.97e-06]Steps:  74%|███████▎  | 3683/5000 [13:45:36<4:22:35, 11.96s/it, loss=1.0852, lr=1.97e-06]Steps:  74%|███████▎  | 3684/5000 [13:45:48<4:22:09, 11.95s/it, loss=1.0852, lr=1.97e-06]Steps:  74%|███████▎  | 3684/5000 [13:45:48<4:22:09, 11.95s/it, loss=0.9915, lr=1.97e-06]Steps:  74%|███████▎  | 3685/5000 [13:46:00<4:21:56, 11.95s/it, loss=0.9915, lr=1.97e-06]Steps:  74%|███████▎  | 3685/5000 [13:46:00<4:21:56, 11.95s/it, loss=0.4313, lr=1.96e-06]Steps:  74%|███████▎  | 3686/5000 [13:46:12<4:22:26, 11.98s/it, loss=0.4313, lr=1.96e-06]Steps:  74%|███████▎  | 3686/5000 [13:46:12<4:22:26, 11.98s/it, loss=0.5744, lr=1.96e-06]Steps:  74%|███████▎  | 3687/5000 [13:46:24<4:21:32, 11.95s/it, loss=0.5744, lr=1.96e-06]Steps:  74%|███████▎  | 3687/5000 [13:46:24<4:21:32, 11.95s/it, loss=1.1027, lr=1.96e-06]Steps:  74%|███████▍  | 3688/5000 [13:46:36<4:23:10, 12.04s/it, loss=1.1027, lr=1.96e-06]Steps:  74%|███████▍  | 3688/5000 [13:46:36<4:23:10, 12.04s/it, loss=0.3838, lr=1.95e-06]Steps:  74%|███████▍  | 3689/5000 [13:46:48<4:21:54, 11.99s/it, loss=0.3838, lr=1.95e-06]Steps:  74%|███████▍  | 3689/5000 [13:46:48<4:21:54, 11.99s/it, loss=0.5029, lr=1.95e-06]Steps:  74%|███████▍  | 3690/5000 [13:47:00<4:21:04, 11.96s/it, loss=0.5029, lr=1.95e-06]Steps:  74%|███████▍  | 3690/5000 [13:47:00<4:21:04, 11.96s/it, loss=0.3597, lr=1.95e-06]
[Step 3690] Training Debug Info:
  Loss: 1.121531
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0049, std: 0.8633
  Noise mean: 0.0043, std: 1.0000
  Target mean: -0.0007, std: 1.3203
  Model pred mean: -0.0026, std: 0.7852
  Sigmas: [0.302734375]... (timesteps: [303.0])

[Step 3690] Training Debug Info:
  Loss: 0.574591
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0206, std: 0.9062
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0200, std: 1.3516
  Model pred mean: 0.0226, std: 1.1172
  Sigmas: [0.6171875]... (timesteps: [618.0])

[Step 3690] Training Debug Info:
  Loss: 0.867782
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0025, std: 0.9727
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0025, std: 1.3984
  Model pred mean: 0.0017, std: 1.0391
  Sigmas: [0.345703125]... (timesteps: [346.0])

[Step 3690] Training Debug Info:
  Loss: 0.585548
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.9102
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0038, std: 1.3516
  Model pred mean: 0.0031, std: 1.1094
  Sigmas: [0.578125]... (timesteps: [580.0])
Steps:  74%|███████▍  | 3691/5000 [13:47:12<4:20:45, 11.95s/it, loss=0.3597, lr=1.95e-06]Steps:  74%|███████▍  | 3691/5000 [13:47:12<4:20:45, 11.95s/it, loss=0.5855, lr=1.95e-06]Steps:  74%|███████▍  | 3692/5000 [13:47:24<4:20:14, 11.94s/it, loss=0.5855, lr=1.95e-06]Steps:  74%|███████▍  | 3692/5000 [13:47:24<4:20:14, 11.94s/it, loss=0.6339, lr=1.94e-06]Steps:  74%|███████▍  | 3693/5000 [13:47:36<4:19:28, 11.91s/it, loss=0.6339, lr=1.94e-06]Steps:  74%|███████▍  | 3693/5000 [13:47:36<4:19:28, 11.91s/it, loss=0.3744, lr=1.94e-06]Steps:  74%|███████▍  | 3694/5000 [13:47:48<4:19:22, 11.92s/it, loss=0.3744, lr=1.94e-06]Steps:  74%|███████▍  | 3694/5000 [13:47:48<4:19:22, 11.92s/it, loss=1.0914, lr=1.94e-06]Steps:  74%|███████▍  | 3695/5000 [13:48:00<4:20:52, 11.99s/it, loss=1.0914, lr=1.94e-06]Steps:  74%|███████▍  | 3695/5000 [13:48:00<4:20:52, 11.99s/it, loss=1.1592, lr=1.94e-06]Steps:  74%|███████▍  | 3696/5000 [13:48:12<4:19:54, 11.96s/it, loss=1.1592, lr=1.94e-06]Steps:  74%|███████▍  | 3696/5000 [13:48:12<4:19:54, 11.96s/it, loss=0.5333, lr=1.93e-06]Steps:  74%|███████▍  | 3697/5000 [13:48:24<4:19:38, 11.96s/it, loss=0.5333, lr=1.93e-06]Steps:  74%|███████▍  | 3697/5000 [13:48:24<4:19:38, 11.96s/it, loss=0.6051, lr=1.93e-06]Steps:  74%|███████▍  | 3698/5000 [13:48:36<4:19:05, 11.94s/it, loss=0.6051, lr=1.93e-06]Steps:  74%|███████▍  | 3698/5000 [13:48:36<4:19:05, 11.94s/it, loss=1.0448, lr=1.93e-06]Steps:  74%|███████▍  | 3699/5000 [13:48:48<4:19:17, 11.96s/it, loss=1.0448, lr=1.93e-06]Steps:  74%|███████▍  | 3699/5000 [13:48:48<4:19:17, 11.96s/it, loss=0.3955, lr=1.92e-06]Steps:  74%|███████▍  | 3700/5000 [13:49:00<4:18:51, 11.95s/it, loss=0.3955, lr=1.92e-06]Steps:  74%|███████▍  | 3700/5000 [13:49:00<4:18:51, 11.95s/it, loss=0.8329, lr=1.92e-06]01/22/2026 21:34:46 - INFO - __main__ - 
[Step 3700] ✅ Loss in normal range (0.8329)
01/22/2026 21:34:46 - INFO - __main__ -   Loss avg (last 100): 0.7386
01/22/2026 21:34:46 - INFO - __main__ -   Loss range: [0.3471, 1.1763]

[Step 3700] Training Debug Info:
  Loss: 0.774412
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0052, std: 0.9102
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0052, std: 1.3516
  Model pred mean: -0.0055, std: 1.0234
  Sigmas: [0.46484375]... (timesteps: [464.0])

[Step 3700] Training Debug Info:
  Loss: 0.498402
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0216, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0211, std: 1.3594
  Model pred mean: -0.0152, std: 1.1562
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 3700] Training Debug Info:
  Loss: 0.877798
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0104, std: 0.8945
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0094, std: 1.3438
  Model pred mean: 0.0091, std: 0.9609
  Sigmas: [0.443359375]... (timesteps: [444.0])

[Step 3700] Training Debug Info:
  Loss: 0.374362
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0250, std: 0.9023
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0236, std: 1.3438
  Model pred mean: -0.0238, std: 1.1953
  Sigmas: [0.8671875]... (timesteps: [868.0])
Steps:  74%|███████▍  | 3701/5000 [13:49:12<4:18:53, 11.96s/it, loss=0.8329, lr=1.92e-06]Steps:  74%|███████▍  | 3701/5000 [13:49:12<4:18:53, 11.96s/it, loss=0.3744, lr=1.92e-06]Steps:  74%|███████▍  | 3702/5000 [13:49:24<4:20:36, 12.05s/it, loss=0.3744, lr=1.92e-06]Steps:  74%|███████▍  | 3702/5000 [13:49:24<4:20:36, 12.05s/it, loss=0.5133, lr=1.92e-06]Steps:  74%|███████▍  | 3703/5000 [13:49:36<4:18:44, 11.97s/it, loss=0.5133, lr=1.92e-06]Steps:  74%|███████▍  | 3703/5000 [13:49:36<4:18:44, 11.97s/it, loss=0.3878, lr=1.91e-06]Steps:  74%|███████▍  | 3704/5000 [13:49:48<4:18:41, 11.98s/it, loss=0.3878, lr=1.91e-06]Steps:  74%|███████▍  | 3704/5000 [13:49:48<4:18:41, 11.98s/it, loss=1.1389, lr=1.91e-06]Steps:  74%|███████▍  | 3705/5000 [13:49:59<4:18:08, 11.96s/it, loss=1.1389, lr=1.91e-06]Steps:  74%|███████▍  | 3705/5000 [13:49:59<4:18:08, 11.96s/it, loss=0.5169, lr=1.91e-06]Steps:  74%|███████▍  | 3706/5000 [13:50:11<4:17:55, 11.96s/it, loss=0.5169, lr=1.91e-06]Steps:  74%|███████▍  | 3706/5000 [13:50:11<4:17:55, 11.96s/it, loss=0.6357, lr=1.91e-06]Steps:  74%|███████▍  | 3707/5000 [13:50:23<4:17:31, 11.95s/it, loss=0.6357, lr=1.91e-06]Steps:  74%|███████▍  | 3707/5000 [13:50:23<4:17:31, 11.95s/it, loss=0.4282, lr=1.90e-06]Steps:  74%|███████▍  | 3708/5000 [13:50:35<4:18:27, 12.00s/it, loss=0.4282, lr=1.90e-06]Steps:  74%|███████▍  | 3708/5000 [13:50:35<4:18:27, 12.00s/it, loss=0.5414, lr=1.90e-06]Steps:  74%|███████▍  | 3709/5000 [13:50:47<4:17:23, 11.96s/it, loss=0.5414, lr=1.90e-06]Steps:  74%|███████▍  | 3709/5000 [13:50:47<4:17:23, 11.96s/it, loss=0.9513, lr=1.90e-06]Steps:  74%|███████▍  | 3710/5000 [13:50:59<4:16:59, 11.95s/it, loss=0.9513, lr=1.90e-06]Steps:  74%|███████▍  | 3710/5000 [13:50:59<4:16:59, 11.95s/it, loss=0.3477, lr=1.89e-06]
[Step 3710] Training Debug Info:
  Loss: 1.107986
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0120, std: 0.9336
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0120, std: 1.3750
  Model pred mean: -0.0116, std: 0.8789
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 3710] Training Debug Info:
  Loss: 0.402899
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0114, std: 0.8867
  Noise mean: 0.0039, std: 1.0000
  Target mean: 0.0153, std: 1.3359
  Model pred mean: 0.0167, std: 1.1797
  Sigmas: [0.796875]... (timesteps: [797.0])

[Step 3710] Training Debug Info:
  Loss: 0.593305
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0371, std: 0.9062
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0361, std: 1.3516
  Model pred mean: -0.0361, std: 1.1094
  Sigmas: [0.5625]... (timesteps: [562.0])

[Step 3710] Training Debug Info:
  Loss: 0.649302
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0031, std: 0.9023
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0032, std: 1.3438
  Model pred mean: -0.0014, std: 1.0859
  Sigmas: [0.98828125]... (timesteps: [989.0])
Steps:  74%|███████▍  | 3711/5000 [13:51:11<4:16:14, 11.93s/it, loss=0.3477, lr=1.89e-06]Steps:  74%|███████▍  | 3711/5000 [13:51:11<4:16:14, 11.93s/it, loss=0.6493, lr=1.89e-06]Steps:  74%|███████▍  | 3712/5000 [13:51:23<4:15:20, 11.90s/it, loss=0.6493, lr=1.89e-06]Steps:  74%|███████▍  | 3712/5000 [13:51:23<4:15:20, 11.90s/it, loss=1.0762, lr=1.89e-06]Steps:  74%|███████▍  | 3713/5000 [13:51:35<4:16:05, 11.94s/it, loss=1.0762, lr=1.89e-06]Steps:  74%|███████▍  | 3713/5000 [13:51:35<4:16:05, 11.94s/it, loss=0.3313, lr=1.89e-06]Steps:  74%|███████▍  | 3714/5000 [13:51:47<4:15:50, 11.94s/it, loss=0.3313, lr=1.89e-06]Steps:  74%|███████▍  | 3714/5000 [13:51:47<4:15:50, 11.94s/it, loss=1.0550, lr=1.88e-06]Steps:  74%|███████▍  | 3715/5000 [13:51:59<4:17:24, 12.02s/it, loss=1.0550, lr=1.88e-06]Steps:  74%|███████▍  | 3715/5000 [13:51:59<4:17:24, 12.02s/it, loss=1.0717, lr=1.88e-06]Steps:  74%|███████▍  | 3716/5000 [13:52:11<4:16:15, 11.97s/it, loss=1.0717, lr=1.88e-06]Steps:  74%|███████▍  | 3716/5000 [13:52:11<4:16:15, 11.97s/it, loss=0.4717, lr=1.88e-06]Steps:  74%|███████▍  | 3717/5000 [13:52:23<4:15:46, 11.96s/it, loss=0.4717, lr=1.88e-06]Steps:  74%|███████▍  | 3717/5000 [13:52:23<4:15:46, 11.96s/it, loss=0.4578, lr=1.88e-06]Steps:  74%|███████▍  | 3718/5000 [13:52:35<4:15:27, 11.96s/it, loss=0.4578, lr=1.88e-06]Steps:  74%|███████▍  | 3718/5000 [13:52:35<4:15:27, 11.96s/it, loss=0.5269, lr=1.87e-06]Steps:  74%|███████▍  | 3719/5000 [13:52:47<4:14:56, 11.94s/it, loss=0.5269, lr=1.87e-06]Steps:  74%|███████▍  | 3719/5000 [13:52:47<4:14:56, 11.94s/it, loss=0.5980, lr=1.87e-06]Steps:  74%|███████▍  | 3720/5000 [13:52:59<4:13:56, 11.90s/it, loss=0.5980, lr=1.87e-06]Steps:  74%|███████▍  | 3720/5000 [13:52:59<4:13:56, 11.90s/it, loss=0.5820, lr=1.87e-06]
[Step 3720] Training Debug Info:
  Loss: 0.549712
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0078, std: 0.9297
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0094, std: 1.3672
  Model pred mean: -0.0084, std: 1.1484
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 3720] Training Debug Info:
  Loss: 1.092881
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0227, std: 0.9648
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0208, std: 1.3906
  Model pred mean: -0.0215, std: 0.9180
  Sigmas: [0.076171875]... (timesteps: [76.0])

[Step 3720] Training Debug Info:
  Loss: 0.659317
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0374, std: 0.9141
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0386, std: 1.3516
  Model pred mean: -0.0302, std: 1.0859
  Sigmas: [0.94140625]... (timesteps: [943.0])

[Step 3720] Training Debug Info:
  Loss: 0.991069
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0018, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0020, std: 1.3594
  Model pred mean: -0.0003, std: 0.9258
  Sigmas: [0.357421875]... (timesteps: [357.0])
Steps:  74%|███████▍  | 3721/5000 [13:53:11<4:13:40, 11.90s/it, loss=0.5820, lr=1.87e-06]Steps:  74%|███████▍  | 3721/5000 [13:53:11<4:13:40, 11.90s/it, loss=0.9911, lr=1.86e-06]Steps:  74%|███████▍  | 3722/5000 [13:53:23<4:15:32, 12.00s/it, loss=0.9911, lr=1.86e-06]Steps:  74%|███████▍  | 3722/5000 [13:53:23<4:15:32, 12.00s/it, loss=0.9811, lr=1.86e-06]Steps:  74%|███████▍  | 3723/5000 [13:53:35<4:14:23, 11.95s/it, loss=0.9811, lr=1.86e-06]Steps:  74%|███████▍  | 3723/5000 [13:53:35<4:14:23, 11.95s/it, loss=0.4932, lr=1.86e-06]Steps:  74%|███████▍  | 3724/5000 [13:53:47<4:14:15, 11.96s/it, loss=0.4932, lr=1.86e-06]Steps:  74%|███████▍  | 3724/5000 [13:53:47<4:14:15, 11.96s/it, loss=1.0731, lr=1.86e-06]Steps:  74%|███████▍  | 3725/5000 [13:53:58<4:14:00, 11.95s/it, loss=1.0731, lr=1.86e-06]Steps:  74%|███████▍  | 3725/5000 [13:53:58<4:14:00, 11.95s/it, loss=0.6152, lr=1.85e-06]Steps:  75%|███████▍  | 3726/5000 [13:54:10<4:13:47, 11.95s/it, loss=0.6152, lr=1.85e-06]Steps:  75%|███████▍  | 3726/5000 [13:54:10<4:13:47, 11.95s/it, loss=0.5124, lr=1.85e-06]Steps:  75%|███████▍  | 3727/5000 [13:54:22<4:13:37, 11.95s/it, loss=0.5124, lr=1.85e-06]Steps:  75%|███████▍  | 3727/5000 [13:54:22<4:13:37, 11.95s/it, loss=0.6346, lr=1.85e-06]Steps:  75%|███████▍  | 3728/5000 [13:54:34<4:13:14, 11.95s/it, loss=0.6346, lr=1.85e-06]Steps:  75%|███████▍  | 3728/5000 [13:54:34<4:13:14, 11.95s/it, loss=1.0829, lr=1.85e-06]Steps:  75%|███████▍  | 3729/5000 [13:54:46<4:14:14, 12.00s/it, loss=1.0829, lr=1.85e-06]Steps:  75%|███████▍  | 3729/5000 [13:54:46<4:14:14, 12.00s/it, loss=0.4708, lr=1.84e-06]Steps:  75%|███████▍  | 3730/5000 [13:54:58<4:13:17, 11.97s/it, loss=0.4708, lr=1.84e-06]Steps:  75%|███████▍  | 3730/5000 [13:54:58<4:13:17, 11.97s/it, loss=0.5013, lr=1.84e-06]
[Step 3730] Training Debug Info:
  Loss: 1.069199
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0312, std: 0.9414
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0309, std: 1.3750
  Model pred mean: -0.0298, std: 0.9062
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 3730] Training Debug Info:
  Loss: 0.451287
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0135, std: 0.9141
  Noise mean: 0.0007, std: 0.9961
  Target mean: 0.0142, std: 1.3516
  Model pred mean: 0.0080, std: 1.1719
  Sigmas: [0.73046875]... (timesteps: [729.0])

[Step 3730] Training Debug Info:
  Loss: 0.414661
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0090, std: 0.9141
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0069, std: 1.3594
  Model pred mean: -0.0076, std: 1.1875
  Sigmas: [0.71875]... (timesteps: [717.0])

[Step 3730] Training Debug Info:
  Loss: 1.177348
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0053, std: 0.8906
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0038, std: 1.3359
  Model pred mean: 0.0061, std: 0.7891
  Sigmas: [0.23046875]... (timesteps: [230.0])
Steps:  75%|███████▍  | 3731/5000 [13:55:10<4:13:32, 11.99s/it, loss=0.5013, lr=1.84e-06]Steps:  75%|███████▍  | 3731/5000 [13:55:10<4:13:32, 11.99s/it, loss=1.1773, lr=1.84e-06]Steps:  75%|███████▍  | 3732/5000 [13:55:22<4:12:59, 11.97s/it, loss=1.1773, lr=1.84e-06]Steps:  75%|███████▍  | 3732/5000 [13:55:22<4:12:59, 11.97s/it, loss=0.4412, lr=1.83e-06]Steps:  75%|███████▍  | 3733/5000 [13:55:34<4:12:46, 11.97s/it, loss=0.4412, lr=1.83e-06]Steps:  75%|███████▍  | 3733/5000 [13:55:34<4:12:46, 11.97s/it, loss=0.3893, lr=1.83e-06]Steps:  75%|███████▍  | 3734/5000 [13:55:46<4:12:30, 11.97s/it, loss=0.3893, lr=1.83e-06]Steps:  75%|███████▍  | 3734/5000 [13:55:46<4:12:30, 11.97s/it, loss=0.8821, lr=1.83e-06]Steps:  75%|███████▍  | 3735/5000 [13:55:58<4:13:28, 12.02s/it, loss=0.8821, lr=1.83e-06]Steps:  75%|███████▍  | 3735/5000 [13:55:58<4:13:28, 12.02s/it, loss=1.0619, lr=1.83e-06]Steps:  75%|███████▍  | 3736/5000 [13:56:10<4:12:44, 12.00s/it, loss=1.0619, lr=1.83e-06]Steps:  75%|███████▍  | 3736/5000 [13:56:10<4:12:44, 12.00s/it, loss=0.4244, lr=1.82e-06]Steps:  75%|███████▍  | 3737/5000 [13:56:22<4:11:31, 11.95s/it, loss=0.4244, lr=1.82e-06]Steps:  75%|███████▍  | 3737/5000 [13:56:22<4:11:31, 11.95s/it, loss=0.8704, lr=1.82e-06]Steps:  75%|███████▍  | 3738/5000 [13:56:34<4:10:49, 11.93s/it, loss=0.8704, lr=1.82e-06]Steps:  75%|███████▍  | 3738/5000 [13:56:34<4:10:49, 11.93s/it, loss=0.4499, lr=1.82e-06]Steps:  75%|███████▍  | 3739/5000 [13:56:46<4:10:29, 11.92s/it, loss=0.4499, lr=1.82e-06]Steps:  75%|███████▍  | 3739/5000 [13:56:46<4:10:29, 11.92s/it, loss=0.4786, lr=1.82e-06]Steps:  75%|███████▍  | 3740/5000 [13:56:58<4:10:49, 11.94s/it, loss=0.4786, lr=1.82e-06]Steps:  75%|███████▍  | 3740/5000 [13:56:58<4:10:49, 11.94s/it, loss=1.0340, lr=1.81e-06]
[Step 3740] Training Debug Info:
  Loss: 0.678377
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0062, std: 0.9297
  Noise mean: -0.0036, std: 1.0000
  Target mean: -0.0098, std: 1.3672
  Model pred mean: -0.0063, std: 1.0859
  Sigmas: [0.49609375]... (timesteps: [497.0])

[Step 3740] Training Debug Info:
  Loss: 0.994536
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0576, std: 0.9297
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0559, std: 1.3672
  Model pred mean: -0.0598, std: 0.9336
  Sigmas: [0.2490234375]... (timesteps: [249.0])

[Step 3740] Training Debug Info:
  Loss: 0.568634
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0496, std: 0.9219
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0513, std: 1.3594
  Model pred mean: -0.0569, std: 1.1328
  Sigmas: [0.94140625]... (timesteps: [942.0])

[Step 3740] Training Debug Info:
  Loss: 0.572212
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0081, std: 0.9180
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0112, std: 1.3594
  Model pred mean: -0.0090, std: 1.1250
  Sigmas: [0.58984375]... (timesteps: [589.0])
Steps:  75%|███████▍  | 3741/5000 [13:57:10<4:10:46, 11.95s/it, loss=1.0340, lr=1.81e-06]Steps:  75%|███████▍  | 3741/5000 [13:57:10<4:10:46, 11.95s/it, loss=0.5722, lr=1.81e-06]Steps:  75%|███████▍  | 3742/5000 [13:57:22<4:12:12, 12.03s/it, loss=0.5722, lr=1.81e-06]Steps:  75%|███████▍  | 3742/5000 [13:57:22<4:12:12, 12.03s/it, loss=1.0187, lr=1.81e-06]Steps:  75%|███████▍  | 3743/5000 [13:57:34<4:11:02, 11.98s/it, loss=1.0187, lr=1.81e-06]Steps:  75%|███████▍  | 3743/5000 [13:57:34<4:11:02, 11.98s/it, loss=0.4076, lr=1.80e-06]Steps:  75%|███████▍  | 3744/5000 [13:57:46<4:10:32, 11.97s/it, loss=0.4076, lr=1.80e-06]Steps:  75%|███████▍  | 3744/5000 [13:57:46<4:10:32, 11.97s/it, loss=1.0998, lr=1.80e-06]Steps:  75%|███████▍  | 3745/5000 [13:57:58<4:10:27, 11.97s/it, loss=1.0998, lr=1.80e-06]Steps:  75%|███████▍  | 3745/5000 [13:57:58<4:10:27, 11.97s/it, loss=0.7653, lr=1.80e-06]Steps:  75%|███████▍  | 3746/5000 [13:58:10<4:09:33, 11.94s/it, loss=0.7653, lr=1.80e-06]Steps:  75%|███████▍  | 3746/5000 [13:58:10<4:09:33, 11.94s/it, loss=0.7946, lr=1.80e-06]Steps:  75%|███████▍  | 3747/5000 [13:58:22<4:09:16, 11.94s/it, loss=0.7946, lr=1.80e-06]Steps:  75%|███████▍  | 3747/5000 [13:58:22<4:09:16, 11.94s/it, loss=0.8005, lr=1.79e-06]Steps:  75%|███████▍  | 3748/5000 [13:58:34<4:08:35, 11.91s/it, loss=0.8005, lr=1.79e-06]Steps:  75%|███████▍  | 3748/5000 [13:58:34<4:08:35, 11.91s/it, loss=1.0534, lr=1.79e-06]Steps:  75%|███████▍  | 3749/5000 [13:58:46<4:10:01, 11.99s/it, loss=1.0534, lr=1.79e-06]Steps:  75%|███████▍  | 3749/5000 [13:58:46<4:10:01, 11.99s/it, loss=0.9689, lr=1.79e-06]Steps:  75%|███████▌  | 3750/5000 [13:58:58<4:09:14, 11.96s/it, loss=0.9689, lr=1.79e-06]Steps:  75%|███████▌  | 3750/5000 [13:58:58<4:09:14, 11.96s/it, loss=1.0103, lr=1.79e-06]
[Step 3750] Training Debug Info:
  Loss: 0.722996
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0250, std: 0.9414
  Noise mean: -0.0004, std: 0.9961
  Target mean: -0.0254, std: 1.3750
  Model pred mean: -0.0217, std: 1.0625
  Sigmas: [0.9765625]... (timesteps: [978.0])

[Step 3750] Training Debug Info:
  Loss: 1.101801
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0136, std: 0.9062
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0152, std: 1.3516
  Model pred mean: 0.0139, std: 0.8516
  Sigmas: [0.283203125]... (timesteps: [283.0])

[Step 3750] Training Debug Info:
  Loss: 0.411625
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0022, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0010, std: 1.3672
  Model pred mean: -0.0021, std: 1.2109
  Sigmas: [0.77734375]... (timesteps: [776.0])

[Step 3750] Training Debug Info:
  Loss: 1.174744
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0106, std: 1.3359
  Model pred mean: -0.0091, std: 0.7852
  Sigmas: [0.1484375]... (timesteps: [148.0])
Steps:  75%|███████▌  | 3751/5000 [13:59:10<4:08:53, 11.96s/it, loss=1.0103, lr=1.79e-06]Steps:  75%|███████▌  | 3751/5000 [13:59:10<4:08:53, 11.96s/it, loss=1.1747, lr=1.78e-06]Steps:  75%|███████▌  | 3752/5000 [13:59:22<4:08:35, 11.95s/it, loss=1.1747, lr=1.78e-06]Steps:  75%|███████▌  | 3752/5000 [13:59:22<4:08:35, 11.95s/it, loss=0.4722, lr=1.78e-06]Steps:  75%|███████▌  | 3753/5000 [13:59:33<4:08:15, 11.95s/it, loss=0.4722, lr=1.78e-06]Steps:  75%|███████▌  | 3753/5000 [13:59:33<4:08:15, 11.95s/it, loss=0.4312, lr=1.78e-06]Steps:  75%|███████▌  | 3754/5000 [13:59:45<4:07:30, 11.92s/it, loss=0.4312, lr=1.78e-06]Steps:  75%|███████▌  | 3754/5000 [13:59:45<4:07:30, 11.92s/it, loss=0.8798, lr=1.78e-06]Steps:  75%|███████▌  | 3755/5000 [13:59:57<4:06:53, 11.90s/it, loss=0.8798, lr=1.78e-06]Steps:  75%|███████▌  | 3755/5000 [13:59:57<4:06:53, 11.90s/it, loss=0.5565, lr=1.77e-06]Steps:  75%|███████▌  | 3756/5000 [14:00:09<4:08:24, 11.98s/it, loss=0.5565, lr=1.77e-06]Steps:  75%|███████▌  | 3756/5000 [14:00:09<4:08:24, 11.98s/it, loss=0.5719, lr=1.77e-06]Steps:  75%|███████▌  | 3757/5000 [14:00:21<4:07:41, 11.96s/it, loss=0.5719, lr=1.77e-06]Steps:  75%|███████▌  | 3757/5000 [14:00:21<4:07:41, 11.96s/it, loss=0.6441, lr=1.77e-06]Steps:  75%|███████▌  | 3758/5000 [14:00:33<4:07:59, 11.98s/it, loss=0.6441, lr=1.77e-06]Steps:  75%|███████▌  | 3758/5000 [14:00:33<4:07:59, 11.98s/it, loss=0.9441, lr=1.76e-06]Steps:  75%|███████▌  | 3759/5000 [14:00:45<4:07:16, 11.96s/it, loss=0.9441, lr=1.76e-06]Steps:  75%|███████▌  | 3759/5000 [14:00:45<4:07:16, 11.96s/it, loss=0.6963, lr=1.76e-06]Steps:  75%|███████▌  | 3760/5000 [14:00:57<4:07:03, 11.95s/it, loss=0.6963, lr=1.76e-06]Steps:  75%|███████▌  | 3760/5000 [14:00:57<4:07:03, 11.95s/it, loss=0.6253, lr=1.76e-06]
[Step 3760] Training Debug Info:
  Loss: 0.631493
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0092, std: 0.9102
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0064, std: 1.3516
  Model pred mean: 0.0084, std: 1.0938
  Sigmas: [0.55078125]... (timesteps: [551.0])

[Step 3760] Training Debug Info:
  Loss: 0.752394
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0095, std: 0.9219
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0115, std: 1.3594
  Model pred mean: -0.0106, std: 1.0469
  Sigmas: [0.46875]... (timesteps: [468.0])

[Step 3760] Training Debug Info:
  Loss: 0.821869
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0084, std: 0.8750
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0079, std: 1.3281
  Model pred mean: 0.0096, std: 0.9688
  Sigmas: [0.474609375]... (timesteps: [475.0])

[Step 3760] Training Debug Info:
  Loss: 0.488275
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0013, std: 0.9336
  Noise mean: 0.0044, std: 1.0000
  Target mean: 0.0031, std: 1.3672
  Model pred mean: 0.0034, std: 1.1797
  Sigmas: [0.640625]... (timesteps: [641.0])
Steps:  75%|███████▌  | 3761/5000 [14:01:09<4:06:47, 11.95s/it, loss=0.6253, lr=1.76e-06]Steps:  75%|███████▌  | 3761/5000 [14:01:09<4:06:47, 11.95s/it, loss=0.4883, lr=1.76e-06]Steps:  75%|███████▌  | 3762/5000 [14:01:21<4:07:53, 12.01s/it, loss=0.4883, lr=1.76e-06]Steps:  75%|███████▌  | 3762/5000 [14:01:21<4:07:53, 12.01s/it, loss=0.4253, lr=1.75e-06]Steps:  75%|███████▌  | 3763/5000 [14:01:33<4:07:04, 11.98s/it, loss=0.4253, lr=1.75e-06]Steps:  75%|███████▌  | 3763/5000 [14:01:33<4:07:04, 11.98s/it, loss=0.7988, lr=1.75e-06]Steps:  75%|███████▌  | 3764/5000 [14:01:45<4:06:50, 11.98s/it, loss=0.7988, lr=1.75e-06]Steps:  75%|███████▌  | 3764/5000 [14:01:45<4:06:50, 11.98s/it, loss=1.0225, lr=1.75e-06]Steps:  75%|███████▌  | 3765/5000 [14:01:57<4:06:23, 11.97s/it, loss=1.0225, lr=1.75e-06]Steps:  75%|███████▌  | 3765/5000 [14:01:57<4:06:23, 11.97s/it, loss=1.0078, lr=1.75e-06]Steps:  75%|███████▌  | 3766/5000 [14:02:09<4:06:02, 11.96s/it, loss=1.0078, lr=1.75e-06]Steps:  75%|███████▌  | 3766/5000 [14:02:09<4:06:02, 11.96s/it, loss=1.0861, lr=1.74e-06]Steps:  75%|███████▌  | 3767/5000 [14:02:21<4:06:38, 12.00s/it, loss=1.0861, lr=1.74e-06]Steps:  75%|███████▌  | 3767/5000 [14:02:21<4:06:38, 12.00s/it, loss=0.5215, lr=1.74e-06]Steps:  75%|███████▌  | 3768/5000 [14:02:33<4:06:06, 11.99s/it, loss=0.5215, lr=1.74e-06]Steps:  75%|███████▌  | 3768/5000 [14:02:33<4:06:06, 11.99s/it, loss=0.9718, lr=1.74e-06]Steps:  75%|███████▌  | 3769/5000 [14:02:45<4:06:38, 12.02s/it, loss=0.9718, lr=1.74e-06]Steps:  75%|███████▌  | 3769/5000 [14:02:45<4:06:38, 12.02s/it, loss=1.1046, lr=1.74e-06]Steps:  75%|███████▌  | 3770/5000 [14:02:57<4:05:48, 11.99s/it, loss=1.1046, lr=1.74e-06]Steps:  75%|███████▌  | 3770/5000 [14:02:57<4:05:48, 11.99s/it, loss=0.7607, lr=1.73e-06]
[Step 3770] Training Debug Info:
  Loss: 0.455470
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0085, std: 0.9688
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0120, std: 1.3906
  Model pred mean: -0.0098, std: 1.2188
  Sigmas: [0.7265625]... (timesteps: [726.0])

[Step 3770] Training Debug Info:
  Loss: 1.027970
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0398, std: 0.9258
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0383, std: 1.3594
  Model pred mean: -0.0381, std: 0.9102
  Sigmas: [0.0159912109375]... (timesteps: [16.0])

[Step 3770] Training Debug Info:
  Loss: 0.425091
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0166, std: 1.0000
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0167, std: 1.4141
  Model pred mean: -0.0177, std: 1.2578
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 3770] Training Debug Info:
  Loss: 0.790259
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0311, std: 0.9570
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0310, std: 1.3828
  Model pred mean: -0.0337, std: 1.0547
  Sigmas: [0.408203125]... (timesteps: [408.0])
Steps:  75%|███████▌  | 3771/5000 [14:03:09<4:05:16, 11.97s/it, loss=0.7607, lr=1.73e-06]Steps:  75%|███████▌  | 3771/5000 [14:03:09<4:05:16, 11.97s/it, loss=0.7903, lr=1.73e-06]Steps:  75%|███████▌  | 3772/5000 [14:03:21<4:04:28, 11.94s/it, loss=0.7903, lr=1.73e-06]Steps:  75%|███████▌  | 3772/5000 [14:03:21<4:04:28, 11.94s/it, loss=0.7685, lr=1.73e-06]Steps:  75%|███████▌  | 3773/5000 [14:03:33<4:04:07, 11.94s/it, loss=0.7685, lr=1.73e-06]Steps:  75%|███████▌  | 3773/5000 [14:03:33<4:04:07, 11.94s/it, loss=0.3695, lr=1.72e-06]Steps:  75%|███████▌  | 3774/5000 [14:03:45<4:03:31, 11.92s/it, loss=0.3695, lr=1.72e-06]Steps:  75%|███████▌  | 3774/5000 [14:03:45<4:03:31, 11.92s/it, loss=1.0746, lr=1.72e-06]Steps:  76%|███████▌  | 3775/5000 [14:03:57<4:03:07, 11.91s/it, loss=1.0746, lr=1.72e-06]Steps:  76%|███████▌  | 3775/5000 [14:03:57<4:03:07, 11.91s/it, loss=0.3436, lr=1.72e-06]Steps:  76%|███████▌  | 3776/5000 [14:04:09<4:04:31, 11.99s/it, loss=0.3436, lr=1.72e-06]Steps:  76%|███████▌  | 3776/5000 [14:04:09<4:04:31, 11.99s/it, loss=1.1728, lr=1.72e-06]Steps:  76%|███████▌  | 3777/5000 [14:04:21<4:03:35, 11.95s/it, loss=1.1728, lr=1.72e-06]Steps:  76%|███████▌  | 3777/5000 [14:04:21<4:03:35, 11.95s/it, loss=1.0686, lr=1.71e-06]Steps:  76%|███████▌  | 3778/5000 [14:04:33<4:03:20, 11.95s/it, loss=1.0686, lr=1.71e-06]Steps:  76%|███████▌  | 3778/5000 [14:04:33<4:03:20, 11.95s/it, loss=1.0030, lr=1.71e-06]Steps:  76%|███████▌  | 3779/5000 [14:04:45<4:03:18, 11.96s/it, loss=1.0030, lr=1.71e-06]Steps:  76%|███████▌  | 3779/5000 [14:04:45<4:03:18, 11.96s/it, loss=0.4786, lr=1.71e-06]Steps:  76%|███████▌  | 3780/5000 [14:04:56<4:03:14, 11.96s/it, loss=0.4786, lr=1.71e-06]Steps:  76%|███████▌  | 3780/5000 [14:04:56<4:03:14, 11.96s/it, loss=0.7412, lr=1.71e-06]
[Step 3780] Training Debug Info:
  Loss: 0.476436
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.8828
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0024, std: 1.3281
  Model pred mean: 0.0187, std: 1.1484
  Sigmas: [0.97265625]... (timesteps: [973.0])

[Step 3780] Training Debug Info:
  Loss: 0.684154
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0027, std: 0.9688
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0015, std: 1.3906
  Model pred mean: 0.0002, std: 1.1172
  Sigmas: [0.5078125]... (timesteps: [507.0000305175781])

[Step 3780] Training Debug Info:
  Loss: 0.554241
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0009, std: 0.9375
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0008, std: 1.3672
  Model pred mean: 0.0029, std: 1.1484
  Sigmas: [0.5234375]... (timesteps: [523.0])

[Step 3780] Training Debug Info:
  Loss: 1.107132
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0173, std: 0.8945
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0150, std: 1.3438
  Model pred mean: 0.0178, std: 0.8359
  Sigmas: [0.0771484375]... (timesteps: [77.0])
Steps:  76%|███████▌  | 3781/5000 [14:05:08<4:02:36, 11.94s/it, loss=0.7412, lr=1.71e-06]Steps:  76%|███████▌  | 3781/5000 [14:05:08<4:02:36, 11.94s/it, loss=1.1071, lr=1.70e-06]Steps:  76%|███████▌  | 3782/5000 [14:05:20<4:01:58, 11.92s/it, loss=1.1071, lr=1.70e-06]Steps:  76%|███████▌  | 3782/5000 [14:05:20<4:01:58, 11.92s/it, loss=0.7605, lr=1.70e-06]Steps:  76%|███████▌  | 3783/5000 [14:05:32<4:02:47, 11.97s/it, loss=0.7605, lr=1.70e-06]Steps:  76%|███████▌  | 3783/5000 [14:05:32<4:02:47, 11.97s/it, loss=0.4573, lr=1.70e-06]Steps:  76%|███████▌  | 3784/5000 [14:05:44<4:02:17, 11.95s/it, loss=0.4573, lr=1.70e-06]Steps:  76%|███████▌  | 3784/5000 [14:05:44<4:02:17, 11.95s/it, loss=0.3718, lr=1.70e-06]Steps:  76%|███████▌  | 3785/5000 [14:05:56<4:02:46, 11.99s/it, loss=0.3718, lr=1.70e-06]Steps:  76%|███████▌  | 3785/5000 [14:05:56<4:02:46, 11.99s/it, loss=0.4486, lr=1.69e-06]Steps:  76%|███████▌  | 3786/5000 [14:06:08<4:02:04, 11.96s/it, loss=0.4486, lr=1.69e-06]Steps:  76%|███████▌  | 3786/5000 [14:06:08<4:02:04, 11.96s/it, loss=0.4302, lr=1.69e-06]Steps:  76%|███████▌  | 3787/5000 [14:06:20<4:01:28, 11.94s/it, loss=0.4302, lr=1.69e-06]Steps:  76%|███████▌  | 3787/5000 [14:06:20<4:01:28, 11.94s/it, loss=0.4407, lr=1.69e-06]Steps:  76%|███████▌  | 3788/5000 [14:06:32<4:00:56, 11.93s/it, loss=0.4407, lr=1.69e-06]Steps:  76%|███████▌  | 3788/5000 [14:06:32<4:00:56, 11.93s/it, loss=1.0759, lr=1.69e-06]Steps:  76%|███████▌  | 3789/5000 [14:06:44<4:02:36, 12.02s/it, loss=1.0759, lr=1.69e-06]Steps:  76%|███████▌  | 3789/5000 [14:06:44<4:02:36, 12.02s/it, loss=1.0452, lr=1.68e-06]Steps:  76%|███████▌  | 3790/5000 [14:06:56<4:01:23, 11.97s/it, loss=1.0452, lr=1.68e-06]Steps:  76%|███████▌  | 3790/5000 [14:06:56<4:01:23, 11.97s/it, loss=0.5049, lr=1.68e-06]
[Step 3790] Training Debug Info:
  Loss: 0.505889
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0056, std: 0.9219
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0076, std: 1.3672
  Model pred mean: 0.0035, std: 1.1562
  Sigmas: [0.671875]... (timesteps: [672.0])

[Step 3790] Training Debug Info:
  Loss: 0.653888
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0167, std: 0.9453
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0188, std: 1.3750
  Model pred mean: -0.0271, std: 1.1016
  Sigmas: [0.9453125]... (timesteps: [946.0])

[Step 3790] Training Debug Info:
  Loss: 1.042404
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0337, std: 0.9102
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0342, std: 1.3594
  Model pred mean: -0.0304, std: 0.8945
  Sigmas: [0.240234375]... (timesteps: [240.0])

[Step 3790] Training Debug Info:
  Loss: 1.008630
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0077, std: 0.8945
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0066, std: 1.3438
  Model pred mean: -0.0109, std: 0.8945
  Sigmas: [0.3515625]... (timesteps: [352.0])
Steps:  76%|███████▌  | 3791/5000 [14:07:08<4:00:43, 11.95s/it, loss=0.5049, lr=1.68e-06]Steps:  76%|███████▌  | 3791/5000 [14:07:08<4:00:43, 11.95s/it, loss=1.0086, lr=1.68e-06]Steps:  76%|███████▌  | 3792/5000 [14:07:20<3:59:43, 11.91s/it, loss=1.0086, lr=1.68e-06]Steps:  76%|███████▌  | 3792/5000 [14:07:20<3:59:43, 11.91s/it, loss=0.6998, lr=1.68e-06]Steps:  76%|███████▌  | 3793/5000 [14:07:32<4:00:00, 11.93s/it, loss=0.6998, lr=1.68e-06]Steps:  76%|███████▌  | 3793/5000 [14:07:32<4:00:00, 11.93s/it, loss=0.3547, lr=1.67e-06]Steps:  76%|███████▌  | 3794/5000 [14:07:44<3:59:09, 11.90s/it, loss=0.3547, lr=1.67e-06]Steps:  76%|███████▌  | 3794/5000 [14:07:44<3:59:09, 11.90s/it, loss=1.1424, lr=1.67e-06]Steps:  76%|███████▌  | 3795/5000 [14:07:56<3:59:11, 11.91s/it, loss=1.1424, lr=1.67e-06]Steps:  76%|███████▌  | 3795/5000 [14:07:56<3:59:11, 11.91s/it, loss=0.3651, lr=1.67e-06]Steps:  76%|███████▌  | 3796/5000 [14:08:08<4:00:27, 11.98s/it, loss=0.3651, lr=1.67e-06]Steps:  76%|███████▌  | 3796/5000 [14:08:08<4:00:27, 11.98s/it, loss=0.4926, lr=1.66e-06]Steps:  76%|███████▌  | 3797/5000 [14:08:20<3:59:15, 11.93s/it, loss=0.4926, lr=1.66e-06]Steps:  76%|███████▌  | 3797/5000 [14:08:20<3:59:15, 11.93s/it, loss=0.7224, lr=1.66e-06]Steps:  76%|███████▌  | 3798/5000 [14:08:31<3:59:00, 11.93s/it, loss=0.7224, lr=1.66e-06]Steps:  76%|███████▌  | 3798/5000 [14:08:31<3:59:00, 11.93s/it, loss=0.3500, lr=1.66e-06]Steps:  76%|███████▌  | 3799/5000 [14:08:43<3:58:14, 11.90s/it, loss=0.3500, lr=1.66e-06]Steps:  76%|███████▌  | 3799/5000 [14:08:43<3:58:14, 11.90s/it, loss=1.0507, lr=1.66e-06]Steps:  76%|███████▌  | 3800/5000 [14:08:55<3:58:01, 11.90s/it, loss=1.0507, lr=1.66e-06]Steps:  76%|███████▌  | 3800/5000 [14:08:55<3:58:01, 11.90s/it, loss=0.5047, lr=1.65e-06]01/22/2026 21:54:42 - INFO - __main__ - 
[Step 3800] ✅ Loss in normal range (0.5047)
01/22/2026 21:54:42 - INFO - __main__ -   Loss avg (last 100): 0.7204
01/22/2026 21:54:42 - INFO - __main__ -   Loss range: [0.3313, 1.1773]
01/22/2026 21:54:42 - INFO - __main__ - 
🔍 Running validation at step 3800...
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3800 (parquet mode)...
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 3800...
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 21:54:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.23it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.50it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.46it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.46it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/22/2026 21:55:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 21:55:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.17it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.56it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 21:55:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 21:55:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.13it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 21:55:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 21:55:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:13,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 21:56:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 21:56:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 21:56:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 21:56:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 21:56:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 21:56:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:57:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 21:57:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:57:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 21:57:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.37it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:57:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 21:57:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 21:58:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 21:58:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.43it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.41it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.41it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.41it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.41it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.41it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.41it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.41it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.41it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 21:58:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 21:58:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.16it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 21:58:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800/step003800_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 21:58:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 21:58:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 21:58:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_003800
01/22/2026 21:58:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 3800] Training Debug Info:
  Loss: 0.792614
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0071, std: 0.9141
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0096, std: 1.3516
  Model pred mean: -0.0039, std: 1.0234
  Sigmas: [0.462890625]... (timesteps: [462.0])

[Step 3800] Training Debug Info:
  Loss: 0.794688
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0261, std: 0.9961
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0240, std: 1.4141
  Model pred mean: -0.0413, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [989.0])

[Step 3800] Training Debug Info:
  Loss: 0.613812
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0063, std: 0.9062
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0051, std: 1.3516
  Model pred mean: 0.0085, std: 1.0938
  Sigmas: [0.56640625]... (timesteps: [568.0])

[Step 3800] Training Debug Info:
  Loss: 0.405113
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0194, std: 0.8828
  Noise mean: -0.0046, std: 1.0000
  Target mean: -0.0240, std: 1.3359
  Model pred mean: -0.0304, std: 1.1719
  Sigmas: [0.90234375]... (timesteps: [903.0])
Steps:  76%|███████▌  | 3801/5000 [14:13:29<30:06:23, 90.39s/it, loss=0.5047, lr=1.65e-06]Steps:  76%|███████▌  | 3801/5000 [14:13:29<30:06:23, 90.39s/it, loss=0.4051, lr=1.65e-06]Steps:  76%|███████▌  | 3802/5000 [14:13:41<22:14:33, 66.84s/it, loss=0.4051, lr=1.65e-06]Steps:  76%|███████▌  | 3802/5000 [14:13:41<22:14:33, 66.84s/it, loss=1.0097, lr=1.65e-06]Steps:  76%|███████▌  | 3803/5000 [14:13:53<16:45:51, 50.42s/it, loss=1.0097, lr=1.65e-06]Steps:  76%|███████▌  | 3803/5000 [14:13:53<16:45:51, 50.42s/it, loss=0.7277, lr=1.65e-06]Steps:  76%|███████▌  | 3804/5000 [14:14:05<12:55:00, 38.88s/it, loss=0.7277, lr=1.65e-06]Steps:  76%|███████▌  | 3804/5000 [14:14:05<12:55:00, 38.88s/it, loss=0.4154, lr=1.64e-06]Steps:  76%|███████▌  | 3805/5000 [14:14:17<10:13:05, 30.78s/it, loss=0.4154, lr=1.64e-06]Steps:  76%|███████▌  | 3805/5000 [14:14:17<10:13:05, 30.78s/it, loss=0.5629, lr=1.64e-06]Steps:  76%|███████▌  | 3806/5000 [14:14:28<8:19:45, 25.11s/it, loss=0.5629, lr=1.64e-06] Steps:  76%|███████▌  | 3806/5000 [14:14:28<8:19:45, 25.11s/it, loss=0.4443, lr=1.64e-06]Steps:  76%|███████▌  | 3807/5000 [14:14:40<7:00:54, 21.17s/it, loss=0.4443, lr=1.64e-06]Steps:  76%|███████▌  | 3807/5000 [14:14:40<7:00:54, 21.17s/it, loss=0.6471, lr=1.64e-06]Steps:  76%|███████▌  | 3808/5000 [14:14:52<6:05:31, 18.40s/it, loss=0.6471, lr=1.64e-06]Steps:  76%|███████▌  | 3808/5000 [14:14:52<6:05:31, 18.40s/it, loss=0.3641, lr=1.63e-06]Steps:  76%|███████▌  | 3809/5000 [14:15:04<5:27:00, 16.47s/it, loss=0.3641, lr=1.63e-06]Steps:  76%|███████▌  | 3809/5000 [14:15:04<5:27:00, 16.47s/it, loss=0.6820, lr=1.63e-06]Steps:  76%|███████▌  | 3810/5000 [14:15:16<5:00:44, 15.16s/it, loss=0.6820, lr=1.63e-06]Steps:  76%|███████▌  | 3810/5000 [14:15:16<5:00:44, 15.16s/it, loss=0.8520, lr=1.63e-06]
[Step 3810] Training Debug Info:
  Loss: 0.365150
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0286, std: 0.9180
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0278, std: 1.3594
  Model pred mean: -0.0261, std: 1.2109
  Sigmas: [0.74609375]... (timesteps: [748.0])

[Step 3810] Training Debug Info:
  Loss: 1.172165
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0425, std: 0.9102
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0425, std: 1.3516
  Model pred mean: 0.0420, std: 0.8125
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 3810] Training Debug Info:
  Loss: 1.147879
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0219, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0211, std: 1.3594
  Model pred mean: 0.0237, std: 0.8359
  Sigmas: [0.201171875]... (timesteps: [201.0])

[Step 3810] Training Debug Info:
  Loss: 1.102833
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0149, std: 0.8906
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0170, std: 1.3438
  Model pred mean: -0.0145, std: 0.8320
  Sigmas: [0.09521484375]... (timesteps: [95.0])
Steps:  76%|███████▌  | 3811/5000 [14:15:28<4:41:11, 14.19s/it, loss=0.8520, lr=1.63e-06]Steps:  76%|███████▌  | 3811/5000 [14:15:28<4:41:11, 14.19s/it, loss=1.1028, lr=1.63e-06]Steps:  76%|███████▌  | 3812/5000 [14:15:40<4:27:51, 13.53s/it, loss=1.1028, lr=1.63e-06]Steps:  76%|███████▌  | 3812/5000 [14:15:40<4:27:51, 13.53s/it, loss=0.6631, lr=1.62e-06]Steps:  76%|███████▋  | 3813/5000 [14:15:52<4:17:54, 13.04s/it, loss=0.6631, lr=1.62e-06]Steps:  76%|███████▋  | 3813/5000 [14:15:52<4:17:54, 13.04s/it, loss=1.0572, lr=1.62e-06]Steps:  76%|███████▋  | 3814/5000 [14:16:04<4:10:54, 12.69s/it, loss=1.0572, lr=1.62e-06]Steps:  76%|███████▋  | 3814/5000 [14:16:04<4:10:54, 12.69s/it, loss=1.0174, lr=1.62e-06]Steps:  76%|███████▋  | 3815/5000 [14:16:16<4:06:22, 12.47s/it, loss=1.0174, lr=1.62e-06]Steps:  76%|███████▋  | 3815/5000 [14:16:16<4:06:22, 12.47s/it, loss=1.0169, lr=1.62e-06]Steps:  76%|███████▋  | 3816/5000 [14:16:28<4:03:56, 12.36s/it, loss=1.0169, lr=1.62e-06]Steps:  76%|███████▋  | 3816/5000 [14:16:28<4:03:56, 12.36s/it, loss=0.7321, lr=1.61e-06]Steps:  76%|███████▋  | 3817/5000 [14:16:40<4:01:00, 12.22s/it, loss=0.7321, lr=1.61e-06]Steps:  76%|███████▋  | 3817/5000 [14:16:40<4:01:00, 12.22s/it, loss=0.5860, lr=1.61e-06]Steps:  76%|███████▋  | 3818/5000 [14:16:52<3:59:12, 12.14s/it, loss=0.5860, lr=1.61e-06]Steps:  76%|███████▋  | 3818/5000 [14:16:52<3:59:12, 12.14s/it, loss=1.0665, lr=1.61e-06]Steps:  76%|███████▋  | 3819/5000 [14:17:04<3:58:12, 12.10s/it, loss=1.0665, lr=1.61e-06]Steps:  76%|███████▋  | 3819/5000 [14:17:04<3:58:12, 12.10s/it, loss=1.1134, lr=1.61e-06]Steps:  76%|███████▋  | 3820/5000 [14:17:16<3:57:09, 12.06s/it, loss=1.1134, lr=1.61e-06]Steps:  76%|███████▋  | 3820/5000 [14:17:16<3:57:09, 12.06s/it, loss=1.1454, lr=1.60e-06]
[Step 3820] Training Debug Info:
  Loss: 0.451190
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0032, std: 1.0000
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0017, std: 1.4141
  Model pred mean: -0.0066, std: 1.2422
  Sigmas: [0.796875]... (timesteps: [796.0])

[Step 3820] Training Debug Info:
  Loss: 0.389606
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0320, std: 0.9180
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0347, std: 1.3594
  Model pred mean: 0.0299, std: 1.2109
  Sigmas: [0.921875]... (timesteps: [922.0])

[Step 3820] Training Debug Info:
  Loss: 0.422197
  Latent shape: torch.Size([1, 32, 138, 66]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0332, std: 0.9531
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0312, std: 1.3828
  Model pred mean: 0.0322, std: 1.2188
  Sigmas: [0.75]... (timesteps: [751.0])

[Step 3820] Training Debug Info:
  Loss: 0.750752
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0151, std: 0.8867
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0132, std: 1.3359
  Model pred mean: -0.0123, std: 1.0156
  Sigmas: [0.5]... (timesteps: [500.0])
Steps:  76%|███████▋  | 3821/5000 [14:17:28<3:56:23, 12.03s/it, loss=1.1454, lr=1.60e-06]Steps:  76%|███████▋  | 3821/5000 [14:17:28<3:56:23, 12.03s/it, loss=0.7508, lr=1.60e-06]Steps:  76%|███████▋  | 3822/5000 [14:17:40<3:55:39, 12.00s/it, loss=0.7508, lr=1.60e-06]Steps:  76%|███████▋  | 3822/5000 [14:17:40<3:55:39, 12.00s/it, loss=1.1091, lr=1.60e-06]Steps:  76%|███████▋  | 3823/5000 [14:17:52<3:56:20, 12.05s/it, loss=1.1091, lr=1.60e-06]Steps:  76%|███████▋  | 3823/5000 [14:17:52<3:56:20, 12.05s/it, loss=1.0936, lr=1.60e-06]Steps:  76%|███████▋  | 3824/5000 [14:18:04<3:56:20, 12.06s/it, loss=1.0936, lr=1.60e-06]Steps:  76%|███████▋  | 3824/5000 [14:18:04<3:56:20, 12.06s/it, loss=0.5980, lr=1.59e-06]Steps:  76%|███████▋  | 3825/5000 [14:18:16<3:55:19, 12.02s/it, loss=0.5980, lr=1.59e-06]Steps:  76%|███████▋  | 3825/5000 [14:18:16<3:55:19, 12.02s/it, loss=1.0721, lr=1.59e-06]Steps:  77%|███████▋  | 3826/5000 [14:18:28<3:54:22, 11.98s/it, loss=1.0721, lr=1.59e-06]Steps:  77%|███████▋  | 3826/5000 [14:18:28<3:54:22, 11.98s/it, loss=1.1633, lr=1.59e-06]Steps:  77%|███████▋  | 3827/5000 [14:18:40<3:53:40, 11.95s/it, loss=1.1633, lr=1.59e-06]Steps:  77%|███████▋  | 3827/5000 [14:18:40<3:53:40, 11.95s/it, loss=0.8438, lr=1.58e-06]Steps:  77%|███████▋  | 3828/5000 [14:18:52<3:53:13, 11.94s/it, loss=0.8438, lr=1.58e-06]Steps:  77%|███████▋  | 3828/5000 [14:18:52<3:53:13, 11.94s/it, loss=0.9317, lr=1.58e-06]Steps:  77%|███████▋  | 3829/5000 [14:19:04<3:52:28, 11.91s/it, loss=0.9317, lr=1.58e-06]Steps:  77%|███████▋  | 3829/5000 [14:19:04<3:52:28, 11.91s/it, loss=0.8992, lr=1.58e-06]Steps:  77%|███████▋  | 3830/5000 [14:19:16<3:53:28, 11.97s/it, loss=0.8992, lr=1.58e-06]Steps:  77%|███████▋  | 3830/5000 [14:19:16<3:53:28, 11.97s/it, loss=0.7102, lr=1.58e-06]
[Step 3830] Training Debug Info:
  Loss: 0.369166
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0132, std: 0.8789
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0134, std: 1.3281
  Model pred mean: -0.0150, std: 1.1875
  Sigmas: [0.86328125]... (timesteps: [864.0])

[Step 3830] Training Debug Info:
  Loss: 0.892315
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0060, std: 0.8633
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0064, std: 1.3203
  Model pred mean: 0.0089, std: 0.9258
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 3830] Training Debug Info:
  Loss: 0.354283
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0042, std: 0.9141
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0022, std: 1.3594
  Model pred mean: -0.0040, std: 1.2109
  Sigmas: [0.91015625]... (timesteps: [909.0])

[Step 3830] Training Debug Info:
  Loss: 0.597372
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0081, std: 0.9219
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0078, std: 1.3594
  Model pred mean: -0.0143, std: 1.1328
  Sigmas: [0.94921875]... (timesteps: [951.0])
Steps:  77%|███████▋  | 3831/5000 [14:19:28<3:52:39, 11.94s/it, loss=0.7102, lr=1.58e-06]Steps:  77%|███████▋  | 3831/5000 [14:19:28<3:52:39, 11.94s/it, loss=0.5974, lr=1.57e-06]Steps:  77%|███████▋  | 3832/5000 [14:19:39<3:52:03, 11.92s/it, loss=0.5974, lr=1.57e-06]Steps:  77%|███████▋  | 3832/5000 [14:19:39<3:52:03, 11.92s/it, loss=0.3996, lr=1.57e-06]Steps:  77%|███████▋  | 3833/5000 [14:19:51<3:52:25, 11.95s/it, loss=0.3996, lr=1.57e-06]Steps:  77%|███████▋  | 3833/5000 [14:19:51<3:52:25, 11.95s/it, loss=1.0603, lr=1.57e-06]Steps:  77%|███████▋  | 3834/5000 [14:20:03<3:52:08, 11.95s/it, loss=1.0603, lr=1.57e-06]Steps:  77%|███████▋  | 3834/5000 [14:20:03<3:52:08, 11.95s/it, loss=1.0547, lr=1.57e-06]Steps:  77%|███████▋  | 3835/5000 [14:20:15<3:51:24, 11.92s/it, loss=1.0547, lr=1.57e-06]Steps:  77%|███████▋  | 3835/5000 [14:20:15<3:51:24, 11.92s/it, loss=0.7251, lr=1.56e-06]Steps:  77%|███████▋  | 3836/5000 [14:20:27<3:50:53, 11.90s/it, loss=0.7251, lr=1.56e-06]Steps:  77%|███████▋  | 3836/5000 [14:20:27<3:50:53, 11.90s/it, loss=0.7232, lr=1.56e-06]Steps:  77%|███████▋  | 3837/5000 [14:20:39<3:52:16, 11.98s/it, loss=0.7232, lr=1.56e-06]Steps:  77%|███████▋  | 3837/5000 [14:20:39<3:52:16, 11.98s/it, loss=0.3768, lr=1.56e-06]Steps:  77%|███████▋  | 3838/5000 [14:20:51<3:51:36, 11.96s/it, loss=0.3768, lr=1.56e-06]Steps:  77%|███████▋  | 3838/5000 [14:20:51<3:51:36, 11.96s/it, loss=0.9357, lr=1.56e-06]Steps:  77%|███████▋  | 3839/5000 [14:21:03<3:50:44, 11.92s/it, loss=0.9357, lr=1.56e-06]Steps:  77%|███████▋  | 3839/5000 [14:21:03<3:50:44, 11.92s/it, loss=1.0880, lr=1.55e-06]Steps:  77%|███████▋  | 3840/5000 [14:21:15<3:50:26, 11.92s/it, loss=1.0880, lr=1.55e-06]Steps:  77%|███████▋  | 3840/5000 [14:21:15<3:50:26, 11.92s/it, loss=0.6005, lr=1.55e-06]
[Step 3840] Training Debug Info:
  Loss: 0.653876
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0045, std: 0.9258
  Noise mean: 0.0006, std: 0.9961
  Target mean: 0.0051, std: 1.3594
  Model pred mean: 0.0043, std: 1.0938
  Sigmas: [0.5859375]... (timesteps: [585.0])

[Step 3840] Training Debug Info:
  Loss: 0.331928
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0413, std: 0.9492
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0413, std: 1.3750
  Model pred mean: -0.0295, std: 1.2578
  Sigmas: [0.78515625]... (timesteps: [786.0])

[Step 3840] Training Debug Info:
  Loss: 0.765113
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0066, std: 0.8633
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0052, std: 1.3203
  Model pred mean: -0.0034, std: 0.9883
  Sigmas: [0.5]... (timesteps: [500.0])

[Step 3840] Training Debug Info:
  Loss: 0.464979
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0302, std: 0.9375
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0310, std: 1.3672
  Model pred mean: -0.0291, std: 1.1953
  Sigmas: [0.65625]... (timesteps: [657.0])
Steps:  77%|███████▋  | 3841/5000 [14:21:27<3:49:45, 11.89s/it, loss=0.6005, lr=1.55e-06]Steps:  77%|███████▋  | 3841/5000 [14:21:27<3:49:45, 11.89s/it, loss=0.4650, lr=1.55e-06]Steps:  77%|███████▋  | 3842/5000 [14:21:39<3:51:29, 11.99s/it, loss=0.4650, lr=1.55e-06]Steps:  77%|███████▋  | 3842/5000 [14:21:39<3:51:29, 11.99s/it, loss=1.0236, lr=1.55e-06]Steps:  77%|███████▋  | 3843/5000 [14:21:51<3:51:35, 12.01s/it, loss=1.0236, lr=1.55e-06]Steps:  77%|███████▋  | 3843/5000 [14:21:51<3:51:35, 12.01s/it, loss=1.0757, lr=1.54e-06]Steps:  77%|███████▋  | 3844/5000 [14:22:03<3:50:53, 11.98s/it, loss=1.0757, lr=1.54e-06]Steps:  77%|███████▋  | 3844/5000 [14:22:03<3:50:53, 11.98s/it, loss=1.1519, lr=1.54e-06]Steps:  77%|███████▋  | 3845/5000 [14:22:15<3:50:27, 11.97s/it, loss=1.1519, lr=1.54e-06]Steps:  77%|███████▋  | 3845/5000 [14:22:15<3:50:27, 11.97s/it, loss=0.4061, lr=1.54e-06]Steps:  77%|███████▋  | 3846/5000 [14:22:27<3:50:01, 11.96s/it, loss=0.4061, lr=1.54e-06]Steps:  77%|███████▋  | 3846/5000 [14:22:27<3:50:01, 11.96s/it, loss=0.3774, lr=1.54e-06]Steps:  77%|███████▋  | 3847/5000 [14:22:39<3:49:49, 11.96s/it, loss=0.3774, lr=1.54e-06]Steps:  77%|███████▋  | 3847/5000 [14:22:39<3:49:49, 11.96s/it, loss=0.4227, lr=1.53e-06]Steps:  77%|███████▋  | 3848/5000 [14:22:51<3:50:04, 11.98s/it, loss=0.4227, lr=1.53e-06]Steps:  77%|███████▋  | 3848/5000 [14:22:51<3:50:04, 11.98s/it, loss=1.0961, lr=1.53e-06]Steps:  77%|███████▋  | 3849/5000 [14:23:03<3:49:35, 11.97s/it, loss=1.0961, lr=1.53e-06]Steps:  77%|███████▋  | 3849/5000 [14:23:03<3:49:35, 11.97s/it, loss=0.6760, lr=1.53e-06]Steps:  77%|███████▋  | 3850/5000 [14:23:15<3:50:20, 12.02s/it, loss=0.6760, lr=1.53e-06]Steps:  77%|███████▋  | 3850/5000 [14:23:15<3:50:20, 12.02s/it, loss=0.8796, lr=1.53e-06]
[Step 3850] Training Debug Info:
  Loss: 0.701822
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0102, std: 0.9258
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0075, std: 1.3594
  Model pred mean: -0.0251, std: 1.0859
  Sigmas: [0.953125]... (timesteps: [952.0])

[Step 3850] Training Debug Info:
  Loss: 0.667313
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0052, std: 0.9258
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0066, std: 1.3672
  Model pred mean: -0.0059, std: 1.0938
  Sigmas: [0.5390625]... (timesteps: [538.0])

[Step 3850] Training Debug Info:
  Loss: 1.058012
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0503, std: 0.9492
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0488, std: 1.3828
  Model pred mean: -0.0500, std: 0.9180
  Sigmas: [0.0458984375]... (timesteps: [46.0])

[Step 3850] Training Debug Info:
  Loss: 1.131792
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0062, std: 0.9258
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0054, std: 1.3594
  Model pred mean: -0.0073, std: 0.8477
  Sigmas: [0.125]... (timesteps: [125.0])
Steps:  77%|███████▋  | 3851/5000 [14:23:27<3:50:28, 12.03s/it, loss=0.8796, lr=1.53e-06]Steps:  77%|███████▋  | 3851/5000 [14:23:27<3:50:28, 12.03s/it, loss=1.1318, lr=1.52e-06]Steps:  77%|███████▋  | 3852/5000 [14:23:39<3:49:52, 12.01s/it, loss=1.1318, lr=1.52e-06]Steps:  77%|███████▋  | 3852/5000 [14:23:39<3:49:52, 12.01s/it, loss=0.3751, lr=1.52e-06]Steps:  77%|███████▋  | 3853/5000 [14:23:51<3:49:05, 11.98s/it, loss=0.3751, lr=1.52e-06]Steps:  77%|███████▋  | 3853/5000 [14:23:51<3:49:05, 11.98s/it, loss=1.1722, lr=1.52e-06]Steps:  77%|███████▋  | 3854/5000 [14:24:03<3:48:20, 11.96s/it, loss=1.1722, lr=1.52e-06]Steps:  77%|███████▋  | 3854/5000 [14:24:03<3:48:20, 11.96s/it, loss=0.5634, lr=1.52e-06]Steps:  77%|███████▋  | 3855/5000 [14:24:15<3:48:07, 11.95s/it, loss=0.5634, lr=1.52e-06]Steps:  77%|███████▋  | 3855/5000 [14:24:15<3:48:07, 11.95s/it, loss=1.0941, lr=1.51e-06]Steps:  77%|███████▋  | 3856/5000 [14:24:27<3:47:31, 11.93s/it, loss=1.0941, lr=1.51e-06]Steps:  77%|███████▋  | 3856/5000 [14:24:27<3:47:31, 11.93s/it, loss=1.0608, lr=1.51e-06]Steps:  77%|███████▋  | 3857/5000 [14:24:39<3:48:32, 12.00s/it, loss=1.0608, lr=1.51e-06]Steps:  77%|███████▋  | 3857/5000 [14:24:39<3:48:32, 12.00s/it, loss=0.6977, lr=1.51e-06]Steps:  77%|███████▋  | 3858/5000 [14:24:51<3:47:46, 11.97s/it, loss=0.6977, lr=1.51e-06]Steps:  77%|███████▋  | 3858/5000 [14:24:51<3:47:46, 11.97s/it, loss=0.5412, lr=1.51e-06]Steps:  77%|███████▋  | 3859/5000 [14:25:03<3:47:20, 11.95s/it, loss=0.5412, lr=1.51e-06]Steps:  77%|███████▋  | 3859/5000 [14:25:03<3:47:20, 11.95s/it, loss=1.0106, lr=1.50e-06]Steps:  77%|███████▋  | 3860/5000 [14:25:15<3:47:45, 11.99s/it, loss=1.0106, lr=1.50e-06]Steps:  77%|███████▋  | 3860/5000 [14:25:15<3:47:45, 11.99s/it, loss=0.5455, lr=1.50e-06]
[Step 3860] Training Debug Info:
  Loss: 0.552914
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0071, std: 0.9102
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0091, std: 1.3516
  Model pred mean: -0.0110, std: 1.1328
  Sigmas: [0.6328125]... (timesteps: [631.0])

[Step 3860] Training Debug Info:
  Loss: 0.448249
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0172, std: 0.8945
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0188, std: 1.3438
  Model pred mean: -0.0192, std: 1.1719
  Sigmas: [0.93359375]... (timesteps: [934.0])

[Step 3860] Training Debug Info:
  Loss: 0.767842
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0086, std: 0.9141
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0097, std: 1.3516
  Model pred mean: -0.0078, std: 1.0391
  Sigmas: [0.451171875]... (timesteps: [451.0])

[Step 3860] Training Debug Info:
  Loss: 0.383349
  Latent shape: torch.Size([1, 32, 84, 102]), Packed shape: torch.Size([1, 2142, 128])
  Latent mean: -0.0315, std: 0.9102
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0310, std: 1.3516
  Model pred mean: 0.0320, std: 1.2031
  Sigmas: [0.83984375]... (timesteps: [840.0])
Steps:  77%|███████▋  | 3861/5000 [14:25:26<3:46:48, 11.95s/it, loss=0.5455, lr=1.50e-06]Steps:  77%|███████▋  | 3861/5000 [14:25:26<3:46:48, 11.95s/it, loss=0.3833, lr=1.50e-06]Steps:  77%|███████▋  | 3862/5000 [14:25:38<3:46:18, 11.93s/it, loss=0.3833, lr=1.50e-06]Steps:  77%|███████▋  | 3862/5000 [14:25:38<3:46:18, 11.93s/it, loss=0.7195, lr=1.50e-06]Steps:  77%|███████▋  | 3863/5000 [14:25:50<3:46:04, 11.93s/it, loss=0.7195, lr=1.50e-06]Steps:  77%|███████▋  | 3863/5000 [14:25:50<3:46:04, 11.93s/it, loss=0.3903, lr=1.49e-06]Steps:  77%|███████▋  | 3864/5000 [14:26:02<3:47:07, 12.00s/it, loss=0.3903, lr=1.49e-06]Steps:  77%|███████▋  | 3864/5000 [14:26:02<3:47:07, 12.00s/it, loss=0.6503, lr=1.49e-06]Steps:  77%|███████▋  | 3865/5000 [14:26:14<3:46:18, 11.96s/it, loss=0.6503, lr=1.49e-06]Steps:  77%|███████▋  | 3865/5000 [14:26:14<3:46:18, 11.96s/it, loss=0.9180, lr=1.49e-06]Steps:  77%|███████▋  | 3866/5000 [14:26:26<3:45:26, 11.93s/it, loss=0.9180, lr=1.49e-06]Steps:  77%|███████▋  | 3866/5000 [14:26:26<3:45:26, 11.93s/it, loss=0.6577, lr=1.49e-06]Steps:  77%|███████▋  | 3867/5000 [14:26:38<3:44:43, 11.90s/it, loss=0.6577, lr=1.49e-06]Steps:  77%|███████▋  | 3867/5000 [14:26:38<3:44:43, 11.90s/it, loss=0.5313, lr=1.48e-06]Steps:  77%|███████▋  | 3868/5000 [14:26:50<3:44:45, 11.91s/it, loss=0.5313, lr=1.48e-06]Steps:  77%|███████▋  | 3868/5000 [14:26:50<3:44:45, 11.91s/it, loss=0.4630, lr=1.48e-06]Steps:  77%|███████▋  | 3869/5000 [14:27:02<3:44:43, 11.92s/it, loss=0.4630, lr=1.48e-06]Steps:  77%|███████▋  | 3869/5000 [14:27:02<3:44:43, 11.92s/it, loss=0.8905, lr=1.48e-06]Steps:  77%|███████▋  | 3870/5000 [14:27:14<3:46:12, 12.01s/it, loss=0.8905, lr=1.48e-06]Steps:  77%|███████▋  | 3870/5000 [14:27:14<3:46:12, 12.01s/it, loss=0.4090, lr=1.48e-06]
[Step 3870] Training Debug Info:
  Loss: 0.521885
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0160, std: 0.9258
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0151, std: 1.3594
  Model pred mean: -0.0146, std: 1.1562
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 3870] Training Debug Info:
  Loss: 0.398940
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0270, std: 0.9219
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0283, std: 1.3594
  Model pred mean: -0.0270, std: 1.2031
  Sigmas: [0.69921875]... (timesteps: [701.0])

[Step 3870] Training Debug Info:
  Loss: 0.388349
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0104, std: 0.9102
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0107, std: 1.3516
  Model pred mean: -0.0138, std: 1.1953
  Sigmas: [0.88671875]... (timesteps: [885.0])

[Step 3870] Training Debug Info:
  Loss: 0.567602
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0023, std: 0.8867
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0019, std: 1.3359
  Model pred mean: -0.0058, std: 1.1094
  Sigmas: [0.62890625]... (timesteps: [628.0])
Steps:  77%|███████▋  | 3871/5000 [14:27:26<3:45:40, 11.99s/it, loss=0.4090, lr=1.48e-06]Steps:  77%|███████▋  | 3871/5000 [14:27:26<3:45:40, 11.99s/it, loss=0.5676, lr=1.47e-06]Steps:  77%|███████▋  | 3872/5000 [14:27:38<3:45:08, 11.98s/it, loss=0.5676, lr=1.47e-06]Steps:  77%|███████▋  | 3872/5000 [14:27:38<3:45:08, 11.98s/it, loss=1.1439, lr=1.47e-06]Steps:  77%|███████▋  | 3873/5000 [14:27:50<3:44:54, 11.97s/it, loss=1.1439, lr=1.47e-06]Steps:  77%|███████▋  | 3873/5000 [14:27:50<3:44:54, 11.97s/it, loss=0.8042, lr=1.47e-06]Steps:  77%|███████▋  | 3874/5000 [14:28:02<3:44:35, 11.97s/it, loss=0.8042, lr=1.47e-06]Steps:  77%|███████▋  | 3874/5000 [14:28:02<3:44:35, 11.97s/it, loss=1.1111, lr=1.47e-06]Steps:  78%|███████▊  | 3875/5000 [14:28:14<3:43:36, 11.93s/it, loss=1.1111, lr=1.47e-06]Steps:  78%|███████▊  | 3875/5000 [14:28:14<3:43:36, 11.93s/it, loss=1.1454, lr=1.46e-06]Steps:  78%|███████▊  | 3876/5000 [14:28:26<3:43:28, 11.93s/it, loss=1.1454, lr=1.46e-06]Steps:  78%|███████▊  | 3876/5000 [14:28:26<3:43:28, 11.93s/it, loss=1.0559, lr=1.46e-06]Steps:  78%|███████▊  | 3877/5000 [14:28:38<3:44:43, 12.01s/it, loss=1.0559, lr=1.46e-06]Steps:  78%|███████▊  | 3877/5000 [14:28:38<3:44:43, 12.01s/it, loss=0.5801, lr=1.46e-06]Steps:  78%|███████▊  | 3878/5000 [14:28:50<3:44:40, 12.02s/it, loss=0.5801, lr=1.46e-06]Steps:  78%|███████▊  | 3878/5000 [14:28:50<3:44:40, 12.02s/it, loss=0.4703, lr=1.46e-06]Steps:  78%|███████▊  | 3879/5000 [14:29:02<3:44:07, 12.00s/it, loss=0.4703, lr=1.46e-06]Steps:  78%|███████▊  | 3879/5000 [14:29:02<3:44:07, 12.00s/it, loss=1.1115, lr=1.45e-06]Steps:  78%|███████▊  | 3880/5000 [14:29:14<3:43:28, 11.97s/it, loss=1.1115, lr=1.45e-06]Steps:  78%|███████▊  | 3880/5000 [14:29:14<3:43:28, 11.97s/it, loss=1.0452, lr=1.45e-06]
[Step 3880] Training Debug Info:
  Loss: 0.395350
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0117, std: 0.9414
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0127, std: 1.3750
  Model pred mean: 0.0149, std: 1.2188
  Sigmas: [0.765625]... (timesteps: [767.0])

[Step 3880] Training Debug Info:
  Loss: 1.015726
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0165, std: 0.9766
  Noise mean: 0.0002, std: 0.9961
  Target mean: 0.0166, std: 1.3984
  Model pred mean: 0.0150, std: 0.9727
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 3880] Training Debug Info:
  Loss: 0.808002
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0549, std: 0.9062
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0549, std: 1.3516
  Model pred mean: -0.0557, std: 1.0078
  Sigmas: [0.390625]... (timesteps: [390.0])

[Step 3880] Training Debug Info:
  Loss: 1.185554
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0049, std: 0.8633
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0068, std: 1.3203
  Model pred mean: -0.0036, std: 0.7539
  Sigmas: [0.1279296875]... (timesteps: [128.0])
Steps:  78%|███████▊  | 3881/5000 [14:29:26<3:43:08, 11.97s/it, loss=1.0452, lr=1.45e-06]Steps:  78%|███████▊  | 3881/5000 [14:29:26<3:43:08, 11.97s/it, loss=1.1856, lr=1.45e-06]Steps:  78%|███████▊  | 3882/5000 [14:29:38<3:43:00, 11.97s/it, loss=1.1856, lr=1.45e-06]Steps:  78%|███████▊  | 3882/5000 [14:29:38<3:43:00, 11.97s/it, loss=0.4234, lr=1.45e-06]Steps:  78%|███████▊  | 3883/5000 [14:29:50<3:42:13, 11.94s/it, loss=0.4234, lr=1.45e-06]Steps:  78%|███████▊  | 3883/5000 [14:29:50<3:42:13, 11.94s/it, loss=0.4202, lr=1.44e-06]Steps:  78%|███████▊  | 3884/5000 [14:30:02<3:42:57, 11.99s/it, loss=0.4202, lr=1.44e-06]Steps:  78%|███████▊  | 3884/5000 [14:30:02<3:42:57, 11.99s/it, loss=1.0458, lr=1.44e-06]Steps:  78%|███████▊  | 3885/5000 [14:30:14<3:42:12, 11.96s/it, loss=1.0458, lr=1.44e-06]Steps:  78%|███████▊  | 3885/5000 [14:30:14<3:42:12, 11.96s/it, loss=0.9368, lr=1.44e-06]Steps:  78%|███████▊  | 3886/5000 [14:30:25<3:41:44, 11.94s/it, loss=0.9368, lr=1.44e-06]Steps:  78%|███████▊  | 3886/5000 [14:30:25<3:41:44, 11.94s/it, loss=0.6516, lr=1.44e-06]Steps:  78%|███████▊  | 3887/5000 [14:30:38<3:42:29, 11.99s/it, loss=0.6516, lr=1.44e-06]Steps:  78%|███████▊  | 3887/5000 [14:30:38<3:42:29, 11.99s/it, loss=1.1565, lr=1.43e-06]Steps:  78%|███████▊  | 3888/5000 [14:30:50<3:41:46, 11.97s/it, loss=1.1565, lr=1.43e-06]Steps:  78%|███████▊  | 3888/5000 [14:30:50<3:41:46, 11.97s/it, loss=1.0907, lr=1.43e-06]Steps:  78%|███████▊  | 3889/5000 [14:31:01<3:40:54, 11.93s/it, loss=1.0907, lr=1.43e-06]Steps:  78%|███████▊  | 3889/5000 [14:31:01<3:40:54, 11.93s/it, loss=1.0830, lr=1.43e-06]Steps:  78%|███████▊  | 3890/5000 [14:31:13<3:40:05, 11.90s/it, loss=1.0830, lr=1.43e-06]Steps:  78%|███████▊  | 3890/5000 [14:31:13<3:40:05, 11.90s/it, loss=1.1116, lr=1.43e-06]
[Step 3890] Training Debug Info:
  Loss: 0.549298
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0053, std: 0.9180
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0058, std: 1.3594
  Model pred mean: 0.0117, std: 1.1328
  Sigmas: [0.92578125]... (timesteps: [924.0])

[Step 3890] Training Debug Info:
  Loss: 0.564614
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0234, std: 0.9023
  Noise mean: -0.0033, std: 0.9961
  Target mean: -0.0267, std: 1.3438
  Model pred mean: -0.0234, std: 1.1172
  Sigmas: [0.5546875]... (timesteps: [556.0])

[Step 3890] Training Debug Info:
  Loss: 0.468489
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0134, std: 0.9023
  Noise mean: 0.0009, std: 0.9961
  Target mean: 0.0143, std: 1.3438
  Model pred mean: 0.0098, std: 1.1641
  Sigmas: [0.671875]... (timesteps: [670.0])

[Step 3890] Training Debug Info:
  Loss: 0.578719
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0033, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0035, std: 1.3594
  Model pred mean: -0.0046, std: 1.1250
  Sigmas: [0.57421875]... (timesteps: [576.0])
Steps:  78%|███████▊  | 3891/5000 [14:31:25<3:41:07, 11.96s/it, loss=1.1116, lr=1.43e-06]Steps:  78%|███████▊  | 3891/5000 [14:31:25<3:41:07, 11.96s/it, loss=0.5787, lr=1.43e-06]Steps:  78%|███████▊  | 3892/5000 [14:31:37<3:40:32, 11.94s/it, loss=0.5787, lr=1.43e-06]Steps:  78%|███████▊  | 3892/5000 [14:31:37<3:40:32, 11.94s/it, loss=0.5087, lr=1.42e-06]Steps:  78%|███████▊  | 3893/5000 [14:31:49<3:40:14, 11.94s/it, loss=0.5087, lr=1.42e-06]Steps:  78%|███████▊  | 3893/5000 [14:31:49<3:40:14, 11.94s/it, loss=0.4797, lr=1.42e-06]Steps:  78%|███████▊  | 3894/5000 [14:32:01<3:39:42, 11.92s/it, loss=0.4797, lr=1.42e-06]Steps:  78%|███████▊  | 3894/5000 [14:32:01<3:39:42, 11.92s/it, loss=0.5309, lr=1.42e-06]Steps:  78%|███████▊  | 3895/5000 [14:32:13<3:39:29, 11.92s/it, loss=0.5309, lr=1.42e-06]Steps:  78%|███████▊  | 3895/5000 [14:32:13<3:39:29, 11.92s/it, loss=0.6076, lr=1.42e-06]Steps:  78%|███████▊  | 3896/5000 [14:32:25<3:41:16, 12.03s/it, loss=0.6076, lr=1.42e-06]Steps:  78%|███████▊  | 3896/5000 [14:32:25<3:41:16, 12.03s/it, loss=0.4431, lr=1.41e-06]Steps:  78%|███████▊  | 3897/5000 [14:32:37<3:42:04, 12.08s/it, loss=0.4431, lr=1.41e-06]Steps:  78%|███████▊  | 3897/5000 [14:32:37<3:42:04, 12.08s/it, loss=0.9525, lr=1.41e-06]Steps:  78%|███████▊  | 3898/5000 [14:32:49<3:40:52, 12.03s/it, loss=0.9525, lr=1.41e-06]Steps:  78%|███████▊  | 3898/5000 [14:32:49<3:40:52, 12.03s/it, loss=0.4012, lr=1.41e-06]Steps:  78%|███████▊  | 3899/5000 [14:33:01<3:40:17, 12.00s/it, loss=0.4012, lr=1.41e-06]Steps:  78%|███████▊  | 3899/5000 [14:33:01<3:40:17, 12.00s/it, loss=1.0631, lr=1.41e-06]Steps:  78%|███████▊  | 3900/5000 [14:33:13<3:39:51, 11.99s/it, loss=1.0631, lr=1.41e-06]Steps:  78%|███████▊  | 3900/5000 [14:33:13<3:39:51, 11.99s/it, loss=0.3961, lr=1.40e-06]01/22/2026 22:19:00 - INFO - __main__ - 
[Step 3900] ✅ Loss in normal range (0.3961)
01/22/2026 22:19:00 - INFO - __main__ -   Loss avg (last 100): 0.7823
01/22/2026 22:19:00 - INFO - __main__ -   Loss range: [0.3641, 1.1856]

[Step 3900] Training Debug Info:
  Loss: 0.765612
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0096, std: 0.8828
  Noise mean: -0.0043, std: 0.9961
  Target mean: 0.0054, std: 1.3359
  Model pred mean: 0.0092, std: 1.0078
  Sigmas: [0.494140625]... (timesteps: [495.0])

[Step 3900] Training Debug Info:
  Loss: 1.036971
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0124, std: 0.8867
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0112, std: 1.3359
  Model pred mean: 0.0113, std: 0.8672
  Sigmas: [0.341796875]... (timesteps: [342.0])

[Step 3900] Training Debug Info:
  Loss: 1.103059
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0193, std: 0.8789
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0186, std: 1.3281
  Model pred mean: 0.0211, std: 0.8164
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 3900] Training Debug Info:
  Loss: 0.613004
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0117, std: 1.3750
  Model pred mean: -0.0080, std: 1.1328
  Sigmas: [0.50390625]... (timesteps: [501.9999694824219])
Steps:  78%|███████▊  | 3901/5000 [14:33:25<3:39:28, 11.98s/it, loss=0.3961, lr=1.40e-06]Steps:  78%|███████▊  | 3901/5000 [14:33:25<3:39:28, 11.98s/it, loss=0.6130, lr=1.40e-06]Steps:  78%|███████▊  | 3902/5000 [14:33:37<3:39:06, 11.97s/it, loss=0.6130, lr=1.40e-06]Steps:  78%|███████▊  | 3902/5000 [14:33:37<3:39:06, 11.97s/it, loss=0.8738, lr=1.40e-06]Steps:  78%|███████▊  | 3903/5000 [14:33:49<3:38:48, 11.97s/it, loss=0.8738, lr=1.40e-06]Steps:  78%|███████▊  | 3903/5000 [14:33:49<3:38:48, 11.97s/it, loss=0.9163, lr=1.40e-06]Steps:  78%|███████▊  | 3904/5000 [14:34:01<3:39:37, 12.02s/it, loss=0.9163, lr=1.40e-06]Steps:  78%|███████▊  | 3904/5000 [14:34:01<3:39:37, 12.02s/it, loss=0.3364, lr=1.39e-06]Steps:  78%|███████▊  | 3905/5000 [14:34:13<3:39:31, 12.03s/it, loss=0.3364, lr=1.39e-06]Steps:  78%|███████▊  | 3905/5000 [14:34:13<3:39:31, 12.03s/it, loss=0.6748, lr=1.39e-06]Steps:  78%|███████▊  | 3906/5000 [14:34:25<3:38:24, 11.98s/it, loss=0.6748, lr=1.39e-06]Steps:  78%|███████▊  | 3906/5000 [14:34:25<3:38:24, 11.98s/it, loss=1.0333, lr=1.39e-06]Steps:  78%|███████▊  | 3907/5000 [14:34:37<3:38:15, 11.98s/it, loss=1.0333, lr=1.39e-06]Steps:  78%|███████▊  | 3907/5000 [14:34:37<3:38:15, 11.98s/it, loss=0.3596, lr=1.39e-06]Steps:  78%|███████▊  | 3908/5000 [14:34:49<3:37:52, 11.97s/it, loss=0.3596, lr=1.39e-06]Steps:  78%|███████▊  | 3908/5000 [14:34:49<3:37:52, 11.97s/it, loss=0.4260, lr=1.38e-06]Steps:  78%|███████▊  | 3909/5000 [14:35:01<3:37:42, 11.97s/it, loss=0.4260, lr=1.38e-06]Steps:  78%|███████▊  | 3909/5000 [14:35:01<3:37:42, 11.97s/it, loss=0.7979, lr=1.38e-06]Steps:  78%|███████▊  | 3910/5000 [14:35:13<3:36:52, 11.94s/it, loss=0.7979, lr=1.38e-06]Steps:  78%|███████▊  | 3910/5000 [14:35:13<3:36:52, 11.94s/it, loss=0.6112, lr=1.38e-06]
[Step 3910] Training Debug Info:
  Loss: 0.546938
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0060, std: 0.9375
  Noise mean: 0.0044, std: 1.0000
  Target mean: -0.0016, std: 1.3672
  Model pred mean: -0.0045, std: 1.1562
  Sigmas: [0.56640625]... (timesteps: [566.0])

[Step 3910] Training Debug Info:
  Loss: 0.402106
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0066, std: 0.9258
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0067, std: 1.3594
  Model pred mean: 0.0022, std: 1.2031
  Sigmas: [0.890625]... (timesteps: [892.0])

[Step 3910] Training Debug Info:
  Loss: 0.477247
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0190, std: 0.9727
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0189, std: 1.3984
  Model pred mean: -0.0192, std: 1.2031
  Sigmas: [0.73828125]... (timesteps: [740.0])

[Step 3910] Training Debug Info:
  Loss: 0.726666
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0398, std: 0.9258
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0386, std: 1.3594
  Model pred mean: 0.0386, std: 1.0625
  Sigmas: [0.4765625]... (timesteps: [477.0])
Steps:  78%|███████▊  | 3911/5000 [14:35:25<3:38:13, 12.02s/it, loss=0.6112, lr=1.38e-06]Steps:  78%|███████▊  | 3911/5000 [14:35:25<3:38:13, 12.02s/it, loss=0.7267, lr=1.38e-06]Steps:  78%|███████▊  | 3912/5000 [14:35:37<3:37:33, 12.00s/it, loss=0.7267, lr=1.38e-06]Steps:  78%|███████▊  | 3912/5000 [14:35:37<3:37:33, 12.00s/it, loss=1.0494, lr=1.37e-06]Steps:  78%|███████▊  | 3913/5000 [14:35:49<3:36:34, 11.95s/it, loss=1.0494, lr=1.37e-06]Steps:  78%|███████▊  | 3913/5000 [14:35:49<3:36:34, 11.95s/it, loss=1.1983, lr=1.37e-06]Steps:  78%|███████▊  | 3914/5000 [14:36:01<3:36:33, 11.96s/it, loss=1.1983, lr=1.37e-06]Steps:  78%|███████▊  | 3914/5000 [14:36:01<3:36:33, 11.96s/it, loss=1.0948, lr=1.37e-06]Steps:  78%|███████▊  | 3915/5000 [14:36:13<3:35:58, 11.94s/it, loss=1.0948, lr=1.37e-06]Steps:  78%|███████▊  | 3915/5000 [14:36:13<3:35:58, 11.94s/it, loss=0.4554, lr=1.37e-06]Steps:  78%|███████▊  | 3916/5000 [14:36:25<3:35:25, 11.92s/it, loss=0.4554, lr=1.37e-06]Steps:  78%|███████▊  | 3916/5000 [14:36:25<3:35:25, 11.92s/it, loss=0.4896, lr=1.36e-06]Steps:  78%|███████▊  | 3917/5000 [14:36:37<3:34:40, 11.89s/it, loss=0.4896, lr=1.36e-06]Steps:  78%|███████▊  | 3917/5000 [14:36:37<3:34:40, 11.89s/it, loss=0.4946, lr=1.36e-06]Steps:  78%|███████▊  | 3918/5000 [14:36:49<3:36:04, 11.98s/it, loss=0.4946, lr=1.36e-06]Steps:  78%|███████▊  | 3918/5000 [14:36:49<3:36:04, 11.98s/it, loss=1.1234, lr=1.36e-06]Steps:  78%|███████▊  | 3919/5000 [14:37:01<3:35:23, 11.95s/it, loss=1.1234, lr=1.36e-06]Steps:  78%|███████▊  | 3919/5000 [14:37:01<3:35:23, 11.95s/it, loss=0.4277, lr=1.36e-06]Steps:  78%|███████▊  | 3920/5000 [14:37:12<3:34:53, 11.94s/it, loss=0.4277, lr=1.36e-06]Steps:  78%|███████▊  | 3920/5000 [14:37:12<3:34:53, 11.94s/it, loss=1.0623, lr=1.36e-06]
[Step 3920] Training Debug Info:
  Loss: 0.362194
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0173, std: 0.9375
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0159, std: 1.3750
  Model pred mean: -0.0194, std: 1.2344
  Sigmas: [0.78515625]... (timesteps: [787.0])

[Step 3920] Training Debug Info:
  Loss: 1.091622
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0166, std: 0.9023
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0156, std: 1.3438
  Model pred mean: 0.0162, std: 0.8516
  Sigmas: [0.2734375]... (timesteps: [274.0])

[Step 3920] Training Debug Info:
  Loss: 1.063370
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0067, std: 0.9180
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0072, std: 1.3594
  Model pred mean: -0.0048, std: 0.8828
  Sigmas: [0.0400390625]... (timesteps: [40.0])

[Step 3920] Training Debug Info:
  Loss: 0.416162
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0654, std: 0.9375
  Noise mean: 0.0042, std: 1.0000
  Target mean: -0.0613, std: 1.3672
  Model pred mean: -0.0640, std: 1.2109
  Sigmas: [0.859375]... (timesteps: [860.0])
Steps:  78%|███████▊  | 3921/5000 [14:37:24<3:34:51, 11.95s/it, loss=1.0623, lr=1.36e-06]Steps:  78%|███████▊  | 3921/5000 [14:37:24<3:34:51, 11.95s/it, loss=0.4162, lr=1.35e-06]Steps:  78%|███████▊  | 3922/5000 [14:37:36<3:35:00, 11.97s/it, loss=0.4162, lr=1.35e-06]Steps:  78%|███████▊  | 3922/5000 [14:37:36<3:35:00, 11.97s/it, loss=0.7709, lr=1.35e-06]Steps:  78%|███████▊  | 3923/5000 [14:37:49<3:35:28, 12.00s/it, loss=0.7709, lr=1.35e-06]Steps:  78%|███████▊  | 3923/5000 [14:37:49<3:35:28, 12.00s/it, loss=0.7901, lr=1.35e-06]Steps:  78%|███████▊  | 3924/5000 [14:38:01<3:36:18, 12.06s/it, loss=0.7901, lr=1.35e-06]Steps:  78%|███████▊  | 3924/5000 [14:38:01<3:36:18, 12.06s/it, loss=0.4361, lr=1.35e-06]Steps:  78%|███████▊  | 3925/5000 [14:38:13<3:35:48, 12.05s/it, loss=0.4361, lr=1.35e-06]Steps:  78%|███████▊  | 3925/5000 [14:38:13<3:35:48, 12.05s/it, loss=0.7142, lr=1.34e-06]Steps:  79%|███████▊  | 3926/5000 [14:38:25<3:35:01, 12.01s/it, loss=0.7142, lr=1.34e-06]Steps:  79%|███████▊  | 3926/5000 [14:38:25<3:35:01, 12.01s/it, loss=0.3641, lr=1.34e-06]Steps:  79%|███████▊  | 3927/5000 [14:38:37<3:34:33, 12.00s/it, loss=0.3641, lr=1.34e-06]Steps:  79%|███████▊  | 3927/5000 [14:38:37<3:34:33, 12.00s/it, loss=0.4111, lr=1.34e-06]Steps:  79%|███████▊  | 3928/5000 [14:38:49<3:33:37, 11.96s/it, loss=0.4111, lr=1.34e-06]Steps:  79%|███████▊  | 3928/5000 [14:38:49<3:33:37, 11.96s/it, loss=0.5243, lr=1.34e-06]Steps:  79%|███████▊  | 3929/5000 [14:39:00<3:33:14, 11.95s/it, loss=0.5243, lr=1.34e-06]Steps:  79%|███████▊  | 3929/5000 [14:39:00<3:33:14, 11.95s/it, loss=1.1713, lr=1.33e-06]Steps:  79%|███████▊  | 3930/5000 [14:39:12<3:32:46, 11.93s/it, loss=1.1713, lr=1.33e-06]Steps:  79%|███████▊  | 3930/5000 [14:39:12<3:32:46, 11.93s/it, loss=1.0831, lr=1.33e-06]
[Step 3930] Training Debug Info:
  Loss: 0.478868
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0215, std: 0.9219
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0209, std: 1.3594
  Model pred mean: -0.0188, std: 1.1641
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 3930] Training Debug Info:
  Loss: 0.392668
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0063, std: 0.9180
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0043, std: 1.3516
  Model pred mean: 0.0046, std: 1.1953
  Sigmas: [0.84375]... (timesteps: [842.0])

[Step 3930] Training Debug Info:
  Loss: 0.752401
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0361, std: 0.9414
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0364, std: 1.3750
  Model pred mean: -0.0352, std: 1.0625
  Sigmas: [0.421875]... (timesteps: [422.0])

[Step 3930] Training Debug Info:
  Loss: 1.036188
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0063, std: 0.8711
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0077, std: 1.3281
  Model pred mean: -0.0053, std: 0.8477
  Sigmas: [0.0179443359375]... (timesteps: [18.0])
Steps:  79%|███████▊  | 3931/5000 [14:39:25<3:34:00, 12.01s/it, loss=1.0831, lr=1.33e-06]Steps:  79%|███████▊  | 3931/5000 [14:39:25<3:34:00, 12.01s/it, loss=1.0362, lr=1.33e-06]Steps:  79%|███████▊  | 3932/5000 [14:39:37<3:33:57, 12.02s/it, loss=1.0362, lr=1.33e-06]Steps:  79%|███████▊  | 3932/5000 [14:39:37<3:33:57, 12.02s/it, loss=1.1147, lr=1.33e-06]Steps:  79%|███████▊  | 3933/5000 [14:39:48<3:32:53, 11.97s/it, loss=1.1147, lr=1.33e-06]Steps:  79%|███████▊  | 3933/5000 [14:39:48<3:32:53, 11.97s/it, loss=0.7331, lr=1.32e-06]Steps:  79%|███████▊  | 3934/5000 [14:40:00<3:32:07, 11.94s/it, loss=0.7331, lr=1.32e-06]Steps:  79%|███████▊  | 3934/5000 [14:40:00<3:32:07, 11.94s/it, loss=0.7324, lr=1.32e-06]Steps:  79%|███████▊  | 3935/5000 [14:40:12<3:32:02, 11.95s/it, loss=0.7324, lr=1.32e-06]Steps:  79%|███████▊  | 3935/5000 [14:40:12<3:32:02, 11.95s/it, loss=1.1653, lr=1.32e-06]Steps:  79%|███████▊  | 3936/5000 [14:40:24<3:31:30, 11.93s/it, loss=1.1653, lr=1.32e-06]Steps:  79%|███████▊  | 3936/5000 [14:40:24<3:31:30, 11.93s/it, loss=0.5611, lr=1.32e-06]Steps:  79%|███████▊  | 3937/5000 [14:40:36<3:31:43, 11.95s/it, loss=0.5611, lr=1.32e-06]Steps:  79%|███████▊  | 3937/5000 [14:40:36<3:31:43, 11.95s/it, loss=1.0684, lr=1.31e-06]Steps:  79%|███████▉  | 3938/5000 [14:40:48<3:32:56, 12.03s/it, loss=1.0684, lr=1.31e-06]Steps:  79%|███████▉  | 3938/5000 [14:40:48<3:32:56, 12.03s/it, loss=0.5883, lr=1.31e-06]Steps:  79%|███████▉  | 3939/5000 [14:41:00<3:31:52, 11.98s/it, loss=0.5883, lr=1.31e-06]Steps:  79%|███████▉  | 3939/5000 [14:41:00<3:31:52, 11.98s/it, loss=0.6794, lr=1.31e-06]Steps:  79%|███████▉  | 3940/5000 [14:41:12<3:31:46, 11.99s/it, loss=0.6794, lr=1.31e-06]Steps:  79%|███████▉  | 3940/5000 [14:41:12<3:31:46, 11.99s/it, loss=0.6672, lr=1.31e-06]
[Step 3940] Training Debug Info:
  Loss: 0.973308
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0233, std: 0.9727
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0201, std: 1.3984
  Model pred mean: -0.0240, std: 0.9844
  Sigmas: [0.296875]... (timesteps: [297.0])

[Step 3940] Training Debug Info:
  Loss: 0.425176
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0654, std: 0.9531
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0640, std: 1.3828
  Model pred mean: -0.0598, std: 1.2188
  Sigmas: [0.77734375]... (timesteps: [779.0])

[Step 3940] Training Debug Info:
  Loss: 0.467082
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0214, std: 0.8945
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0194, std: 1.3438
  Model pred mean: 0.0193, std: 1.1562
  Sigmas: [0.71875]... (timesteps: [719.0])

[Step 3940] Training Debug Info:
  Loss: 0.559940
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0153, std: 0.9102
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0142, std: 1.3516
  Model pred mean: -0.0161, std: 1.1250
  Sigmas: [0.56640625]... (timesteps: [567.0])
Steps:  79%|███████▉  | 3941/5000 [14:41:24<3:32:06, 12.02s/it, loss=0.6672, lr=1.31e-06]Steps:  79%|███████▉  | 3941/5000 [14:41:24<3:32:06, 12.02s/it, loss=0.5599, lr=1.31e-06]Steps:  79%|███████▉  | 3942/5000 [14:41:36<3:31:32, 12.00s/it, loss=0.5599, lr=1.31e-06]Steps:  79%|███████▉  | 3942/5000 [14:41:36<3:31:32, 12.00s/it, loss=0.5565, lr=1.30e-06]Steps:  79%|███████▉  | 3943/5000 [14:41:48<3:31:11, 11.99s/it, loss=0.5565, lr=1.30e-06]Steps:  79%|███████▉  | 3943/5000 [14:41:48<3:31:11, 11.99s/it, loss=1.1229, lr=1.30e-06]Steps:  79%|███████▉  | 3944/5000 [14:42:00<3:30:39, 11.97s/it, loss=1.1229, lr=1.30e-06]Steps:  79%|███████▉  | 3944/5000 [14:42:00<3:30:39, 11.97s/it, loss=0.4249, lr=1.30e-06]Steps:  79%|███████▉  | 3945/5000 [14:42:12<3:31:19, 12.02s/it, loss=0.4249, lr=1.30e-06]Steps:  79%|███████▉  | 3945/5000 [14:42:12<3:31:19, 12.02s/it, loss=0.6987, lr=1.30e-06]Steps:  79%|███████▉  | 3946/5000 [14:42:24<3:30:45, 12.00s/it, loss=0.6987, lr=1.30e-06]Steps:  79%|███████▉  | 3946/5000 [14:42:24<3:30:45, 12.00s/it, loss=0.3665, lr=1.29e-06]Steps:  79%|███████▉  | 3947/5000 [14:42:36<3:30:08, 11.97s/it, loss=0.3665, lr=1.29e-06]Steps:  79%|███████▉  | 3947/5000 [14:42:36<3:30:08, 11.97s/it, loss=0.7636, lr=1.29e-06]Steps:  79%|███████▉  | 3948/5000 [14:42:48<3:29:47, 11.97s/it, loss=0.7636, lr=1.29e-06]Steps:  79%|███████▉  | 3948/5000 [14:42:48<3:29:47, 11.97s/it, loss=0.3953, lr=1.29e-06]Steps:  79%|███████▉  | 3949/5000 [14:43:00<3:29:20, 11.95s/it, loss=0.3953, lr=1.29e-06]Steps:  79%|███████▉  | 3949/5000 [14:43:00<3:29:20, 11.95s/it, loss=0.6503, lr=1.29e-06]Steps:  79%|███████▉  | 3950/5000 [14:43:12<3:29:52, 11.99s/it, loss=0.6503, lr=1.29e-06]Steps:  79%|███████▉  | 3950/5000 [14:43:12<3:29:52, 11.99s/it, loss=0.5655, lr=1.28e-06]
[Step 3950] Training Debug Info:
  Loss: 1.141400
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0025, std: 0.9219
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0000, std: 1.3594
  Model pred mean: -0.0038, std: 0.8398
  Sigmas: [0.10595703125]... (timesteps: [106.0])

[Step 3950] Training Debug Info:
  Loss: 0.465429
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0242, std: 0.9453
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0236, std: 1.3750
  Model pred mean: -0.0190, std: 1.1953
  Sigmas: [0.69921875]... (timesteps: [698.0])

[Step 3950] Training Debug Info:
  Loss: 0.765449
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0420, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0420, std: 1.3516
  Model pred mean: -0.0437, std: 1.0312
  Sigmas: [0.3984375]... (timesteps: [398.0])

[Step 3950] Training Debug Info:
  Loss: 0.780442
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0009, std: 0.9219
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0005, std: 1.3594
  Model pred mean: -0.0013, std: 1.0312
  Sigmas: [0.466796875]... (timesteps: [467.0])
Steps:  79%|███████▉  | 3951/5000 [14:43:24<3:30:29, 12.04s/it, loss=0.5655, lr=1.28e-06]Steps:  79%|███████▉  | 3951/5000 [14:43:24<3:30:29, 12.04s/it, loss=0.7804, lr=1.28e-06]Steps:  79%|███████▉  | 3952/5000 [14:43:36<3:29:38, 12.00s/it, loss=0.7804, lr=1.28e-06]Steps:  79%|███████▉  | 3952/5000 [14:43:36<3:29:38, 12.00s/it, loss=0.4193, lr=1.28e-06]Steps:  79%|███████▉  | 3953/5000 [14:43:48<3:29:04, 11.98s/it, loss=0.4193, lr=1.28e-06]Steps:  79%|███████▉  | 3953/5000 [14:43:48<3:29:04, 11.98s/it, loss=1.0146, lr=1.28e-06]Steps:  79%|███████▉  | 3954/5000 [14:44:00<3:28:13, 11.94s/it, loss=1.0146, lr=1.28e-06]Steps:  79%|███████▉  | 3954/5000 [14:44:00<3:28:13, 11.94s/it, loss=0.4310, lr=1.27e-06]Steps:  79%|███████▉  | 3955/5000 [14:44:12<3:27:33, 11.92s/it, loss=0.4310, lr=1.27e-06]Steps:  79%|███████▉  | 3955/5000 [14:44:12<3:27:33, 11.92s/it, loss=0.6227, lr=1.27e-06]Steps:  79%|███████▉  | 3956/5000 [14:44:24<3:27:01, 11.90s/it, loss=0.6227, lr=1.27e-06]Steps:  79%|███████▉  | 3956/5000 [14:44:24<3:27:01, 11.90s/it, loss=0.6212, lr=1.27e-06]Steps:  79%|███████▉  | 3957/5000 [14:44:36<3:26:53, 11.90s/it, loss=0.6212, lr=1.27e-06]Steps:  79%|███████▉  | 3957/5000 [14:44:36<3:26:53, 11.90s/it, loss=1.1998, lr=1.27e-06]Steps:  79%|███████▉  | 3958/5000 [14:44:48<3:28:30, 12.01s/it, loss=1.1998, lr=1.27e-06]Steps:  79%|███████▉  | 3958/5000 [14:44:48<3:28:30, 12.01s/it, loss=0.6847, lr=1.27e-06]Steps:  79%|███████▉  | 3959/5000 [14:45:00<3:28:51, 12.04s/it, loss=0.6847, lr=1.27e-06]Steps:  79%|███████▉  | 3959/5000 [14:45:00<3:28:51, 12.04s/it, loss=0.8840, lr=1.26e-06]Steps:  79%|███████▉  | 3960/5000 [14:45:12<3:28:10, 12.01s/it, loss=0.8840, lr=1.26e-06]Steps:  79%|███████▉  | 3960/5000 [14:45:12<3:28:10, 12.01s/it, loss=0.9988, lr=1.26e-06]
[Step 3960] Training Debug Info:
  Loss: 0.982439
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0079, std: 0.8984
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0078, std: 1.3438
  Model pred mean: -0.0094, std: 0.9102
  Sigmas: [0.31640625]... (timesteps: [317.0])

[Step 3960] Training Debug Info:
  Loss: 0.840601
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0236, std: 0.9219
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0232, std: 1.3594
  Model pred mean: -0.0229, std: 1.0000
  Sigmas: [0.38671875]... (timesteps: [387.0])

[Step 3960] Training Debug Info:
  Loss: 0.560749
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0210, std: 0.8984
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0208, std: 1.3438
  Model pred mean: -0.0192, std: 1.1172
  Sigmas: [0.625]... (timesteps: [626.0])

[Step 3960] Training Debug Info:
  Loss: 1.113973
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0215, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0223, std: 1.3516
  Model pred mean: -0.0194, std: 0.8438
  Sigmas: [0.10302734375]... (timesteps: [103.0])
Steps:  79%|███████▉  | 3961/5000 [14:45:24<3:27:30, 11.98s/it, loss=0.9988, lr=1.26e-06]Steps:  79%|███████▉  | 3961/5000 [14:45:24<3:27:30, 11.98s/it, loss=1.1140, lr=1.26e-06]Steps:  79%|███████▉  | 3962/5000 [14:45:36<3:26:50, 11.96s/it, loss=1.1140, lr=1.26e-06]Steps:  79%|███████▉  | 3962/5000 [14:45:36<3:26:50, 11.96s/it, loss=0.4707, lr=1.26e-06]Steps:  79%|███████▉  | 3963/5000 [14:45:48<3:26:40, 11.96s/it, loss=0.4707, lr=1.26e-06]Steps:  79%|███████▉  | 3963/5000 [14:45:48<3:26:40, 11.96s/it, loss=1.1055, lr=1.25e-06]Steps:  79%|███████▉  | 3964/5000 [14:46:00<3:26:14, 11.94s/it, loss=1.1055, lr=1.25e-06]Steps:  79%|███████▉  | 3964/5000 [14:46:00<3:26:14, 11.94s/it, loss=0.4647, lr=1.25e-06]Steps:  79%|███████▉  | 3965/5000 [14:46:12<3:26:54, 11.99s/it, loss=0.4647, lr=1.25e-06]Steps:  79%|███████▉  | 3965/5000 [14:46:12<3:26:54, 11.99s/it, loss=1.0412, lr=1.25e-06]Steps:  79%|███████▉  | 3966/5000 [14:46:24<3:26:20, 11.97s/it, loss=1.0412, lr=1.25e-06]Steps:  79%|███████▉  | 3966/5000 [14:46:24<3:26:20, 11.97s/it, loss=0.8182, lr=1.25e-06]Steps:  79%|███████▉  | 3967/5000 [14:46:36<3:25:50, 11.96s/it, loss=0.8182, lr=1.25e-06]Steps:  79%|███████▉  | 3967/5000 [14:46:36<3:25:50, 11.96s/it, loss=1.0605, lr=1.24e-06]Steps:  79%|███████▉  | 3968/5000 [14:46:48<3:26:04, 11.98s/it, loss=1.0605, lr=1.24e-06]Steps:  79%|███████▉  | 3968/5000 [14:46:48<3:26:04, 11.98s/it, loss=0.8380, lr=1.24e-06]Steps:  79%|███████▉  | 3969/5000 [14:46:59<3:25:26, 11.96s/it, loss=0.8380, lr=1.24e-06]Steps:  79%|███████▉  | 3969/5000 [14:46:59<3:25:26, 11.96s/it, loss=0.5162, lr=1.24e-06]Steps:  79%|███████▉  | 3970/5000 [14:47:11<3:24:59, 11.94s/it, loss=0.5162, lr=1.24e-06]Steps:  79%|███████▉  | 3970/5000 [14:47:11<3:24:59, 11.94s/it, loss=1.1786, lr=1.24e-06]
[Step 3970] Training Debug Info:
  Loss: 1.112381
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0369, std: 0.9219
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0361, std: 1.3594
  Model pred mean: 0.0376, std: 0.8594
  Sigmas: [0.27734375]... (timesteps: [278.0])

[Step 3970] Training Debug Info:
  Loss: 0.989263
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0026, std: 0.8945
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0023, std: 1.3438
  Model pred mean: -0.0038, std: 0.8984
  Sigmas: [0.359375]... (timesteps: [360.0])

[Step 3970] Training Debug Info:
  Loss: 1.061550
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0208, std: 0.9531
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0199, std: 1.3828
  Model pred mean: 0.0201, std: 0.9219
  Sigmas: [0.037109375]... (timesteps: [37.0])

[Step 3970] Training Debug Info:
  Loss: 0.402622
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9102
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0228, std: 1.3516
  Model pred mean: -0.0209, std: 1.1875
  Sigmas: [0.8515625]... (timesteps: [853.0])
Steps:  79%|███████▉  | 3971/5000 [14:47:23<3:24:51, 11.94s/it, loss=1.1786, lr=1.24e-06]Steps:  79%|███████▉  | 3971/5000 [14:47:23<3:24:51, 11.94s/it, loss=0.4026, lr=1.24e-06]Steps:  79%|███████▉  | 3972/5000 [14:47:36<3:25:54, 12.02s/it, loss=0.4026, lr=1.24e-06]Steps:  79%|███████▉  | 3972/5000 [14:47:36<3:25:54, 12.02s/it, loss=0.5934, lr=1.23e-06]Steps:  79%|███████▉  | 3973/5000 [14:47:47<3:25:18, 12.00s/it, loss=0.5934, lr=1.23e-06]Steps:  79%|███████▉  | 3973/5000 [14:47:47<3:25:18, 12.00s/it, loss=0.3849, lr=1.23e-06]Steps:  79%|███████▉  | 3974/5000 [14:47:59<3:24:45, 11.97s/it, loss=0.3849, lr=1.23e-06]Steps:  79%|███████▉  | 3974/5000 [14:47:59<3:24:45, 11.97s/it, loss=0.7814, lr=1.23e-06]Steps:  80%|███████▉  | 3975/5000 [14:48:11<3:24:29, 11.97s/it, loss=0.7814, lr=1.23e-06]Steps:  80%|███████▉  | 3975/5000 [14:48:11<3:24:29, 11.97s/it, loss=0.4221, lr=1.23e-06]Steps:  80%|███████▉  | 3976/5000 [14:48:23<3:24:23, 11.98s/it, loss=0.4221, lr=1.23e-06]Steps:  80%|███████▉  | 3976/5000 [14:48:23<3:24:23, 11.98s/it, loss=1.1179, lr=1.22e-06]Steps:  80%|███████▉  | 3977/5000 [14:48:35<3:24:21, 11.99s/it, loss=1.1179, lr=1.22e-06]Steps:  80%|███████▉  | 3977/5000 [14:48:35<3:24:21, 11.99s/it, loss=1.1178, lr=1.22e-06]Steps:  80%|███████▉  | 3978/5000 [14:48:48<3:25:33, 12.07s/it, loss=1.1178, lr=1.22e-06]Steps:  80%|███████▉  | 3978/5000 [14:48:48<3:25:33, 12.07s/it, loss=1.0905, lr=1.22e-06]Steps:  80%|███████▉  | 3979/5000 [14:49:00<3:24:54, 12.04s/it, loss=1.0905, lr=1.22e-06]Steps:  80%|███████▉  | 3979/5000 [14:49:00<3:24:54, 12.04s/it, loss=0.6221, lr=1.22e-06]Steps:  80%|███████▉  | 3980/5000 [14:49:11<3:24:04, 12.00s/it, loss=0.6221, lr=1.22e-06]Steps:  80%|███████▉  | 3980/5000 [14:49:11<3:24:04, 12.00s/it, loss=1.1410, lr=1.22e-06]
[Step 3980] Training Debug Info:
  Loss: 0.583609
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0322, std: 0.8750
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0297, std: 1.3281
  Model pred mean: 0.0256, std: 1.1094
  Sigmas: [0.98046875]... (timesteps: [982.0])

[Step 3980] Training Debug Info:
  Loss: 0.549377
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0033, std: 0.8984
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0037, std: 1.3438
  Model pred mean: 0.0082, std: 1.1172
  Sigmas: [0.6328125]... (timesteps: [633.0])

[Step 3980] Training Debug Info:
  Loss: 1.093153
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0378, std: 0.9023
  Noise mean: -0.0015, std: 0.9961
  Target mean: -0.0393, std: 1.3438
  Model pred mean: -0.0378, std: 0.8477
  Sigmas: [0.07421875]... (timesteps: [74.0])

[Step 3980] Training Debug Info:
  Loss: 1.147013
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0125, std: 0.9453
  Noise mean: -0.0029, std: 0.9961
  Target mean: -0.0154, std: 1.3750
  Model pred mean: -0.0134, std: 0.8633
  Sigmas: [0.138671875]... (timesteps: [139.0])
Steps:  80%|███████▉  | 3981/5000 [14:49:23<3:23:14, 11.97s/it, loss=1.1410, lr=1.22e-06]Steps:  80%|███████▉  | 3981/5000 [14:49:23<3:23:14, 11.97s/it, loss=1.1470, lr=1.21e-06]Steps:  80%|███████▉  | 3982/5000 [14:49:35<3:22:46, 11.95s/it, loss=1.1470, lr=1.21e-06]Steps:  80%|███████▉  | 3982/5000 [14:49:35<3:22:46, 11.95s/it, loss=0.9696, lr=1.21e-06]Steps:  80%|███████▉  | 3983/5000 [14:49:47<3:22:09, 11.93s/it, loss=0.9696, lr=1.21e-06]Steps:  80%|███████▉  | 3983/5000 [14:49:47<3:22:09, 11.93s/it, loss=0.9067, lr=1.21e-06]Steps:  80%|███████▉  | 3984/5000 [14:49:59<3:21:58, 11.93s/it, loss=0.9067, lr=1.21e-06]Steps:  80%|███████▉  | 3984/5000 [14:49:59<3:21:58, 11.93s/it, loss=1.0989, lr=1.21e-06]Steps:  80%|███████▉  | 3985/5000 [14:50:11<3:23:03, 12.00s/it, loss=1.0989, lr=1.21e-06]Steps:  80%|███████▉  | 3985/5000 [14:50:11<3:23:03, 12.00s/it, loss=0.5451, lr=1.20e-06]Steps:  80%|███████▉  | 3986/5000 [14:50:23<3:22:32, 11.98s/it, loss=0.5451, lr=1.20e-06]Steps:  80%|███████▉  | 3986/5000 [14:50:23<3:22:32, 11.98s/it, loss=0.4162, lr=1.20e-06]Steps:  80%|███████▉  | 3987/5000 [14:50:35<3:22:08, 11.97s/it, loss=0.4162, lr=1.20e-06]Steps:  80%|███████▉  | 3987/5000 [14:50:35<3:22:08, 11.97s/it, loss=0.4430, lr=1.20e-06]Steps:  80%|███████▉  | 3988/5000 [14:50:47<3:21:52, 11.97s/it, loss=0.4430, lr=1.20e-06]Steps:  80%|███████▉  | 3988/5000 [14:50:47<3:21:52, 11.97s/it, loss=1.0819, lr=1.20e-06]Steps:  80%|███████▉  | 3989/5000 [14:50:59<3:21:14, 11.94s/it, loss=1.0819, lr=1.20e-06]Steps:  80%|███████▉  | 3989/5000 [14:50:59<3:21:14, 11.94s/it, loss=0.6283, lr=1.19e-06]Steps:  80%|███████▉  | 3990/5000 [14:51:11<3:20:19, 11.90s/it, loss=0.6283, lr=1.19e-06]Steps:  80%|███████▉  | 3990/5000 [14:51:11<3:20:19, 11.90s/it, loss=1.0560, lr=1.19e-06]
[Step 3990] Training Debug Info:
  Loss: 0.370627
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0322, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0315, std: 1.3438
  Model pred mean: 0.0304, std: 1.2031
  Sigmas: [0.796875]... (timesteps: [797.0])

[Step 3990] Training Debug Info:
  Loss: 0.595513
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0034, std: 0.9258
  Noise mean: -0.0041, std: 1.0000
  Target mean: -0.0075, std: 1.3672
  Model pred mean: -0.0032, std: 1.1250
  Sigmas: [0.515625]... (timesteps: [514.0])

[Step 3990] Training Debug Info:
  Loss: 0.403617
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0282, std: 0.9023
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0289, std: 1.3438
  Model pred mean: -0.0281, std: 1.1875
  Sigmas: [0.75]... (timesteps: [751.0])

[Step 3990] Training Debug Info:
  Loss: 0.450238
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0041, std: 0.8828
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0031, std: 1.3359
  Model pred mean: 0.0056, std: 1.1562
  Sigmas: [0.7109375]... (timesteps: [710.0])
Steps:  80%|███████▉  | 3991/5000 [14:51:23<3:19:52, 11.89s/it, loss=1.0560, lr=1.19e-06]Steps:  80%|███████▉  | 3991/5000 [14:51:23<3:19:52, 11.89s/it, loss=0.4502, lr=1.19e-06]Steps:  80%|███████▉  | 3992/5000 [14:51:35<3:21:19, 11.98s/it, loss=0.4502, lr=1.19e-06]Steps:  80%|███████▉  | 3992/5000 [14:51:35<3:21:19, 11.98s/it, loss=0.9772, lr=1.19e-06]Steps:  80%|███████▉  | 3993/5000 [14:51:47<3:20:32, 11.95s/it, loss=0.9772, lr=1.19e-06]Steps:  80%|███████▉  | 3993/5000 [14:51:47<3:20:32, 11.95s/it, loss=0.3710, lr=1.19e-06]Steps:  80%|███████▉  | 3994/5000 [14:51:59<3:19:53, 11.92s/it, loss=0.3710, lr=1.19e-06]Steps:  80%|███████▉  | 3994/5000 [14:51:59<3:19:53, 11.92s/it, loss=0.4651, lr=1.18e-06]Steps:  80%|███████▉  | 3995/5000 [14:52:11<3:20:11, 11.95s/it, loss=0.4651, lr=1.18e-06]Steps:  80%|███████▉  | 3995/5000 [14:52:11<3:20:11, 11.95s/it, loss=1.2075, lr=1.18e-06]Steps:  80%|███████▉  | 3996/5000 [14:52:23<3:19:48, 11.94s/it, loss=1.2075, lr=1.18e-06]Steps:  80%|███████▉  | 3996/5000 [14:52:23<3:19:48, 11.94s/it, loss=0.4342, lr=1.18e-06]Steps:  80%|███████▉  | 3997/5000 [14:52:34<3:19:10, 11.91s/it, loss=0.4342, lr=1.18e-06]Steps:  80%|███████▉  | 3997/5000 [14:52:34<3:19:10, 11.91s/it, loss=0.8650, lr=1.18e-06]Steps:  80%|███████▉  | 3998/5000 [14:52:46<3:19:10, 11.93s/it, loss=0.8650, lr=1.18e-06]Steps:  80%|███████▉  | 3998/5000 [14:52:46<3:19:10, 11.93s/it, loss=1.1450, lr=1.17e-06]Steps:  80%|███████▉  | 3999/5000 [14:52:58<3:19:41, 11.97s/it, loss=1.1450, lr=1.17e-06]Steps:  80%|███████▉  | 3999/5000 [14:52:58<3:19:41, 11.97s/it, loss=0.3883, lr=1.17e-06]Steps:  80%|████████  | 4000/5000 [14:53:10<3:18:58, 11.94s/it, loss=0.3883, lr=1.17e-06]Steps:  80%|████████  | 4000/5000 [14:53:10<3:18:58, 11.94s/it, loss=0.6155, lr=1.17e-06]01/22/2026 22:38:57 - INFO - __main__ - 
[Step 4000] ✅ Loss in normal range (0.6155)
01/22/2026 22:38:57 - INFO - __main__ -   Loss avg (last 100): 0.7505
01/22/2026 22:38:57 - INFO - __main__ -   Loss range: [0.3364, 1.2075]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/transformer/diffusion_pytorch_model.safetensors
01/22/2026 22:39:57 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000
01/22/2026 22:39:57 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/accelerator
01/22/2026 22:39:57 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/22/2026 22:43:14 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/accelerator/pytorch_model
01/22/2026 22:43:14 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/accelerator/scheduler.bin
01/22/2026 22:43:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/accelerator/sampler.bin
01/22/2026 22:43:14 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-4000/accelerator/random_states_0.pkl
01/22/2026 22:43:14 - INFO - __main__ - Removing 1 old checkpoints
01/22/2026 22:43:23 - INFO - __main__ - 
🔍 Running validation at step 4000...
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4000 (parquet mode)...
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4000...
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 22:43:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.47it/s]
01/22/2026 22:43:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 22:43:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 22:44:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 22:44:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 22:44:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 22:44:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 22:44:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 22:44:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/22/2026 22:45:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 22:45:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 22:45:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 22:45:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 22:45:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 22:45:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 22:46:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 22:46:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:12,  1.31it/s][A
 46%|████▋     | 13/28 [00:09<00:11,  1.33it/s][A
 50%|█████     | 14/28 [00:10<00:10,  1.34it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.35it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.36it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.36it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:18<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.38it/s]
01/22/2026 22:46:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 22:46:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 22:46:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 22:46:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/22/2026 22:47:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 22:47:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 22:47:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000/step004000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 22:47:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 22:47:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 22:47:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004000
01/22/2026 22:47:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 4000] Training Debug Info:
  Loss: 0.805573
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0281, std: 0.8555
  Noise mean: 0.0048, std: 1.0000
  Target mean: 0.0330, std: 1.3125
  Model pred mean: 0.0272, std: 0.9570
  Sigmas: [0.486328125]... (timesteps: [487.0])

[Step 4000] Training Debug Info:
  Loss: 0.963180
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0442, std: 0.9102
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0461, std: 1.3516
  Model pred mean: -0.0439, std: 0.9297
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 4000] Training Debug Info:
  Loss: 0.400744
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0223, std: 0.9023
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0220, std: 1.3516
  Model pred mean: -0.0226, std: 1.1875
  Sigmas: [0.8203125]... (timesteps: [822.0])

[Step 4000] Training Debug Info:
  Loss: 0.516308
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0493, std: 0.9375
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0515, std: 1.3672
  Model pred mean: -0.0408, std: 1.1562
  Sigmas: [0.90234375]... (timesteps: [901.0])
Steps:  80%|████████  | 4001/5000 [15:02:11<47:17:54, 170.44s/it, loss=0.6155, lr=1.17e-06]Steps:  80%|████████  | 4001/5000 [15:02:11<47:17:54, 170.44s/it, loss=0.5163, lr=1.17e-06]Steps:  80%|████████  | 4002/5000 [15:02:22<34:04:00, 122.89s/it, loss=0.5163, lr=1.17e-06]Steps:  80%|████████  | 4002/5000 [15:02:22<34:04:00, 122.89s/it, loss=1.0235, lr=1.17e-06]Steps:  80%|████████  | 4003/5000 [15:02:34<24:48:40, 89.59s/it, loss=1.0235, lr=1.17e-06] Steps:  80%|████████  | 4003/5000 [15:02:34<24:48:40, 89.59s/it, loss=0.8770, lr=1.16e-06]Steps:  80%|████████  | 4004/5000 [15:02:46<18:21:00, 66.33s/it, loss=0.8770, lr=1.16e-06]Steps:  80%|████████  | 4004/5000 [15:02:46<18:21:00, 66.33s/it, loss=0.5676, lr=1.16e-06]Steps:  80%|████████  | 4005/5000 [15:02:58<13:49:06, 50.00s/it, loss=0.5676, lr=1.16e-06]Steps:  80%|████████  | 4005/5000 [15:02:58<13:49:06, 50.00s/it, loss=1.2126, lr=1.16e-06]Steps:  80%|████████  | 4006/5000 [15:03:10<10:40:07, 38.64s/it, loss=1.2126, lr=1.16e-06]Steps:  80%|████████  | 4006/5000 [15:03:10<10:40:07, 38.64s/it, loss=0.9318, lr=1.16e-06]Steps:  80%|████████  | 4007/5000 [15:03:23<8:28:20, 30.72s/it, loss=0.9318, lr=1.16e-06] Steps:  80%|████████  | 4007/5000 [15:03:23<8:28:20, 30.72s/it, loss=1.1214, lr=1.15e-06]Steps:  80%|████████  | 4008/5000 [15:03:35<6:54:35, 25.08s/it, loss=1.1214, lr=1.15e-06]Steps:  80%|████████  | 4008/5000 [15:03:35<6:54:35, 25.08s/it, loss=0.9123, lr=1.15e-06]Steps:  80%|████████  | 4009/5000 [15:03:47<5:49:00, 21.13s/it, loss=0.9123, lr=1.15e-06]Steps:  80%|████████  | 4009/5000 [15:03:47<5:49:00, 21.13s/it, loss=1.1496, lr=1.15e-06]Steps:  80%|████████  | 4010/5000 [15:03:58<5:02:58, 18.36s/it, loss=1.1496, lr=1.15e-06]Steps:  80%|████████  | 4010/5000 [15:03:58<5:02:58, 18.36s/it, loss=0.4367, lr=1.15e-06]
[Step 4010] Training Debug Info:
  Loss: 0.496809
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0293, std: 0.9219
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0315, std: 1.3594
  Model pred mean: -0.0291, std: 1.1719
  Sigmas: [0.85546875]... (timesteps: [854.0])

[Step 4010] Training Debug Info:
  Loss: 1.066310
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0025, std: 0.9570
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0038, std: 1.3828
  Model pred mean: -0.0003, std: 0.9258
  Sigmas: [0.17578125]... (timesteps: [176.0])

[Step 4010] Training Debug Info:
  Loss: 0.583261
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0037, std: 0.9180
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0060, std: 1.3594
  Model pred mean: -0.0044, std: 1.1250
  Sigmas: [0.91015625]... (timesteps: [911.0])

[Step 4010] Training Debug Info:
  Loss: 0.469730
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0038, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0052, std: 1.3516
  Model pred mean: -0.0034, std: 1.1641
  Sigmas: [0.66796875]... (timesteps: [668.0])
Steps:  80%|████████  | 4011/5000 [15:04:10<4:30:26, 16.41s/it, loss=0.4367, lr=1.15e-06]Steps:  80%|████████  | 4011/5000 [15:04:10<4:30:26, 16.41s/it, loss=0.4697, lr=1.15e-06]Steps:  80%|████████  | 4012/5000 [15:04:22<4:08:22, 15.08s/it, loss=0.4697, lr=1.15e-06]Steps:  80%|████████  | 4012/5000 [15:04:22<4:08:22, 15.08s/it, loss=0.9712, lr=1.14e-06]Steps:  80%|████████  | 4013/5000 [15:04:34<3:53:37, 14.20s/it, loss=0.9712, lr=1.14e-06]Steps:  80%|████████  | 4013/5000 [15:04:34<3:53:37, 14.20s/it, loss=1.1494, lr=1.14e-06]Steps:  80%|████████  | 4014/5000 [15:04:46<3:42:02, 13.51s/it, loss=1.1494, lr=1.14e-06]Steps:  80%|████████  | 4014/5000 [15:04:46<3:42:02, 13.51s/it, loss=0.3985, lr=1.14e-06]Steps:  80%|████████  | 4015/5000 [15:04:58<3:33:52, 13.03s/it, loss=0.3985, lr=1.14e-06]Steps:  80%|████████  | 4015/5000 [15:04:58<3:33:52, 13.03s/it, loss=1.1627, lr=1.14e-06]Steps:  80%|████████  | 4016/5000 [15:05:10<3:27:58, 12.68s/it, loss=1.1627, lr=1.14e-06]Steps:  80%|████████  | 4016/5000 [15:05:10<3:27:58, 12.68s/it, loss=1.1577, lr=1.13e-06]Steps:  80%|████████  | 4017/5000 [15:05:22<3:23:58, 12.45s/it, loss=1.1577, lr=1.13e-06]Steps:  80%|████████  | 4017/5000 [15:05:22<3:23:58, 12.45s/it, loss=1.0652, lr=1.13e-06]Steps:  80%|████████  | 4018/5000 [15:05:34<3:21:05, 12.29s/it, loss=1.0652, lr=1.13e-06]Steps:  80%|████████  | 4018/5000 [15:05:34<3:21:05, 12.29s/it, loss=1.1028, lr=1.13e-06]Steps:  80%|████████  | 4019/5000 [15:05:46<3:18:57, 12.17s/it, loss=1.1028, lr=1.13e-06]Steps:  80%|████████  | 4019/5000 [15:05:46<3:18:57, 12.17s/it, loss=0.7621, lr=1.13e-06]Steps:  80%|████████  | 4020/5000 [15:05:58<3:18:37, 12.16s/it, loss=0.7621, lr=1.13e-06]Steps:  80%|████████  | 4020/5000 [15:05:58<3:18:37, 12.16s/it, loss=0.4364, lr=1.13e-06]
[Step 4020] Training Debug Info:
  Loss: 0.590872
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0435, std: 0.9375
  Noise mean: -0.0001, std: 0.9961
  Target mean: -0.0435, std: 1.3672
  Model pred mean: -0.0422, std: 1.1328
  Sigmas: [0.51171875]... (timesteps: [510.0])

[Step 4020] Training Debug Info:
  Loss: 0.481361
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0126, std: 0.8594
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0111, std: 1.3125
  Model pred mean: 0.0132, std: 1.1172
  Sigmas: [0.7109375]... (timesteps: [709.0])

[Step 4020] Training Debug Info:
  Loss: 0.665512
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0048, std: 0.9414
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0031, std: 1.3750
  Model pred mean: -0.0066, std: 1.1094
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 4020] Training Debug Info:
  Loss: 0.407252
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0016, std: 0.9414
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0020, std: 1.3750
  Model pred mean: 0.0058, std: 1.2188
  Sigmas: [0.8203125]... (timesteps: [821.0])
Steps:  80%|████████  | 4021/5000 [15:06:10<3:17:07, 12.08s/it, loss=0.4364, lr=1.13e-06]Steps:  80%|████████  | 4021/5000 [15:06:10<3:17:07, 12.08s/it, loss=0.4073, lr=1.12e-06]Steps:  80%|████████  | 4022/5000 [15:06:22<3:16:03, 12.03s/it, loss=0.4073, lr=1.12e-06]Steps:  80%|████████  | 4022/5000 [15:06:22<3:16:03, 12.03s/it, loss=0.4906, lr=1.12e-06]Steps:  80%|████████  | 4023/5000 [15:06:34<3:15:18, 11.99s/it, loss=0.4906, lr=1.12e-06]Steps:  80%|████████  | 4023/5000 [15:06:34<3:15:18, 11.99s/it, loss=1.1239, lr=1.12e-06]Steps:  80%|████████  | 4024/5000 [15:06:46<3:15:33, 12.02s/it, loss=1.1239, lr=1.12e-06]Steps:  80%|████████  | 4024/5000 [15:06:46<3:15:33, 12.02s/it, loss=0.5823, lr=1.12e-06]Steps:  80%|████████  | 4025/5000 [15:06:58<3:14:53, 11.99s/it, loss=0.5823, lr=1.12e-06]Steps:  80%|████████  | 4025/5000 [15:06:58<3:14:53, 11.99s/it, loss=1.1008, lr=1.11e-06]Steps:  81%|████████  | 4026/5000 [15:07:10<3:14:22, 11.97s/it, loss=1.1008, lr=1.11e-06]Steps:  81%|████████  | 4026/5000 [15:07:10<3:14:22, 11.97s/it, loss=0.5617, lr=1.11e-06]Steps:  81%|████████  | 4027/5000 [15:07:22<3:14:51, 12.02s/it, loss=0.5617, lr=1.11e-06]Steps:  81%|████████  | 4027/5000 [15:07:22<3:14:51, 12.02s/it, loss=1.0497, lr=1.11e-06]Steps:  81%|████████  | 4028/5000 [15:07:34<3:14:37, 12.01s/it, loss=1.0497, lr=1.11e-06]Steps:  81%|████████  | 4028/5000 [15:07:34<3:14:37, 12.01s/it, loss=0.7737, lr=1.11e-06]Steps:  81%|████████  | 4029/5000 [15:07:46<3:13:49, 11.98s/it, loss=0.7737, lr=1.11e-06]Steps:  81%|████████  | 4029/5000 [15:07:46<3:13:49, 11.98s/it, loss=0.3597, lr=1.11e-06]Steps:  81%|████████  | 4030/5000 [15:07:58<3:13:27, 11.97s/it, loss=0.3597, lr=1.11e-06]Steps:  81%|████████  | 4030/5000 [15:07:58<3:13:27, 11.97s/it, loss=1.0559, lr=1.10e-06]
[Step 4030] Training Debug Info:
  Loss: 1.109978
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0359, std: 0.9336
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0386, std: 1.3672
  Model pred mean: -0.0347, std: 0.8711
  Sigmas: [0.14453125]... (timesteps: [145.0])

[Step 4030] Training Debug Info:
  Loss: 0.719095
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0056, std: 0.9531
  Noise mean: -0.0035, std: 0.9961
  Target mean: -0.0091, std: 1.3828
  Model pred mean: -0.0040, std: 1.0859
  Sigmas: [0.4375]... (timesteps: [438.0])

[Step 4030] Training Debug Info:
  Loss: 0.639192
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0040, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0048, std: 1.3516
  Model pred mean: 0.0041, std: 1.0859
  Sigmas: [0.54296875]... (timesteps: [542.0])

[Step 4030] Training Debug Info:
  Loss: 0.399740
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0234, std: 0.9141
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0215, std: 1.3516
  Model pred mean: -0.0221, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [859.0])
Steps:  81%|████████  | 4031/5000 [15:08:09<3:13:09, 11.96s/it, loss=1.0559, lr=1.10e-06]Steps:  81%|████████  | 4031/5000 [15:08:09<3:13:09, 11.96s/it, loss=0.3997, lr=1.10e-06]Steps:  81%|████████  | 4032/5000 [15:08:21<3:12:56, 11.96s/it, loss=0.3997, lr=1.10e-06]Steps:  81%|████████  | 4032/5000 [15:08:21<3:12:56, 11.96s/it, loss=0.7815, lr=1.10e-06]Steps:  81%|████████  | 4033/5000 [15:08:33<3:12:55, 11.97s/it, loss=0.7815, lr=1.10e-06]Steps:  81%|████████  | 4033/5000 [15:08:33<3:12:55, 11.97s/it, loss=1.0218, lr=1.10e-06]Steps:  81%|████████  | 4034/5000 [15:08:46<3:13:33, 12.02s/it, loss=1.0218, lr=1.10e-06]Steps:  81%|████████  | 4034/5000 [15:08:46<3:13:33, 12.02s/it, loss=1.0699, lr=1.09e-06]Steps:  81%|████████  | 4035/5000 [15:08:58<3:12:50, 11.99s/it, loss=1.0699, lr=1.09e-06]Steps:  81%|████████  | 4035/5000 [15:08:58<3:12:50, 11.99s/it, loss=0.3457, lr=1.09e-06]Steps:  81%|████████  | 4036/5000 [15:09:09<3:11:49, 11.94s/it, loss=0.3457, lr=1.09e-06]Steps:  81%|████████  | 4036/5000 [15:09:09<3:11:49, 11.94s/it, loss=1.1389, lr=1.09e-06]Steps:  81%|████████  | 4037/5000 [15:09:21<3:11:19, 11.92s/it, loss=1.1389, lr=1.09e-06]Steps:  81%|████████  | 4037/5000 [15:09:21<3:11:19, 11.92s/it, loss=0.6200, lr=1.09e-06]Steps:  81%|████████  | 4038/5000 [15:09:33<3:11:00, 11.91s/it, loss=0.6200, lr=1.09e-06]Steps:  81%|████████  | 4038/5000 [15:09:33<3:11:00, 11.91s/it, loss=0.5283, lr=1.09e-06]Steps:  81%|████████  | 4039/5000 [15:09:45<3:10:43, 11.91s/it, loss=0.5283, lr=1.09e-06]Steps:  81%|████████  | 4039/5000 [15:09:45<3:10:43, 11.91s/it, loss=0.8908, lr=1.08e-06]Steps:  81%|████████  | 4040/5000 [15:09:57<3:11:35, 11.97s/it, loss=0.8908, lr=1.08e-06]Steps:  81%|████████  | 4040/5000 [15:09:57<3:11:35, 11.97s/it, loss=0.5093, lr=1.08e-06]
[Step 4040] Training Debug Info:
  Loss: 1.094432
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0320, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0306, std: 1.3516
  Model pred mean: 0.0310, std: 0.8594
  Sigmas: [0.267578125]... (timesteps: [267.0])

[Step 4040] Training Debug Info:
  Loss: 0.416103
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0245, std: 0.9023
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0272, std: 1.3438
  Model pred mean: -0.0255, std: 1.1875
  Sigmas: [0.8671875]... (timesteps: [867.0])

[Step 4040] Training Debug Info:
  Loss: 0.652574
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0115, std: 0.9297
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0098, std: 1.3672
  Model pred mean: -0.0129, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [989.0])

[Step 4040] Training Debug Info:
  Loss: 0.885722
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0095, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0115, std: 1.3438
  Model pred mean: -0.0101, std: 0.9570
  Sigmas: [0.40234375]... (timesteps: [402.0])
Steps:  81%|████████  | 4041/5000 [15:10:09<3:11:12, 11.96s/it, loss=0.5093, lr=1.08e-06]Steps:  81%|████████  | 4041/5000 [15:10:09<3:11:12, 11.96s/it, loss=0.8857, lr=1.08e-06]Steps:  81%|████████  | 4042/5000 [15:10:21<3:11:26, 11.99s/it, loss=0.8857, lr=1.08e-06]Steps:  81%|████████  | 4042/5000 [15:10:21<3:11:26, 11.99s/it, loss=1.1396, lr=1.08e-06]Steps:  81%|████████  | 4043/5000 [15:10:33<3:10:54, 11.97s/it, loss=1.1396, lr=1.08e-06]Steps:  81%|████████  | 4043/5000 [15:10:33<3:10:54, 11.97s/it, loss=1.0065, lr=1.08e-06]Steps:  81%|████████  | 4044/5000 [15:10:45<3:10:32, 11.96s/it, loss=1.0065, lr=1.08e-06]Steps:  81%|████████  | 4044/5000 [15:10:45<3:10:32, 11.96s/it, loss=0.5428, lr=1.07e-06]Steps:  81%|████████  | 4045/5000 [15:10:57<3:10:09, 11.95s/it, loss=0.5428, lr=1.07e-06]Steps:  81%|████████  | 4045/5000 [15:10:57<3:10:09, 11.95s/it, loss=1.0604, lr=1.07e-06]Steps:  81%|████████  | 4046/5000 [15:11:09<3:09:50, 11.94s/it, loss=1.0604, lr=1.07e-06]Steps:  81%|████████  | 4046/5000 [15:11:09<3:09:50, 11.94s/it, loss=0.6365, lr=1.07e-06]Steps:  81%|████████  | 4047/5000 [15:11:21<3:10:49, 12.01s/it, loss=0.6365, lr=1.07e-06]Steps:  81%|████████  | 4047/5000 [15:11:21<3:10:49, 12.01s/it, loss=1.1128, lr=1.07e-06]Steps:  81%|████████  | 4048/5000 [15:11:33<3:10:08, 11.98s/it, loss=1.1128, lr=1.07e-06]Steps:  81%|████████  | 4048/5000 [15:11:33<3:10:08, 11.98s/it, loss=0.8159, lr=1.06e-06]Steps:  81%|████████  | 4049/5000 [15:11:45<3:09:47, 11.97s/it, loss=0.8159, lr=1.06e-06]Steps:  81%|████████  | 4049/5000 [15:11:45<3:09:47, 11.97s/it, loss=0.5541, lr=1.06e-06]Steps:  81%|████████  | 4050/5000 [15:11:57<3:09:49, 11.99s/it, loss=0.5541, lr=1.06e-06]Steps:  81%|████████  | 4050/5000 [15:11:57<3:09:49, 11.99s/it, loss=0.5424, lr=1.06e-06]
[Step 4050] Training Debug Info:
  Loss: 0.874794
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0008, std: 0.8750
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0030, std: 1.3281
  Model pred mean: 0.0011, std: 0.9492
  Sigmas: [0.455078125]... (timesteps: [455.0])

[Step 4050] Training Debug Info:
  Loss: 1.080059
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0654, std: 0.9219
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0645, std: 1.3672
  Model pred mean: -0.0645, std: 0.8789
  Sigmas: [0.14453125]... (timesteps: [145.0])

[Step 4050] Training Debug Info:
  Loss: 0.381646
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0021, std: 0.9180
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0019, std: 1.3516
  Model pred mean: 0.0039, std: 1.2109
  Sigmas: [0.86328125]... (timesteps: [862.0])

[Step 4050] Training Debug Info:
  Loss: 0.515099
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0107, std: 0.8711
  Noise mean: 0.0015, std: 0.9961
  Target mean: 0.0122, std: 1.3281
  Model pred mean: 0.0096, std: 1.1172
  Sigmas: [0.67578125]... (timesteps: [675.0])
Steps:  81%|████████  | 4051/5000 [15:12:09<3:10:23, 12.04s/it, loss=0.5424, lr=1.06e-06]Steps:  81%|████████  | 4051/5000 [15:12:09<3:10:23, 12.04s/it, loss=0.5151, lr=1.06e-06]Steps:  81%|████████  | 4052/5000 [15:12:21<3:09:24, 11.99s/it, loss=0.5151, lr=1.06e-06]Steps:  81%|████████  | 4052/5000 [15:12:21<3:09:24, 11.99s/it, loss=0.4947, lr=1.06e-06]Steps:  81%|████████  | 4053/5000 [15:12:33<3:09:00, 11.98s/it, loss=0.4947, lr=1.06e-06]Steps:  81%|████████  | 4053/5000 [15:12:33<3:09:00, 11.98s/it, loss=0.6458, lr=1.05e-06]Steps:  81%|████████  | 4054/5000 [15:12:45<3:09:19, 12.01s/it, loss=0.6458, lr=1.05e-06]Steps:  81%|████████  | 4054/5000 [15:12:45<3:09:19, 12.01s/it, loss=0.4559, lr=1.05e-06]Steps:  81%|████████  | 4055/5000 [15:12:57<3:08:51, 11.99s/it, loss=0.4559, lr=1.05e-06]Steps:  81%|████████  | 4055/5000 [15:12:57<3:08:51, 11.99s/it, loss=0.4652, lr=1.05e-06]Steps:  81%|████████  | 4056/5000 [15:13:09<3:08:19, 11.97s/it, loss=0.4652, lr=1.05e-06]Steps:  81%|████████  | 4056/5000 [15:13:09<3:08:19, 11.97s/it, loss=0.8270, lr=1.05e-06]Steps:  81%|████████  | 4057/5000 [15:13:21<3:08:07, 11.97s/it, loss=0.8270, lr=1.05e-06]Steps:  81%|████████  | 4057/5000 [15:13:21<3:08:07, 11.97s/it, loss=0.7925, lr=1.04e-06]Steps:  81%|████████  | 4058/5000 [15:13:33<3:07:42, 11.96s/it, loss=0.7925, lr=1.04e-06]Steps:  81%|████████  | 4058/5000 [15:13:33<3:07:42, 11.96s/it, loss=1.0361, lr=1.04e-06]Steps:  81%|████████  | 4059/5000 [15:13:45<3:07:01, 11.93s/it, loss=1.0361, lr=1.04e-06]Steps:  81%|████████  | 4059/5000 [15:13:45<3:07:01, 11.93s/it, loss=0.4313, lr=1.04e-06]Steps:  81%|████████  | 4060/5000 [15:13:57<3:07:24, 11.96s/it, loss=0.4313, lr=1.04e-06]Steps:  81%|████████  | 4060/5000 [15:13:57<3:07:24, 11.96s/it, loss=1.1614, lr=1.04e-06]
[Step 4060] Training Debug Info:
  Loss: 0.411872
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0173, std: 0.9609
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0161, std: 1.3906
  Model pred mean: -0.0183, std: 1.2266
  Sigmas: [0.80859375]... (timesteps: [808.0])

[Step 4060] Training Debug Info:
  Loss: 0.404558
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0162, std: 0.9258
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0137, std: 1.3594
  Model pred mean: -0.0181, std: 1.2031
  Sigmas: [0.8515625]... (timesteps: [853.0])

[Step 4060] Training Debug Info:
  Loss: 1.057023
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0018, std: 0.8906
  Noise mean: 0.0037, std: 1.0000
  Target mean: 0.0055, std: 1.3359
  Model pred mean: 0.0011, std: 0.8555
  Sigmas: [0.3359375]... (timesteps: [336.0])

[Step 4060] Training Debug Info:
  Loss: 0.571331
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0060, std: 0.8828
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0053, std: 1.3359
  Model pred mean: 0.0056, std: 1.1016
  Sigmas: [0.6171875]... (timesteps: [618.0])
Steps:  81%|████████  | 4061/5000 [15:14:09<3:08:18, 12.03s/it, loss=1.1614, lr=1.04e-06]Steps:  81%|████████  | 4061/5000 [15:14:09<3:08:18, 12.03s/it, loss=0.5713, lr=1.04e-06]Steps:  81%|████████  | 4062/5000 [15:14:21<3:07:47, 12.01s/it, loss=0.5713, lr=1.04e-06]Steps:  81%|████████  | 4062/5000 [15:14:21<3:07:47, 12.01s/it, loss=0.9709, lr=1.03e-06]Steps:  81%|████████▏ | 4063/5000 [15:14:33<3:07:22, 12.00s/it, loss=0.9709, lr=1.03e-06]Steps:  81%|████████▏ | 4063/5000 [15:14:33<3:07:22, 12.00s/it, loss=1.0510, lr=1.03e-06]Steps:  81%|████████▏ | 4064/5000 [15:14:45<3:06:51, 11.98s/it, loss=1.0510, lr=1.03e-06]Steps:  81%|████████▏ | 4064/5000 [15:14:45<3:06:51, 11.98s/it, loss=0.3880, lr=1.03e-06]Steps:  81%|████████▏ | 4065/5000 [15:14:57<3:06:24, 11.96s/it, loss=0.3880, lr=1.03e-06]Steps:  81%|████████▏ | 4065/5000 [15:14:57<3:06:24, 11.96s/it, loss=0.9850, lr=1.03e-06]Steps:  81%|████████▏ | 4066/5000 [15:15:09<3:05:59, 11.95s/it, loss=0.9850, lr=1.03e-06]Steps:  81%|████████▏ | 4066/5000 [15:15:09<3:05:59, 11.95s/it, loss=0.5394, lr=1.03e-06]Steps:  81%|████████▏ | 4067/5000 [15:15:21<3:06:50, 12.02s/it, loss=0.5394, lr=1.03e-06]Steps:  81%|████████▏ | 4067/5000 [15:15:21<3:06:50, 12.02s/it, loss=0.7234, lr=1.02e-06]Steps:  81%|████████▏ | 4068/5000 [15:15:33<3:06:05, 11.98s/it, loss=0.7234, lr=1.02e-06]Steps:  81%|████████▏ | 4068/5000 [15:15:33<3:06:05, 11.98s/it, loss=1.1602, lr=1.02e-06]Steps:  81%|████████▏ | 4069/5000 [15:15:45<3:06:00, 11.99s/it, loss=1.1602, lr=1.02e-06]Steps:  81%|████████▏ | 4069/5000 [15:15:45<3:06:00, 11.99s/it, loss=0.3705, lr=1.02e-06]Steps:  81%|████████▏ | 4070/5000 [15:15:57<3:05:34, 11.97s/it, loss=0.3705, lr=1.02e-06]Steps:  81%|████████▏ | 4070/5000 [15:15:57<3:05:34, 11.97s/it, loss=0.4502, lr=1.02e-06]
[Step 4070] Training Debug Info:
  Loss: 0.401019
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0052, std: 0.8906
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0058, std: 1.3438
  Model pred mean: -0.0075, std: 1.1719
  Sigmas: [0.91796875]... (timesteps: [917.0])

[Step 4070] Training Debug Info:
  Loss: 0.356305
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9453
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0167, std: 1.3750
  Model pred mean: -0.0167, std: 1.2422
  Sigmas: [0.73046875]... (timesteps: [731.0])

[Step 4070] Training Debug Info:
  Loss: 1.109518
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0131, std: 0.9141
  Noise mean: 0.0013, std: 1.0000
  Target mean: 0.0143, std: 1.3516
  Model pred mean: 0.0128, std: 0.8516
  Sigmas: [0.271484375]... (timesteps: [272.0])

[Step 4070] Training Debug Info:
  Loss: 0.398704
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0067, std: 0.8867
  Noise mean: -0.0014, std: 0.9961
  Target mean: -0.0081, std: 1.3359
  Model pred mean: -0.0049, std: 1.1797
  Sigmas: [0.90625]... (timesteps: [908.0])
Steps:  81%|████████▏ | 4071/5000 [15:16:08<3:05:01, 11.95s/it, loss=0.4502, lr=1.02e-06]Steps:  81%|████████▏ | 4071/5000 [15:16:08<3:05:01, 11.95s/it, loss=0.3987, lr=1.02e-06]Steps:  81%|████████▏ | 4072/5000 [15:16:20<3:04:43, 11.94s/it, loss=0.3987, lr=1.02e-06]Steps:  81%|████████▏ | 4072/5000 [15:16:20<3:04:43, 11.94s/it, loss=0.3993, lr=1.01e-06]Steps:  81%|████████▏ | 4073/5000 [15:16:32<3:04:16, 11.93s/it, loss=0.3993, lr=1.01e-06]Steps:  81%|████████▏ | 4073/5000 [15:16:32<3:04:16, 11.93s/it, loss=0.6355, lr=1.01e-06]Steps:  81%|████████▏ | 4074/5000 [15:16:44<3:05:14, 12.00s/it, loss=0.6355, lr=1.01e-06]Steps:  81%|████████▏ | 4074/5000 [15:16:44<3:05:14, 12.00s/it, loss=1.1193, lr=1.01e-06]Steps:  82%|████████▏ | 4075/5000 [15:16:56<3:04:42, 11.98s/it, loss=1.1193, lr=1.01e-06]Steps:  82%|████████▏ | 4075/5000 [15:16:56<3:04:42, 11.98s/it, loss=0.4722, lr=1.01e-06]Steps:  82%|████████▏ | 4076/5000 [15:17:08<3:04:13, 11.96s/it, loss=0.4722, lr=1.01e-06]Steps:  82%|████████▏ | 4076/5000 [15:17:08<3:04:13, 11.96s/it, loss=0.6566, lr=1.00e-06]Steps:  82%|████████▏ | 4077/5000 [15:17:20<3:03:53, 11.95s/it, loss=0.6566, lr=1.00e-06]Steps:  82%|████████▏ | 4077/5000 [15:17:20<3:03:53, 11.95s/it, loss=1.1368, lr=1.00e-06]Steps:  82%|████████▏ | 4078/5000 [15:17:32<3:03:56, 11.97s/it, loss=1.1368, lr=1.00e-06]Steps:  82%|████████▏ | 4078/5000 [15:17:32<3:03:56, 11.97s/it, loss=0.4185, lr=1.00e-06]Steps:  82%|████████▏ | 4079/5000 [15:17:44<3:03:40, 11.97s/it, loss=0.4185, lr=1.00e-06]Steps:  82%|████████▏ | 4079/5000 [15:17:44<3:03:40, 11.97s/it, loss=0.5781, lr=9.98e-07]Steps:  82%|████████▏ | 4080/5000 [15:17:56<3:02:58, 11.93s/it, loss=0.5781, lr=9.98e-07]Steps:  82%|████████▏ | 4080/5000 [15:17:56<3:02:58, 11.93s/it, loss=1.1644, lr=9.96e-07]
[Step 4080] Training Debug Info:
  Loss: 0.948821
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0089, std: 0.9844
  Noise mean: 0.0026, std: 1.0000
  Target mean: -0.0063, std: 1.4062
  Model pred mean: -0.0076, std: 1.0078
  Sigmas: [0.318359375]... (timesteps: [319.0])

[Step 4080] Training Debug Info:
  Loss: 1.025323
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0554, std: 0.9609
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0557, std: 1.3906
  Model pred mean: -0.0554, std: 0.9492
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 4080] Training Debug Info:
  Loss: 0.347305
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0273, std: 0.9023
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0298, std: 1.3438
  Model pred mean: -0.0283, std: 1.2109
  Sigmas: [0.87890625]... (timesteps: [879.0])

[Step 4080] Training Debug Info:
  Loss: 0.424071
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0209, std: 0.8867
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0195, std: 1.3359
  Model pred mean: 0.0173, std: 1.1562
  Sigmas: [0.9375]... (timesteps: [939.0])
Steps:  82%|████████▏ | 4081/5000 [15:18:08<3:03:18, 11.97s/it, loss=1.1644, lr=9.96e-07]Steps:  82%|████████▏ | 4081/5000 [15:18:08<3:03:18, 11.97s/it, loss=0.4241, lr=9.94e-07]Steps:  82%|████████▏ | 4082/5000 [15:18:20<3:02:41, 11.94s/it, loss=0.4241, lr=9.94e-07]Steps:  82%|████████▏ | 4082/5000 [15:18:20<3:02:41, 11.94s/it, loss=1.0134, lr=9.92e-07]Steps:  82%|████████▏ | 4083/5000 [15:18:32<3:02:02, 11.91s/it, loss=1.0134, lr=9.92e-07]Steps:  82%|████████▏ | 4083/5000 [15:18:32<3:02:02, 11.91s/it, loss=1.0528, lr=9.90e-07]Steps:  82%|████████▏ | 4084/5000 [15:18:44<3:02:00, 11.92s/it, loss=1.0528, lr=9.90e-07]Steps:  82%|████████▏ | 4084/5000 [15:18:44<3:02:00, 11.92s/it, loss=0.6921, lr=9.88e-07]Steps:  82%|████████▏ | 4085/5000 [15:18:56<3:01:40, 11.91s/it, loss=0.6921, lr=9.88e-07]Steps:  82%|████████▏ | 4085/5000 [15:18:56<3:01:40, 11.91s/it, loss=1.0691, lr=9.86e-07]Steps:  82%|████████▏ | 4086/5000 [15:19:08<3:01:18, 11.90s/it, loss=1.0691, lr=9.86e-07]Steps:  82%|████████▏ | 4086/5000 [15:19:08<3:01:18, 11.90s/it, loss=1.0876, lr=9.84e-07]Steps:  82%|████████▏ | 4087/5000 [15:19:20<3:01:41, 11.94s/it, loss=1.0876, lr=9.84e-07]Steps:  82%|████████▏ | 4087/5000 [15:19:20<3:01:41, 11.94s/it, loss=0.7654, lr=9.82e-07]Steps:  82%|████████▏ | 4088/5000 [15:19:32<3:02:45, 12.02s/it, loss=0.7654, lr=9.82e-07]Steps:  82%|████████▏ | 4088/5000 [15:19:32<3:02:45, 12.02s/it, loss=0.4251, lr=9.80e-07]Steps:  82%|████████▏ | 4089/5000 [15:19:44<3:01:35, 11.96s/it, loss=0.4251, lr=9.80e-07]Steps:  82%|████████▏ | 4089/5000 [15:19:44<3:01:35, 11.96s/it, loss=0.4372, lr=9.78e-07]Steps:  82%|████████▏ | 4090/5000 [15:19:56<3:01:25, 11.96s/it, loss=0.4372, lr=9.78e-07]Steps:  82%|████████▏ | 4090/5000 [15:19:56<3:01:25, 11.96s/it, loss=0.5805, lr=9.76e-07]
[Step 4090] Training Debug Info:
  Loss: 0.913775
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0127, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0138, std: 1.3672
  Model pred mean: 0.0107, std: 0.9688
  Sigmas: [0.33984375]... (timesteps: [339.0])

[Step 4090] Training Debug Info:
  Loss: 0.497717
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0242, std: 0.8672
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0251, std: 1.3281
  Model pred mean: 0.0222, std: 1.1250
  Sigmas: [0.703125]... (timesteps: [703.0])

[Step 4090] Training Debug Info:
  Loss: 1.079075
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0214, std: 1.0078
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0212, std: 1.4219
  Model pred mean: -0.0237, std: 0.9648
  Sigmas: [0.0751953125]... (timesteps: [75.0])

[Step 4090] Training Debug Info:
  Loss: 0.382618
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0084, std: 0.9062
  Noise mean: 0.0007, std: 0.9961
  Target mean: 0.0091, std: 1.3516
  Model pred mean: 0.0052, std: 1.2031
  Sigmas: [0.84765625]... (timesteps: [848.0])
Steps:  82%|████████▏ | 4091/5000 [15:20:08<3:01:18, 11.97s/it, loss=0.5805, lr=9.76e-07]Steps:  82%|████████▏ | 4091/5000 [15:20:08<3:01:18, 11.97s/it, loss=0.3826, lr=9.73e-07]Steps:  82%|████████▏ | 4092/5000 [15:20:19<3:01:06, 11.97s/it, loss=0.3826, lr=9.73e-07]Steps:  82%|████████▏ | 4092/5000 [15:20:19<3:01:06, 11.97s/it, loss=0.4629, lr=9.71e-07]Steps:  82%|████████▏ | 4093/5000 [15:20:31<3:00:41, 11.95s/it, loss=0.4629, lr=9.71e-07]Steps:  82%|████████▏ | 4093/5000 [15:20:31<3:00:41, 11.95s/it, loss=0.8235, lr=9.69e-07]Steps:  82%|████████▏ | 4094/5000 [15:20:44<3:01:15, 12.00s/it, loss=0.8235, lr=9.69e-07]Steps:  82%|████████▏ | 4094/5000 [15:20:44<3:01:15, 12.00s/it, loss=0.5247, lr=9.67e-07]Steps:  82%|████████▏ | 4095/5000 [15:20:55<3:00:51, 11.99s/it, loss=0.5247, lr=9.67e-07]Steps:  82%|████████▏ | 4095/5000 [15:20:55<3:00:51, 11.99s/it, loss=1.0495, lr=9.65e-07]Steps:  82%|████████▏ | 4096/5000 [15:21:08<3:00:56, 12.01s/it, loss=1.0495, lr=9.65e-07]Steps:  82%|████████▏ | 4096/5000 [15:21:08<3:00:56, 12.01s/it, loss=0.4775, lr=9.63e-07]Steps:  82%|████████▏ | 4097/5000 [15:21:20<3:00:33, 12.00s/it, loss=0.4775, lr=9.63e-07]Steps:  82%|████████▏ | 4097/5000 [15:21:20<3:00:33, 12.00s/it, loss=1.0370, lr=9.61e-07]Steps:  82%|████████▏ | 4098/5000 [15:21:31<2:59:55, 11.97s/it, loss=1.0370, lr=9.61e-07]Steps:  82%|████████▏ | 4098/5000 [15:21:31<2:59:55, 11.97s/it, loss=0.5658, lr=9.59e-07]Steps:  82%|████████▏ | 4099/5000 [15:21:43<2:59:43, 11.97s/it, loss=0.5658, lr=9.59e-07]Steps:  82%|████████▏ | 4099/5000 [15:21:43<2:59:43, 11.97s/it, loss=1.0025, lr=9.57e-07]Steps:  82%|████████▏ | 4100/5000 [15:21:55<2:59:28, 11.96s/it, loss=1.0025, lr=9.57e-07]Steps:  82%|████████▏ | 4100/5000 [15:21:55<2:59:28, 11.96s/it, loss=0.4739, lr=9.55e-07]01/22/2026 23:07:42 - INFO - __main__ - 
[Step 4100] ✅ Loss in normal range (0.4739)
01/22/2026 23:07:42 - INFO - __main__ -   Loss avg (last 100): 0.7589
01/22/2026 23:07:42 - INFO - __main__ -   Loss range: [0.3457, 1.2126]

[Step 4100] Training Debug Info:
  Loss: 1.185160
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0203, std: 0.8711
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0175, std: 1.3281
  Model pred mean: 0.0214, std: 0.7578
  Sigmas: [0.140625]... (timesteps: [141.0])

[Step 4100] Training Debug Info:
  Loss: 0.529726
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0073, std: 0.9336
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0050, std: 1.3672
  Model pred mean: 0.0036, std: 1.1562
  Sigmas: [0.60546875]... (timesteps: [605.0])

[Step 4100] Training Debug Info:
  Loss: 0.771138
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0275, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0281, std: 1.3438
  Model pred mean: -0.0242, std: 1.0078
  Sigmas: [0.423828125]... (timesteps: [424.0])

[Step 4100] Training Debug Info:
  Loss: 1.000316
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0129, std: 0.9062
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0117, std: 1.3516
  Model pred mean: 0.0122, std: 0.9102
  Sigmas: [0.00099945068359375]... (timesteps: [1.0])
Steps:  82%|████████▏ | 4101/5000 [15:22:07<3:00:04, 12.02s/it, loss=0.4739, lr=9.55e-07]Steps:  82%|████████▏ | 4101/5000 [15:22:07<3:00:04, 12.02s/it, loss=1.0003, lr=9.53e-07]Steps:  82%|████████▏ | 4102/5000 [15:22:19<2:59:17, 11.98s/it, loss=1.0003, lr=9.53e-07]Steps:  82%|████████▏ | 4102/5000 [15:22:19<2:59:17, 11.98s/it, loss=0.5735, lr=9.51e-07]Steps:  82%|████████▏ | 4103/5000 [15:22:31<2:58:36, 11.95s/it, loss=0.5735, lr=9.51e-07]Steps:  82%|████████▏ | 4103/5000 [15:22:31<2:58:36, 11.95s/it, loss=0.9609, lr=9.49e-07]Steps:  82%|████████▏ | 4104/5000 [15:22:43<2:58:11, 11.93s/it, loss=0.9609, lr=9.49e-07]Steps:  82%|████████▏ | 4104/5000 [15:22:43<2:58:11, 11.93s/it, loss=0.8235, lr=9.47e-07]Steps:  82%|████████▏ | 4105/5000 [15:22:55<2:58:36, 11.97s/it, loss=0.8235, lr=9.47e-07]Steps:  82%|████████▏ | 4105/5000 [15:22:55<2:58:36, 11.97s/it, loss=0.4648, lr=9.45e-07]Steps:  82%|████████▏ | 4106/5000 [15:23:07<2:58:05, 11.95s/it, loss=0.4648, lr=9.45e-07]Steps:  82%|████████▏ | 4106/5000 [15:23:07<2:58:05, 11.95s/it, loss=0.4028, lr=9.43e-07]Steps:  82%|████████▏ | 4107/5000 [15:23:19<2:57:43, 11.94s/it, loss=0.4028, lr=9.43e-07]Steps:  82%|████████▏ | 4107/5000 [15:23:19<2:57:43, 11.94s/it, loss=0.3963, lr=9.41e-07]Steps:  82%|████████▏ | 4108/5000 [15:23:31<2:58:18, 11.99s/it, loss=0.3963, lr=9.41e-07]Steps:  82%|████████▏ | 4108/5000 [15:23:31<2:58:18, 11.99s/it, loss=0.8149, lr=9.39e-07]Steps:  82%|████████▏ | 4109/5000 [15:23:43<2:57:47, 11.97s/it, loss=0.8149, lr=9.39e-07]Steps:  82%|████████▏ | 4109/5000 [15:23:43<2:57:47, 11.97s/it, loss=1.1491, lr=9.37e-07]Steps:  82%|████████▏ | 4110/5000 [15:23:55<2:57:23, 11.96s/it, loss=1.1491, lr=9.37e-07]Steps:  82%|████████▏ | 4110/5000 [15:23:55<2:57:23, 11.96s/it, loss=1.1573, lr=9.34e-07]
[Step 4110] Training Debug Info:
  Loss: 1.018162
  Latent shape: torch.Size([1, 32, 54, 156]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0249, std: 0.9180
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0253, std: 1.3516
  Model pred mean: 0.0271, std: 0.9062
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 4110] Training Debug Info:
  Loss: 1.104867
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0254, std: 0.9531
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0266, std: 1.3828
  Model pred mean: 0.0242, std: 0.8945
  Sigmas: [0.2041015625]... (timesteps: [204.0])

[Step 4110] Training Debug Info:
  Loss: 1.123455
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0062, std: 0.9062
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0044, std: 1.3516
  Model pred mean: 0.0077, std: 0.8320
  Sigmas: [0.1650390625]... (timesteps: [165.0])

[Step 4110] Training Debug Info:
  Loss: 0.764676
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0374, std: 0.9961
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0376, std: 1.4141
  Model pred mean: -0.0400, std: 1.1094
  Sigmas: [0.482421875]... (timesteps: [483.0])
Steps:  82%|████████▏ | 4111/5000 [15:24:07<2:56:41, 11.93s/it, loss=1.1573, lr=9.34e-07]Steps:  82%|████████▏ | 4111/5000 [15:24:07<2:56:41, 11.93s/it, loss=0.7647, lr=9.32e-07]Steps:  82%|████████▏ | 4112/5000 [15:24:19<2:56:28, 11.92s/it, loss=0.7647, lr=9.32e-07]Steps:  82%|████████▏ | 4112/5000 [15:24:19<2:56:28, 11.92s/it, loss=1.1241, lr=9.30e-07]Steps:  82%|████████▏ | 4113/5000 [15:24:31<2:56:05, 11.91s/it, loss=1.1241, lr=9.30e-07]Steps:  82%|████████▏ | 4113/5000 [15:24:31<2:56:05, 11.91s/it, loss=1.0913, lr=9.28e-07]Steps:  82%|████████▏ | 4114/5000 [15:24:43<2:56:48, 11.97s/it, loss=1.0913, lr=9.28e-07]Steps:  82%|████████▏ | 4114/5000 [15:24:43<2:56:48, 11.97s/it, loss=0.3579, lr=9.26e-07]Steps:  82%|████████▏ | 4115/5000 [15:24:55<2:57:55, 12.06s/it, loss=0.3579, lr=9.26e-07]Steps:  82%|████████▏ | 4115/5000 [15:24:55<2:57:55, 12.06s/it, loss=1.1788, lr=9.24e-07]Steps:  82%|████████▏ | 4116/5000 [15:25:07<2:57:21, 12.04s/it, loss=1.1788, lr=9.24e-07]Steps:  82%|████████▏ | 4116/5000 [15:25:07<2:57:21, 12.04s/it, loss=0.5345, lr=9.22e-07]Steps:  82%|████████▏ | 4117/5000 [15:25:19<2:56:51, 12.02s/it, loss=0.5345, lr=9.22e-07]Steps:  82%|████████▏ | 4117/5000 [15:25:19<2:56:51, 12.02s/it, loss=1.0901, lr=9.20e-07]Steps:  82%|████████▏ | 4118/5000 [15:25:31<2:56:21, 12.00s/it, loss=1.0901, lr=9.20e-07]Steps:  82%|████████▏ | 4118/5000 [15:25:31<2:56:21, 12.00s/it, loss=0.6044, lr=9.18e-07]Steps:  82%|████████▏ | 4119/5000 [15:25:43<2:56:01, 11.99s/it, loss=0.6044, lr=9.18e-07]Steps:  82%|████████▏ | 4119/5000 [15:25:43<2:56:01, 11.99s/it, loss=0.5554, lr=9.16e-07]Steps:  82%|████████▏ | 4120/5000 [15:25:55<2:55:44, 11.98s/it, loss=0.5554, lr=9.16e-07]Steps:  82%|████████▏ | 4120/5000 [15:25:55<2:55:44, 11.98s/it, loss=0.4861, lr=9.14e-07]
[Step 4120] Training Debug Info:
  Loss: 0.422216
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0452, std: 0.9609
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0461, std: 1.3906
  Model pred mean: -0.0430, std: 1.2266
  Sigmas: [0.74609375]... (timesteps: [747.0])

[Step 4120] Training Debug Info:
  Loss: 1.028613
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0064, std: 0.9414
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0066, std: 1.3750
  Model pred mean: -0.0060, std: 0.9258
  Sigmas: [0.0150146484375]... (timesteps: [15.0])

[Step 4120] Training Debug Info:
  Loss: 0.589670
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0054, std: 0.8711
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0056, std: 1.3281
  Model pred mean: -0.0056, std: 1.0859
  Sigmas: [0.59375]... (timesteps: [593.0])

[Step 4120] Training Debug Info:
  Loss: 0.673920
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0159, std: 0.9297
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0190, std: 1.3672
  Model pred mean: 0.0108, std: 1.0938
  Sigmas: [0.96484375]... (timesteps: [966.0])
Steps:  82%|████████▏ | 4121/5000 [15:26:07<2:56:20, 12.04s/it, loss=0.4861, lr=9.14e-07]Steps:  82%|████████▏ | 4121/5000 [15:26:07<2:56:20, 12.04s/it, loss=0.6739, lr=9.12e-07]Steps:  82%|████████▏ | 4122/5000 [15:26:19<2:55:54, 12.02s/it, loss=0.6739, lr=9.12e-07]Steps:  82%|████████▏ | 4122/5000 [15:26:19<2:55:54, 12.02s/it, loss=0.3854, lr=9.10e-07]Steps:  82%|████████▏ | 4123/5000 [15:26:31<2:55:44, 12.02s/it, loss=0.3854, lr=9.10e-07]Steps:  82%|████████▏ | 4123/5000 [15:26:31<2:55:44, 12.02s/it, loss=0.6085, lr=9.08e-07]Steps:  82%|████████▏ | 4124/5000 [15:26:43<2:54:46, 11.97s/it, loss=0.6085, lr=9.08e-07]Steps:  82%|████████▏ | 4124/5000 [15:26:43<2:54:46, 11.97s/it, loss=0.5592, lr=9.06e-07]Steps:  82%|████████▎ | 4125/5000 [15:26:55<2:53:56, 11.93s/it, loss=0.5592, lr=9.06e-07]Steps:  82%|████████▎ | 4125/5000 [15:26:55<2:53:56, 11.93s/it, loss=0.4197, lr=9.04e-07]Steps:  83%|████████▎ | 4126/5000 [15:27:07<2:53:58, 11.94s/it, loss=0.4197, lr=9.04e-07]Steps:  83%|████████▎ | 4126/5000 [15:27:07<2:53:58, 11.94s/it, loss=0.4205, lr=9.02e-07]Steps:  83%|████████▎ | 4127/5000 [15:27:19<2:53:34, 11.93s/it, loss=0.4205, lr=9.02e-07]Steps:  83%|████████▎ | 4127/5000 [15:27:19<2:53:34, 11.93s/it, loss=0.6268, lr=9.00e-07]Steps:  83%|████████▎ | 4128/5000 [15:27:31<2:54:28, 12.01s/it, loss=0.6268, lr=9.00e-07]Steps:  83%|████████▎ | 4128/5000 [15:27:31<2:54:28, 12.01s/it, loss=0.4202, lr=8.98e-07]Steps:  83%|████████▎ | 4129/5000 [15:27:43<2:53:33, 11.96s/it, loss=0.4202, lr=8.98e-07]Steps:  83%|████████▎ | 4129/5000 [15:27:43<2:53:33, 11.96s/it, loss=1.2029, lr=8.96e-07]Steps:  83%|████████▎ | 4130/5000 [15:27:55<2:53:30, 11.97s/it, loss=1.2029, lr=8.96e-07]Steps:  83%|████████▎ | 4130/5000 [15:27:55<2:53:30, 11.97s/it, loss=1.1624, lr=8.94e-07]
[Step 4130] Training Debug Info:
  Loss: 0.348299
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0023, std: 0.9375
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0031, std: 1.3672
  Model pred mean: 0.0009, std: 1.2344
  Sigmas: [0.84765625]... (timesteps: [849.0])

[Step 4130] Training Debug Info:
  Loss: 1.173054
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0004, std: 0.8984
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0001, std: 1.3438
  Model pred mean: 0.0001, std: 0.7969
  Sigmas: [0.21484375]... (timesteps: [215.0])

[Step 4130] Training Debug Info:
  Loss: 0.863957
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0630, std: 0.9375
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0645, std: 1.3672
  Model pred mean: 0.0625, std: 1.0000
  Sigmas: [0.37109375]... (timesteps: [372.0])

[Step 4130] Training Debug Info:
  Loss: 1.099638
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0155, std: 0.9297
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0137, std: 1.3672
  Model pred mean: -0.0140, std: 0.8750
  Sigmas: [0.10693359375]... (timesteps: [107.0])
Steps:  83%|████████▎ | 4131/5000 [15:28:07<2:53:06, 11.95s/it, loss=1.1624, lr=8.94e-07]Steps:  83%|████████▎ | 4131/5000 [15:28:07<2:53:06, 11.95s/it, loss=1.0996, lr=8.92e-07]Steps:  83%|████████▎ | 4132/5000 [15:28:19<2:53:22, 11.98s/it, loss=1.0996, lr=8.92e-07]Steps:  83%|████████▎ | 4132/5000 [15:28:19<2:53:22, 11.98s/it, loss=1.0314, lr=8.90e-07]Steps:  83%|████████▎ | 4133/5000 [15:28:31<2:53:10, 11.98s/it, loss=1.0314, lr=8.90e-07]Steps:  83%|████████▎ | 4133/5000 [15:28:31<2:53:10, 11.98s/it, loss=1.1017, lr=8.88e-07]Steps:  83%|████████▎ | 4134/5000 [15:28:42<2:52:41, 11.96s/it, loss=1.1017, lr=8.88e-07]Steps:  83%|████████▎ | 4134/5000 [15:28:42<2:52:41, 11.96s/it, loss=0.5717, lr=8.86e-07]Steps:  83%|████████▎ | 4135/5000 [15:28:55<2:53:18, 12.02s/it, loss=0.5717, lr=8.86e-07]Steps:  83%|████████▎ | 4135/5000 [15:28:55<2:53:18, 12.02s/it, loss=1.0147, lr=8.84e-07]Steps:  83%|████████▎ | 4136/5000 [15:29:07<2:52:35, 11.99s/it, loss=1.0147, lr=8.84e-07]Steps:  83%|████████▎ | 4136/5000 [15:29:07<2:52:35, 11.99s/it, loss=1.0091, lr=8.82e-07]Steps:  83%|████████▎ | 4137/5000 [15:29:18<2:52:06, 11.97s/it, loss=1.0091, lr=8.82e-07]Steps:  83%|████████▎ | 4137/5000 [15:29:18<2:52:06, 11.97s/it, loss=1.1757, lr=8.80e-07]Steps:  83%|████████▎ | 4138/5000 [15:29:30<2:51:28, 11.94s/it, loss=1.1757, lr=8.80e-07]Steps:  83%|████████▎ | 4138/5000 [15:29:30<2:51:28, 11.94s/it, loss=0.3715, lr=8.78e-07]Steps:  83%|████████▎ | 4139/5000 [15:29:42<2:50:47, 11.90s/it, loss=0.3715, lr=8.78e-07]Steps:  83%|████████▎ | 4139/5000 [15:29:42<2:50:47, 11.90s/it, loss=1.1299, lr=8.76e-07]Steps:  83%|████████▎ | 4140/5000 [15:29:54<2:50:40, 11.91s/it, loss=1.1299, lr=8.76e-07]Steps:  83%|████████▎ | 4140/5000 [15:29:54<2:50:40, 11.91s/it, loss=0.6626, lr=8.74e-07]
[Step 4140] Training Debug Info:
  Loss: 0.995478
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0030, std: 0.9062
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: -0.0013, std: 0.9102
  Sigmas: [0.369140625]... (timesteps: [370.0])

[Step 4140] Training Debug Info:
  Loss: 0.524495
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0131, std: 0.9297
  Noise mean: -0.0016, std: 1.0000
  Target mean: 0.0115, std: 1.3672
  Model pred mean: 0.0112, std: 1.1719
  Sigmas: [0.9296875]... (timesteps: [930.0])

[Step 4140] Training Debug Info:
  Loss: 0.482266
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0199, std: 0.8984
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0199, std: 1.3438
  Model pred mean: -0.0170, std: 1.1484
  Sigmas: [0.6796875]... (timesteps: [680.0])

[Step 4140] Training Debug Info:
  Loss: 0.661717
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0354, std: 0.8984
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0330, std: 1.3438
  Model pred mean: 0.0376, std: 1.0703
  Sigmas: [0.546875]... (timesteps: [547.0])
Steps:  83%|████████▎ | 4141/5000 [15:30:06<2:50:47, 11.93s/it, loss=0.6626, lr=8.74e-07]Steps:  83%|████████▎ | 4141/5000 [15:30:06<2:50:47, 11.93s/it, loss=0.6617, lr=8.72e-07]Steps:  83%|████████▎ | 4142/5000 [15:30:18<2:51:31, 11.99s/it, loss=0.6617, lr=8.72e-07]Steps:  83%|████████▎ | 4142/5000 [15:30:18<2:51:31, 11.99s/it, loss=0.9443, lr=8.70e-07]Steps:  83%|████████▎ | 4143/5000 [15:30:30<2:50:56, 11.97s/it, loss=0.9443, lr=8.70e-07]Steps:  83%|████████▎ | 4143/5000 [15:30:30<2:50:56, 11.97s/it, loss=0.4325, lr=8.69e-07]Steps:  83%|████████▎ | 4144/5000 [15:30:42<2:50:44, 11.97s/it, loss=0.4325, lr=8.69e-07]Steps:  83%|████████▎ | 4144/5000 [15:30:42<2:50:44, 11.97s/it, loss=0.6146, lr=8.67e-07]Steps:  83%|████████▎ | 4145/5000 [15:30:54<2:50:41, 11.98s/it, loss=0.6146, lr=8.67e-07]Steps:  83%|████████▎ | 4145/5000 [15:30:54<2:50:41, 11.98s/it, loss=1.0196, lr=8.65e-07]Steps:  83%|████████▎ | 4146/5000 [15:31:06<2:50:15, 11.96s/it, loss=1.0196, lr=8.65e-07]Steps:  83%|████████▎ | 4146/5000 [15:31:06<2:50:15, 11.96s/it, loss=0.5343, lr=8.63e-07]Steps:  83%|████████▎ | 4147/5000 [15:31:18<2:49:40, 11.93s/it, loss=0.5343, lr=8.63e-07]Steps:  83%|████████▎ | 4147/5000 [15:31:18<2:49:40, 11.93s/it, loss=0.8143, lr=8.61e-07]Steps:  83%|████████▎ | 4148/5000 [15:31:30<2:50:42, 12.02s/it, loss=0.8143, lr=8.61e-07]Steps:  83%|████████▎ | 4148/5000 [15:31:30<2:50:42, 12.02s/it, loss=1.1304, lr=8.59e-07]Steps:  83%|████████▎ | 4149/5000 [15:31:42<2:49:52, 11.98s/it, loss=1.1304, lr=8.59e-07]Steps:  83%|████████▎ | 4149/5000 [15:31:42<2:49:52, 11.98s/it, loss=0.3935, lr=8.57e-07]Steps:  83%|████████▎ | 4150/5000 [15:31:54<2:50:52, 12.06s/it, loss=0.3935, lr=8.57e-07]Steps:  83%|████████▎ | 4150/5000 [15:31:54<2:50:52, 12.06s/it, loss=0.8044, lr=8.55e-07]
[Step 4150] Training Debug Info:
  Loss: 0.621840
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0117, std: 0.9414
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0149, std: 1.3672
  Model pred mean: 0.0150, std: 1.1250
  Sigmas: [0.578125]... (timesteps: [579.0])

[Step 4150] Training Debug Info:
  Loss: 0.804739
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0240, std: 0.8516
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0227, std: 1.3125
  Model pred mean: 0.0251, std: 0.9570
  Sigmas: [0.4921875]... (timesteps: [493.0])

[Step 4150] Training Debug Info:
  Loss: 0.780718
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0366, std: 0.9688
  Noise mean: -0.0013, std: 0.9961
  Target mean: -0.0381, std: 1.3906
  Model pred mean: -0.0396, std: 1.0625
  Sigmas: [0.99609375]... (timesteps: [998.0])

[Step 4150] Training Debug Info:
  Loss: 1.131228
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0388, std: 0.8398
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0398, std: 1.3047
  Model pred mean: 0.0388, std: 0.7617
  Sigmas: [0.078125]... (timesteps: [78.0])
Steps:  83%|████████▎ | 4151/5000 [15:32:06<2:49:50, 12.00s/it, loss=0.8044, lr=8.55e-07]Steps:  83%|████████▎ | 4151/5000 [15:32:06<2:49:50, 12.00s/it, loss=1.1312, lr=8.53e-07]Steps:  83%|████████▎ | 4152/5000 [15:32:18<2:49:27, 11.99s/it, loss=1.1312, lr=8.53e-07]Steps:  83%|████████▎ | 4152/5000 [15:32:18<2:49:27, 11.99s/it, loss=0.9234, lr=8.51e-07]Steps:  83%|████████▎ | 4153/5000 [15:32:30<2:48:46, 11.96s/it, loss=0.9234, lr=8.51e-07]Steps:  83%|████████▎ | 4153/5000 [15:32:30<2:48:46, 11.96s/it, loss=0.3362, lr=8.49e-07]Steps:  83%|████████▎ | 4154/5000 [15:32:42<2:48:36, 11.96s/it, loss=0.3362, lr=8.49e-07]Steps:  83%|████████▎ | 4154/5000 [15:32:42<2:48:36, 11.96s/it, loss=1.1094, lr=8.47e-07]Steps:  83%|████████▎ | 4155/5000 [15:32:54<2:49:12, 12.02s/it, loss=1.1094, lr=8.47e-07]Steps:  83%|████████▎ | 4155/5000 [15:32:54<2:49:12, 12.02s/it, loss=1.1969, lr=8.45e-07]Steps:  83%|████████▎ | 4156/5000 [15:33:06<2:48:26, 11.97s/it, loss=1.1969, lr=8.45e-07]Steps:  83%|████████▎ | 4156/5000 [15:33:06<2:48:26, 11.97s/it, loss=0.3524, lr=8.43e-07]Steps:  83%|████████▎ | 4157/5000 [15:33:18<2:47:39, 11.93s/it, loss=0.3524, lr=8.43e-07]Steps:  83%|████████▎ | 4157/5000 [15:33:18<2:47:39, 11.93s/it, loss=0.9691, lr=8.41e-07]Steps:  83%|████████▎ | 4158/5000 [15:33:30<2:47:27, 11.93s/it, loss=0.9691, lr=8.41e-07]Steps:  83%|████████▎ | 4158/5000 [15:33:30<2:47:27, 11.93s/it, loss=1.0017, lr=8.39e-07]Steps:  83%|████████▎ | 4159/5000 [15:33:42<2:47:38, 11.96s/it, loss=1.0017, lr=8.39e-07]Steps:  83%|████████▎ | 4159/5000 [15:33:42<2:47:38, 11.96s/it, loss=1.0375, lr=8.37e-07]Steps:  83%|████████▎ | 4160/5000 [15:33:54<2:47:19, 11.95s/it, loss=1.0375, lr=8.37e-07]Steps:  83%|████████▎ | 4160/5000 [15:33:54<2:47:19, 11.95s/it, loss=0.4336, lr=8.35e-07]
[Step 4160] Training Debug Info:
  Loss: 1.095558
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0154, std: 0.9180
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0143, std: 1.3594
  Model pred mean: -0.0130, std: 0.8633
  Sigmas: [0.24609375]... (timesteps: [246.0])

[Step 4160] Training Debug Info:
  Loss: 0.358670
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0315, std: 0.9180
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0332, std: 1.3594
  Model pred mean: -0.0276, std: 1.2188
  Sigmas: [0.85546875]... (timesteps: [854.0])

[Step 4160] Training Debug Info:
  Loss: 1.068812
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.9414
  Noise mean: 0.0035, std: 1.0000
  Target mean: -0.0007, std: 1.3750
  Model pred mean: -0.0025, std: 0.9023
  Sigmas: [0.0458984375]... (timesteps: [46.0])

[Step 4160] Training Debug Info:
  Loss: 0.357235
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0312, std: 0.9648
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0330, std: 1.3828
  Model pred mean: 0.0354, std: 1.2500
  Sigmas: [0.80859375]... (timesteps: [810.0])
Steps:  83%|████████▎ | 4161/5000 [15:34:05<2:46:38, 11.92s/it, loss=0.4336, lr=8.35e-07]Steps:  83%|████████▎ | 4161/5000 [15:34:05<2:46:38, 11.92s/it, loss=0.3572, lr=8.33e-07]Steps:  83%|████████▎ | 4162/5000 [15:34:18<2:47:26, 11.99s/it, loss=0.3572, lr=8.33e-07]Steps:  83%|████████▎ | 4162/5000 [15:34:18<2:47:26, 11.99s/it, loss=0.3875, lr=8.32e-07]Steps:  83%|████████▎ | 4163/5000 [15:34:30<2:47:10, 11.98s/it, loss=0.3875, lr=8.32e-07]Steps:  83%|████████▎ | 4163/5000 [15:34:30<2:47:10, 11.98s/it, loss=0.6014, lr=8.30e-07]Steps:  83%|████████▎ | 4164/5000 [15:34:42<2:46:57, 11.98s/it, loss=0.6014, lr=8.30e-07]Steps:  83%|████████▎ | 4164/5000 [15:34:42<2:46:57, 11.98s/it, loss=0.5971, lr=8.28e-07]Steps:  83%|████████▎ | 4165/5000 [15:34:54<2:46:49, 11.99s/it, loss=0.5971, lr=8.28e-07]Steps:  83%|████████▎ | 4165/5000 [15:34:54<2:46:49, 11.99s/it, loss=1.1530, lr=8.26e-07]Steps:  83%|████████▎ | 4166/5000 [15:35:06<2:46:29, 11.98s/it, loss=1.1530, lr=8.26e-07]Steps:  83%|████████▎ | 4166/5000 [15:35:06<2:46:29, 11.98s/it, loss=1.0538, lr=8.24e-07]Steps:  83%|████████▎ | 4167/5000 [15:35:17<2:46:07, 11.97s/it, loss=1.0538, lr=8.24e-07]Steps:  83%|████████▎ | 4167/5000 [15:35:17<2:46:07, 11.97s/it, loss=1.1294, lr=8.22e-07]Steps:  83%|████████▎ | 4168/5000 [15:35:30<2:46:21, 12.00s/it, loss=1.1294, lr=8.22e-07]Steps:  83%|████████▎ | 4168/5000 [15:35:30<2:46:21, 12.00s/it, loss=1.1164, lr=8.20e-07]Steps:  83%|████████▎ | 4169/5000 [15:35:42<2:46:57, 12.05s/it, loss=1.1164, lr=8.20e-07]Steps:  83%|████████▎ | 4169/5000 [15:35:42<2:46:57, 12.05s/it, loss=0.6225, lr=8.18e-07]Steps:  83%|████████▎ | 4170/5000 [15:35:54<2:45:45, 11.98s/it, loss=0.6225, lr=8.18e-07]Steps:  83%|████████▎ | 4170/5000 [15:35:54<2:45:45, 11.98s/it, loss=1.0367, lr=8.16e-07]
[Step 4170] Training Debug Info:
  Loss: 0.579644
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0132, std: 0.9102
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0142, std: 1.3516
  Model pred mean: -0.0188, std: 1.1172
  Sigmas: [0.97265625]... (timesteps: [972.0])

[Step 4170] Training Debug Info:
  Loss: 1.167831
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0204, std: 0.9258
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0219, std: 1.3594
  Model pred mean: 0.0193, std: 0.8281
  Sigmas: [0.1708984375]... (timesteps: [171.0])

[Step 4170] Training Debug Info:
  Loss: 1.071492
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9336
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0013, std: 1.3672
  Model pred mean: -0.0012, std: 0.8906
  Sigmas: [0.25390625]... (timesteps: [254.00001525878906])

[Step 4170] Training Debug Info:
  Loss: 0.480546
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0610, std: 0.9883
  Noise mean: 0.0011, std: 0.9961
  Target mean: -0.0598, std: 1.3984
  Model pred mean: -0.0586, std: 1.2188
  Sigmas: [0.8203125]... (timesteps: [820.0])
Steps:  83%|████████▎ | 4171/5000 [15:36:05<2:45:14, 11.96s/it, loss=1.0367, lr=8.16e-07]Steps:  83%|████████▎ | 4171/5000 [15:36:05<2:45:14, 11.96s/it, loss=0.4805, lr=8.14e-07]Steps:  83%|████████▎ | 4172/5000 [15:36:17<2:45:00, 11.96s/it, loss=0.4805, lr=8.14e-07]Steps:  83%|████████▎ | 4172/5000 [15:36:17<2:45:00, 11.96s/it, loss=0.7706, lr=8.12e-07]Steps:  83%|████████▎ | 4173/5000 [15:36:29<2:44:24, 11.93s/it, loss=0.7706, lr=8.12e-07]Steps:  83%|████████▎ | 4173/5000 [15:36:29<2:44:24, 11.93s/it, loss=0.4561, lr=8.10e-07]Steps:  83%|████████▎ | 4174/5000 [15:36:41<2:44:18, 11.93s/it, loss=0.4561, lr=8.10e-07]Steps:  83%|████████▎ | 4174/5000 [15:36:41<2:44:18, 11.93s/it, loss=1.0658, lr=8.09e-07]Steps:  84%|████████▎ | 4175/5000 [15:36:53<2:45:03, 12.00s/it, loss=1.0658, lr=8.09e-07]Steps:  84%|████████▎ | 4175/5000 [15:36:53<2:45:03, 12.00s/it, loss=0.8207, lr=8.07e-07]Steps:  84%|████████▎ | 4176/5000 [15:37:05<2:44:32, 11.98s/it, loss=0.8207, lr=8.07e-07]Steps:  84%|████████▎ | 4176/5000 [15:37:05<2:44:32, 11.98s/it, loss=0.3686, lr=8.05e-07]Steps:  84%|████████▎ | 4177/5000 [15:37:18<2:45:36, 12.07s/it, loss=0.3686, lr=8.05e-07]Steps:  84%|████████▎ | 4177/5000 [15:37:18<2:45:36, 12.07s/it, loss=0.3383, lr=8.03e-07]Steps:  84%|████████▎ | 4178/5000 [15:37:30<2:44:44, 12.03s/it, loss=0.3383, lr=8.03e-07]Steps:  84%|████████▎ | 4178/5000 [15:37:30<2:44:44, 12.03s/it, loss=0.4383, lr=8.01e-07]Steps:  84%|████████▎ | 4179/5000 [15:37:41<2:44:04, 11.99s/it, loss=0.4383, lr=8.01e-07]Steps:  84%|████████▎ | 4179/5000 [15:37:41<2:44:04, 11.99s/it, loss=1.0898, lr=7.99e-07]Steps:  84%|████████▎ | 4180/5000 [15:37:53<2:43:34, 11.97s/it, loss=1.0898, lr=7.99e-07]Steps:  84%|████████▎ | 4180/5000 [15:37:53<2:43:34, 11.97s/it, loss=0.8373, lr=7.97e-07]
[Step 4180] Training Debug Info:
  Loss: 0.990264
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0280, std: 0.9219
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0299, std: 1.3594
  Model pred mean: -0.0288, std: 0.9336
  Sigmas: [0.251953125]... (timesteps: [250.99998474121094])

[Step 4180] Training Debug Info:
  Loss: 1.066466
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0159, std: 0.8516
  Noise mean: 0.0040, std: 1.0000
  Target mean: 0.0198, std: 1.3125
  Model pred mean: 0.0143, std: 0.8047
  Sigmas: [0.3515625]... (timesteps: [352.0])

[Step 4180] Training Debug Info:
  Loss: 0.588760
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0474, std: 0.9492
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0488, std: 1.3828
  Model pred mean: -0.0515, std: 1.1484
  Sigmas: [0.9375]... (timesteps: [938.0])

[Step 4180] Training Debug Info:
  Loss: 0.413201
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0322, std: 0.9297
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0317, std: 1.3672
  Model pred mean: 0.0320, std: 1.2031
  Sigmas: [0.69921875]... (timesteps: [700.0])
Steps:  84%|████████▎ | 4181/5000 [15:38:05<2:43:16, 11.96s/it, loss=0.8373, lr=7.97e-07]Steps:  84%|████████▎ | 4181/5000 [15:38:05<2:43:16, 11.96s/it, loss=0.4132, lr=7.95e-07]Steps:  84%|████████▎ | 4182/5000 [15:38:17<2:43:54, 12.02s/it, loss=0.4132, lr=7.95e-07]Steps:  84%|████████▎ | 4182/5000 [15:38:17<2:43:54, 12.02s/it, loss=0.8069, lr=7.93e-07]Steps:  84%|████████▎ | 4183/5000 [15:38:29<2:43:15, 11.99s/it, loss=0.8069, lr=7.93e-07]Steps:  84%|████████▎ | 4183/5000 [15:38:29<2:43:15, 11.99s/it, loss=1.1047, lr=7.92e-07]Steps:  84%|████████▎ | 4184/5000 [15:38:41<2:42:36, 11.96s/it, loss=1.1047, lr=7.92e-07]Steps:  84%|████████▎ | 4184/5000 [15:38:41<2:42:36, 11.96s/it, loss=0.4880, lr=7.90e-07]Steps:  84%|████████▎ | 4185/5000 [15:38:53<2:41:58, 11.92s/it, loss=0.4880, lr=7.90e-07]Steps:  84%|████████▎ | 4185/5000 [15:38:53<2:41:58, 11.92s/it, loss=0.6554, lr=7.88e-07]Steps:  84%|████████▎ | 4186/5000 [15:39:05<2:42:34, 11.98s/it, loss=0.6554, lr=7.88e-07]Steps:  84%|████████▎ | 4186/5000 [15:39:05<2:42:34, 11.98s/it, loss=1.1408, lr=7.86e-07]Steps:  84%|████████▎ | 4187/5000 [15:39:17<2:41:41, 11.93s/it, loss=1.1408, lr=7.86e-07]Steps:  84%|████████▎ | 4187/5000 [15:39:17<2:41:41, 11.93s/it, loss=0.4368, lr=7.84e-07]Steps:  84%|████████▍ | 4188/5000 [15:39:29<2:41:17, 11.92s/it, loss=0.4368, lr=7.84e-07]Steps:  84%|████████▍ | 4188/5000 [15:39:29<2:41:17, 11.92s/it, loss=0.6790, lr=7.82e-07]Steps:  84%|████████▍ | 4189/5000 [15:39:41<2:42:00, 11.99s/it, loss=0.6790, lr=7.82e-07]Steps:  84%|████████▍ | 4189/5000 [15:39:41<2:42:00, 11.99s/it, loss=0.4352, lr=7.80e-07]Steps:  84%|████████▍ | 4190/5000 [15:39:53<2:41:38, 11.97s/it, loss=0.4352, lr=7.80e-07]Steps:  84%|████████▍ | 4190/5000 [15:39:53<2:41:38, 11.97s/it, loss=0.4438, lr=7.78e-07]
[Step 4190] Training Debug Info:
  Loss: 0.962417
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0090, std: 0.9180
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0110, std: 1.3594
  Model pred mean: -0.0084, std: 0.9414
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 4190] Training Debug Info:
  Loss: 0.390414
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0150, std: 0.9102
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0165, std: 1.3516
  Model pred mean: 0.0042, std: 1.1953
  Sigmas: [0.9296875]... (timesteps: [930.0])

[Step 4190] Training Debug Info:
  Loss: 0.375412
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0111, std: 0.9375
  Noise mean: 0.0011, std: 0.9961
  Target mean: 0.0121, std: 1.3672
  Model pred mean: 0.0087, std: 1.2266
  Sigmas: [0.75]... (timesteps: [751.0])

[Step 4190] Training Debug Info:
  Loss: 0.560087
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0118, std: 0.9531
  Noise mean: 0.0010, std: 0.9961
  Target mean: -0.0108, std: 1.3750
  Model pred mean: -0.0103, std: 1.1562
  Sigmas: [0.60546875]... (timesteps: [605.0])
Steps:  84%|████████▍ | 4191/5000 [15:40:05<2:41:06, 11.95s/it, loss=0.4438, lr=7.78e-07]Steps:  84%|████████▍ | 4191/5000 [15:40:05<2:41:06, 11.95s/it, loss=0.5601, lr=7.76e-07]Steps:  84%|████████▍ | 4192/5000 [15:40:17<2:40:52, 11.95s/it, loss=0.5601, lr=7.76e-07]Steps:  84%|████████▍ | 4192/5000 [15:40:17<2:40:52, 11.95s/it, loss=1.1089, lr=7.75e-07]Steps:  84%|████████▍ | 4193/5000 [15:40:29<2:40:17, 11.92s/it, loss=1.1089, lr=7.75e-07]Steps:  84%|████████▍ | 4193/5000 [15:40:29<2:40:17, 11.92s/it, loss=0.9401, lr=7.73e-07]Steps:  84%|████████▍ | 4194/5000 [15:40:41<2:40:10, 11.92s/it, loss=0.9401, lr=7.73e-07]Steps:  84%|████████▍ | 4194/5000 [15:40:41<2:40:10, 11.92s/it, loss=1.0877, lr=7.71e-07]Steps:  84%|████████▍ | 4195/5000 [15:40:53<2:40:35, 11.97s/it, loss=1.0877, lr=7.71e-07]Steps:  84%|████████▍ | 4195/5000 [15:40:53<2:40:35, 11.97s/it, loss=0.4159, lr=7.69e-07]Steps:  84%|████████▍ | 4196/5000 [15:41:05<2:40:43, 11.99s/it, loss=0.4159, lr=7.69e-07]Steps:  84%|████████▍ | 4196/5000 [15:41:05<2:40:43, 11.99s/it, loss=1.0721, lr=7.67e-07]Steps:  84%|████████▍ | 4197/5000 [15:41:17<2:40:16, 11.98s/it, loss=1.0721, lr=7.67e-07]Steps:  84%|████████▍ | 4197/5000 [15:41:17<2:40:16, 11.98s/it, loss=1.1416, lr=7.65e-07]Steps:  84%|████████▍ | 4198/5000 [15:41:29<2:39:49, 11.96s/it, loss=1.1416, lr=7.65e-07]Steps:  84%|████████▍ | 4198/5000 [15:41:29<2:39:49, 11.96s/it, loss=0.7575, lr=7.63e-07]Steps:  84%|████████▍ | 4199/5000 [15:41:41<2:39:42, 11.96s/it, loss=0.7575, lr=7.63e-07]Steps:  84%|████████▍ | 4199/5000 [15:41:41<2:39:42, 11.96s/it, loss=1.0804, lr=7.62e-07]Steps:  84%|████████▍ | 4200/5000 [15:41:52<2:39:12, 11.94s/it, loss=1.0804, lr=7.62e-07]Steps:  84%|████████▍ | 4200/5000 [15:41:52<2:39:12, 11.94s/it, loss=0.9017, lr=7.60e-07]01/22/2026 23:27:39 - INFO - __main__ - 
[Step 4200] ✅ Loss in normal range (0.9017)
01/22/2026 23:27:39 - INFO - __main__ -   Loss avg (last 100): 0.7741
01/22/2026 23:27:39 - INFO - __main__ -   Loss range: [0.3362, 1.2029]
01/22/2026 23:27:39 - INFO - __main__ - 
🔍 Running validation at step 4200...
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4200 (parquet mode)...
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4200...
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/22/2026 23:27:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/22/2026 23:28:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/22/2026 23:28:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/22/2026 23:28:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/22/2026 23:28:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 23:28:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/22/2026 23:28:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/22/2026 23:29:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/22/2026 23:29:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:18,  1.43it/s][A
 11%|█         | 3/28 [00:02<00:17,  1.41it/s][A
 14%|█▍        | 4/28 [00:02<00:17,  1.40it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.39it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.39it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:10<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 23:29:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/22/2026 23:29:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 23:29:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/22/2026 23:29:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 23:30:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/22/2026 23:30:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 23:30:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/22/2026 23:30:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/22/2026 23:30:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/22/2026 23:30:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/22/2026 23:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/22/2026 23:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 23:31:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/22/2026 23:31:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.47it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.44it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.43it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.43it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/22/2026 23:31:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200/step004200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/22/2026 23:31:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/22/2026 23:31:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/22/2026 23:31:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004200
01/22/2026 23:31:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 4200] Training Debug Info:
  Loss: 0.481357
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0189, std: 0.9023
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0210, std: 1.3438
  Model pred mean: -0.0222, std: 1.1562
  Sigmas: [0.66796875]... (timesteps: [667.0])

[Step 4200] Training Debug Info:
  Loss: 0.960413
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0204, std: 0.8984
  Noise mean: 0.0015, std: 0.9961
  Target mean: 0.0220, std: 1.3438
  Model pred mean: 0.0201, std: 0.9219
  Sigmas: [0.3515625]... (timesteps: [351.0])

[Step 4200] Training Debug Info:
  Loss: 1.147291
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0060, std: 0.9258
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0038, std: 1.3594
  Model pred mean: -0.0066, std: 0.8438
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 4200] Training Debug Info:
  Loss: 0.411379
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0020, std: 0.8750
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0011, std: 1.3281
  Model pred mean: 0.0023, std: 1.1641
  Sigmas: [0.76953125]... (timesteps: [771.0])
Steps:  84%|████████▍ | 4201/5000 [15:46:26<20:05:15, 90.51s/it, loss=0.9017, lr=7.60e-07]Steps:  84%|████████▍ | 4201/5000 [15:46:26<20:05:15, 90.51s/it, loss=0.4114, lr=7.58e-07]Steps:  84%|████████▍ | 4202/5000 [15:46:38<14:50:58, 66.99s/it, loss=0.4114, lr=7.58e-07]Steps:  84%|████████▍ | 4202/5000 [15:46:38<14:50:58, 66.99s/it, loss=1.1459, lr=7.56e-07]Steps:  84%|████████▍ | 4203/5000 [15:46:50<11:10:13, 50.46s/it, loss=1.1459, lr=7.56e-07]Steps:  84%|████████▍ | 4203/5000 [15:46:50<11:10:13, 50.46s/it, loss=0.6070, lr=7.54e-07]Steps:  84%|████████▍ | 4204/5000 [15:47:02<8:36:18, 38.92s/it, loss=0.6070, lr=7.54e-07] Steps:  84%|████████▍ | 4204/5000 [15:47:02<8:36:18, 38.92s/it, loss=1.0654, lr=7.52e-07]Steps:  84%|████████▍ | 4205/5000 [15:47:14<6:48:22, 30.82s/it, loss=1.0654, lr=7.52e-07]Steps:  84%|████████▍ | 4205/5000 [15:47:14<6:48:22, 30.82s/it, loss=0.4258, lr=7.51e-07]Steps:  84%|████████▍ | 4206/5000 [15:47:26<5:32:45, 25.15s/it, loss=0.4258, lr=7.51e-07]Steps:  84%|████████▍ | 4206/5000 [15:47:26<5:32:45, 25.15s/it, loss=1.1174, lr=7.49e-07]Steps:  84%|████████▍ | 4207/5000 [15:47:38<4:40:05, 21.19s/it, loss=1.1174, lr=7.49e-07]Steps:  84%|████████▍ | 4207/5000 [15:47:38<4:40:05, 21.19s/it, loss=0.4507, lr=7.47e-07]Steps:  84%|████████▍ | 4208/5000 [15:47:50<4:03:08, 18.42s/it, loss=0.4507, lr=7.47e-07]Steps:  84%|████████▍ | 4208/5000 [15:47:50<4:03:08, 18.42s/it, loss=0.6428, lr=7.45e-07]Steps:  84%|████████▍ | 4209/5000 [15:48:02<3:38:05, 16.54s/it, loss=0.6428, lr=7.45e-07]Steps:  84%|████████▍ | 4209/5000 [15:48:02<3:38:05, 16.54s/it, loss=1.1803, lr=7.43e-07]Steps:  84%|████████▍ | 4210/5000 [15:48:14<3:19:40, 15.17s/it, loss=1.1803, lr=7.43e-07]Steps:  84%|████████▍ | 4210/5000 [15:48:14<3:19:40, 15.17s/it, loss=0.5663, lr=7.41e-07]
[Step 4210] Training Debug Info:
  Loss: 0.555488
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0236, std: 0.9766
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0226, std: 1.3984
  Model pred mean: -0.0250, std: 1.1797
  Sigmas: [0.6171875]... (timesteps: [617.0])

[Step 4210] Training Debug Info:
  Loss: 0.648723
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0559, std: 1.0078
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0542, std: 1.4219
  Model pred mean: -0.0535, std: 1.1797
  Sigmas: [0.5859375]... (timesteps: [585.0])

[Step 4210] Training Debug Info:
  Loss: 1.087679
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0160, std: 0.8789
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0162, std: 1.3281
  Model pred mean: 0.0167, std: 0.8242
  Sigmas: [0.050048828125]... (timesteps: [50.0])

[Step 4210] Training Debug Info:
  Loss: 0.454570
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0134, std: 0.8867
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0109, std: 1.3359
  Model pred mean: 0.0092, std: 1.1562
  Sigmas: [0.71484375]... (timesteps: [714.0])
Steps:  84%|████████▍ | 4211/5000 [15:48:26<3:06:51, 14.21s/it, loss=0.5663, lr=7.41e-07]Steps:  84%|████████▍ | 4211/5000 [15:48:26<3:06:51, 14.21s/it, loss=0.4546, lr=7.40e-07]Steps:  84%|████████▍ | 4212/5000 [15:48:38<2:57:34, 13.52s/it, loss=0.4546, lr=7.40e-07]Steps:  84%|████████▍ | 4212/5000 [15:48:38<2:57:34, 13.52s/it, loss=1.1016, lr=7.38e-07]Steps:  84%|████████▍ | 4213/5000 [15:48:50<2:51:07, 13.05s/it, loss=1.1016, lr=7.38e-07]Steps:  84%|████████▍ | 4213/5000 [15:48:50<2:51:07, 13.05s/it, loss=0.5186, lr=7.36e-07]Steps:  84%|████████▍ | 4214/5000 [15:49:02<2:46:19, 12.70s/it, loss=0.5186, lr=7.36e-07]Steps:  84%|████████▍ | 4214/5000 [15:49:02<2:46:19, 12.70s/it, loss=1.0315, lr=7.34e-07]Steps:  84%|████████▍ | 4215/5000 [15:49:14<2:43:13, 12.48s/it, loss=1.0315, lr=7.34e-07]Steps:  84%|████████▍ | 4215/5000 [15:49:14<2:43:13, 12.48s/it, loss=1.1304, lr=7.32e-07]Steps:  84%|████████▍ | 4216/5000 [15:49:26<2:41:48, 12.38s/it, loss=1.1304, lr=7.32e-07]Steps:  84%|████████▍ | 4216/5000 [15:49:26<2:41:48, 12.38s/it, loss=0.3965, lr=7.30e-07]Steps:  84%|████████▍ | 4217/5000 [15:49:38<2:39:45, 12.24s/it, loss=0.3965, lr=7.30e-07]Steps:  84%|████████▍ | 4217/5000 [15:49:38<2:39:45, 12.24s/it, loss=0.5250, lr=7.29e-07]Steps:  84%|████████▍ | 4218/5000 [15:49:50<2:38:21, 12.15s/it, loss=0.5250, lr=7.29e-07]Steps:  84%|████████▍ | 4218/5000 [15:49:50<2:38:21, 12.15s/it, loss=0.4803, lr=7.27e-07]Steps:  84%|████████▍ | 4219/5000 [15:50:02<2:37:18, 12.08s/it, loss=0.4803, lr=7.27e-07]Steps:  84%|████████▍ | 4219/5000 [15:50:02<2:37:18, 12.08s/it, loss=0.5896, lr=7.25e-07]Steps:  84%|████████▍ | 4220/5000 [15:50:14<2:36:19, 12.02s/it, loss=0.5896, lr=7.25e-07]Steps:  84%|████████▍ | 4220/5000 [15:50:14<2:36:19, 12.02s/it, loss=0.9604, lr=7.23e-07]
[Step 4220] Training Debug Info:
  Loss: 0.666868
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0120, std: 0.8789
  Noise mean: 0.0003, std: 0.9961
  Target mean: 0.0124, std: 1.3281
  Model pred mean: 0.0088, std: 1.0469
  Sigmas: [0.5703125]... (timesteps: [571.0])

[Step 4220] Training Debug Info:
  Loss: 1.027433
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.9219
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0120, std: 1.3672
  Model pred mean: -0.0072, std: 0.9062
  Sigmas: [0.010986328125]... (timesteps: [11.0])

[Step 4220] Training Debug Info:
  Loss: 0.806186
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0199, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0209, std: 1.3594
  Model pred mean: -0.0175, std: 1.0156
  Sigmas: [0.44921875]... (timesteps: [449.0])

[Step 4220] Training Debug Info:
  Loss: 0.786197
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0232, std: 0.9297
  Noise mean: -0.0030, std: 0.9961
  Target mean: -0.0262, std: 1.3594
  Model pred mean: -0.0228, std: 1.0391
  Sigmas: [0.423828125]... (timesteps: [424.0])
Steps:  84%|████████▍ | 4221/5000 [15:50:26<2:35:42, 11.99s/it, loss=0.9604, lr=7.23e-07]Steps:  84%|████████▍ | 4221/5000 [15:50:26<2:35:42, 11.99s/it, loss=0.7862, lr=7.21e-07]Steps:  84%|████████▍ | 4222/5000 [15:50:37<2:35:06, 11.96s/it, loss=0.7862, lr=7.21e-07]Steps:  84%|████████▍ | 4222/5000 [15:50:37<2:35:06, 11.96s/it, loss=1.1266, lr=7.20e-07]Steps:  84%|████████▍ | 4223/5000 [15:50:50<2:35:40, 12.02s/it, loss=1.1266, lr=7.20e-07]Steps:  84%|████████▍ | 4223/5000 [15:50:50<2:35:40, 12.02s/it, loss=0.4001, lr=7.18e-07]Steps:  84%|████████▍ | 4224/5000 [15:51:02<2:35:24, 12.02s/it, loss=0.4001, lr=7.18e-07]Steps:  84%|████████▍ | 4224/5000 [15:51:02<2:35:24, 12.02s/it, loss=0.4604, lr=7.16e-07]Steps:  84%|████████▍ | 4225/5000 [15:51:14<2:34:46, 11.98s/it, loss=0.4604, lr=7.16e-07]Steps:  84%|████████▍ | 4225/5000 [15:51:14<2:34:46, 11.98s/it, loss=1.0991, lr=7.14e-07]Steps:  85%|████████▍ | 4226/5000 [15:51:26<2:34:36, 11.99s/it, loss=1.0991, lr=7.14e-07]Steps:  85%|████████▍ | 4226/5000 [15:51:26<2:34:36, 11.99s/it, loss=0.7380, lr=7.12e-07]Steps:  85%|████████▍ | 4227/5000 [15:51:37<2:34:19, 11.98s/it, loss=0.7380, lr=7.12e-07]Steps:  85%|████████▍ | 4227/5000 [15:51:37<2:34:19, 11.98s/it, loss=0.4037, lr=7.11e-07]Steps:  85%|████████▍ | 4228/5000 [15:51:49<2:33:47, 11.95s/it, loss=0.4037, lr=7.11e-07]Steps:  85%|████████▍ | 4228/5000 [15:51:49<2:33:47, 11.95s/it, loss=1.1333, lr=7.09e-07]Steps:  85%|████████▍ | 4229/5000 [15:52:02<2:34:35, 12.03s/it, loss=1.1333, lr=7.09e-07]Steps:  85%|████████▍ | 4229/5000 [15:52:02<2:34:35, 12.03s/it, loss=0.3784, lr=7.07e-07]Steps:  85%|████████▍ | 4230/5000 [15:52:14<2:34:01, 12.00s/it, loss=0.3784, lr=7.07e-07]Steps:  85%|████████▍ | 4230/5000 [15:52:14<2:34:01, 12.00s/it, loss=0.4777, lr=7.05e-07]
[Step 4230] Training Debug Info:
  Loss: 0.455891
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0009, std: 0.9102
  Noise mean: 0.0035, std: 1.0000
  Target mean: 0.0044, std: 1.3516
  Model pred mean: 0.0003, std: 1.1719
  Sigmas: [0.78125]... (timesteps: [782.0])

[Step 4230] Training Debug Info:
  Loss: 0.532840
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0025, std: 0.9023
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0063, std: 1.3438
  Model pred mean: 0.0054, std: 1.1328
  Sigmas: [0.6328125]... (timesteps: [633.0])

[Step 4230] Training Debug Info:
  Loss: 1.066246
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0053, std: 0.9023
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0055, std: 1.3438
  Model pred mean: -0.0042, std: 0.8633
  Sigmas: [0.294921875]... (timesteps: [294.0])

[Step 4230] Training Debug Info:
  Loss: 0.742492
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0280, std: 0.8828
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0298, std: 1.3359
  Model pred mean: -0.0288, std: 1.0156
  Sigmas: [0.486328125]... (timesteps: [487.0])
Steps:  85%|████████▍ | 4231/5000 [15:52:25<2:33:07, 11.95s/it, loss=0.4777, lr=7.05e-07]Steps:  85%|████████▍ | 4231/5000 [15:52:25<2:33:07, 11.95s/it, loss=0.7425, lr=7.03e-07]Steps:  85%|████████▍ | 4232/5000 [15:52:37<2:32:33, 11.92s/it, loss=0.7425, lr=7.03e-07]Steps:  85%|████████▍ | 4232/5000 [15:52:37<2:32:33, 11.92s/it, loss=1.1383, lr=7.02e-07]Steps:  85%|████████▍ | 4233/5000 [15:52:49<2:32:45, 11.95s/it, loss=1.1383, lr=7.02e-07]Steps:  85%|████████▍ | 4233/5000 [15:52:49<2:32:45, 11.95s/it, loss=0.7391, lr=7.00e-07]Steps:  85%|████████▍ | 4234/5000 [15:53:01<2:32:35, 11.95s/it, loss=0.7391, lr=7.00e-07]Steps:  85%|████████▍ | 4234/5000 [15:53:01<2:32:35, 11.95s/it, loss=0.6398, lr=6.98e-07]Steps:  85%|████████▍ | 4235/5000 [15:53:13<2:32:10, 11.93s/it, loss=0.6398, lr=6.98e-07]Steps:  85%|████████▍ | 4235/5000 [15:53:13<2:32:10, 11.93s/it, loss=0.4588, lr=6.96e-07]Steps:  85%|████████▍ | 4236/5000 [15:53:25<2:32:50, 12.00s/it, loss=0.4588, lr=6.96e-07]Steps:  85%|████████▍ | 4236/5000 [15:53:25<2:32:50, 12.00s/it, loss=0.5505, lr=6.95e-07]Steps:  85%|████████▍ | 4237/5000 [15:53:37<2:32:17, 11.98s/it, loss=0.5505, lr=6.95e-07]Steps:  85%|████████▍ | 4237/5000 [15:53:37<2:32:17, 11.98s/it, loss=0.5081, lr=6.93e-07]Steps:  85%|████████▍ | 4238/5000 [15:53:49<2:31:45, 11.95s/it, loss=0.5081, lr=6.93e-07]Steps:  85%|████████▍ | 4238/5000 [15:53:49<2:31:45, 11.95s/it, loss=0.3819, lr=6.91e-07]Steps:  85%|████████▍ | 4239/5000 [15:54:01<2:31:16, 11.93s/it, loss=0.3819, lr=6.91e-07]Steps:  85%|████████▍ | 4239/5000 [15:54:01<2:31:16, 11.93s/it, loss=0.5206, lr=6.89e-07]Steps:  85%|████████▍ | 4240/5000 [15:54:13<2:30:50, 11.91s/it, loss=0.5206, lr=6.89e-07]Steps:  85%|████████▍ | 4240/5000 [15:54:13<2:30:50, 11.91s/it, loss=0.4448, lr=6.87e-07]
[Step 4240] Training Debug Info:
  Loss: 0.731117
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0109, std: 0.9727
  Noise mean: -0.0040, std: 1.0000
  Target mean: -0.0148, std: 1.3984
  Model pred mean: -0.0161, std: 1.1016
  Sigmas: [0.486328125]... (timesteps: [486.0])

[Step 4240] Training Debug Info:
  Loss: 0.583435
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0182, std: 0.9062
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0184, std: 1.3516
  Model pred mean: 0.0198, std: 1.1094
  Sigmas: [0.60546875]... (timesteps: [605.0])

[Step 4240] Training Debug Info:
  Loss: 0.746895
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0248, std: 0.9297
  Noise mean: 0.0031, std: 1.0000
  Target mean: -0.0217, std: 1.3594
  Model pred mean: -0.0277, std: 1.0547
  Sigmas: [0.373046875]... (timesteps: [374.0])

[Step 4240] Training Debug Info:
  Loss: 0.570079
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0017, std: 0.8750
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0044, std: 1.3281
  Model pred mean: -0.0031, std: 1.1094
  Sigmas: [0.9765625]... (timesteps: [976.0])
Steps:  85%|████████▍ | 4241/5000 [15:54:25<2:30:46, 11.92s/it, loss=0.4448, lr=6.87e-07]Steps:  85%|████████▍ | 4241/5000 [15:54:25<2:30:46, 11.92s/it, loss=0.5701, lr=6.86e-07]Steps:  85%|████████▍ | 4242/5000 [15:54:37<2:31:04, 11.96s/it, loss=0.5701, lr=6.86e-07]Steps:  85%|████████▍ | 4242/5000 [15:54:37<2:31:04, 11.96s/it, loss=0.7089, lr=6.84e-07]Steps:  85%|████████▍ | 4243/5000 [15:54:49<2:31:37, 12.02s/it, loss=0.7089, lr=6.84e-07]Steps:  85%|████████▍ | 4243/5000 [15:54:49<2:31:37, 12.02s/it, loss=0.9145, lr=6.82e-07]Steps:  85%|████████▍ | 4244/5000 [15:55:01<2:31:04, 11.99s/it, loss=0.9145, lr=6.82e-07]Steps:  85%|████████▍ | 4244/5000 [15:55:01<2:31:04, 11.99s/it, loss=0.3512, lr=6.80e-07]Steps:  85%|████████▍ | 4245/5000 [15:55:13<2:30:15, 11.94s/it, loss=0.3512, lr=6.80e-07]Steps:  85%|████████▍ | 4245/5000 [15:55:13<2:30:15, 11.94s/it, loss=0.5407, lr=6.79e-07]Steps:  85%|████████▍ | 4246/5000 [15:55:25<2:30:02, 11.94s/it, loss=0.5407, lr=6.79e-07]Steps:  85%|████████▍ | 4246/5000 [15:55:25<2:30:02, 11.94s/it, loss=0.6315, lr=6.77e-07]Steps:  85%|████████▍ | 4247/5000 [15:55:37<2:29:48, 11.94s/it, loss=0.6315, lr=6.77e-07]Steps:  85%|████████▍ | 4247/5000 [15:55:37<2:29:48, 11.94s/it, loss=0.4050, lr=6.75e-07]Steps:  85%|████████▍ | 4248/5000 [15:55:48<2:29:33, 11.93s/it, loss=0.4050, lr=6.75e-07]Steps:  85%|████████▍ | 4248/5000 [15:55:48<2:29:33, 11.93s/it, loss=0.9807, lr=6.73e-07]Steps:  85%|████████▍ | 4249/5000 [15:56:00<2:29:07, 11.91s/it, loss=0.9807, lr=6.73e-07]Steps:  85%|████████▍ | 4249/5000 [15:56:00<2:29:07, 11.91s/it, loss=0.7668, lr=6.72e-07]Steps:  85%|████████▌ | 4250/5000 [15:56:12<2:29:30, 11.96s/it, loss=0.7668, lr=6.72e-07]Steps:  85%|████████▌ | 4250/5000 [15:56:12<2:29:30, 11.96s/it, loss=1.0557, lr=6.70e-07]
[Step 4250] Training Debug Info:
  Loss: 1.136164
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0198, std: 0.8906
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0164, std: 1.3359
  Model pred mean: -0.0195, std: 0.8086
  Sigmas: [0.158203125]... (timesteps: [158.0])

[Step 4250] Training Debug Info:
  Loss: 0.472296
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0009, std: 0.9062
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0011, std: 1.3516
  Model pred mean: 0.0016, std: 1.1641
  Sigmas: [0.69140625]... (timesteps: [691.0])

[Step 4250] Training Debug Info:
  Loss: 1.157046
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0129, std: 0.8555
  Noise mean: -0.0052, std: 1.0000
  Target mean: 0.0078, std: 1.3125
  Model pred mean: 0.0120, std: 0.7578
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 4250] Training Debug Info:
  Loss: 0.453456
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0405, std: 0.9766
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0405, std: 1.3984
  Model pred mean: -0.0398, std: 1.2266
  Sigmas: [0.73046875]... (timesteps: [730.0])
Steps:  85%|████████▌ | 4251/5000 [15:56:24<2:29:41, 11.99s/it, loss=1.0557, lr=6.70e-07]Steps:  85%|████████▌ | 4251/5000 [15:56:24<2:29:41, 11.99s/it, loss=0.4535, lr=6.68e-07]Steps:  85%|████████▌ | 4252/5000 [15:56:36<2:29:00, 11.95s/it, loss=0.4535, lr=6.68e-07]Steps:  85%|████████▌ | 4252/5000 [15:56:36<2:29:00, 11.95s/it, loss=0.6633, lr=6.66e-07]Steps:  85%|████████▌ | 4253/5000 [15:56:48<2:28:39, 11.94s/it, loss=0.6633, lr=6.66e-07]Steps:  85%|████████▌ | 4253/5000 [15:56:48<2:28:39, 11.94s/it, loss=0.3933, lr=6.65e-07]Steps:  85%|████████▌ | 4254/5000 [15:57:00<2:28:03, 11.91s/it, loss=0.3933, lr=6.65e-07]Steps:  85%|████████▌ | 4254/5000 [15:57:00<2:28:03, 11.91s/it, loss=0.4760, lr=6.63e-07]Steps:  85%|████████▌ | 4255/5000 [15:57:12<2:27:44, 11.90s/it, loss=0.4760, lr=6.63e-07]Steps:  85%|████████▌ | 4255/5000 [15:57:12<2:27:44, 11.90s/it, loss=1.0367, lr=6.61e-07]Steps:  85%|████████▌ | 4256/5000 [15:57:24<2:28:25, 11.97s/it, loss=1.0367, lr=6.61e-07]Steps:  85%|████████▌ | 4256/5000 [15:57:24<2:28:25, 11.97s/it, loss=0.5398, lr=6.59e-07]Steps:  85%|████████▌ | 4257/5000 [15:57:36<2:28:15, 11.97s/it, loss=0.5398, lr=6.59e-07]Steps:  85%|████████▌ | 4257/5000 [15:57:36<2:28:15, 11.97s/it, loss=1.0437, lr=6.58e-07]Steps:  85%|████████▌ | 4258/5000 [15:57:48<2:28:08, 11.98s/it, loss=1.0437, lr=6.58e-07]Steps:  85%|████████▌ | 4258/5000 [15:57:48<2:28:08, 11.98s/it, loss=0.6909, lr=6.56e-07]Steps:  85%|████████▌ | 4259/5000 [15:58:00<2:27:42, 11.96s/it, loss=0.6909, lr=6.56e-07]Steps:  85%|████████▌ | 4259/5000 [15:58:00<2:27:42, 11.96s/it, loss=0.9875, lr=6.54e-07]Steps:  85%|████████▌ | 4260/5000 [15:58:12<2:28:08, 12.01s/it, loss=0.9875, lr=6.54e-07]Steps:  85%|████████▌ | 4260/5000 [15:58:12<2:28:08, 12.01s/it, loss=0.4359, lr=6.53e-07]
[Step 4260] Training Debug Info:
  Loss: 0.456600
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0080, std: 0.9531
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0085, std: 1.3828
  Model pred mean: 0.0009, std: 1.2109
  Sigmas: [0.8671875]... (timesteps: [869.0])

[Step 4260] Training Debug Info:
  Loss: 0.517962
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 1.0391
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0349, std: 1.4375
  Model pred mean: -0.0352, std: 1.2500
  Sigmas: [0.69140625]... (timesteps: [692.0])

[Step 4260] Training Debug Info:
  Loss: 0.372903
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0231, std: 0.8672
  Noise mean: 0.0004, std: 0.9961
  Target mean: 0.0234, std: 1.3203
  Model pred mean: 0.0264, std: 1.1719
  Sigmas: [0.83984375]... (timesteps: [841.0])

[Step 4260] Training Debug Info:
  Loss: 0.826448
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0034, std: 0.9297
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0007, std: 1.3672
  Model pred mean: 0.0040, std: 1.0156
  Sigmas: [0.40625]... (timesteps: [406.0])
Steps:  85%|████████▌ | 4261/5000 [15:58:24<2:27:45, 12.00s/it, loss=0.4359, lr=6.53e-07]Steps:  85%|████████▌ | 4261/5000 [15:58:24<2:27:45, 12.00s/it, loss=0.8264, lr=6.51e-07]Steps:  85%|████████▌ | 4262/5000 [15:58:36<2:27:25, 11.99s/it, loss=0.8264, lr=6.51e-07]Steps:  85%|████████▌ | 4262/5000 [15:58:36<2:27:25, 11.99s/it, loss=0.8646, lr=6.49e-07]Steps:  85%|████████▌ | 4263/5000 [15:58:48<2:28:04, 12.05s/it, loss=0.8646, lr=6.49e-07]Steps:  85%|████████▌ | 4263/5000 [15:58:48<2:28:04, 12.05s/it, loss=0.3678, lr=6.47e-07]Steps:  85%|████████▌ | 4264/5000 [15:59:00<2:27:23, 12.02s/it, loss=0.3678, lr=6.47e-07]Steps:  85%|████████▌ | 4264/5000 [15:59:00<2:27:23, 12.02s/it, loss=1.0478, lr=6.46e-07]Steps:  85%|████████▌ | 4265/5000 [15:59:12<2:26:32, 11.96s/it, loss=1.0478, lr=6.46e-07]Steps:  85%|████████▌ | 4265/5000 [15:59:12<2:26:32, 11.96s/it, loss=1.1396, lr=6.44e-07]Steps:  85%|████████▌ | 4266/5000 [15:59:24<2:26:13, 11.95s/it, loss=1.1396, lr=6.44e-07]Steps:  85%|████████▌ | 4266/5000 [15:59:24<2:26:13, 11.95s/it, loss=0.9934, lr=6.42e-07]Steps:  85%|████████▌ | 4267/5000 [15:59:36<2:25:40, 11.92s/it, loss=0.9934, lr=6.42e-07]Steps:  85%|████████▌ | 4267/5000 [15:59:36<2:25:40, 11.92s/it, loss=0.4403, lr=6.41e-07]Steps:  85%|████████▌ | 4268/5000 [15:59:48<2:25:36, 11.93s/it, loss=0.4403, lr=6.41e-07]Steps:  85%|████████▌ | 4268/5000 [15:59:48<2:25:36, 11.93s/it, loss=1.0082, lr=6.39e-07]Steps:  85%|████████▌ | 4269/5000 [16:00:00<2:26:02, 11.99s/it, loss=1.0082, lr=6.39e-07]Steps:  85%|████████▌ | 4269/5000 [16:00:00<2:26:02, 11.99s/it, loss=0.5853, lr=6.37e-07]Steps:  85%|████████▌ | 4270/5000 [16:00:12<2:26:27, 12.04s/it, loss=0.5853, lr=6.37e-07]Steps:  85%|████████▌ | 4270/5000 [16:00:12<2:26:27, 12.04s/it, loss=0.8394, lr=6.35e-07]
[Step 4270] Training Debug Info:
  Loss: 1.114558
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0020, std: 0.9258
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0017, std: 1.3672
  Model pred mean: -0.0027, std: 0.8633
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 4270] Training Debug Info:
  Loss: 1.023202
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0046, std: 0.8750
  Noise mean: -0.0036, std: 1.0000
  Target mean: 0.0011, std: 1.3281
  Model pred mean: 0.0035, std: 0.8633
  Sigmas: [0.010986328125]... (timesteps: [11.0])

[Step 4270] Training Debug Info:
  Loss: 0.907417
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0610, std: 0.9414
  Noise mean: 0.0016, std: 0.9961
  Target mean: -0.0593, std: 1.3750
  Model pred mean: -0.0630, std: 0.9883
  Sigmas: [0.2578125]... (timesteps: [257.0])

[Step 4270] Training Debug Info:
  Loss: 0.422421
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0262, std: 0.9258
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0265, std: 1.3594
  Model pred mean: 0.0267, std: 1.1953
  Sigmas: [0.72265625]... (timesteps: [723.0])
Steps:  85%|████████▌ | 4271/5000 [16:00:24<2:25:40, 11.99s/it, loss=0.8394, lr=6.35e-07]Steps:  85%|████████▌ | 4271/5000 [16:00:24<2:25:40, 11.99s/it, loss=0.4224, lr=6.34e-07]Steps:  85%|████████▌ | 4272/5000 [16:00:36<2:25:11, 11.97s/it, loss=0.4224, lr=6.34e-07]Steps:  85%|████████▌ | 4272/5000 [16:00:36<2:25:11, 11.97s/it, loss=1.1101, lr=6.32e-07]Steps:  85%|████████▌ | 4273/5000 [16:00:48<2:24:49, 11.95s/it, loss=1.1101, lr=6.32e-07]Steps:  85%|████████▌ | 4273/5000 [16:00:48<2:24:49, 11.95s/it, loss=0.6009, lr=6.30e-07]Steps:  85%|████████▌ | 4274/5000 [16:01:00<2:24:20, 11.93s/it, loss=0.6009, lr=6.30e-07]Steps:  85%|████████▌ | 4274/5000 [16:01:00<2:24:20, 11.93s/it, loss=0.4043, lr=6.29e-07]Steps:  86%|████████▌ | 4275/5000 [16:01:11<2:24:00, 11.92s/it, loss=0.4043, lr=6.29e-07]Steps:  86%|████████▌ | 4275/5000 [16:01:11<2:24:00, 11.92s/it, loss=0.7880, lr=6.27e-07]Steps:  86%|████████▌ | 4276/5000 [16:01:23<2:23:58, 11.93s/it, loss=0.7880, lr=6.27e-07]Steps:  86%|████████▌ | 4276/5000 [16:01:23<2:23:58, 11.93s/it, loss=1.0321, lr=6.25e-07]Steps:  86%|████████▌ | 4277/5000 [16:01:36<2:24:16, 11.97s/it, loss=1.0321, lr=6.25e-07]Steps:  86%|████████▌ | 4277/5000 [16:01:36<2:24:16, 11.97s/it, loss=0.3715, lr=6.24e-07]Steps:  86%|████████▌ | 4278/5000 [16:01:48<2:24:30, 12.01s/it, loss=0.3715, lr=6.24e-07]Steps:  86%|████████▌ | 4278/5000 [16:01:48<2:24:30, 12.01s/it, loss=1.1975, lr=6.22e-07]Steps:  86%|████████▌ | 4279/5000 [16:02:00<2:24:02, 11.99s/it, loss=1.1975, lr=6.22e-07]Steps:  86%|████████▌ | 4279/5000 [16:02:00<2:24:02, 11.99s/it, loss=0.6476, lr=6.20e-07]Steps:  86%|████████▌ | 4280/5000 [16:02:12<2:23:48, 11.98s/it, loss=0.6476, lr=6.20e-07]Steps:  86%|████████▌ | 4280/5000 [16:02:12<2:23:48, 11.98s/it, loss=0.3666, lr=6.18e-07]
[Step 4280] Training Debug Info:
  Loss: 1.041091
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0405, std: 0.9375
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0432, std: 1.3672
  Model pred mean: -0.0403, std: 0.9180
  Sigmas: [0.0269775390625]... (timesteps: [27.0])

[Step 4280] Training Debug Info:
  Loss: 0.515535
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0072, std: 0.9102
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0098, std: 1.3516
  Model pred mean: -0.0050, std: 1.1562
  Sigmas: [0.9375]... (timesteps: [937.0])

[Step 4280] Training Debug Info:
  Loss: 1.032554
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0410, std: 0.9453
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0388, std: 1.3750
  Model pred mean: -0.0413, std: 0.9297
  Sigmas: [0.24609375]... (timesteps: [246.0])

[Step 4280] Training Debug Info:
  Loss: 1.073711
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0271, std: 0.9531
  Noise mean: 0.0047, std: 1.0000
  Target mean: -0.0223, std: 1.3828
  Model pred mean: -0.0250, std: 0.9180
  Sigmas: [0.2373046875]... (timesteps: [237.0])
Steps:  86%|████████▌ | 4281/5000 [16:02:24<2:23:35, 11.98s/it, loss=0.3666, lr=6.18e-07]Steps:  86%|████████▌ | 4281/5000 [16:02:24<2:23:35, 11.98s/it, loss=1.0737, lr=6.17e-07]Steps:  86%|████████▌ | 4282/5000 [16:02:35<2:23:10, 11.96s/it, loss=1.0737, lr=6.17e-07]Steps:  86%|████████▌ | 4282/5000 [16:02:35<2:23:10, 11.96s/it, loss=0.4702, lr=6.15e-07]Steps:  86%|████████▌ | 4283/5000 [16:02:48<2:23:47, 12.03s/it, loss=0.4702, lr=6.15e-07]Steps:  86%|████████▌ | 4283/5000 [16:02:48<2:23:47, 12.03s/it, loss=0.6955, lr=6.13e-07]Steps:  86%|████████▌ | 4284/5000 [16:03:00<2:23:08, 11.99s/it, loss=0.6955, lr=6.13e-07]Steps:  86%|████████▌ | 4284/5000 [16:03:00<2:23:08, 11.99s/it, loss=1.1490, lr=6.12e-07]Steps:  86%|████████▌ | 4285/5000 [16:03:11<2:22:28, 11.96s/it, loss=1.1490, lr=6.12e-07]Steps:  86%|████████▌ | 4285/5000 [16:03:11<2:22:28, 11.96s/it, loss=1.1023, lr=6.10e-07]Steps:  86%|████████▌ | 4286/5000 [16:03:23<2:22:14, 11.95s/it, loss=1.1023, lr=6.10e-07]Steps:  86%|████████▌ | 4286/5000 [16:03:23<2:22:14, 11.95s/it, loss=1.1448, lr=6.08e-07]Steps:  86%|████████▌ | 4287/5000 [16:03:35<2:22:25, 11.99s/it, loss=1.1448, lr=6.08e-07]Steps:  86%|████████▌ | 4287/5000 [16:03:35<2:22:25, 11.99s/it, loss=0.8562, lr=6.07e-07]Steps:  86%|████████▌ | 4288/5000 [16:03:47<2:22:04, 11.97s/it, loss=0.8562, lr=6.07e-07]Steps:  86%|████████▌ | 4288/5000 [16:03:47<2:22:04, 11.97s/it, loss=1.2285, lr=6.05e-07]Steps:  86%|████████▌ | 4289/5000 [16:03:59<2:21:43, 11.96s/it, loss=1.2285, lr=6.05e-07]Steps:  86%|████████▌ | 4289/5000 [16:03:59<2:21:43, 11.96s/it, loss=0.4763, lr=6.03e-07]Steps:  86%|████████▌ | 4290/5000 [16:04:11<2:22:05, 12.01s/it, loss=0.4763, lr=6.03e-07]Steps:  86%|████████▌ | 4290/5000 [16:04:11<2:22:05, 12.01s/it, loss=0.4707, lr=6.02e-07]
[Step 4290] Training Debug Info:
  Loss: 0.718204
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0547, std: 0.8984
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0562, std: 1.3438
  Model pred mean: -0.0554, std: 1.0469
  Sigmas: [0.4375]... (timesteps: [437.0])

[Step 4290] Training Debug Info:
  Loss: 0.419193
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0172, std: 0.9180
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0187, std: 1.3594
  Model pred mean: 0.0164, std: 1.1953
  Sigmas: [0.88671875]... (timesteps: [886.0])

[Step 4290] Training Debug Info:
  Loss: 1.007251
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0265, std: 0.9375
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0265, std: 1.3672
  Model pred mean: -0.0265, std: 0.9297
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 4290] Training Debug Info:
  Loss: 1.115160
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0043, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0031, std: 1.3516
  Model pred mean: 0.0052, std: 0.8477
  Sigmas: [0.2265625]... (timesteps: [227.0])
Steps:  86%|████████▌ | 4291/5000 [16:04:23<2:21:41, 11.99s/it, loss=0.4707, lr=6.02e-07]Steps:  86%|████████▌ | 4291/5000 [16:04:23<2:21:41, 11.99s/it, loss=1.1152, lr=6.00e-07]Steps:  86%|████████▌ | 4292/5000 [16:04:35<2:21:09, 11.96s/it, loss=1.1152, lr=6.00e-07]Steps:  86%|████████▌ | 4292/5000 [16:04:35<2:21:09, 11.96s/it, loss=0.4867, lr=5.98e-07]Steps:  86%|████████▌ | 4293/5000 [16:04:47<2:20:34, 11.93s/it, loss=0.4867, lr=5.98e-07]Steps:  86%|████████▌ | 4293/5000 [16:04:47<2:20:34, 11.93s/it, loss=0.3493, lr=5.97e-07]Steps:  86%|████████▌ | 4294/5000 [16:04:59<2:20:07, 11.91s/it, loss=0.3493, lr=5.97e-07]Steps:  86%|████████▌ | 4294/5000 [16:04:59<2:20:07, 11.91s/it, loss=0.4447, lr=5.95e-07]Steps:  86%|████████▌ | 4295/5000 [16:05:11<2:19:47, 11.90s/it, loss=0.4447, lr=5.95e-07]Steps:  86%|████████▌ | 4295/5000 [16:05:11<2:19:47, 11.90s/it, loss=0.8066, lr=5.93e-07]Steps:  86%|████████▌ | 4296/5000 [16:05:23<2:19:52, 11.92s/it, loss=0.8066, lr=5.93e-07]Steps:  86%|████████▌ | 4296/5000 [16:05:23<2:19:52, 11.92s/it, loss=1.1989, lr=5.92e-07]Steps:  86%|████████▌ | 4297/5000 [16:05:35<2:20:26, 11.99s/it, loss=1.1989, lr=5.92e-07]Steps:  86%|████████▌ | 4297/5000 [16:05:35<2:20:26, 11.99s/it, loss=0.5850, lr=5.90e-07]Steps:  86%|████████▌ | 4298/5000 [16:05:47<2:20:05, 11.97s/it, loss=0.5850, lr=5.90e-07]Steps:  86%|████████▌ | 4298/5000 [16:05:47<2:20:05, 11.97s/it, loss=1.1373, lr=5.89e-07]Steps:  86%|████████▌ | 4299/5000 [16:05:59<2:19:41, 11.96s/it, loss=1.1373, lr=5.89e-07]Steps:  86%|████████▌ | 4299/5000 [16:05:59<2:19:41, 11.96s/it, loss=0.5087, lr=5.87e-07]Steps:  86%|████████▌ | 4300/5000 [16:06:11<2:19:41, 11.97s/it, loss=0.5087, lr=5.87e-07]Steps:  86%|████████▌ | 4300/5000 [16:06:11<2:19:41, 11.97s/it, loss=1.0083, lr=5.85e-07]01/22/2026 23:51:58 - INFO - __main__ - 
[Step 4300] ✅ Loss in normal range (1.0083)
01/22/2026 23:51:58 - INFO - __main__ -   Loss avg (last 100): 0.7294
01/22/2026 23:51:58 - INFO - __main__ -   Loss range: [0.3493, 1.2285]

[Step 4300] Training Debug Info:
  Loss: 0.681563
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0168, std: 0.9609
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0171, std: 1.3828
  Model pred mean: 0.0160, std: 1.1172
  Sigmas: [0.5234375]... (timesteps: [525.0])

[Step 4300] Training Debug Info:
  Loss: 1.100258
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0073, std: 0.9141
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0092, std: 1.3516
  Model pred mean: 0.0080, std: 0.8594
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 4300] Training Debug Info:
  Loss: 0.848376
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0192, std: 0.9258
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0173, std: 1.3672
  Model pred mean: -0.0179, std: 1.0000
  Sigmas: [0.400390625]... (timesteps: [401.0])

[Step 4300] Training Debug Info:
  Loss: 0.367965
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0118, std: 0.9102
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0112, std: 1.3516
  Model pred mean: -0.0154, std: 1.2109
  Sigmas: [0.875]... (timesteps: [875.0])
Steps:  86%|████████▌ | 4301/5000 [16:06:23<2:19:04, 11.94s/it, loss=1.0083, lr=5.85e-07]Steps:  86%|████████▌ | 4301/5000 [16:06:23<2:19:04, 11.94s/it, loss=0.3680, lr=5.84e-07]Steps:  86%|████████▌ | 4302/5000 [16:06:35<2:19:01, 11.95s/it, loss=0.3680, lr=5.84e-07]Steps:  86%|████████▌ | 4302/5000 [16:06:35<2:19:01, 11.95s/it, loss=0.6589, lr=5.82e-07]Steps:  86%|████████▌ | 4303/5000 [16:06:47<2:18:36, 11.93s/it, loss=0.6589, lr=5.82e-07]Steps:  86%|████████▌ | 4303/5000 [16:06:47<2:18:36, 11.93s/it, loss=1.0994, lr=5.80e-07]Steps:  86%|████████▌ | 4304/5000 [16:06:59<2:19:28, 12.02s/it, loss=1.0994, lr=5.80e-07]Steps:  86%|████████▌ | 4304/5000 [16:06:59<2:19:28, 12.02s/it, loss=0.9118, lr=5.79e-07]Steps:  86%|████████▌ | 4305/5000 [16:07:11<2:18:52, 11.99s/it, loss=0.9118, lr=5.79e-07]Steps:  86%|████████▌ | 4305/5000 [16:07:11<2:18:52, 11.99s/it, loss=0.5633, lr=5.77e-07]Steps:  86%|████████▌ | 4306/5000 [16:07:23<2:18:18, 11.96s/it, loss=0.5633, lr=5.77e-07]Steps:  86%|████████▌ | 4306/5000 [16:07:23<2:18:18, 11.96s/it, loss=0.5754, lr=5.75e-07]Steps:  86%|████████▌ | 4307/5000 [16:07:34<2:17:45, 11.93s/it, loss=0.5754, lr=5.75e-07]Steps:  86%|████████▌ | 4307/5000 [16:07:34<2:17:45, 11.93s/it, loss=0.4253, lr=5.74e-07]Steps:  86%|████████▌ | 4308/5000 [16:07:46<2:17:16, 11.90s/it, loss=0.4253, lr=5.74e-07]Steps:  86%|████████▌ | 4308/5000 [16:07:46<2:17:16, 11.90s/it, loss=1.0823, lr=5.72e-07]Steps:  86%|████████▌ | 4309/5000 [16:07:58<2:17:00, 11.90s/it, loss=1.0823, lr=5.72e-07]Steps:  86%|████████▌ | 4309/5000 [16:07:58<2:17:00, 11.90s/it, loss=0.4473, lr=5.71e-07]Steps:  86%|████████▌ | 4310/5000 [16:08:10<2:17:30, 11.96s/it, loss=0.4473, lr=5.71e-07]Steps:  86%|████████▌ | 4310/5000 [16:08:10<2:17:30, 11.96s/it, loss=0.6031, lr=5.69e-07]
[Step 4310] Training Debug Info:
  Loss: 0.945668
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0005, std: 0.9297
  Noise mean: 0.0013, std: 1.0000
  Target mean: 0.0018, std: 1.3672
  Model pred mean: -0.0005, std: 0.9609
  Sigmas: [0.34765625]... (timesteps: [348.0])

[Step 4310] Training Debug Info:
  Loss: 0.618336
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0108, std: 0.9180
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0117, std: 1.3594
  Model pred mean: 0.0092, std: 1.1094
  Sigmas: [0.56640625]... (timesteps: [567.0])

[Step 4310] Training Debug Info:
  Loss: 0.375066
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0035, std: 0.8867
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0014, std: 1.3359
  Model pred mean: -0.0022, std: 1.1875
  Sigmas: [0.8046875]... (timesteps: [806.0])

[Step 4310] Training Debug Info:
  Loss: 1.099822
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0137, std: 0.9219
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0137, std: 1.3594
  Model pred mean: -0.0129, std: 0.8633
  Sigmas: [0.0751953125]... (timesteps: [75.0])
Steps:  86%|████████▌ | 4311/5000 [16:08:22<2:17:00, 11.93s/it, loss=0.6031, lr=5.69e-07]Steps:  86%|████████▌ | 4311/5000 [16:08:22<2:17:00, 11.93s/it, loss=1.0998, lr=5.67e-07]Steps:  86%|████████▌ | 4312/5000 [16:08:34<2:17:02, 11.95s/it, loss=1.0998, lr=5.67e-07]Steps:  86%|████████▌ | 4312/5000 [16:08:34<2:17:02, 11.95s/it, loss=1.1437, lr=5.66e-07]Steps:  86%|████████▋ | 4313/5000 [16:08:46<2:16:54, 11.96s/it, loss=1.1437, lr=5.66e-07]Steps:  86%|████████▋ | 4313/5000 [16:08:46<2:16:54, 11.96s/it, loss=0.6090, lr=5.64e-07]Steps:  86%|████████▋ | 4314/5000 [16:08:58<2:16:37, 11.95s/it, loss=0.6090, lr=5.64e-07]Steps:  86%|████████▋ | 4314/5000 [16:08:58<2:16:37, 11.95s/it, loss=0.9394, lr=5.63e-07]Steps:  86%|████████▋ | 4315/5000 [16:09:10<2:16:05, 11.92s/it, loss=0.9394, lr=5.63e-07]Steps:  86%|████████▋ | 4315/5000 [16:09:10<2:16:05, 11.92s/it, loss=0.8155, lr=5.61e-07]Steps:  86%|████████▋ | 4316/5000 [16:09:22<2:16:04, 11.94s/it, loss=0.8155, lr=5.61e-07]Steps:  86%|████████▋ | 4316/5000 [16:09:22<2:16:04, 11.94s/it, loss=0.7107, lr=5.59e-07]Steps:  86%|████████▋ | 4317/5000 [16:09:34<2:16:46, 12.02s/it, loss=0.7107, lr=5.59e-07]Steps:  86%|████████▋ | 4317/5000 [16:09:34<2:16:46, 12.02s/it, loss=0.4066, lr=5.58e-07]Steps:  86%|████████▋ | 4318/5000 [16:09:46<2:16:24, 12.00s/it, loss=0.4066, lr=5.58e-07]Steps:  86%|████████▋ | 4318/5000 [16:09:46<2:16:24, 12.00s/it, loss=0.3973, lr=5.56e-07]Steps:  86%|████████▋ | 4319/5000 [16:09:58<2:16:17, 12.01s/it, loss=0.3973, lr=5.56e-07]Steps:  86%|████████▋ | 4319/5000 [16:09:58<2:16:17, 12.01s/it, loss=1.0882, lr=5.55e-07]Steps:  86%|████████▋ | 4320/5000 [16:10:10<2:15:43, 11.98s/it, loss=1.0882, lr=5.55e-07]Steps:  86%|████████▋ | 4320/5000 [16:10:10<2:15:43, 11.98s/it, loss=0.6583, lr=5.53e-07]
[Step 4320] Training Debug Info:
  Loss: 0.840305
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0432, std: 0.8477
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0420, std: 1.3125
  Model pred mean: 0.0449, std: 0.9414
  Sigmas: [0.486328125]... (timesteps: [486.0])

[Step 4320] Training Debug Info:
  Loss: 1.079840
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0282, std: 0.9453
  Noise mean: -0.0006, std: 0.9961
  Target mean: -0.0288, std: 1.3750
  Model pred mean: -0.0269, std: 0.9062
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 4320] Training Debug Info:
  Loss: 1.150866
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0177, std: 0.9297
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0182, std: 1.3672
  Model pred mean: -0.0159, std: 0.8438
  Sigmas: [0.15234375]... (timesteps: [152.0])

[Step 4320] Training Debug Info:
  Loss: 0.973634
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0012, std: 0.9336
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0016, std: 1.3672
  Model pred mean: 0.0026, std: 0.9492
  Sigmas: [0.306640625]... (timesteps: [307.0])
Steps:  86%|████████▋ | 4321/5000 [16:10:22<2:15:23, 11.96s/it, loss=0.6583, lr=5.53e-07]Steps:  86%|████████▋ | 4321/5000 [16:10:22<2:15:23, 11.96s/it, loss=0.9736, lr=5.51e-07]Steps:  86%|████████▋ | 4322/5000 [16:10:34<2:15:03, 11.95s/it, loss=0.9736, lr=5.51e-07]Steps:  86%|████████▋ | 4322/5000 [16:10:34<2:15:03, 11.95s/it, loss=0.4498, lr=5.50e-07]Steps:  86%|████████▋ | 4323/5000 [16:10:46<2:14:44, 11.94s/it, loss=0.4498, lr=5.50e-07]Steps:  86%|████████▋ | 4323/5000 [16:10:46<2:14:44, 11.94s/it, loss=0.8956, lr=5.48e-07]Steps:  86%|████████▋ | 4324/5000 [16:10:58<2:15:23, 12.02s/it, loss=0.8956, lr=5.48e-07]Steps:  86%|████████▋ | 4324/5000 [16:10:58<2:15:23, 12.02s/it, loss=1.0440, lr=5.47e-07]Steps:  86%|████████▋ | 4325/5000 [16:11:10<2:14:45, 11.98s/it, loss=1.0440, lr=5.47e-07]Steps:  86%|████████▋ | 4325/5000 [16:11:10<2:14:45, 11.98s/it, loss=1.0907, lr=5.45e-07]Steps:  87%|████████▋ | 4326/5000 [16:11:22<2:15:09, 12.03s/it, loss=1.0907, lr=5.45e-07]Steps:  87%|████████▋ | 4326/5000 [16:11:22<2:15:09, 12.03s/it, loss=1.0316, lr=5.43e-07]Steps:  87%|████████▋ | 4327/5000 [16:11:34<2:14:31, 11.99s/it, loss=1.0316, lr=5.43e-07]Steps:  87%|████████▋ | 4327/5000 [16:11:34<2:14:31, 11.99s/it, loss=0.7566, lr=5.42e-07]Steps:  87%|████████▋ | 4328/5000 [16:11:46<2:13:59, 11.96s/it, loss=0.7566, lr=5.42e-07]Steps:  87%|████████▋ | 4328/5000 [16:11:46<2:13:59, 11.96s/it, loss=0.4361, lr=5.40e-07]Steps:  87%|████████▋ | 4329/5000 [16:11:58<2:13:39, 11.95s/it, loss=0.4361, lr=5.40e-07]Steps:  87%|████████▋ | 4329/5000 [16:11:58<2:13:39, 11.95s/it, loss=0.3679, lr=5.39e-07]Steps:  87%|████████▋ | 4330/5000 [16:12:10<2:13:23, 11.95s/it, loss=0.3679, lr=5.39e-07]Steps:  87%|████████▋ | 4330/5000 [16:12:10<2:13:23, 11.95s/it, loss=0.3786, lr=5.37e-07]
[Step 4330] Training Debug Info:
  Loss: 0.379763
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0066, std: 0.9141
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0101, std: 1.3594
  Model pred mean: -0.0078, std: 1.2109
  Sigmas: [0.8828125]... (timesteps: [884.0])

[Step 4330] Training Debug Info:
  Loss: 0.373277
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0164, std: 0.9297
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0161, std: 1.3672
  Model pred mean: 0.0086, std: 1.2266
  Sigmas: [0.90234375]... (timesteps: [904.0])

[Step 4330] Training Debug Info:
  Loss: 0.527379
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0361, std: 1.0000
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0356, std: 1.4141
  Model pred mean: -0.0356, std: 1.2109
  Sigmas: [0.51953125]... (timesteps: [519.0])

[Step 4330] Training Debug Info:
  Loss: 0.545934
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0282, std: 0.9688
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0304, std: 1.3906
  Model pred mean: -0.0260, std: 1.1797
  Sigmas: [0.6328125]... (timesteps: [634.0])
Steps:  87%|████████▋ | 4331/5000 [16:12:22<2:13:53, 12.01s/it, loss=0.3786, lr=5.37e-07]Steps:  87%|████████▋ | 4331/5000 [16:12:22<2:13:53, 12.01s/it, loss=0.5459, lr=5.35e-07]Steps:  87%|████████▋ | 4332/5000 [16:12:34<2:13:07, 11.96s/it, loss=0.5459, lr=5.35e-07]Steps:  87%|████████▋ | 4332/5000 [16:12:34<2:13:07, 11.96s/it, loss=0.4938, lr=5.34e-07]Steps:  87%|████████▋ | 4333/5000 [16:12:46<2:13:27, 12.00s/it, loss=0.4938, lr=5.34e-07]Steps:  87%|████████▋ | 4333/5000 [16:12:46<2:13:27, 12.00s/it, loss=0.5592, lr=5.32e-07]Steps:  87%|████████▋ | 4334/5000 [16:12:58<2:12:49, 11.97s/it, loss=0.5592, lr=5.32e-07]Steps:  87%|████████▋ | 4334/5000 [16:12:58<2:12:49, 11.97s/it, loss=0.4616, lr=5.31e-07]Steps:  87%|████████▋ | 4335/5000 [16:13:10<2:12:37, 11.97s/it, loss=0.4616, lr=5.31e-07]Steps:  87%|████████▋ | 4335/5000 [16:13:10<2:12:37, 11.97s/it, loss=0.3817, lr=5.29e-07]Steps:  87%|████████▋ | 4336/5000 [16:13:21<2:12:17, 11.95s/it, loss=0.3817, lr=5.29e-07]Steps:  87%|████████▋ | 4336/5000 [16:13:21<2:12:17, 11.95s/it, loss=1.0474, lr=5.28e-07]Steps:  87%|████████▋ | 4337/5000 [16:13:34<2:12:51, 12.02s/it, loss=1.0474, lr=5.28e-07]Steps:  87%|████████▋ | 4337/5000 [16:13:34<2:12:51, 12.02s/it, loss=1.1092, lr=5.26e-07]Steps:  87%|████████▋ | 4338/5000 [16:13:46<2:12:14, 11.99s/it, loss=1.1092, lr=5.26e-07]Steps:  87%|████████▋ | 4338/5000 [16:13:46<2:12:14, 11.99s/it, loss=1.0168, lr=5.25e-07]Steps:  87%|████████▋ | 4339/5000 [16:13:57<2:11:39, 11.95s/it, loss=1.0168, lr=5.25e-07]Steps:  87%|████████▋ | 4339/5000 [16:13:57<2:11:39, 11.95s/it, loss=0.7767, lr=5.23e-07]Steps:  87%|████████▋ | 4340/5000 [16:14:09<2:11:16, 11.93s/it, loss=0.7767, lr=5.23e-07]Steps:  87%|████████▋ | 4340/5000 [16:14:09<2:11:16, 11.93s/it, loss=0.9651, lr=5.21e-07]
[Step 4340] Training Debug Info:
  Loss: 0.371608
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0209, std: 0.9023
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0206, std: 1.3438
  Model pred mean: 0.0208, std: 1.2031
  Sigmas: [0.89453125]... (timesteps: [895.0])

[Step 4340] Training Debug Info:
  Loss: 0.968627
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0170, std: 1.3516
  Model pred mean: -0.0156, std: 0.9258
  Sigmas: [0.29296875]... (timesteps: [292.0])

[Step 4340] Training Debug Info:
  Loss: 0.405201
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0464, std: 0.8906
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0483, std: 1.3359
  Model pred mean: -0.0432, std: 1.1797
  Sigmas: [0.80859375]... (timesteps: [809.0])

[Step 4340] Training Debug Info:
  Loss: 0.640913
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0388, std: 0.9141
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0391, std: 1.3516
  Model pred mean: -0.0374, std: 1.0938
  Sigmas: [0.96875]... (timesteps: [968.0])
Steps:  87%|████████▋ | 4341/5000 [16:14:21<2:10:48, 11.91s/it, loss=0.9651, lr=5.21e-07]Steps:  87%|████████▋ | 4341/5000 [16:14:21<2:10:48, 11.91s/it, loss=0.6409, lr=5.20e-07]Steps:  87%|████████▋ | 4342/5000 [16:14:33<2:10:43, 11.92s/it, loss=0.6409, lr=5.20e-07]Steps:  87%|████████▋ | 4342/5000 [16:14:33<2:10:43, 11.92s/it, loss=0.8265, lr=5.18e-07]Steps:  87%|████████▋ | 4343/5000 [16:14:45<2:10:26, 11.91s/it, loss=0.8265, lr=5.18e-07]Steps:  87%|████████▋ | 4343/5000 [16:14:45<2:10:26, 11.91s/it, loss=0.3663, lr=5.17e-07]Steps:  87%|████████▋ | 4344/5000 [16:14:57<2:10:46, 11.96s/it, loss=0.3663, lr=5.17e-07]Steps:  87%|████████▋ | 4344/5000 [16:14:57<2:10:46, 11.96s/it, loss=0.3408, lr=5.15e-07]Steps:  87%|████████▋ | 4345/5000 [16:15:09<2:10:18, 11.94s/it, loss=0.3408, lr=5.15e-07]Steps:  87%|████████▋ | 4345/5000 [16:15:09<2:10:18, 11.94s/it, loss=0.6315, lr=5.14e-07]Steps:  87%|████████▋ | 4346/5000 [16:15:21<2:10:01, 11.93s/it, loss=0.6315, lr=5.14e-07]Steps:  87%|████████▋ | 4346/5000 [16:15:21<2:10:01, 11.93s/it, loss=0.5518, lr=5.12e-07]Steps:  87%|████████▋ | 4347/5000 [16:15:33<2:09:53, 11.93s/it, loss=0.5518, lr=5.12e-07]Steps:  87%|████████▋ | 4347/5000 [16:15:33<2:09:53, 11.93s/it, loss=0.4554, lr=5.11e-07]Steps:  87%|████████▋ | 4348/5000 [16:15:45<2:09:43, 11.94s/it, loss=0.4554, lr=5.11e-07]Steps:  87%|████████▋ | 4348/5000 [16:15:45<2:09:43, 11.94s/it, loss=1.0975, lr=5.09e-07]Steps:  87%|████████▋ | 4349/5000 [16:15:57<2:09:36, 11.95s/it, loss=1.0975, lr=5.09e-07]Steps:  87%|████████▋ | 4349/5000 [16:15:57<2:09:36, 11.95s/it, loss=0.9292, lr=5.08e-07]Steps:  87%|████████▋ | 4350/5000 [16:16:09<2:09:17, 11.94s/it, loss=0.9292, lr=5.08e-07]Steps:  87%|████████▋ | 4350/5000 [16:16:09<2:09:17, 11.94s/it, loss=0.9142, lr=5.06e-07]
[Step 4350] Training Debug Info:
  Loss: 1.016053
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0118, std: 0.8984
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0119, std: 1.3438
  Model pred mean: -0.0131, std: 0.8867
  Sigmas: [0.318359375]... (timesteps: [318.0])

[Step 4350] Training Debug Info:
  Loss: 1.102285
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0359, std: 0.9258
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0376, std: 1.3672
  Model pred mean: -0.0334, std: 0.8711
  Sigmas: [0.1923828125]... (timesteps: [192.0])

[Step 4350] Training Debug Info:
  Loss: 1.042808
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0327, std: 0.9414
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0337, std: 1.3672
  Model pred mean: -0.0310, std: 0.9180
  Sigmas: [0.263671875]... (timesteps: [263.0])

[Step 4350] Training Debug Info:
  Loss: 1.097833
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0076, std: 0.9336
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0070, std: 1.3672
  Model pred mean: -0.0077, std: 0.8828
  Sigmas: [0.0751953125]... (timesteps: [75.0])
Steps:  87%|████████▋ | 4351/5000 [16:16:21<2:09:39, 11.99s/it, loss=0.9142, lr=5.06e-07]Steps:  87%|████████▋ | 4351/5000 [16:16:21<2:09:39, 11.99s/it, loss=1.0978, lr=5.05e-07]Steps:  87%|████████▋ | 4352/5000 [16:16:33<2:09:14, 11.97s/it, loss=1.0978, lr=5.05e-07]Steps:  87%|████████▋ | 4352/5000 [16:16:33<2:09:14, 11.97s/it, loss=1.0882, lr=5.03e-07]Steps:  87%|████████▋ | 4353/5000 [16:16:45<2:08:43, 11.94s/it, loss=1.0882, lr=5.03e-07]Steps:  87%|████████▋ | 4353/5000 [16:16:45<2:08:43, 11.94s/it, loss=0.8165, lr=5.01e-07]Steps:  87%|████████▋ | 4354/5000 [16:16:56<2:08:30, 11.94s/it, loss=0.8165, lr=5.01e-07]Steps:  87%|████████▋ | 4354/5000 [16:16:56<2:08:30, 11.94s/it, loss=0.3881, lr=5.00e-07]Steps:  87%|████████▋ | 4355/5000 [16:17:09<2:08:35, 11.96s/it, loss=0.3881, lr=5.00e-07]Steps:  87%|████████▋ | 4355/5000 [16:17:09<2:08:35, 11.96s/it, loss=0.9056, lr=4.98e-07]Steps:  87%|████████▋ | 4356/5000 [16:17:20<2:08:17, 11.95s/it, loss=0.9056, lr=4.98e-07]Steps:  87%|████████▋ | 4356/5000 [16:17:20<2:08:17, 11.95s/it, loss=0.4875, lr=4.97e-07]Steps:  87%|████████▋ | 4357/5000 [16:17:32<2:08:03, 11.95s/it, loss=0.4875, lr=4.97e-07]Steps:  87%|████████▋ | 4357/5000 [16:17:32<2:08:03, 11.95s/it, loss=0.5106, lr=4.95e-07]Steps:  87%|████████▋ | 4358/5000 [16:17:45<2:09:02, 12.06s/it, loss=0.5106, lr=4.95e-07]Steps:  87%|████████▋ | 4358/5000 [16:17:45<2:09:02, 12.06s/it, loss=0.3719, lr=4.94e-07]Steps:  87%|████████▋ | 4359/5000 [16:17:57<2:08:02, 11.99s/it, loss=0.3719, lr=4.94e-07]Steps:  87%|████████▋ | 4359/5000 [16:17:57<2:08:02, 11.99s/it, loss=1.1653, lr=4.92e-07]Steps:  87%|████████▋ | 4360/5000 [16:18:09<2:07:54, 11.99s/it, loss=1.1653, lr=4.92e-07]Steps:  87%|████████▋ | 4360/5000 [16:18:09<2:07:54, 11.99s/it, loss=0.5175, lr=4.91e-07]
[Step 4360] Training Debug Info:
  Loss: 0.565454
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0165, std: 0.9844
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0173, std: 1.3984
  Model pred mean: 0.0188, std: 1.1875
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 4360] Training Debug Info:
  Loss: 0.635688
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0109, std: 0.8945
  Noise mean: 0.0017, std: 1.0078
  Target mean: 0.0126, std: 1.3438
  Model pred mean: 0.0019, std: 1.1016
  Sigmas: [0.97265625]... (timesteps: [973.0])

[Step 4360] Training Debug Info:
  Loss: 0.673273
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0074, std: 0.9102
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0088, std: 1.3516
  Model pred mean: -0.0036, std: 1.0781
  Sigmas: [0.53515625]... (timesteps: [537.0])

[Step 4360] Training Debug Info:
  Loss: 0.498245
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0223, std: 0.8281
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0214, std: 1.2969
  Model pred mean: 0.0189, std: 1.0859
  Sigmas: [0.6953125]... (timesteps: [694.0])
Steps:  87%|████████▋ | 4361/5000 [16:18:21<2:07:55, 12.01s/it, loss=0.5175, lr=4.91e-07]Steps:  87%|████████▋ | 4361/5000 [16:18:21<2:07:55, 12.01s/it, loss=0.4982, lr=4.89e-07]Steps:  87%|████████▋ | 4362/5000 [16:18:32<2:07:22, 11.98s/it, loss=0.4982, lr=4.89e-07]Steps:  87%|████████▋ | 4362/5000 [16:18:32<2:07:22, 11.98s/it, loss=0.7636, lr=4.88e-07]Steps:  87%|████████▋ | 4363/5000 [16:18:44<2:06:46, 11.94s/it, loss=0.7636, lr=4.88e-07]Steps:  87%|████████▋ | 4363/5000 [16:18:44<2:06:46, 11.94s/it, loss=1.1148, lr=4.86e-07]Steps:  87%|████████▋ | 4364/5000 [16:18:56<2:07:14, 12.00s/it, loss=1.1148, lr=4.86e-07]Steps:  87%|████████▋ | 4364/5000 [16:18:56<2:07:14, 12.00s/it, loss=0.9905, lr=4.85e-07]Steps:  87%|████████▋ | 4365/5000 [16:19:08<2:06:35, 11.96s/it, loss=0.9905, lr=4.85e-07]Steps:  87%|████████▋ | 4365/5000 [16:19:08<2:06:35, 11.96s/it, loss=0.6296, lr=4.83e-07]Steps:  87%|████████▋ | 4366/5000 [16:19:20<2:06:06, 11.93s/it, loss=0.6296, lr=4.83e-07]Steps:  87%|████████▋ | 4366/5000 [16:19:20<2:06:06, 11.93s/it, loss=0.3849, lr=4.82e-07]Steps:  87%|████████▋ | 4367/5000 [16:19:32<2:06:17, 11.97s/it, loss=0.3849, lr=4.82e-07]Steps:  87%|████████▋ | 4367/5000 [16:19:32<2:06:17, 11.97s/it, loss=0.5261, lr=4.80e-07]Steps:  87%|████████▋ | 4368/5000 [16:19:44<2:05:44, 11.94s/it, loss=0.5261, lr=4.80e-07]Steps:  87%|████████▋ | 4368/5000 [16:19:44<2:05:44, 11.94s/it, loss=1.0658, lr=4.79e-07]Steps:  87%|████████▋ | 4369/5000 [16:19:56<2:05:17, 11.91s/it, loss=1.0658, lr=4.79e-07]Steps:  87%|████████▋ | 4369/5000 [16:19:56<2:05:17, 11.91s/it, loss=0.7375, lr=4.77e-07]Steps:  87%|████████▋ | 4370/5000 [16:20:08<2:04:49, 11.89s/it, loss=0.7375, lr=4.77e-07]Steps:  87%|████████▋ | 4370/5000 [16:20:08<2:04:49, 11.89s/it, loss=0.3951, lr=4.76e-07]
[Step 4370] Training Debug Info:
  Loss: 0.812323
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0130, std: 0.9102
  Noise mean: -0.0020, std: 0.9961
  Target mean: 0.0110, std: 1.3516
  Model pred mean: 0.0154, std: 1.0078
  Sigmas: [0.44921875]... (timesteps: [449.0])

[Step 4370] Training Debug Info:
  Loss: 0.968803
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0016, std: 0.9609
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0005, std: 1.3828
  Model pred mean: 0.0003, std: 0.9766
  Sigmas: [0.287109375]... (timesteps: [288.0])

[Step 4370] Training Debug Info:
  Loss: 1.112867
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0068, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0081, std: 1.3672
  Model pred mean: 0.0071, std: 0.8672
  Sigmas: [0.1943359375]... (timesteps: [194.0])

[Step 4370] Training Debug Info:
  Loss: 1.120576
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0132, std: 0.8984
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0151, std: 1.3438
  Model pred mean: 0.0126, std: 0.8320
  Sigmas: [0.078125]... (timesteps: [78.0])
Steps:  87%|████████▋ | 4371/5000 [16:20:20<2:05:33, 11.98s/it, loss=0.3951, lr=4.76e-07]Steps:  87%|████████▋ | 4371/5000 [16:20:20<2:05:33, 11.98s/it, loss=1.1206, lr=4.74e-07]Steps:  87%|████████▋ | 4372/5000 [16:20:32<2:05:05, 11.95s/it, loss=1.1206, lr=4.74e-07]Steps:  87%|████████▋ | 4372/5000 [16:20:32<2:05:05, 11.95s/it, loss=0.3985, lr=4.73e-07]Steps:  87%|████████▋ | 4373/5000 [16:20:44<2:04:57, 11.96s/it, loss=0.3985, lr=4.73e-07]Steps:  87%|████████▋ | 4373/5000 [16:20:44<2:04:57, 11.96s/it, loss=0.4934, lr=4.71e-07]Steps:  87%|████████▋ | 4374/5000 [16:20:56<2:04:38, 11.95s/it, loss=0.4934, lr=4.71e-07]Steps:  87%|████████▋ | 4374/5000 [16:20:56<2:04:38, 11.95s/it, loss=0.4388, lr=4.70e-07]Steps:  88%|████████▊ | 4375/5000 [16:21:08<2:04:12, 11.92s/it, loss=0.4388, lr=4.70e-07]Steps:  88%|████████▊ | 4375/5000 [16:21:08<2:04:12, 11.92s/it, loss=0.5790, lr=4.68e-07]Steps:  88%|████████▊ | 4376/5000 [16:21:20<2:04:22, 11.96s/it, loss=0.5790, lr=4.68e-07]Steps:  88%|████████▊ | 4376/5000 [16:21:20<2:04:22, 11.96s/it, loss=0.8171, lr=4.67e-07]Steps:  88%|████████▊ | 4377/5000 [16:21:32<2:04:00, 11.94s/it, loss=0.8171, lr=4.67e-07]Steps:  88%|████████▊ | 4377/5000 [16:21:32<2:04:00, 11.94s/it, loss=0.9583, lr=4.66e-07]Steps:  88%|████████▊ | 4378/5000 [16:21:44<2:04:30, 12.01s/it, loss=0.9583, lr=4.66e-07]Steps:  88%|████████▊ | 4378/5000 [16:21:44<2:04:30, 12.01s/it, loss=0.5017, lr=4.64e-07]Steps:  88%|████████▊ | 4379/5000 [16:21:56<2:03:59, 11.98s/it, loss=0.5017, lr=4.64e-07]Steps:  88%|████████▊ | 4379/5000 [16:21:56<2:03:59, 11.98s/it, loss=0.8082, lr=4.63e-07]Steps:  88%|████████▊ | 4380/5000 [16:22:08<2:03:29, 11.95s/it, loss=0.8082, lr=4.63e-07]Steps:  88%|████████▊ | 4380/5000 [16:22:08<2:03:29, 11.95s/it, loss=0.4349, lr=4.61e-07]
[Step 4380] Training Debug Info:
  Loss: 1.085488
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0106, std: 0.9336
  Noise mean: 0.0016, std: 0.9961
  Target mean: -0.0090, std: 1.3672
  Model pred mean: -0.0113, std: 0.8828
  Sigmas: [0.07177734375]... (timesteps: [72.0])

[Step 4380] Training Debug Info:
  Loss: 1.177012
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.8906
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0074, std: 1.3438
  Model pred mean: 0.0091, std: 0.7891
  Sigmas: [0.1787109375]... (timesteps: [179.0])

[Step 4380] Training Debug Info:
  Loss: 0.536761
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0162, std: 0.9102
  Noise mean: -0.0018, std: 1.0000
  Target mean: 0.0145, std: 1.3516
  Model pred mean: -0.0017, std: 1.1484
  Sigmas: [0.94921875]... (timesteps: [949.0])

[Step 4380] Training Debug Info:
  Loss: 0.990799
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0124, std: 0.9609
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0118, std: 1.3828
  Model pred mean: -0.0120, std: 0.9609
  Sigmas: [0.275390625]... (timesteps: [275.0])
Steps:  88%|████████▊ | 4381/5000 [16:22:19<2:03:03, 11.93s/it, loss=0.4349, lr=4.61e-07]Steps:  88%|████████▊ | 4381/5000 [16:22:19<2:03:03, 11.93s/it, loss=0.9908, lr=4.60e-07]Steps:  88%|████████▊ | 4382/5000 [16:22:31<2:02:49, 11.92s/it, loss=0.9908, lr=4.60e-07]Steps:  88%|████████▊ | 4382/5000 [16:22:31<2:02:49, 11.92s/it, loss=1.0779, lr=4.58e-07]Steps:  88%|████████▊ | 4383/5000 [16:22:43<2:02:40, 11.93s/it, loss=1.0779, lr=4.58e-07]Steps:  88%|████████▊ | 4383/5000 [16:22:43<2:02:40, 11.93s/it, loss=1.1151, lr=4.57e-07]Steps:  88%|████████▊ | 4384/5000 [16:22:55<2:02:23, 11.92s/it, loss=1.1151, lr=4.57e-07]Steps:  88%|████████▊ | 4384/5000 [16:22:55<2:02:23, 11.92s/it, loss=0.5322, lr=4.55e-07]Steps:  88%|████████▊ | 4385/5000 [16:23:07<2:03:06, 12.01s/it, loss=0.5322, lr=4.55e-07]Steps:  88%|████████▊ | 4385/5000 [16:23:07<2:03:06, 12.01s/it, loss=0.8565, lr=4.54e-07]Steps:  88%|████████▊ | 4386/5000 [16:23:19<2:02:28, 11.97s/it, loss=0.8565, lr=4.54e-07]Steps:  88%|████████▊ | 4386/5000 [16:23:19<2:02:28, 11.97s/it, loss=0.6144, lr=4.52e-07]Steps:  88%|████████▊ | 4387/5000 [16:23:31<2:02:04, 11.95s/it, loss=0.6144, lr=4.52e-07]Steps:  88%|████████▊ | 4387/5000 [16:23:31<2:02:04, 11.95s/it, loss=1.2153, lr=4.51e-07]Steps:  88%|████████▊ | 4388/5000 [16:23:43<2:01:51, 11.95s/it, loss=1.2153, lr=4.51e-07]Steps:  88%|████████▊ | 4388/5000 [16:23:43<2:01:51, 11.95s/it, loss=0.4047, lr=4.49e-07]Steps:  88%|████████▊ | 4389/5000 [16:23:55<2:01:31, 11.93s/it, loss=0.4047, lr=4.49e-07]Steps:  88%|████████▊ | 4389/5000 [16:23:55<2:01:31, 11.93s/it, loss=1.1217, lr=4.48e-07]Steps:  88%|████████▊ | 4390/5000 [16:24:07<2:01:16, 11.93s/it, loss=1.1217, lr=4.48e-07]Steps:  88%|████████▊ | 4390/5000 [16:24:07<2:01:16, 11.93s/it, loss=1.0847, lr=4.47e-07]
[Step 4390] Training Debug Info:
  Loss: 0.526767
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0232, std: 0.9258
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0222, std: 1.3672
  Model pred mean: -0.0299, std: 1.1562
  Sigmas: [0.93359375]... (timesteps: [932.0])

[Step 4390] Training Debug Info:
  Loss: 1.138188
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0106, std: 0.8984
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0129, std: 1.3438
  Model pred mean: -0.0105, std: 0.8164
  Sigmas: [0.1298828125]... (timesteps: [130.0])

[Step 4390] Training Debug Info:
  Loss: 0.918019
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0177, std: 0.9766
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0177, std: 1.3984
  Model pred mean: -0.0176, std: 1.0156
  Sigmas: [0.333984375]... (timesteps: [334.0])

[Step 4390] Training Debug Info:
  Loss: 0.835992
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0124, std: 0.9062
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0111, std: 1.3438
  Model pred mean: -0.0109, std: 0.9922
  Sigmas: [0.423828125]... (timesteps: [423.0])
Steps:  88%|████████▊ | 4391/5000 [16:24:19<2:01:54, 12.01s/it, loss=1.0847, lr=4.47e-07]Steps:  88%|████████▊ | 4391/5000 [16:24:19<2:01:54, 12.01s/it, loss=0.8360, lr=4.45e-07]Steps:  88%|████████▊ | 4392/5000 [16:24:31<2:01:32, 11.99s/it, loss=0.8360, lr=4.45e-07]Steps:  88%|████████▊ | 4392/5000 [16:24:31<2:01:32, 11.99s/it, loss=0.4662, lr=4.44e-07]Steps:  88%|████████▊ | 4393/5000 [16:24:43<2:01:30, 12.01s/it, loss=0.4662, lr=4.44e-07]Steps:  88%|████████▊ | 4393/5000 [16:24:43<2:01:30, 12.01s/it, loss=0.4747, lr=4.42e-07]Steps:  88%|████████▊ | 4394/5000 [16:24:55<2:01:27, 12.02s/it, loss=0.4747, lr=4.42e-07]Steps:  88%|████████▊ | 4394/5000 [16:24:55<2:01:27, 12.02s/it, loss=0.4585, lr=4.41e-07]Steps:  88%|████████▊ | 4395/5000 [16:25:07<2:00:52, 11.99s/it, loss=0.4585, lr=4.41e-07]Steps:  88%|████████▊ | 4395/5000 [16:25:07<2:00:52, 11.99s/it, loss=0.5156, lr=4.39e-07]Steps:  88%|████████▊ | 4396/5000 [16:25:19<2:00:35, 11.98s/it, loss=0.5156, lr=4.39e-07]Steps:  88%|████████▊ | 4396/5000 [16:25:19<2:00:35, 11.98s/it, loss=0.3488, lr=4.38e-07]Steps:  88%|████████▊ | 4397/5000 [16:25:31<2:00:17, 11.97s/it, loss=0.3488, lr=4.38e-07]Steps:  88%|████████▊ | 4397/5000 [16:25:31<2:00:17, 11.97s/it, loss=1.0978, lr=4.37e-07]Steps:  88%|████████▊ | 4398/5000 [16:25:43<2:00:38, 12.02s/it, loss=1.0978, lr=4.37e-07]Steps:  88%|████████▊ | 4398/5000 [16:25:43<2:00:38, 12.02s/it, loss=1.1357, lr=4.35e-07]Steps:  88%|████████▊ | 4399/5000 [16:25:55<2:00:16, 12.01s/it, loss=1.1357, lr=4.35e-07]Steps:  88%|████████▊ | 4399/5000 [16:25:55<2:00:16, 12.01s/it, loss=1.0341, lr=4.34e-07]Steps:  88%|████████▊ | 4400/5000 [16:26:07<1:59:42, 11.97s/it, loss=1.0341, lr=4.34e-07]Steps:  88%|████████▊ | 4400/5000 [16:26:07<1:59:42, 11.97s/it, loss=1.1370, lr=4.32e-07]01/23/2026 00:11:54 - INFO - __main__ - 
[Step 4400] ✅ Loss in normal range (1.1370)
01/23/2026 00:11:54 - INFO - __main__ -   Loss avg (last 100): 0.7366
01/23/2026 00:11:54 - INFO - __main__ -   Loss range: [0.3408, 1.2153]
01/23/2026 00:11:54 - INFO - __main__ - 
🔍 Running validation at step 4400...
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4400 (parquet mode)...
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4400...
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/23/2026 00:11:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.18it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/23/2026 00:12:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/23/2026 00:12:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.21it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/23/2026 00:12:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/23/2026 00:12:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 00:12:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/23/2026 00:12:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/23/2026 00:13:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/23/2026 00:13:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/23/2026 00:13:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/23/2026 00:13:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/23/2026 00:14:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/23/2026 00:14:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:14:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/23/2026 00:14:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:14:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/23/2026 00:14:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:15:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/23/2026 00:15:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:15:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/23/2026 00:15:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.41it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.41it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/23/2026 00:15:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/23/2026 00:15:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/23/2026 00:16:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400/step004400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/23/2026 00:16:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/23/2026 00:16:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/23/2026 00:16:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004400
01/23/2026 00:16:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 4400] Training Debug Info:
  Loss: 0.517648
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0461, std: 0.9492
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0449, std: 1.3828
  Model pred mean: -0.0508, std: 1.1797
  Sigmas: [0.91796875]... (timesteps: [919.0])

[Step 4400] Training Debug Info:
  Loss: 0.851501
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0084, std: 0.9297
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0084, std: 1.3672
  Model pred mean: -0.0098, std: 1.0078
  Sigmas: [0.392578125]... (timesteps: [392.0])

[Step 4400] Training Debug Info:
  Loss: 1.075634
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0021, std: 0.9023
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0027, std: 1.3438
  Model pred mean: -0.0023, std: 0.8555
  Sigmas: [0.0439453125]... (timesteps: [44.0])

[Step 4400] Training Debug Info:
  Loss: 0.491883
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0151, std: 0.9062
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0159, std: 1.3516
  Model pred mean: -0.0128, std: 1.1562
  Sigmas: [0.6484375]... (timesteps: [647.0])
Steps:  88%|████████▊ | 4401/5000 [16:30:40<15:00:52, 90.24s/it, loss=1.1370, lr=4.32e-07]Steps:  88%|████████▊ | 4401/5000 [16:30:40<15:00:52, 90.24s/it, loss=0.4919, lr=4.31e-07]Steps:  88%|████████▊ | 4402/5000 [16:30:52<11:05:09, 66.74s/it, loss=0.4919, lr=4.31e-07]Steps:  88%|████████▊ | 4402/5000 [16:30:52<11:05:09, 66.74s/it, loss=0.4215, lr=4.29e-07]Steps:  88%|████████▊ | 4403/5000 [16:31:04<8:20:24, 50.29s/it, loss=0.4215, lr=4.29e-07] Steps:  88%|████████▊ | 4403/5000 [16:31:04<8:20:24, 50.29s/it, loss=0.9201, lr=4.28e-07]Steps:  88%|████████▊ | 4404/5000 [16:31:16<6:25:09, 38.77s/it, loss=0.9201, lr=4.28e-07]Steps:  88%|████████▊ | 4404/5000 [16:31:16<6:25:09, 38.77s/it, loss=1.0748, lr=4.27e-07]Steps:  88%|████████▊ | 4405/5000 [16:31:28<5:05:27, 30.80s/it, loss=1.0748, lr=4.27e-07]Steps:  88%|████████▊ | 4405/5000 [16:31:28<5:05:27, 30.80s/it, loss=0.4894, lr=4.25e-07]Steps:  88%|████████▊ | 4406/5000 [16:31:40<4:09:03, 25.16s/it, loss=0.4894, lr=4.25e-07]Steps:  88%|████████▊ | 4406/5000 [16:31:40<4:09:03, 25.16s/it, loss=1.1806, lr=4.24e-07]Steps:  88%|████████▊ | 4407/5000 [16:31:52<3:29:33, 21.20s/it, loss=1.1806, lr=4.24e-07]Steps:  88%|████████▊ | 4407/5000 [16:31:52<3:29:33, 21.20s/it, loss=0.3834, lr=4.22e-07]Steps:  88%|████████▊ | 4408/5000 [16:32:04<3:02:27, 18.49s/it, loss=0.3834, lr=4.22e-07]Steps:  88%|████████▊ | 4408/5000 [16:32:04<3:02:27, 18.49s/it, loss=0.5882, lr=4.21e-07]Steps:  88%|████████▊ | 4409/5000 [16:32:16<2:42:53, 16.54s/it, loss=0.5882, lr=4.21e-07]Steps:  88%|████████▊ | 4409/5000 [16:32:16<2:42:53, 16.54s/it, loss=0.9514, lr=4.20e-07]Steps:  88%|████████▊ | 4410/5000 [16:32:28<2:28:55, 15.15s/it, loss=0.9514, lr=4.20e-07]Steps:  88%|████████▊ | 4410/5000 [16:32:28<2:28:55, 15.15s/it, loss=0.3511, lr=4.18e-07]
[Step 4410] Training Debug Info:
  Loss: 0.801420
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0085, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0086, std: 1.3516
  Model pred mean: -0.0074, std: 1.0156
  Sigmas: [0.44140625]... (timesteps: [442.0])

[Step 4410] Training Debug Info:
  Loss: 1.086244
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0075, std: 0.9453
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0042, std: 1.3750
  Model pred mean: -0.0072, std: 0.8984
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 4410] Training Debug Info:
  Loss: 0.820725
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0051, std: 0.8672
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0060, std: 1.3203
  Model pred mean: -0.0046, std: 0.9648
  Sigmas: [0.478515625]... (timesteps: [479.0])

[Step 4410] Training Debug Info:
  Loss: 1.073656
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0184, std: 0.9102
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0205, std: 1.3516
  Model pred mean: 0.0182, std: 0.8672
  Sigmas: [0.0458984375]... (timesteps: [46.0])
Steps:  88%|████████▊ | 4411/5000 [16:32:40<2:19:17, 14.19s/it, loss=0.3511, lr=4.18e-07]Steps:  88%|████████▊ | 4411/5000 [16:32:40<2:19:17, 14.19s/it, loss=1.0737, lr=4.17e-07]Steps:  88%|████████▊ | 4412/5000 [16:32:52<2:12:53, 13.56s/it, loss=1.0737, lr=4.17e-07]Steps:  88%|████████▊ | 4412/5000 [16:32:52<2:12:53, 13.56s/it, loss=1.0115, lr=4.15e-07]Steps:  88%|████████▊ | 4413/5000 [16:33:04<2:07:57, 13.08s/it, loss=1.0115, lr=4.15e-07]Steps:  88%|████████▊ | 4413/5000 [16:33:04<2:07:57, 13.08s/it, loss=1.1036, lr=4.14e-07]Steps:  88%|████████▊ | 4414/5000 [16:33:16<2:04:26, 12.74s/it, loss=1.1036, lr=4.14e-07]Steps:  88%|████████▊ | 4414/5000 [16:33:16<2:04:26, 12.74s/it, loss=0.4866, lr=4.13e-07]Steps:  88%|████████▊ | 4415/5000 [16:33:28<2:01:53, 12.50s/it, loss=0.4866, lr=4.13e-07]Steps:  88%|████████▊ | 4415/5000 [16:33:28<2:01:53, 12.50s/it, loss=1.0489, lr=4.11e-07]Steps:  88%|████████▊ | 4416/5000 [16:33:40<1:59:56, 12.32s/it, loss=1.0489, lr=4.11e-07]Steps:  88%|████████▊ | 4416/5000 [16:33:40<1:59:56, 12.32s/it, loss=0.8818, lr=4.10e-07]Steps:  88%|████████▊ | 4417/5000 [16:33:52<1:58:34, 12.20s/it, loss=0.8818, lr=4.10e-07]Steps:  88%|████████▊ | 4417/5000 [16:33:52<1:58:34, 12.20s/it, loss=0.5435, lr=4.08e-07]Steps:  88%|████████▊ | 4418/5000 [16:34:04<1:57:58, 12.16s/it, loss=0.5435, lr=4.08e-07]Steps:  88%|████████▊ | 4418/5000 [16:34:04<1:57:58, 12.16s/it, loss=0.5054, lr=4.07e-07]Steps:  88%|████████▊ | 4419/5000 [16:34:16<1:57:00, 12.08s/it, loss=0.5054, lr=4.07e-07]Steps:  88%|████████▊ | 4419/5000 [16:34:16<1:57:00, 12.08s/it, loss=0.3792, lr=4.06e-07]Steps:  88%|████████▊ | 4420/5000 [16:34:27<1:56:13, 12.02s/it, loss=0.3792, lr=4.06e-07]Steps:  88%|████████▊ | 4420/5000 [16:34:27<1:56:13, 12.02s/it, loss=0.4145, lr=4.04e-07]
[Step 4420] Training Debug Info:
  Loss: 1.102093
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0272, std: 0.8945
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0255, std: 1.3438
  Model pred mean: 0.0282, std: 0.8398
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 4420] Training Debug Info:
  Loss: 0.391703
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0034, std: 0.9141
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0014, std: 1.3516
  Model pred mean: -0.0043, std: 1.1953
  Sigmas: [0.859375]... (timesteps: [859.0])

[Step 4420] Training Debug Info:
  Loss: 0.501206
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0249, std: 0.8906
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0226, std: 1.3359
  Model pred mean: 0.0231, std: 1.1406
  Sigmas: [0.671875]... (timesteps: [670.0])

[Step 4420] Training Debug Info:
  Loss: 0.389958
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0016, std: 0.9141
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0019, std: 1.3516
  Model pred mean: 0.0001, std: 1.2031
  Sigmas: [0.83984375]... (timesteps: [838.0])
Steps:  88%|████████▊ | 4421/5000 [16:34:39<1:55:39, 11.98s/it, loss=0.4145, lr=4.04e-07]Steps:  88%|████████▊ | 4421/5000 [16:34:39<1:55:39, 11.98s/it, loss=0.3900, lr=4.03e-07]Steps:  88%|████████▊ | 4422/5000 [16:34:51<1:56:03, 12.05s/it, loss=0.3900, lr=4.03e-07]Steps:  88%|████████▊ | 4422/5000 [16:34:51<1:56:03, 12.05s/it, loss=0.6976, lr=4.02e-07]Steps:  88%|████████▊ | 4423/5000 [16:35:03<1:55:35, 12.02s/it, loss=0.6976, lr=4.02e-07]Steps:  88%|████████▊ | 4423/5000 [16:35:03<1:55:35, 12.02s/it, loss=0.6187, lr=4.00e-07]Steps:  88%|████████▊ | 4424/5000 [16:35:15<1:55:21, 12.02s/it, loss=0.6187, lr=4.00e-07]Steps:  88%|████████▊ | 4424/5000 [16:35:15<1:55:21, 12.02s/it, loss=1.0138, lr=3.99e-07]Steps:  88%|████████▊ | 4425/5000 [16:35:28<1:55:41, 12.07s/it, loss=1.0138, lr=3.99e-07]Steps:  88%|████████▊ | 4425/5000 [16:35:28<1:55:41, 12.07s/it, loss=0.3459, lr=3.97e-07]Steps:  89%|████████▊ | 4426/5000 [16:35:40<1:55:09, 12.04s/it, loss=0.3459, lr=3.97e-07]Steps:  89%|████████▊ | 4426/5000 [16:35:40<1:55:09, 12.04s/it, loss=0.7993, lr=3.96e-07]Steps:  89%|████████▊ | 4427/5000 [16:35:52<1:54:38, 12.00s/it, loss=0.7993, lr=3.96e-07]Steps:  89%|████████▊ | 4427/5000 [16:35:52<1:54:38, 12.00s/it, loss=0.8821, lr=3.95e-07]Steps:  89%|████████▊ | 4428/5000 [16:36:03<1:54:03, 11.96s/it, loss=0.8821, lr=3.95e-07]Steps:  89%|████████▊ | 4428/5000 [16:36:03<1:54:03, 11.96s/it, loss=1.0248, lr=3.93e-07]Steps:  89%|████████▊ | 4429/5000 [16:36:16<1:54:47, 12.06s/it, loss=1.0248, lr=3.93e-07]Steps:  89%|████████▊ | 4429/5000 [16:36:16<1:54:47, 12.06s/it, loss=0.4252, lr=3.92e-07]Steps:  89%|████████▊ | 4430/5000 [16:36:28<1:54:13, 12.02s/it, loss=0.4252, lr=3.92e-07]Steps:  89%|████████▊ | 4430/5000 [16:36:28<1:54:13, 12.02s/it, loss=1.1040, lr=3.91e-07]
[Step 4430] Training Debug Info:
  Loss: 0.603719
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0043, std: 0.8984
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0069, std: 1.3438
  Model pred mean: -0.0071, std: 1.0938
  Sigmas: [0.58203125]... (timesteps: [582.0])

[Step 4430] Training Debug Info:
  Loss: 1.004576
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0393, std: 0.9570
  Noise mean: 0.0039, std: 1.0000
  Target mean: -0.0354, std: 1.3828
  Model pred mean: -0.0386, std: 0.9492
  Sigmas: [0.31640625]... (timesteps: [317.0])

[Step 4430] Training Debug Info:
  Loss: 0.892997
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0262, std: 0.9180
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0272, std: 1.3594
  Model pred mean: -0.0259, std: 0.9805
  Sigmas: [0.400390625]... (timesteps: [401.0])

[Step 4430] Training Debug Info:
  Loss: 1.018903
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0256, std: 0.9141
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0229, std: 1.3594
  Model pred mean: -0.0255, std: 0.9023
  Sigmas: [0.010009765625]... (timesteps: [10.0])
Steps:  89%|████████▊ | 4431/5000 [16:36:39<1:53:33, 11.97s/it, loss=1.1040, lr=3.91e-07]Steps:  89%|████████▊ | 4431/5000 [16:36:39<1:53:33, 11.97s/it, loss=1.0189, lr=3.89e-07]Steps:  89%|████████▊ | 4432/5000 [16:36:52<1:53:52, 12.03s/it, loss=1.0189, lr=3.89e-07]Steps:  89%|████████▊ | 4432/5000 [16:36:52<1:53:52, 12.03s/it, loss=0.4022, lr=3.88e-07]Steps:  89%|████████▊ | 4433/5000 [16:37:04<1:53:15, 11.98s/it, loss=0.4022, lr=3.88e-07]Steps:  89%|████████▊ | 4433/5000 [16:37:04<1:53:15, 11.98s/it, loss=0.9908, lr=3.87e-07]Steps:  89%|████████▊ | 4434/5000 [16:37:15<1:52:52, 11.97s/it, loss=0.9908, lr=3.87e-07]Steps:  89%|████████▊ | 4434/5000 [16:37:15<1:52:52, 11.97s/it, loss=0.4169, lr=3.85e-07]Steps:  89%|████████▊ | 4435/5000 [16:37:27<1:52:16, 11.92s/it, loss=0.4169, lr=3.85e-07]Steps:  89%|████████▊ | 4435/5000 [16:37:27<1:52:16, 11.92s/it, loss=0.6413, lr=3.84e-07]Steps:  89%|████████▊ | 4436/5000 [16:37:40<1:53:05, 12.03s/it, loss=0.6413, lr=3.84e-07]Steps:  89%|████████▊ | 4436/5000 [16:37:40<1:53:05, 12.03s/it, loss=0.9658, lr=3.83e-07]Steps:  89%|████████▊ | 4437/5000 [16:37:51<1:52:35, 12.00s/it, loss=0.9658, lr=3.83e-07]Steps:  89%|████████▊ | 4437/5000 [16:37:51<1:52:35, 12.00s/it, loss=0.5263, lr=3.81e-07]Steps:  89%|████████▉ | 4438/5000 [16:38:03<1:52:05, 11.97s/it, loss=0.5263, lr=3.81e-07]Steps:  89%|████████▉ | 4438/5000 [16:38:03<1:52:05, 11.97s/it, loss=0.3833, lr=3.80e-07]Steps:  89%|████████▉ | 4439/5000 [16:38:16<1:52:19, 12.01s/it, loss=0.3833, lr=3.80e-07]Steps:  89%|████████▉ | 4439/5000 [16:38:16<1:52:19, 12.01s/it, loss=0.4105, lr=3.79e-07]Steps:  89%|████████▉ | 4440/5000 [16:38:27<1:51:54, 11.99s/it, loss=0.4105, lr=3.79e-07]Steps:  89%|████████▉ | 4440/5000 [16:38:27<1:51:54, 11.99s/it, loss=0.3801, lr=3.77e-07]
[Step 4440] Training Debug Info:
  Loss: 1.150694
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0130, std: 0.8828
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0165, std: 1.3359
  Model pred mean: 0.0132, std: 0.7891
  Sigmas: [0.251953125]... (timesteps: [252.0])

[Step 4440] Training Debug Info:
  Loss: 0.756511
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0194, std: 0.9570
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0172, std: 1.3828
  Model pred mean: -0.0186, std: 1.0781
  Sigmas: [0.9765625]... (timesteps: [976.0])

[Step 4440] Training Debug Info:
  Loss: 1.084990
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0234, std: 0.9375
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0248, std: 1.3672
  Model pred mean: -0.0254, std: 0.8867
  Sigmas: [0.169921875]... (timesteps: [170.0])

[Step 4440] Training Debug Info:
  Loss: 1.143750
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0103, std: 0.9219
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0089, std: 1.3594
  Model pred mean: -0.0095, std: 0.8398
  Sigmas: [0.1171875]... (timesteps: [117.0])
Steps:  89%|████████▉ | 4441/5000 [16:38:39<1:51:22, 11.95s/it, loss=0.3801, lr=3.77e-07]Steps:  89%|████████▉ | 4441/5000 [16:38:39<1:51:22, 11.95s/it, loss=1.1437, lr=3.76e-07]Steps:  89%|████████▉ | 4442/5000 [16:38:51<1:50:50, 11.92s/it, loss=1.1437, lr=3.76e-07]Steps:  89%|████████▉ | 4442/5000 [16:38:51<1:50:50, 11.92s/it, loss=1.1159, lr=3.75e-07]Steps:  89%|████████▉ | 4443/5000 [16:39:03<1:51:18, 11.99s/it, loss=1.1159, lr=3.75e-07]Steps:  89%|████████▉ | 4443/5000 [16:39:03<1:51:18, 11.99s/it, loss=1.0864, lr=3.73e-07]Steps:  89%|████████▉ | 4444/5000 [16:39:15<1:50:44, 11.95s/it, loss=1.0864, lr=3.73e-07]Steps:  89%|████████▉ | 4444/5000 [16:39:15<1:50:44, 11.95s/it, loss=0.4642, lr=3.72e-07]Steps:  89%|████████▉ | 4445/5000 [16:39:27<1:51:13, 12.02s/it, loss=0.4642, lr=3.72e-07]Steps:  89%|████████▉ | 4445/5000 [16:39:27<1:51:13, 12.02s/it, loss=1.0897, lr=3.71e-07]Steps:  89%|████████▉ | 4446/5000 [16:39:39<1:50:47, 12.00s/it, loss=1.0897, lr=3.71e-07]Steps:  89%|████████▉ | 4446/5000 [16:39:39<1:50:47, 12.00s/it, loss=0.5255, lr=3.69e-07]Steps:  89%|████████▉ | 4447/5000 [16:39:51<1:50:13, 11.96s/it, loss=0.5255, lr=3.69e-07]Steps:  89%|████████▉ | 4447/5000 [16:39:51<1:50:13, 11.96s/it, loss=1.1055, lr=3.68e-07]Steps:  89%|████████▉ | 4448/5000 [16:40:03<1:49:43, 11.93s/it, loss=1.1055, lr=3.68e-07]Steps:  89%|████████▉ | 4448/5000 [16:40:03<1:49:43, 11.93s/it, loss=0.4097, lr=3.67e-07]Steps:  89%|████████▉ | 4449/5000 [16:40:15<1:49:28, 11.92s/it, loss=0.4097, lr=3.67e-07]Steps:  89%|████████▉ | 4449/5000 [16:40:15<1:49:28, 11.92s/it, loss=0.4161, lr=3.65e-07]Steps:  89%|████████▉ | 4450/5000 [16:40:27<1:49:10, 11.91s/it, loss=0.4161, lr=3.65e-07]Steps:  89%|████████▉ | 4450/5000 [16:40:27<1:49:10, 11.91s/it, loss=1.0405, lr=3.64e-07]
[Step 4450] Training Debug Info:
  Loss: 1.216389
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0115, std: 0.8516
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0087, std: 1.3125
  Model pred mean: 0.0131, std: 0.7148
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 4450] Training Debug Info:
  Loss: 0.415918
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0066, std: 0.8906
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0071, std: 1.3359
  Model pred mean: -0.0083, std: 1.1719
  Sigmas: [0.75]... (timesteps: [750.0])

[Step 4450] Training Debug Info:
  Loss: 0.564043
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0045, std: 0.8906
  Noise mean: 0.0035, std: 1.0000
  Target mean: -0.0010, std: 1.3438
  Model pred mean: -0.0033, std: 1.1094
  Sigmas: [0.609375]... (timesteps: [609.0])

[Step 4450] Training Debug Info:
  Loss: 0.495384
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0039, std: 0.8828
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0048, std: 1.3359
  Model pred mean: -0.0030, std: 1.1328
  Sigmas: [0.9296875]... (timesteps: [930.0])
Steps:  89%|████████▉ | 4451/5000 [16:40:39<1:49:04, 11.92s/it, loss=1.0405, lr=3.64e-07]Steps:  89%|████████▉ | 4451/5000 [16:40:39<1:49:04, 11.92s/it, loss=0.4954, lr=3.63e-07]Steps:  89%|████████▉ | 4452/5000 [16:40:51<1:49:52, 12.03s/it, loss=0.4954, lr=3.63e-07]Steps:  89%|████████▉ | 4452/5000 [16:40:51<1:49:52, 12.03s/it, loss=0.4070, lr=3.61e-07]Steps:  89%|████████▉ | 4453/5000 [16:41:03<1:49:18, 11.99s/it, loss=0.4070, lr=3.61e-07]Steps:  89%|████████▉ | 4453/5000 [16:41:03<1:49:18, 11.99s/it, loss=0.8239, lr=3.60e-07]Steps:  89%|████████▉ | 4454/5000 [16:41:15<1:48:53, 11.97s/it, loss=0.8239, lr=3.60e-07]Steps:  89%|████████▉ | 4454/5000 [16:41:15<1:48:53, 11.97s/it, loss=0.9374, lr=3.59e-07]Steps:  89%|████████▉ | 4455/5000 [16:41:27<1:48:39, 11.96s/it, loss=0.9374, lr=3.59e-07]Steps:  89%|████████▉ | 4455/5000 [16:41:27<1:48:39, 11.96s/it, loss=0.3611, lr=3.58e-07]Steps:  89%|████████▉ | 4456/5000 [16:41:39<1:48:15, 11.94s/it, loss=0.3611, lr=3.58e-07]Steps:  89%|████████▉ | 4456/5000 [16:41:39<1:48:15, 11.94s/it, loss=1.0084, lr=3.56e-07]Steps:  89%|████████▉ | 4457/5000 [16:41:51<1:48:06, 11.95s/it, loss=1.0084, lr=3.56e-07]Steps:  89%|████████▉ | 4457/5000 [16:41:51<1:48:06, 11.95s/it, loss=1.1188, lr=3.55e-07]Steps:  89%|████████▉ | 4458/5000 [16:42:03<1:47:58, 11.95s/it, loss=1.1188, lr=3.55e-07]Steps:  89%|████████▉ | 4458/5000 [16:42:03<1:47:58, 11.95s/it, loss=0.8583, lr=3.54e-07]Steps:  89%|████████▉ | 4459/5000 [16:42:15<1:48:25, 12.03s/it, loss=0.8583, lr=3.54e-07]Steps:  89%|████████▉ | 4459/5000 [16:42:15<1:48:25, 12.03s/it, loss=0.4369, lr=3.52e-07]Steps:  89%|████████▉ | 4460/5000 [16:42:27<1:47:51, 11.98s/it, loss=0.4369, lr=3.52e-07]Steps:  89%|████████▉ | 4460/5000 [16:42:27<1:47:51, 11.98s/it, loss=1.1602, lr=3.51e-07]
[Step 4460] Training Debug Info:
  Loss: 0.695166
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0056, std: 0.9141
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0050, std: 1.3516
  Model pred mean: -0.0063, std: 1.0625
  Sigmas: [0.50390625]... (timesteps: [505.0])

[Step 4460] Training Debug Info:
  Loss: 0.419272
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0439, std: 0.9609
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0425, std: 1.3906
  Model pred mean: -0.0420, std: 1.2344
  Sigmas: [0.8359375]... (timesteps: [834.0])

[Step 4460] Training Debug Info:
  Loss: 1.033249
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0029, std: 0.9023
  Noise mean: 0.0006, std: 0.9961
  Target mean: -0.0023, std: 1.3438
  Model pred mean: -0.0026, std: 0.8828
  Sigmas: [0.02099609375]... (timesteps: [21.0])

[Step 4460] Training Debug Info:
  Loss: 0.879314
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0052, std: 0.9258
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0026, std: 1.3672
  Model pred mean: -0.0058, std: 0.9922
  Sigmas: [0.41796875]... (timesteps: [418.0])
Steps:  89%|████████▉ | 4461/5000 [16:42:39<1:47:48, 12.00s/it, loss=1.1602, lr=3.51e-07]Steps:  89%|████████▉ | 4461/5000 [16:42:39<1:47:48, 12.00s/it, loss=0.8793, lr=3.50e-07]Steps:  89%|████████▉ | 4462/5000 [16:42:51<1:47:24, 11.98s/it, loss=0.8793, lr=3.50e-07]Steps:  89%|████████▉ | 4462/5000 [16:42:51<1:47:24, 11.98s/it, loss=0.6141, lr=3.49e-07]Steps:  89%|████████▉ | 4463/5000 [16:43:03<1:47:02, 11.96s/it, loss=0.6141, lr=3.49e-07]Steps:  89%|████████▉ | 4463/5000 [16:43:03<1:47:02, 11.96s/it, loss=1.0706, lr=3.47e-07]Steps:  89%|████████▉ | 4464/5000 [16:43:15<1:46:47, 11.95s/it, loss=1.0706, lr=3.47e-07]Steps:  89%|████████▉ | 4464/5000 [16:43:15<1:46:47, 11.95s/it, loss=1.0854, lr=3.46e-07]Steps:  89%|████████▉ | 4465/5000 [16:43:26<1:46:20, 11.93s/it, loss=1.0854, lr=3.46e-07]Steps:  89%|████████▉ | 4465/5000 [16:43:26<1:46:20, 11.93s/it, loss=0.4436, lr=3.45e-07]Steps:  89%|████████▉ | 4466/5000 [16:43:39<1:46:40, 11.99s/it, loss=0.4436, lr=3.45e-07]Steps:  89%|████████▉ | 4466/5000 [16:43:39<1:46:40, 11.99s/it, loss=1.0364, lr=3.43e-07]Steps:  89%|████████▉ | 4467/5000 [16:43:50<1:46:02, 11.94s/it, loss=1.0364, lr=3.43e-07]Steps:  89%|████████▉ | 4467/5000 [16:43:50<1:46:02, 11.94s/it, loss=0.5898, lr=3.42e-07]Steps:  89%|████████▉ | 4468/5000 [16:44:02<1:45:50, 11.94s/it, loss=0.5898, lr=3.42e-07]Steps:  89%|████████▉ | 4468/5000 [16:44:02<1:45:50, 11.94s/it, loss=1.0555, lr=3.41e-07]Steps:  89%|████████▉ | 4469/5000 [16:44:14<1:45:36, 11.93s/it, loss=1.0555, lr=3.41e-07]Steps:  89%|████████▉ | 4469/5000 [16:44:14<1:45:36, 11.93s/it, loss=0.5717, lr=3.40e-07]Steps:  89%|████████▉ | 4470/5000 [16:44:26<1:45:42, 11.97s/it, loss=0.5717, lr=3.40e-07]Steps:  89%|████████▉ | 4470/5000 [16:44:26<1:45:42, 11.97s/it, loss=0.4211, lr=3.38e-07]
[Step 4470] Training Debug Info:
  Loss: 0.393293
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0085, std: 0.8906
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0107, std: 1.3438
  Model pred mean: 0.0146, std: 1.1797
  Sigmas: [0.92578125]... (timesteps: [925.0])

[Step 4470] Training Debug Info:
  Loss: 0.676392
  Latent shape: torch.Size([1, 32, 120, 72]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0231, std: 0.9570
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0249, std: 1.3828
  Model pred mean: 0.0237, std: 1.1172
  Sigmas: [0.51953125]... (timesteps: [518.0])

[Step 4470] Training Debug Info:
  Loss: 1.173583
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0244, std: 0.8477
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0264, std: 1.3125
  Model pred mean: 0.0244, std: 0.7422
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 4470] Training Debug Info:
  Loss: 0.534494
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0410, std: 0.9219
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0417, std: 1.3594
  Model pred mean: -0.0425, std: 1.1484
  Sigmas: [0.609375]... (timesteps: [608.0])
Steps:  89%|████████▉ | 4471/5000 [16:44:38<1:45:20, 11.95s/it, loss=0.4211, lr=3.38e-07]Steps:  89%|████████▉ | 4471/5000 [16:44:38<1:45:20, 11.95s/it, loss=0.5345, lr=3.37e-07]Steps:  89%|████████▉ | 4472/5000 [16:44:50<1:45:41, 12.01s/it, loss=0.5345, lr=3.37e-07]Steps:  89%|████████▉ | 4472/5000 [16:44:50<1:45:41, 12.01s/it, loss=0.5714, lr=3.36e-07]Steps:  89%|████████▉ | 4473/5000 [16:45:02<1:45:21, 12.00s/it, loss=0.5714, lr=3.36e-07]Steps:  89%|████████▉ | 4473/5000 [16:45:02<1:45:21, 12.00s/it, loss=1.0321, lr=3.35e-07]Steps:  89%|████████▉ | 4474/5000 [16:45:14<1:44:51, 11.96s/it, loss=1.0321, lr=3.35e-07]Steps:  89%|████████▉ | 4474/5000 [16:45:14<1:44:51, 11.96s/it, loss=0.4203, lr=3.33e-07]Steps:  90%|████████▉ | 4475/5000 [16:45:26<1:44:29, 11.94s/it, loss=0.4203, lr=3.33e-07]Steps:  90%|████████▉ | 4475/5000 [16:45:26<1:44:29, 11.94s/it, loss=0.6499, lr=3.32e-07]Steps:  90%|████████▉ | 4476/5000 [16:45:38<1:44:08, 11.92s/it, loss=0.6499, lr=3.32e-07]Steps:  90%|████████▉ | 4476/5000 [16:45:38<1:44:08, 11.92s/it, loss=0.5308, lr=3.31e-07]Steps:  90%|████████▉ | 4477/5000 [16:45:50<1:44:02, 11.94s/it, loss=0.5308, lr=3.31e-07]Steps:  90%|████████▉ | 4477/5000 [16:45:50<1:44:02, 11.94s/it, loss=1.1202, lr=3.30e-07]Steps:  90%|████████▉ | 4478/5000 [16:46:02<1:43:35, 11.91s/it, loss=1.1202, lr=3.30e-07]Steps:  90%|████████▉ | 4478/5000 [16:46:02<1:43:35, 11.91s/it, loss=1.2137, lr=3.28e-07]Steps:  90%|████████▉ | 4479/5000 [16:46:14<1:44:17, 12.01s/it, loss=1.2137, lr=3.28e-07]Steps:  90%|████████▉ | 4479/5000 [16:46:14<1:44:17, 12.01s/it, loss=1.0741, lr=3.27e-07]Steps:  90%|████████▉ | 4480/5000 [16:46:26<1:43:52, 11.99s/it, loss=1.0741, lr=3.27e-07]Steps:  90%|████████▉ | 4480/5000 [16:46:26<1:43:52, 11.99s/it, loss=0.6271, lr=3.26e-07]
[Step 4480] Training Debug Info:
  Loss: 0.589450
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0013, std: 0.9570
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0008, std: 1.3828
  Model pred mean: 0.0012, std: 1.1562
  Sigmas: [0.6640625]... (timesteps: [663.0])

[Step 4480] Training Debug Info:
  Loss: 0.819785
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.9648
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0073, std: 1.3906
  Model pred mean: 0.0063, std: 1.0547
  Sigmas: [0.431640625]... (timesteps: [432.0])

[Step 4480] Training Debug Info:
  Loss: 1.035336
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0086, std: 0.9648
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0081, std: 1.3906
  Model pred mean: -0.0075, std: 0.9453
  Sigmas: [0.01904296875]... (timesteps: [19.0])

[Step 4480] Training Debug Info:
  Loss: 0.371946
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0156, std: 0.9180
  Noise mean: 0.0039, std: 1.0000
  Target mean: -0.0117, std: 1.3594
  Model pred mean: -0.0151, std: 1.2109
  Sigmas: [0.75390625]... (timesteps: [752.0])
Steps:  90%|████████▉ | 4481/5000 [16:46:38<1:43:32, 11.97s/it, loss=0.6271, lr=3.26e-07]Steps:  90%|████████▉ | 4481/5000 [16:46:38<1:43:32, 11.97s/it, loss=0.3719, lr=3.25e-07]Steps:  90%|████████▉ | 4482/5000 [16:46:50<1:43:11, 11.95s/it, loss=0.3719, lr=3.25e-07]Steps:  90%|████████▉ | 4482/5000 [16:46:50<1:43:11, 11.95s/it, loss=1.1069, lr=3.23e-07]Steps:  90%|████████▉ | 4483/5000 [16:47:02<1:42:51, 11.94s/it, loss=1.1069, lr=3.23e-07]Steps:  90%|████████▉ | 4483/5000 [16:47:02<1:42:51, 11.94s/it, loss=1.1657, lr=3.22e-07]Steps:  90%|████████▉ | 4484/5000 [16:47:14<1:42:43, 11.94s/it, loss=1.1657, lr=3.22e-07]Steps:  90%|████████▉ | 4484/5000 [16:47:14<1:42:43, 11.94s/it, loss=1.0591, lr=3.21e-07]Steps:  90%|████████▉ | 4485/5000 [16:47:25<1:42:22, 11.93s/it, loss=1.0591, lr=3.21e-07]Steps:  90%|████████▉ | 4485/5000 [16:47:25<1:42:22, 11.93s/it, loss=0.8722, lr=3.20e-07]Steps:  90%|████████▉ | 4486/5000 [16:47:38<1:42:53, 12.01s/it, loss=0.8722, lr=3.20e-07]Steps:  90%|████████▉ | 4486/5000 [16:47:38<1:42:53, 12.01s/it, loss=1.0911, lr=3.18e-07]Steps:  90%|████████▉ | 4487/5000 [16:47:50<1:42:34, 12.00s/it, loss=1.0911, lr=3.18e-07]Steps:  90%|████████▉ | 4487/5000 [16:47:50<1:42:34, 12.00s/it, loss=0.9435, lr=3.17e-07]Steps:  90%|████████▉ | 4488/5000 [16:48:02<1:42:28, 12.01s/it, loss=0.9435, lr=3.17e-07]Steps:  90%|████████▉ | 4488/5000 [16:48:02<1:42:28, 12.01s/it, loss=1.0516, lr=3.16e-07]Steps:  90%|████████▉ | 4489/5000 [16:48:14<1:41:59, 11.98s/it, loss=1.0516, lr=3.16e-07]Steps:  90%|████████▉ | 4489/5000 [16:48:14<1:41:59, 11.98s/it, loss=0.3549, lr=3.15e-07]Steps:  90%|████████▉ | 4490/5000 [16:48:26<1:41:50, 11.98s/it, loss=0.3549, lr=3.15e-07]Steps:  90%|████████▉ | 4490/5000 [16:48:26<1:41:50, 11.98s/it, loss=0.5639, lr=3.14e-07]
[Step 4490] Training Debug Info:
  Loss: 0.419550
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0272, std: 0.9922
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0291, std: 1.4062
  Model pred mean: -0.0270, std: 1.2578
  Sigmas: [0.8125]... (timesteps: [814.0])

[Step 4490] Training Debug Info:
  Loss: 0.892203
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0084, std: 0.9297
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0095, std: 1.3672
  Model pred mean: -0.0081, std: 0.9922
  Sigmas: [0.36328125]... (timesteps: [363.0])

[Step 4490] Training Debug Info:
  Loss: 0.987604
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0403, std: 0.9219
  Noise mean: -0.0045, std: 0.9961
  Target mean: -0.0449, std: 1.3594
  Model pred mean: -0.0398, std: 0.9297
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 4490] Training Debug Info:
  Loss: 0.864757
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0427, std: 0.9688
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0400, std: 1.3906
  Model pred mean: -0.0444, std: 1.0391
  Sigmas: [0.353515625]... (timesteps: [353.0])
Steps:  90%|████████▉ | 4491/5000 [16:48:38<1:41:35, 11.98s/it, loss=0.5639, lr=3.14e-07]Steps:  90%|████████▉ | 4491/5000 [16:48:38<1:41:35, 11.98s/it, loss=0.8648, lr=3.12e-07]Steps:  90%|████████▉ | 4492/5000 [16:48:49<1:41:06, 11.94s/it, loss=0.8648, lr=3.12e-07]Steps:  90%|████████▉ | 4492/5000 [16:48:49<1:41:06, 11.94s/it, loss=1.0824, lr=3.11e-07]Steps:  90%|████████▉ | 4493/5000 [16:49:02<1:41:40, 12.03s/it, loss=1.0824, lr=3.11e-07]Steps:  90%|████████▉ | 4493/5000 [16:49:02<1:41:40, 12.03s/it, loss=0.3819, lr=3.10e-07]Steps:  90%|████████▉ | 4494/5000 [16:49:14<1:41:12, 12.00s/it, loss=0.3819, lr=3.10e-07]Steps:  90%|████████▉ | 4494/5000 [16:49:14<1:41:12, 12.00s/it, loss=0.6164, lr=3.09e-07]Steps:  90%|████████▉ | 4495/5000 [16:49:26<1:41:04, 12.01s/it, loss=0.6164, lr=3.09e-07]Steps:  90%|████████▉ | 4495/5000 [16:49:26<1:41:04, 12.01s/it, loss=0.5707, lr=3.08e-07]Steps:  90%|████████▉ | 4496/5000 [16:49:38<1:40:54, 12.01s/it, loss=0.5707, lr=3.08e-07]Steps:  90%|████████▉ | 4496/5000 [16:49:38<1:40:54, 12.01s/it, loss=1.0317, lr=3.06e-07]Steps:  90%|████████▉ | 4497/5000 [16:49:50<1:40:50, 12.03s/it, loss=1.0317, lr=3.06e-07]Steps:  90%|████████▉ | 4497/5000 [16:49:50<1:40:50, 12.03s/it, loss=1.0454, lr=3.05e-07]Steps:  90%|████████▉ | 4498/5000 [16:50:02<1:40:28, 12.01s/it, loss=1.0454, lr=3.05e-07]Steps:  90%|████████▉ | 4498/5000 [16:50:02<1:40:28, 12.01s/it, loss=1.1131, lr=3.04e-07]Steps:  90%|████████▉ | 4499/5000 [16:50:14<1:40:50, 12.08s/it, loss=1.1131, lr=3.04e-07]Steps:  90%|████████▉ | 4499/5000 [16:50:14<1:40:50, 12.08s/it, loss=0.3881, lr=3.03e-07]Steps:  90%|█████████ | 4500/5000 [16:50:26<1:40:29, 12.06s/it, loss=0.3881, lr=3.03e-07]Steps:  90%|█████████ | 4500/5000 [16:50:26<1:40:29, 12.06s/it, loss=0.4001, lr=3.02e-07]01/23/2026 00:36:13 - INFO - __main__ - 
[Step 4500] ✅ Loss in normal range (0.4001)
01/23/2026 00:36:13 - INFO - __main__ -   Loss avg (last 100): 0.7536
01/23/2026 00:36:13 - INFO - __main__ -   Loss range: [0.3459, 1.2137]

[Step 4500] Training Debug Info:
  Loss: 0.747445
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0048, std: 0.9297
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0019, std: 1.3672
  Model pred mean: 0.0070, std: 1.0625
  Sigmas: [0.423828125]... (timesteps: [423.0])

[Step 4500] Training Debug Info:
  Loss: 0.760182
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0146, std: 0.9297
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0165, std: 1.3672
  Model pred mean: -0.0170, std: 1.0547
  Sigmas: [0.4375]... (timesteps: [437.0])

[Step 4500] Training Debug Info:
  Loss: 0.918710
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0156, std: 0.9375
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0187, std: 1.3750
  Model pred mean: -0.0176, std: 0.9805
  Sigmas: [0.37109375]... (timesteps: [372.0])

[Step 4500] Training Debug Info:
  Loss: 0.373452
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0028, std: 0.9062
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0011, std: 1.3516
  Model pred mean: 0.0074, std: 1.2031
  Sigmas: [0.8515625]... (timesteps: [851.0])
Steps:  90%|█████████ | 4501/5000 [16:50:38<1:40:09, 12.04s/it, loss=0.4001, lr=3.02e-07]Steps:  90%|█████████ | 4501/5000 [16:50:38<1:40:09, 12.04s/it, loss=0.3735, lr=3.00e-07]Steps:  90%|█████████ | 4502/5000 [16:50:50<1:39:41, 12.01s/it, loss=0.3735, lr=3.00e-07]Steps:  90%|█████████ | 4502/5000 [16:50:50<1:39:41, 12.01s/it, loss=0.3881, lr=2.99e-07]Steps:  90%|█████████ | 4503/5000 [16:51:02<1:39:15, 11.98s/it, loss=0.3881, lr=2.99e-07]Steps:  90%|█████████ | 4503/5000 [16:51:02<1:39:15, 11.98s/it, loss=0.4792, lr=2.98e-07]Steps:  90%|█████████ | 4504/5000 [16:51:14<1:39:02, 11.98s/it, loss=0.4792, lr=2.98e-07]Steps:  90%|█████████ | 4504/5000 [16:51:14<1:39:02, 11.98s/it, loss=1.0501, lr=2.97e-07]Steps:  90%|█████████ | 4505/5000 [16:51:26<1:38:41, 11.96s/it, loss=1.0501, lr=2.97e-07]Steps:  90%|█████████ | 4505/5000 [16:51:26<1:38:41, 11.96s/it, loss=0.4948, lr=2.96e-07]Steps:  90%|█████████ | 4506/5000 [16:51:38<1:39:29, 12.08s/it, loss=0.4948, lr=2.96e-07]Steps:  90%|█████████ | 4506/5000 [16:51:38<1:39:29, 12.08s/it, loss=0.4618, lr=2.94e-07]Steps:  90%|█████████ | 4507/5000 [16:51:50<1:38:42, 12.01s/it, loss=0.4618, lr=2.94e-07]Steps:  90%|█████████ | 4507/5000 [16:51:50<1:38:42, 12.01s/it, loss=0.4251, lr=2.93e-07]Steps:  90%|█████████ | 4508/5000 [16:52:02<1:38:10, 11.97s/it, loss=0.4251, lr=2.93e-07]Steps:  90%|█████████ | 4508/5000 [16:52:02<1:38:10, 11.97s/it, loss=0.4210, lr=2.92e-07]Steps:  90%|█████████ | 4509/5000 [16:52:14<1:38:00, 11.98s/it, loss=0.4210, lr=2.92e-07]Steps:  90%|█████████ | 4509/5000 [16:52:14<1:38:00, 11.98s/it, loss=0.5241, lr=2.91e-07]Steps:  90%|█████████ | 4510/5000 [16:52:26<1:37:37, 11.95s/it, loss=0.5241, lr=2.91e-07]Steps:  90%|█████████ | 4510/5000 [16:52:26<1:37:37, 11.95s/it, loss=1.0910, lr=2.90e-07]
[Step 4510] Training Debug Info:
  Loss: 0.377700
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0134, std: 0.8711
  Noise mean: -0.0035, std: 1.0000
  Target mean: 0.0100, std: 1.3281
  Model pred mean: 0.0076, std: 1.1719
  Sigmas: [0.84375]... (timesteps: [842.0])

[Step 4510] Training Debug Info:
  Loss: 0.835722
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0155, std: 0.9297
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0130, std: 1.3672
  Model pred mean: -0.0153, std: 1.0156
  Sigmas: [0.419921875]... (timesteps: [419.0])

[Step 4510] Training Debug Info:
  Loss: 0.439211
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0002, std: 0.8789
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0026, std: 1.3359
  Model pred mean: 0.0001, std: 1.1562
  Sigmas: [0.7734375]... (timesteps: [773.0])

[Step 4510] Training Debug Info:
  Loss: 1.109406
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0199, std: 0.9492
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0199, std: 1.3828
  Model pred mean: -0.0198, std: 0.8906
  Sigmas: [0.0771484375]... (timesteps: [77.0])
Steps:  90%|█████████ | 4511/5000 [16:52:38<1:37:08, 11.92s/it, loss=1.0910, lr=2.90e-07]Steps:  90%|█████████ | 4511/5000 [16:52:38<1:37:08, 11.92s/it, loss=1.1094, lr=2.89e-07]Steps:  90%|█████████ | 4512/5000 [16:52:49<1:37:04, 11.94s/it, loss=1.1094, lr=2.89e-07]Steps:  90%|█████████ | 4512/5000 [16:52:49<1:37:04, 11.94s/it, loss=1.0655, lr=2.87e-07]Steps:  90%|█████████ | 4513/5000 [16:53:02<1:37:31, 12.02s/it, loss=1.0655, lr=2.87e-07]Steps:  90%|█████████ | 4513/5000 [16:53:02<1:37:31, 12.02s/it, loss=0.4135, lr=2.86e-07]Steps:  90%|█████████ | 4514/5000 [16:53:14<1:37:04, 11.98s/it, loss=0.4135, lr=2.86e-07]Steps:  90%|█████████ | 4514/5000 [16:53:14<1:37:04, 11.98s/it, loss=0.9324, lr=2.85e-07]Steps:  90%|█████████ | 4515/5000 [16:53:26<1:37:01, 12.00s/it, loss=0.9324, lr=2.85e-07]Steps:  90%|█████████ | 4515/5000 [16:53:26<1:37:01, 12.00s/it, loss=0.7453, lr=2.84e-07]Steps:  90%|█████████ | 4516/5000 [16:53:37<1:36:27, 11.96s/it, loss=0.7453, lr=2.84e-07]Steps:  90%|█████████ | 4516/5000 [16:53:37<1:36:27, 11.96s/it, loss=0.8471, lr=2.83e-07]Steps:  90%|█████████ | 4517/5000 [16:53:49<1:36:06, 11.94s/it, loss=0.8471, lr=2.83e-07]Steps:  90%|█████████ | 4517/5000 [16:53:49<1:36:06, 11.94s/it, loss=0.4109, lr=2.82e-07]Steps:  90%|█████████ | 4518/5000 [16:54:01<1:35:59, 11.95s/it, loss=0.4109, lr=2.82e-07]Steps:  90%|█████████ | 4518/5000 [16:54:01<1:35:59, 11.95s/it, loss=1.1700, lr=2.80e-07]Steps:  90%|█████████ | 4519/5000 [16:54:13<1:35:42, 11.94s/it, loss=1.1700, lr=2.80e-07]Steps:  90%|█████████ | 4519/5000 [16:54:13<1:35:42, 11.94s/it, loss=0.4516, lr=2.79e-07]Steps:  90%|█████████ | 4520/5000 [16:54:26<1:36:17, 12.04s/it, loss=0.4516, lr=2.79e-07]Steps:  90%|█████████ | 4520/5000 [16:54:26<1:36:17, 12.04s/it, loss=0.6523, lr=2.78e-07]
[Step 4520] Training Debug Info:
  Loss: 1.025831
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0791, std: 0.8984
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0767, std: 1.3438
  Model pred mean: -0.0801, std: 0.8828
  Sigmas: [0.1259765625]... (timesteps: [126.0])

[Step 4520] Training Debug Info:
  Loss: 1.095171
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0004, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0001, std: 1.3672
  Model pred mean: 0.0001, std: 0.8867
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 4520] Training Debug Info:
  Loss: 1.094884
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0140, std: 0.9531
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0139, std: 1.3828
  Model pred mean: -0.0149, std: 0.9062
  Sigmas: [0.251953125]... (timesteps: [252.0])

[Step 4520] Training Debug Info:
  Loss: 0.921094
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0588, std: 1.0078
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0564, std: 1.4219
  Model pred mean: -0.0581, std: 1.0547
  Sigmas: [0.2353515625]... (timesteps: [235.0])
Steps:  90%|█████████ | 4521/5000 [16:54:37<1:35:50, 12.01s/it, loss=0.6523, lr=2.78e-07]Steps:  90%|█████████ | 4521/5000 [16:54:37<1:35:50, 12.01s/it, loss=0.9211, lr=2.77e-07]Steps:  90%|█████████ | 4522/5000 [16:54:49<1:35:29, 11.99s/it, loss=0.9211, lr=2.77e-07]Steps:  90%|█████████ | 4522/5000 [16:54:49<1:35:29, 11.99s/it, loss=0.5133, lr=2.76e-07]Steps:  90%|█████████ | 4523/5000 [16:55:01<1:35:11, 11.97s/it, loss=0.5133, lr=2.76e-07]Steps:  90%|█████████ | 4523/5000 [16:55:01<1:35:11, 11.97s/it, loss=0.9791, lr=2.75e-07]Steps:  90%|█████████ | 4524/5000 [16:55:13<1:35:14, 12.01s/it, loss=0.9791, lr=2.75e-07]Steps:  90%|█████████ | 4524/5000 [16:55:13<1:35:14, 12.01s/it, loss=0.6864, lr=2.74e-07]Steps:  90%|█████████ | 4525/5000 [16:55:25<1:34:56, 11.99s/it, loss=0.6864, lr=2.74e-07]Steps:  90%|█████████ | 4525/5000 [16:55:25<1:34:56, 11.99s/it, loss=0.7786, lr=2.72e-07]Steps:  91%|█████████ | 4526/5000 [16:55:38<1:35:12, 12.05s/it, loss=0.7786, lr=2.72e-07]Steps:  91%|█████████ | 4526/5000 [16:55:38<1:35:12, 12.05s/it, loss=0.4393, lr=2.71e-07]Steps:  91%|█████████ | 4527/5000 [16:55:50<1:34:49, 12.03s/it, loss=0.4393, lr=2.71e-07]Steps:  91%|█████████ | 4527/5000 [16:55:50<1:34:49, 12.03s/it, loss=0.8675, lr=2.70e-07]Steps:  91%|█████████ | 4528/5000 [16:56:02<1:34:27, 12.01s/it, loss=0.8675, lr=2.70e-07]Steps:  91%|█████████ | 4528/5000 [16:56:02<1:34:27, 12.01s/it, loss=0.6081, lr=2.69e-07]Steps:  91%|█████████ | 4529/5000 [16:56:13<1:33:59, 11.97s/it, loss=0.6081, lr=2.69e-07]Steps:  91%|█████████ | 4529/5000 [16:56:13<1:33:59, 11.97s/it, loss=1.0850, lr=2.68e-07]Steps:  91%|█████████ | 4530/5000 [16:56:25<1:33:43, 11.96s/it, loss=1.0850, lr=2.68e-07]Steps:  91%|█████████ | 4530/5000 [16:56:25<1:33:43, 11.96s/it, loss=1.1609, lr=2.67e-07]
[Step 4530] Training Debug Info:
  Loss: 0.551391
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0084, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0093, std: 1.3516
  Model pred mean: -0.0067, std: 1.1250
  Sigmas: [0.62890625]... (timesteps: [630.0])

[Step 4530] Training Debug Info:
  Loss: 1.113217
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0010, std: 0.9570
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0019, std: 1.3828
  Model pred mean: 0.0015, std: 0.8945
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 4530] Training Debug Info:
  Loss: 0.746965
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0227, std: 0.9297
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0243, std: 1.3672
  Model pred mean: -0.0244, std: 1.0547
  Sigmas: [0.4609375]... (timesteps: [460.0])

[Step 4530] Training Debug Info:
  Loss: 1.012293
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0299, std: 0.8945
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0303, std: 1.3438
  Model pred mean: -0.0284, std: 0.8906
  Sigmas: [0.328125]... (timesteps: [329.0])
Steps:  91%|█████████ | 4531/5000 [16:56:37<1:33:30, 11.96s/it, loss=1.1609, lr=2.67e-07]Steps:  91%|█████████ | 4531/5000 [16:56:37<1:33:30, 11.96s/it, loss=1.0123, lr=2.66e-07]Steps:  91%|█████████ | 4532/5000 [16:56:49<1:33:19, 11.96s/it, loss=1.0123, lr=2.66e-07]Steps:  91%|█████████ | 4532/5000 [16:56:49<1:33:19, 11.96s/it, loss=0.3595, lr=2.65e-07]Steps:  91%|█████████ | 4533/5000 [16:57:02<1:33:59, 12.08s/it, loss=0.3595, lr=2.65e-07]Steps:  91%|█████████ | 4533/5000 [16:57:02<1:33:59, 12.08s/it, loss=0.3827, lr=2.63e-07]Steps:  91%|█████████ | 4534/5000 [16:57:14<1:33:26, 12.03s/it, loss=0.3827, lr=2.63e-07]Steps:  91%|█████████ | 4534/5000 [16:57:14<1:33:26, 12.03s/it, loss=0.8576, lr=2.62e-07]Steps:  91%|█████████ | 4535/5000 [16:57:25<1:33:00, 12.00s/it, loss=0.8576, lr=2.62e-07]Steps:  91%|█████████ | 4535/5000 [16:57:25<1:33:00, 12.00s/it, loss=1.1493, lr=2.61e-07]Steps:  91%|█████████ | 4536/5000 [16:57:37<1:32:32, 11.97s/it, loss=1.1493, lr=2.61e-07]Steps:  91%|█████████ | 4536/5000 [16:57:37<1:32:32, 11.97s/it, loss=1.0220, lr=2.60e-07]Steps:  91%|█████████ | 4537/5000 [16:57:49<1:32:15, 11.95s/it, loss=1.0220, lr=2.60e-07]Steps:  91%|█████████ | 4537/5000 [16:57:49<1:32:15, 11.95s/it, loss=1.0880, lr=2.59e-07]Steps:  91%|█████████ | 4538/5000 [16:58:01<1:31:59, 11.95s/it, loss=1.0880, lr=2.59e-07]Steps:  91%|█████████ | 4538/5000 [16:58:01<1:31:59, 11.95s/it, loss=0.7911, lr=2.58e-07]Steps:  91%|█████████ | 4539/5000 [16:58:13<1:31:46, 11.94s/it, loss=0.7911, lr=2.58e-07]Steps:  91%|█████████ | 4539/5000 [16:58:13<1:31:46, 11.94s/it, loss=0.7933, lr=2.57e-07]Steps:  91%|█████████ | 4540/5000 [16:58:25<1:32:06, 12.01s/it, loss=0.7933, lr=2.57e-07]Steps:  91%|█████████ | 4540/5000 [16:58:25<1:32:06, 12.01s/it, loss=0.6489, lr=2.56e-07]
[Step 4540] Training Debug Info:
  Loss: 1.034843
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0017, std: 1.3438
  Model pred mean: 0.0004, std: 0.8750
  Sigmas: [0.31640625]... (timesteps: [317.0])

[Step 4540] Training Debug Info:
  Loss: 0.634228
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0007, std: 0.8906
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0029, std: 1.3359
  Model pred mean: -0.0035, std: 1.0781
  Sigmas: [0.578125]... (timesteps: [578.0])

[Step 4540] Training Debug Info:
  Loss: 0.441001
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0112, std: 0.9023
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0101, std: 1.3438
  Model pred mean: -0.0134, std: 1.1719
  Sigmas: [0.734375]... (timesteps: [736.0])

[Step 4540] Training Debug Info:
  Loss: 1.122836
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0017, std: 0.8789
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0014, std: 1.3359
  Model pred mean: 0.0019, std: 0.8086
  Sigmas: [0.0751953125]... (timesteps: [75.0])
Steps:  91%|█████████ | 4541/5000 [16:58:37<1:31:45, 11.99s/it, loss=0.6489, lr=2.56e-07]Steps:  91%|█████████ | 4541/5000 [16:58:37<1:31:45, 11.99s/it, loss=1.1228, lr=2.55e-07]Steps:  91%|█████████ | 4542/5000 [16:58:49<1:31:53, 12.04s/it, loss=1.1228, lr=2.55e-07]Steps:  91%|█████████ | 4542/5000 [16:58:49<1:31:53, 12.04s/it, loss=0.5019, lr=2.53e-07]Steps:  91%|█████████ | 4543/5000 [16:59:01<1:31:31, 12.02s/it, loss=0.5019, lr=2.53e-07]Steps:  91%|█████████ | 4543/5000 [16:59:01<1:31:31, 12.02s/it, loss=0.5927, lr=2.52e-07]Steps:  91%|█████████ | 4544/5000 [16:59:13<1:31:16, 12.01s/it, loss=0.5927, lr=2.52e-07]Steps:  91%|█████████ | 4544/5000 [16:59:13<1:31:16, 12.01s/it, loss=1.0081, lr=2.51e-07]Steps:  91%|█████████ | 4545/5000 [16:59:25<1:30:48, 11.97s/it, loss=1.0081, lr=2.51e-07]Steps:  91%|█████████ | 4545/5000 [16:59:25<1:30:48, 11.97s/it, loss=0.4081, lr=2.50e-07]Steps:  91%|█████████ | 4546/5000 [16:59:37<1:30:41, 11.99s/it, loss=0.4081, lr=2.50e-07]Steps:  91%|█████████ | 4546/5000 [16:59:37<1:30:41, 11.99s/it, loss=0.9721, lr=2.49e-07]Steps:  91%|█████████ | 4547/5000 [16:59:49<1:30:53, 12.04s/it, loss=0.9721, lr=2.49e-07]Steps:  91%|█████████ | 4547/5000 [16:59:49<1:30:53, 12.04s/it, loss=0.6723, lr=2.48e-07]Steps:  91%|█████████ | 4548/5000 [17:00:01<1:30:36, 12.03s/it, loss=0.6723, lr=2.48e-07]Steps:  91%|█████████ | 4548/5000 [17:00:01<1:30:36, 12.03s/it, loss=0.6099, lr=2.47e-07]Steps:  91%|█████████ | 4549/5000 [17:00:13<1:30:12, 12.00s/it, loss=0.6099, lr=2.47e-07]Steps:  91%|█████████ | 4549/5000 [17:00:13<1:30:12, 12.00s/it, loss=0.7942, lr=2.46e-07]Steps:  91%|█████████ | 4550/5000 [17:00:25<1:29:45, 11.97s/it, loss=0.7942, lr=2.46e-07]Steps:  91%|█████████ | 4550/5000 [17:00:25<1:29:45, 11.97s/it, loss=0.6455, lr=2.45e-07]
[Step 4550] Training Debug Info:
  Loss: 0.677688
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0164, std: 0.9258
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0149, std: 1.3594
  Model pred mean: 0.0121, std: 1.0781
  Sigmas: [0.9765625]... (timesteps: [976.0])

[Step 4550] Training Debug Info:
  Loss: 1.092205
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0095, std: 0.9453
  Noise mean: 0.0030, std: 1.0000
  Target mean: -0.0065, std: 1.3750
  Model pred mean: -0.0089, std: 0.8945
  Sigmas: [0.06787109375]... (timesteps: [68.0])

[Step 4550] Training Debug Info:
  Loss: 0.534060
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0078, std: 0.8477
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0072, std: 1.3125
  Model pred mean: 0.0072, std: 1.0859
  Sigmas: [0.66015625]... (timesteps: [662.0])

[Step 4550] Training Debug Info:
  Loss: 0.409640
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0004, std: 0.9453
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0007, std: 1.3750
  Model pred mean: -0.0022, std: 1.2109
  Sigmas: [0.77734375]... (timesteps: [778.0])
Steps:  91%|█████████ | 4551/5000 [17:00:37<1:29:33, 11.97s/it, loss=0.6455, lr=2.45e-07]Steps:  91%|█████████ | 4551/5000 [17:00:37<1:29:33, 11.97s/it, loss=0.4096, lr=2.44e-07]Steps:  91%|█████████ | 4552/5000 [17:00:49<1:29:17, 11.96s/it, loss=0.4096, lr=2.44e-07]Steps:  91%|█████████ | 4552/5000 [17:00:49<1:29:17, 11.96s/it, loss=0.3963, lr=2.43e-07]Steps:  91%|█████████ | 4553/5000 [17:01:01<1:29:40, 12.04s/it, loss=0.3963, lr=2.43e-07]Steps:  91%|█████████ | 4553/5000 [17:01:01<1:29:40, 12.04s/it, loss=1.0998, lr=2.41e-07]Steps:  91%|█████████ | 4554/5000 [17:01:13<1:29:12, 12.00s/it, loss=1.0998, lr=2.41e-07]Steps:  91%|█████████ | 4554/5000 [17:01:13<1:29:12, 12.00s/it, loss=1.0129, lr=2.40e-07]Steps:  91%|█████████ | 4555/5000 [17:01:25<1:28:43, 11.96s/it, loss=1.0129, lr=2.40e-07]Steps:  91%|█████████ | 4555/5000 [17:01:25<1:28:43, 11.96s/it, loss=0.7073, lr=2.39e-07]Steps:  91%|█████████ | 4556/5000 [17:01:37<1:28:20, 11.94s/it, loss=0.7073, lr=2.39e-07]Steps:  91%|█████████ | 4556/5000 [17:01:37<1:28:20, 11.94s/it, loss=1.1324, lr=2.38e-07]Steps:  91%|█████████ | 4557/5000 [17:01:49<1:28:04, 11.93s/it, loss=1.1324, lr=2.38e-07]Steps:  91%|█████████ | 4557/5000 [17:01:49<1:28:04, 11.93s/it, loss=0.6898, lr=2.37e-07]Steps:  91%|█████████ | 4558/5000 [17:02:01<1:27:52, 11.93s/it, loss=0.6898, lr=2.37e-07]Steps:  91%|█████████ | 4558/5000 [17:02:01<1:27:52, 11.93s/it, loss=1.1249, lr=2.36e-07]Steps:  91%|█████████ | 4559/5000 [17:02:13<1:27:44, 11.94s/it, loss=1.1249, lr=2.36e-07]Steps:  91%|█████████ | 4559/5000 [17:02:13<1:27:44, 11.94s/it, loss=0.3981, lr=2.35e-07]Steps:  91%|█████████ | 4560/5000 [17:02:25<1:28:37, 12.09s/it, loss=0.3981, lr=2.35e-07]Steps:  91%|█████████ | 4560/5000 [17:02:25<1:28:37, 12.09s/it, loss=0.8129, lr=2.34e-07]
[Step 4560] Training Debug Info:
  Loss: 0.417144
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0302, std: 0.9180
  Noise mean: 0.0001, std: 0.9961
  Target mean: 0.0303, std: 1.3594
  Model pred mean: 0.0310, std: 1.1953
  Sigmas: [0.6953125]... (timesteps: [695.0])

[Step 4560] Training Debug Info:
  Loss: 0.427670
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0293, std: 0.9297
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0283, std: 1.3672
  Model pred mean: -0.0320, std: 1.2031
  Sigmas: [0.65625]... (timesteps: [657.0])

[Step 4560] Training Debug Info:
  Loss: 0.346392
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0135, std: 0.9336
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0142, std: 1.3672
  Model pred mean: -0.0132, std: 1.2344
  Sigmas: [0.86328125]... (timesteps: [863.0])

[Step 4560] Training Debug Info:
  Loss: 1.020882
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0272, std: 0.9375
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0282, std: 1.3750
  Model pred mean: -0.0271, std: 0.9219
  Sigmas: [0.00897216796875]... (timesteps: [9.0])
Steps:  91%|█████████ | 4561/5000 [17:02:37<1:28:02, 12.03s/it, loss=0.8129, lr=2.34e-07]Steps:  91%|█████████ | 4561/5000 [17:02:37<1:28:02, 12.03s/it, loss=1.0209, lr=2.33e-07]Steps:  91%|█████████ | 4562/5000 [17:02:49<1:27:50, 12.03s/it, loss=1.0209, lr=2.33e-07]Steps:  91%|█████████ | 4562/5000 [17:02:49<1:27:50, 12.03s/it, loss=0.5565, lr=2.32e-07]Steps:  91%|█████████▏| 4563/5000 [17:03:01<1:27:33, 12.02s/it, loss=0.5565, lr=2.32e-07]Steps:  91%|█████████▏| 4563/5000 [17:03:01<1:27:33, 12.02s/it, loss=0.5918, lr=2.31e-07]Steps:  91%|█████████▏| 4564/5000 [17:03:13<1:27:27, 12.04s/it, loss=0.5918, lr=2.31e-07]Steps:  91%|█████████▏| 4564/5000 [17:03:13<1:27:27, 12.04s/it, loss=1.0022, lr=2.30e-07]Steps:  91%|█████████▏| 4565/5000 [17:03:25<1:27:15, 12.03s/it, loss=1.0022, lr=2.30e-07]Steps:  91%|█████████▏| 4565/5000 [17:03:25<1:27:15, 12.03s/it, loss=0.8140, lr=2.29e-07]Steps:  91%|█████████▏| 4566/5000 [17:03:37<1:26:54, 12.01s/it, loss=0.8140, lr=2.29e-07]Steps:  91%|█████████▏| 4566/5000 [17:03:37<1:26:54, 12.01s/it, loss=0.9075, lr=2.28e-07]Steps:  91%|█████████▏| 4567/5000 [17:03:50<1:27:11, 12.08s/it, loss=0.9075, lr=2.28e-07]Steps:  91%|█████████▏| 4567/5000 [17:03:50<1:27:11, 12.08s/it, loss=1.0950, lr=2.27e-07]Steps:  91%|█████████▏| 4568/5000 [17:04:01<1:26:36, 12.03s/it, loss=1.0950, lr=2.27e-07]Steps:  91%|█████████▏| 4568/5000 [17:04:01<1:26:36, 12.03s/it, loss=0.4039, lr=2.26e-07]Steps:  91%|█████████▏| 4569/5000 [17:04:14<1:26:30, 12.04s/it, loss=0.4039, lr=2.26e-07]Steps:  91%|█████████▏| 4569/5000 [17:04:14<1:26:30, 12.04s/it, loss=0.4943, lr=2.25e-07]Steps:  91%|█████████▏| 4570/5000 [17:04:26<1:26:09, 12.02s/it, loss=0.4943, lr=2.25e-07]Steps:  91%|█████████▏| 4570/5000 [17:04:26<1:26:09, 12.02s/it, loss=0.7918, lr=2.24e-07]
[Step 4570] Training Debug Info:
  Loss: 0.386404
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0009, std: 0.8789
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0008, std: 1.3281
  Model pred mean: -0.0008, std: 1.1719
  Sigmas: [0.8203125]... (timesteps: [821.0])

[Step 4570] Training Debug Info:
  Loss: 0.757073
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0152, std: 0.9375
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0176, std: 1.3750
  Model pred mean: -0.0192, std: 1.0703
  Sigmas: [0.97265625]... (timesteps: [972.0])

[Step 4570] Training Debug Info:
  Loss: 1.105614
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0057, std: 0.8828
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0040, std: 1.3359
  Model pred mean: 0.0055, std: 0.8281
  Sigmas: [0.06494140625]... (timesteps: [65.0])

[Step 4570] Training Debug Info:
  Loss: 0.795720
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0327, std: 0.9336
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0322, std: 1.3672
  Model pred mean: -0.0325, std: 1.0391
  Sigmas: [0.412109375]... (timesteps: [412.0])
Steps:  91%|█████████▏| 4571/5000 [17:04:37<1:25:45, 11.99s/it, loss=0.7918, lr=2.24e-07]Steps:  91%|█████████▏| 4571/5000 [17:04:37<1:25:45, 11.99s/it, loss=0.7957, lr=2.23e-07]Steps:  91%|█████████▏| 4572/5000 [17:04:49<1:25:24, 11.97s/it, loss=0.7957, lr=2.23e-07]Steps:  91%|█████████▏| 4572/5000 [17:04:49<1:25:24, 11.97s/it, loss=0.7028, lr=2.22e-07]Steps:  91%|█████████▏| 4573/5000 [17:05:01<1:25:08, 11.96s/it, loss=0.7028, lr=2.22e-07]Steps:  91%|█████████▏| 4573/5000 [17:05:01<1:25:08, 11.96s/it, loss=0.3532, lr=2.21e-07]Steps:  91%|█████████▏| 4574/5000 [17:05:14<1:25:31, 12.05s/it, loss=0.3532, lr=2.21e-07]Steps:  91%|█████████▏| 4574/5000 [17:05:14<1:25:31, 12.05s/it, loss=1.1940, lr=2.19e-07]Steps:  92%|█████████▏| 4575/5000 [17:05:25<1:25:05, 12.01s/it, loss=1.1940, lr=2.19e-07]Steps:  92%|█████████▏| 4575/5000 [17:05:25<1:25:05, 12.01s/it, loss=0.5063, lr=2.18e-07]Steps:  92%|█████████▏| 4576/5000 [17:05:37<1:24:50, 12.01s/it, loss=0.5063, lr=2.18e-07]Steps:  92%|█████████▏| 4576/5000 [17:05:37<1:24:50, 12.01s/it, loss=0.3962, lr=2.17e-07]Steps:  92%|█████████▏| 4577/5000 [17:05:49<1:24:39, 12.01s/it, loss=0.3962, lr=2.17e-07]Steps:  92%|█████████▏| 4577/5000 [17:05:49<1:24:39, 12.01s/it, loss=1.0709, lr=2.16e-07]Steps:  92%|█████████▏| 4578/5000 [17:06:02<1:24:31, 12.02s/it, loss=1.0709, lr=2.16e-07]Steps:  92%|█████████▏| 4578/5000 [17:06:02<1:24:31, 12.02s/it, loss=0.6567, lr=2.15e-07]Steps:  92%|█████████▏| 4579/5000 [17:06:14<1:24:16, 12.01s/it, loss=0.6567, lr=2.15e-07]Steps:  92%|█████████▏| 4579/5000 [17:06:14<1:24:16, 12.01s/it, loss=0.8046, lr=2.14e-07]Steps:  92%|█████████▏| 4580/5000 [17:06:26<1:24:38, 12.09s/it, loss=0.8046, lr=2.14e-07]Steps:  92%|█████████▏| 4580/5000 [17:06:26<1:24:38, 12.09s/it, loss=1.0785, lr=2.13e-07]
[Step 4580] Training Debug Info:
  Loss: 1.112501
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0239, std: 0.9492
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0247, std: 1.3750
  Model pred mean: -0.0232, std: 0.8867
  Sigmas: [0.0927734375]... (timesteps: [93.0])

[Step 4580] Training Debug Info:
  Loss: 0.619614
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0085, std: 0.9141
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0095, std: 1.3594
  Model pred mean: -0.0087, std: 1.1094
  Sigmas: [0.62109375]... (timesteps: [621.0])

[Step 4580] Training Debug Info:
  Loss: 0.514290
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0067, std: 0.8984
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0053, std: 1.3438
  Model pred mean: -0.0084, std: 1.1406
  Sigmas: [0.6484375]... (timesteps: [649.0])

[Step 4580] Training Debug Info:
  Loss: 0.376903
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0272, std: 0.9180
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0259, std: 1.3516
  Model pred mean: 0.0344, std: 1.2031
  Sigmas: [0.9453125]... (timesteps: [944.0])
Steps:  92%|█████████▏| 4581/5000 [17:06:38<1:24:10, 12.05s/it, loss=1.0785, lr=2.13e-07]Steps:  92%|█████████▏| 4581/5000 [17:06:38<1:24:10, 12.05s/it, loss=0.3769, lr=2.12e-07]Steps:  92%|█████████▏| 4582/5000 [17:06:50<1:23:47, 12.03s/it, loss=0.3769, lr=2.12e-07]Steps:  92%|█████████▏| 4582/5000 [17:06:50<1:23:47, 12.03s/it, loss=1.1228, lr=2.11e-07]Steps:  92%|█████████▏| 4583/5000 [17:07:02<1:23:34, 12.03s/it, loss=1.1228, lr=2.11e-07]Steps:  92%|█████████▏| 4583/5000 [17:07:02<1:23:34, 12.03s/it, loss=0.3349, lr=2.10e-07]Steps:  92%|█████████▏| 4584/5000 [17:07:14<1:23:19, 12.02s/it, loss=0.3349, lr=2.10e-07]Steps:  92%|█████████▏| 4584/5000 [17:07:14<1:23:19, 12.02s/it, loss=0.5268, lr=2.09e-07]Steps:  92%|█████████▏| 4585/5000 [17:07:26<1:22:58, 12.00s/it, loss=0.5268, lr=2.09e-07]Steps:  92%|█████████▏| 4585/5000 [17:07:26<1:22:58, 12.00s/it, loss=1.2125, lr=2.08e-07]Steps:  92%|█████████▏| 4586/5000 [17:07:38<1:22:35, 11.97s/it, loss=1.2125, lr=2.08e-07]Steps:  92%|█████████▏| 4586/5000 [17:07:38<1:22:35, 11.97s/it, loss=0.4372, lr=2.07e-07]Steps:  92%|█████████▏| 4587/5000 [17:07:50<1:23:06, 12.07s/it, loss=0.4372, lr=2.07e-07]Steps:  92%|█████████▏| 4587/5000 [17:07:50<1:23:06, 12.07s/it, loss=1.1274, lr=2.06e-07]Steps:  92%|█████████▏| 4588/5000 [17:08:02<1:22:35, 12.03s/it, loss=1.1274, lr=2.06e-07]Steps:  92%|█████████▏| 4588/5000 [17:08:02<1:22:35, 12.03s/it, loss=0.4314, lr=2.05e-07]Steps:  92%|█████████▏| 4589/5000 [17:08:14<1:22:17, 12.01s/it, loss=0.4314, lr=2.05e-07]Steps:  92%|█████████▏| 4589/5000 [17:08:14<1:22:17, 12.01s/it, loss=0.3883, lr=2.04e-07]Steps:  92%|█████████▏| 4590/5000 [17:08:26<1:22:01, 12.00s/it, loss=0.3883, lr=2.04e-07]Steps:  92%|█████████▏| 4590/5000 [17:08:26<1:22:01, 12.00s/it, loss=1.1897, lr=2.03e-07]
[Step 4590] Training Debug Info:
  Loss: 0.356178
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0261, std: 0.9180
  Noise mean: -0.0029, std: 0.9961
  Target mean: 0.0232, std: 1.3516
  Model pred mean: 0.0242, std: 1.2109
  Sigmas: [0.83203125]... (timesteps: [831.0])

[Step 4590] Training Debug Info:
  Loss: 0.577496
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0192, std: 0.8828
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0186, std: 1.3281
  Model pred mean: 0.0152, std: 1.1016
  Sigmas: [0.61328125]... (timesteps: [615.0])

[Step 4590] Training Debug Info:
  Loss: 0.330394
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0017, std: 0.9492
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0019, std: 1.3750
  Model pred mean: -0.0036, std: 1.2500
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 4590] Training Debug Info:
  Loss: 0.628519
  Latent shape: torch.Size([1, 32, 96, 90]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0286, std: 0.9180
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0271, std: 1.3594
  Model pred mean: -0.0234, std: 1.1016
  Sigmas: [0.984375]... (timesteps: [983.0])
Steps:  92%|█████████▏| 4591/5000 [17:08:38<1:21:38, 11.98s/it, loss=1.1897, lr=2.03e-07]Steps:  92%|█████████▏| 4591/5000 [17:08:38<1:21:38, 11.98s/it, loss=0.6285, lr=2.02e-07]Steps:  92%|█████████▏| 4592/5000 [17:08:50<1:21:23, 11.97s/it, loss=0.6285, lr=2.02e-07]Steps:  92%|█████████▏| 4592/5000 [17:08:50<1:21:23, 11.97s/it, loss=1.1195, lr=2.01e-07]Steps:  92%|█████████▏| 4593/5000 [17:09:02<1:21:16, 11.98s/it, loss=1.1195, lr=2.01e-07]Steps:  92%|█████████▏| 4593/5000 [17:09:02<1:21:16, 11.98s/it, loss=0.8634, lr=2.00e-07]Steps:  92%|█████████▏| 4594/5000 [17:09:14<1:21:35, 12.06s/it, loss=0.8634, lr=2.00e-07]Steps:  92%|█████████▏| 4594/5000 [17:09:14<1:21:35, 12.06s/it, loss=1.0913, lr=2.00e-07]Steps:  92%|█████████▏| 4595/5000 [17:09:26<1:21:05, 12.01s/it, loss=1.0913, lr=2.00e-07]Steps:  92%|█████████▏| 4595/5000 [17:09:26<1:21:05, 12.01s/it, loss=1.0408, lr=1.99e-07]Steps:  92%|█████████▏| 4596/5000 [17:09:38<1:21:02, 12.04s/it, loss=1.0408, lr=1.99e-07]Steps:  92%|█████████▏| 4596/5000 [17:09:38<1:21:02, 12.04s/it, loss=0.4413, lr=1.98e-07]Steps:  92%|█████████▏| 4597/5000 [17:09:50<1:20:50, 12.04s/it, loss=0.4413, lr=1.98e-07]Steps:  92%|█████████▏| 4597/5000 [17:09:50<1:20:50, 12.04s/it, loss=0.3907, lr=1.97e-07]Steps:  92%|█████████▏| 4598/5000 [17:10:02<1:20:32, 12.02s/it, loss=0.3907, lr=1.97e-07]Steps:  92%|█████████▏| 4598/5000 [17:10:02<1:20:32, 12.02s/it, loss=0.3567, lr=1.96e-07]Steps:  92%|█████████▏| 4599/5000 [17:10:14<1:20:21, 12.02s/it, loss=0.3567, lr=1.96e-07]Steps:  92%|█████████▏| 4599/5000 [17:10:14<1:20:21, 12.02s/it, loss=1.1473, lr=1.95e-07]Steps:  92%|█████████▏| 4600/5000 [17:10:26<1:19:53, 11.98s/it, loss=1.1473, lr=1.95e-07]Steps:  92%|█████████▏| 4600/5000 [17:10:26<1:19:53, 11.98s/it, loss=0.4284, lr=1.94e-07]01/23/2026 00:56:13 - INFO - __main__ - 
[Step 4600] ✅ Loss in normal range (0.4284)
01/23/2026 00:56:13 - INFO - __main__ -   Loss avg (last 100): 0.7466
01/23/2026 00:56:13 - INFO - __main__ -   Loss range: [0.3349, 1.2125]
01/23/2026 00:56:13 - INFO - __main__ - 
🔍 Running validation at step 4600...
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4600 (parquet mode)...
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4600...
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/23/2026 00:56:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/23/2026 00:56:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/23/2026 00:56:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.46it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.44it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.43it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/23/2026 00:56:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/23/2026 00:56:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 00:57:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/23/2026 00:57:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 00:57:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/23/2026 00:57:39 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/23/2026 00:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/23/2026 00:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:58:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/23/2026 00:58:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:58:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/23/2026 00:58:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:59:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/23/2026 00:59:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.37it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:59:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/23/2026 00:59:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 00:59:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/23/2026 00:59:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.13it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.48it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.41it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/23/2026 01:00:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/23/2026 01:00:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:08,  1.31it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.33it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.36it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.41it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.41it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.41it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.41it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.42it/s]
01/23/2026 01:00:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600/step004600_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/23/2026 01:00:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/23/2026 01:00:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/23/2026 01:00:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004600
01/23/2026 01:00:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 4600] Training Debug Info:
  Loss: 0.612586
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0042, std: 0.8789
  Noise mean: -0.0018, std: 0.9961
  Target mean: -0.0059, std: 1.3281
  Model pred mean: -0.0032, std: 1.0781
  Sigmas: [0.58203125]... (timesteps: [581.0])

[Step 4600] Training Debug Info:
  Loss: 0.582122
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9297
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0208, std: 1.3672
  Model pred mean: -0.0204, std: 1.1484
  Sigmas: [0.9453125]... (timesteps: [947.0])

[Step 4600] Training Debug Info:
  Loss: 1.081378
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 0.9219
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0361, std: 1.3594
  Model pred mean: -0.0361, std: 0.8750
  Sigmas: [0.05810546875]... (timesteps: [58.0])

[Step 4600] Training Debug Info:
  Loss: 0.391540
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0442, std: 0.9258
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0422, std: 1.3672
  Model pred mean: -0.0474, std: 1.2109
  Sigmas: [0.875]... (timesteps: [874.0])
Steps:  92%|█████████▏| 4601/5000 [17:15:02<10:05:42, 91.08s/it, loss=0.4284, lr=1.94e-07]Steps:  92%|█████████▏| 4601/5000 [17:15:02<10:05:42, 91.08s/it, loss=0.3915, lr=1.93e-07]Steps:  92%|█████████▏| 4602/5000 [17:15:13<7:26:35, 67.32s/it, loss=0.3915, lr=1.93e-07] Steps:  92%|█████████▏| 4602/5000 [17:15:13<7:26:35, 67.32s/it, loss=0.6832, lr=1.92e-07]Steps:  92%|█████████▏| 4603/5000 [17:15:25<5:35:37, 50.73s/it, loss=0.6832, lr=1.92e-07]Steps:  92%|█████████▏| 4603/5000 [17:15:25<5:35:37, 50.73s/it, loss=0.4318, lr=1.91e-07]Steps:  92%|█████████▏| 4604/5000 [17:15:37<4:18:01, 39.09s/it, loss=0.4318, lr=1.91e-07]Steps:  92%|█████████▏| 4604/5000 [17:15:37<4:18:01, 39.09s/it, loss=1.1153, lr=1.90e-07]Steps:  92%|█████████▏| 4605/5000 [17:15:49<3:23:38, 30.93s/it, loss=1.1153, lr=1.90e-07]Steps:  92%|█████████▏| 4605/5000 [17:15:49<3:23:38, 30.93s/it, loss=1.1670, lr=1.89e-07]Steps:  92%|█████████▏| 4606/5000 [17:16:01<2:45:43, 25.24s/it, loss=1.1670, lr=1.89e-07]Steps:  92%|█████████▏| 4606/5000 [17:16:01<2:45:43, 25.24s/it, loss=0.9507, lr=1.88e-07]Steps:  92%|█████████▏| 4607/5000 [17:16:13<2:19:42, 21.33s/it, loss=0.9507, lr=1.88e-07]Steps:  92%|█████████▏| 4607/5000 [17:16:13<2:19:42, 21.33s/it, loss=0.6677, lr=1.87e-07]Steps:  92%|█████████▏| 4608/5000 [17:16:25<2:01:00, 18.52s/it, loss=0.6677, lr=1.87e-07]Steps:  92%|█████████▏| 4608/5000 [17:16:25<2:01:00, 18.52s/it, loss=0.4229, lr=1.86e-07]Steps:  92%|█████████▏| 4609/5000 [17:16:37<1:47:52, 16.55s/it, loss=0.4229, lr=1.86e-07]Steps:  92%|█████████▏| 4609/5000 [17:16:37<1:47:52, 16.55s/it, loss=0.6615, lr=1.85e-07]Steps:  92%|█████████▏| 4610/5000 [17:16:49<1:38:28, 15.15s/it, loss=0.6615, lr=1.85e-07]Steps:  92%|█████████▏| 4610/5000 [17:16:49<1:38:28, 15.15s/it, loss=0.7081, lr=1.84e-07]
[Step 4610] Training Debug Info:
  Loss: 0.400555
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0079, std: 0.9102
  Noise mean: -0.0024, std: 1.0000
  Target mean: 0.0055, std: 1.3516
  Model pred mean: 0.0051, std: 1.1953
  Sigmas: [0.77734375]... (timesteps: [778.0])

[Step 4610] Training Debug Info:
  Loss: 0.865703
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0103, std: 0.9219
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0103, std: 1.3594
  Model pred mean: 0.0101, std: 0.9883
  Sigmas: [0.40625]... (timesteps: [406.0])

[Step 4610] Training Debug Info:
  Loss: 0.379309
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0175, std: 0.8945
  Noise mean: -0.0030, std: 1.0000
  Target mean: -0.0204, std: 1.3438
  Model pred mean: -0.0155, std: 1.1953
  Sigmas: [0.80859375]... (timesteps: [808.0])

[Step 4610] Training Debug Info:
  Loss: 0.927644
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0050, std: 0.9023
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0072, std: 1.3438
  Model pred mean: 0.0060, std: 0.9414
  Sigmas: [0.380859375]... (timesteps: [380.0])
Steps:  92%|█████████▏| 4611/5000 [17:17:01<1:31:56, 14.18s/it, loss=0.7081, lr=1.84e-07]Steps:  92%|█████████▏| 4611/5000 [17:17:01<1:31:56, 14.18s/it, loss=0.9276, lr=1.83e-07]Steps:  92%|█████████▏| 4612/5000 [17:17:13<1:27:12, 13.49s/it, loss=0.9276, lr=1.83e-07]Steps:  92%|█████████▏| 4612/5000 [17:17:13<1:27:12, 13.49s/it, loss=0.5565, lr=1.82e-07]Steps:  92%|█████████▏| 4613/5000 [17:17:25<1:24:03, 13.03s/it, loss=0.5565, lr=1.82e-07]Steps:  92%|█████████▏| 4613/5000 [17:17:25<1:24:03, 13.03s/it, loss=1.1422, lr=1.81e-07]Steps:  92%|█████████▏| 4614/5000 [17:17:37<1:22:17, 12.79s/it, loss=1.1422, lr=1.81e-07]Steps:  92%|█████████▏| 4614/5000 [17:17:37<1:22:17, 12.79s/it, loss=1.1366, lr=1.80e-07]Steps:  92%|█████████▏| 4615/5000 [17:17:49<1:20:28, 12.54s/it, loss=1.1366, lr=1.80e-07]Steps:  92%|█████████▏| 4615/5000 [17:17:49<1:20:28, 12.54s/it, loss=1.1210, lr=1.80e-07]Steps:  92%|█████████▏| 4616/5000 [17:18:01<1:19:08, 12.37s/it, loss=1.1210, lr=1.80e-07]Steps:  92%|█████████▏| 4616/5000 [17:18:01<1:19:08, 12.37s/it, loss=0.4204, lr=1.79e-07]Steps:  92%|█████████▏| 4617/5000 [17:18:13<1:18:03, 12.23s/it, loss=0.4204, lr=1.79e-07]Steps:  92%|█████████▏| 4617/5000 [17:18:13<1:18:03, 12.23s/it, loss=0.5918, lr=1.78e-07]Steps:  92%|█████████▏| 4618/5000 [17:18:25<1:17:05, 12.11s/it, loss=0.5918, lr=1.78e-07]Steps:  92%|█████████▏| 4618/5000 [17:18:25<1:17:05, 12.11s/it, loss=1.0231, lr=1.77e-07]Steps:  92%|█████████▏| 4619/5000 [17:18:37<1:16:32, 12.05s/it, loss=1.0231, lr=1.77e-07]Steps:  92%|█████████▏| 4619/5000 [17:18:37<1:16:32, 12.05s/it, loss=0.3623, lr=1.76e-07]Steps:  92%|█████████▏| 4620/5000 [17:18:49<1:16:02, 12.01s/it, loss=0.3623, lr=1.76e-07]Steps:  92%|█████████▏| 4620/5000 [17:18:49<1:16:02, 12.01s/it, loss=0.4030, lr=1.75e-07]
[Step 4620] Training Debug Info:
  Loss: 1.175171
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0043, std: 0.8867
  Noise mean: 0.0033, std: 1.0000
  Target mean: 0.0076, std: 1.3359
  Model pred mean: 0.0026, std: 0.7812
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 4620] Training Debug Info:
  Loss: 0.547181
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0393, std: 0.9297
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0374, std: 1.3672
  Model pred mean: -0.0396, std: 1.1484
  Sigmas: [0.546875]... (timesteps: [545.0])

[Step 4620] Training Debug Info:
  Loss: 0.376823
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0028, std: 0.9258
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0052, std: 1.3594
  Model pred mean: 0.0041, std: 1.2188
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 4620] Training Debug Info:
  Loss: 1.008258
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0059, std: 0.8633
  Noise mean: 0.0045, std: 1.0000
  Target mean: 0.0104, std: 1.3203
  Model pred mean: 0.0055, std: 0.8594
  Sigmas: [0.376953125]... (timesteps: [376.0])
Steps:  92%|█████████▏| 4621/5000 [17:19:01<1:16:11, 12.06s/it, loss=0.4030, lr=1.75e-07]Steps:  92%|█████████▏| 4621/5000 [17:19:01<1:16:11, 12.06s/it, loss=1.0083, lr=1.74e-07]Steps:  92%|█████████▏| 4622/5000 [17:19:13<1:15:41, 12.01s/it, loss=1.0083, lr=1.74e-07]Steps:  92%|█████████▏| 4622/5000 [17:19:13<1:15:41, 12.01s/it, loss=1.0556, lr=1.73e-07]Steps:  92%|█████████▏| 4623/5000 [17:19:25<1:15:25, 12.00s/it, loss=1.0556, lr=1.73e-07]Steps:  92%|█████████▏| 4623/5000 [17:19:25<1:15:25, 12.00s/it, loss=1.1794, lr=1.72e-07]Steps:  92%|█████████▏| 4624/5000 [17:19:37<1:15:41, 12.08s/it, loss=1.1794, lr=1.72e-07]Steps:  92%|█████████▏| 4624/5000 [17:19:37<1:15:41, 12.08s/it, loss=0.4228, lr=1.71e-07]Steps:  92%|█████████▎| 4625/5000 [17:19:49<1:15:15, 12.04s/it, loss=0.4228, lr=1.71e-07]Steps:  92%|█████████▎| 4625/5000 [17:19:49<1:15:15, 12.04s/it, loss=0.8495, lr=1.70e-07]Steps:  93%|█████████▎| 4626/5000 [17:20:01<1:14:46, 12.00s/it, loss=0.8495, lr=1.70e-07]Steps:  93%|█████████▎| 4626/5000 [17:20:01<1:14:46, 12.00s/it, loss=0.5570, lr=1.69e-07]Steps:  93%|█████████▎| 4627/5000 [17:20:13<1:14:33, 11.99s/it, loss=0.5570, lr=1.69e-07]Steps:  93%|█████████▎| 4627/5000 [17:20:13<1:14:33, 11.99s/it, loss=1.1408, lr=1.69e-07]Steps:  93%|█████████▎| 4628/5000 [17:20:25<1:14:45, 12.06s/it, loss=1.1408, lr=1.69e-07]Steps:  93%|█████████▎| 4628/5000 [17:20:25<1:14:45, 12.06s/it, loss=0.4147, lr=1.68e-07]Steps:  93%|█████████▎| 4629/5000 [17:20:37<1:14:23, 12.03s/it, loss=0.4147, lr=1.68e-07]Steps:  93%|█████████▎| 4629/5000 [17:20:37<1:14:23, 12.03s/it, loss=0.3675, lr=1.67e-07]Steps:  93%|█████████▎| 4630/5000 [17:20:49<1:14:04, 12.01s/it, loss=0.3675, lr=1.67e-07]Steps:  93%|█████████▎| 4630/5000 [17:20:49<1:14:04, 12.01s/it, loss=0.4437, lr=1.66e-07]
[Step 4630] Training Debug Info:
  Loss: 1.053439
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0183, std: 0.9180
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0176, std: 1.3594
  Model pred mean: -0.0178, std: 0.8867
  Sigmas: [0.029052734375]... (timesteps: [29.0])

[Step 4630] Training Debug Info:
  Loss: 1.068030
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0197, std: 0.9258
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0220, std: 1.3594
  Model pred mean: -0.0189, std: 0.8945
  Sigmas: [0.31640625]... (timesteps: [317.0])

[Step 4630] Training Debug Info:
  Loss: 0.440538
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0215, std: 0.8867
  Noise mean: 0.0051, std: 1.0000
  Target mean: -0.0165, std: 1.3359
  Model pred mean: -0.0157, std: 1.1641
  Sigmas: [0.87890625]... (timesteps: [880.0])

[Step 4630] Training Debug Info:
  Loss: 1.068197
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0059, std: 0.9141
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0070, std: 1.3516
  Model pred mean: 0.0056, std: 0.8750
  Sigmas: [0.263671875]... (timesteps: [263.0])
Steps:  93%|█████████▎| 4631/5000 [17:21:01<1:13:51, 12.01s/it, loss=0.4437, lr=1.66e-07]Steps:  93%|█████████▎| 4631/5000 [17:21:01<1:13:51, 12.01s/it, loss=1.0682, lr=1.65e-07]Steps:  93%|█████████▎| 4632/5000 [17:21:13<1:13:33, 11.99s/it, loss=1.0682, lr=1.65e-07]Steps:  93%|█████████▎| 4632/5000 [17:21:13<1:13:33, 11.99s/it, loss=0.4856, lr=1.64e-07]Steps:  93%|█████████▎| 4633/5000 [17:21:25<1:13:33, 12.03s/it, loss=0.4856, lr=1.64e-07]Steps:  93%|█████████▎| 4633/5000 [17:21:25<1:13:33, 12.03s/it, loss=0.4973, lr=1.63e-07]Steps:  93%|█████████▎| 4634/5000 [17:21:37<1:13:40, 12.08s/it, loss=0.4973, lr=1.63e-07]Steps:  93%|█████████▎| 4634/5000 [17:21:37<1:13:40, 12.08s/it, loss=0.3632, lr=1.62e-07]Steps:  93%|█████████▎| 4635/5000 [17:21:49<1:13:11, 12.03s/it, loss=0.3632, lr=1.62e-07]Steps:  93%|█████████▎| 4635/5000 [17:21:49<1:13:11, 12.03s/it, loss=0.3742, lr=1.61e-07]Steps:  93%|█████████▎| 4636/5000 [17:22:01<1:12:51, 12.01s/it, loss=0.3742, lr=1.61e-07]Steps:  93%|█████████▎| 4636/5000 [17:22:01<1:12:51, 12.01s/it, loss=0.7021, lr=1.61e-07]Steps:  93%|█████████▎| 4637/5000 [17:22:13<1:12:34, 12.00s/it, loss=0.7021, lr=1.61e-07]Steps:  93%|█████████▎| 4637/5000 [17:22:13<1:12:34, 12.00s/it, loss=1.0351, lr=1.60e-07]Steps:  93%|█████████▎| 4638/5000 [17:22:25<1:12:14, 11.97s/it, loss=1.0351, lr=1.60e-07]Steps:  93%|█████████▎| 4638/5000 [17:22:25<1:12:14, 11.97s/it, loss=0.3432, lr=1.59e-07]Steps:  93%|█████████▎| 4639/5000 [17:22:37<1:12:05, 11.98s/it, loss=0.3432, lr=1.59e-07]Steps:  93%|█████████▎| 4639/5000 [17:22:37<1:12:05, 11.98s/it, loss=0.9296, lr=1.58e-07]Steps:  93%|█████████▎| 4640/5000 [17:22:49<1:11:45, 11.96s/it, loss=0.9296, lr=1.58e-07]Steps:  93%|█████████▎| 4640/5000 [17:22:49<1:11:45, 11.96s/it, loss=0.4507, lr=1.57e-07]
[Step 4640] Training Debug Info:
  Loss: 1.131674
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: -0.0175, std: 0.8398
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0193, std: 1.3047
  Model pred mean: 0.0165, std: 0.7617
  Sigmas: [0.29296875]... (timesteps: [293.0])

[Step 4640] Training Debug Info:
  Loss: 1.180827
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0283, std: 0.8867
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0267, std: 1.3359
  Model pred mean: -0.0283, std: 0.7812
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 4640] Training Debug Info:
  Loss: 0.871394
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0011, std: 0.8828
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0016, std: 1.3281
  Model pred mean: -0.0014, std: 0.9531
  Sigmas: [0.439453125]... (timesteps: [440.0])

[Step 4640] Training Debug Info:
  Loss: 0.459106
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0177, std: 0.9062
  Noise mean: 0.0040, std: 1.0000
  Target mean: 0.0217, std: 1.3516
  Model pred mean: 0.0182, std: 1.1641
  Sigmas: [0.69140625]... (timesteps: [692.0])
Steps:  93%|█████████▎| 4641/5000 [17:23:01<1:12:03, 12.04s/it, loss=0.4507, lr=1.57e-07]Steps:  93%|█████████▎| 4641/5000 [17:23:01<1:12:03, 12.04s/it, loss=0.4591, lr=1.56e-07]Steps:  93%|█████████▎| 4642/5000 [17:23:13<1:11:50, 12.04s/it, loss=0.4591, lr=1.56e-07]Steps:  93%|█████████▎| 4642/5000 [17:23:13<1:11:50, 12.04s/it, loss=1.0449, lr=1.55e-07]Steps:  93%|█████████▎| 4643/5000 [17:23:25<1:11:28, 12.01s/it, loss=1.0449, lr=1.55e-07]Steps:  93%|█████████▎| 4643/5000 [17:23:25<1:11:28, 12.01s/it, loss=0.8833, lr=1.54e-07]Steps:  93%|█████████▎| 4644/5000 [17:23:37<1:11:03, 11.98s/it, loss=0.8833, lr=1.54e-07]Steps:  93%|█████████▎| 4644/5000 [17:23:37<1:11:03, 11.98s/it, loss=0.7548, lr=1.54e-07]Steps:  93%|█████████▎| 4645/5000 [17:23:49<1:11:01, 12.00s/it, loss=0.7548, lr=1.54e-07]Steps:  93%|█████████▎| 4645/5000 [17:23:49<1:11:01, 12.00s/it, loss=0.7705, lr=1.53e-07]Steps:  93%|█████████▎| 4646/5000 [17:24:01<1:10:45, 11.99s/it, loss=0.7705, lr=1.53e-07]Steps:  93%|█████████▎| 4646/5000 [17:24:01<1:10:45, 11.99s/it, loss=1.1525, lr=1.52e-07]Steps:  93%|█████████▎| 4647/5000 [17:24:13<1:10:31, 11.99s/it, loss=1.1525, lr=1.52e-07]Steps:  93%|█████████▎| 4647/5000 [17:24:13<1:10:31, 11.99s/it, loss=0.4276, lr=1.51e-07]Steps:  93%|█████████▎| 4648/5000 [17:24:25<1:10:42, 12.05s/it, loss=0.4276, lr=1.51e-07]Steps:  93%|█████████▎| 4648/5000 [17:24:25<1:10:42, 12.05s/it, loss=0.6597, lr=1.50e-07]Steps:  93%|█████████▎| 4649/5000 [17:24:37<1:10:18, 12.02s/it, loss=0.6597, lr=1.50e-07]Steps:  93%|█████████▎| 4649/5000 [17:24:37<1:10:18, 12.02s/it, loss=1.1073, lr=1.49e-07]Steps:  93%|█████████▎| 4650/5000 [17:24:49<1:09:57, 11.99s/it, loss=1.1073, lr=1.49e-07]Steps:  93%|█████████▎| 4650/5000 [17:24:49<1:09:57, 11.99s/it, loss=0.4197, lr=1.49e-07]
[Step 4650] Training Debug Info:
  Loss: 0.873556
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0588, std: 0.9453
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0598, std: 1.3750
  Model pred mean: -0.0588, std: 1.0078
  Sigmas: [0.287109375]... (timesteps: [288.0])

[Step 4650] Training Debug Info:
  Loss: 0.365742
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0074, std: 0.9258
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0081, std: 1.3594
  Model pred mean: 0.0060, std: 1.2188
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 4650] Training Debug Info:
  Loss: 0.501227
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0097, std: 0.8828
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0099, std: 1.3359
  Model pred mean: -0.0103, std: 1.1328
  Sigmas: [0.6796875]... (timesteps: [678.0])

[Step 4650] Training Debug Info:
  Loss: 0.536557
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0116, std: 0.9102
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0113, std: 1.3516
  Model pred mean: 0.0135, std: 1.1406
  Sigmas: [0.59375]... (timesteps: [595.0])
Steps:  93%|█████████▎| 4651/5000 [17:25:01<1:09:58, 12.03s/it, loss=0.4197, lr=1.49e-07]Steps:  93%|█████████▎| 4651/5000 [17:25:01<1:09:58, 12.03s/it, loss=0.5366, lr=1.48e-07]Steps:  93%|█████████▎| 4652/5000 [17:25:13<1:09:32, 11.99s/it, loss=0.5366, lr=1.48e-07]Steps:  93%|█████████▎| 4652/5000 [17:25:13<1:09:32, 11.99s/it, loss=1.0077, lr=1.47e-07]Steps:  93%|█████████▎| 4653/5000 [17:25:25<1:09:17, 11.98s/it, loss=1.0077, lr=1.47e-07]Steps:  93%|█████████▎| 4653/5000 [17:25:25<1:09:17, 11.98s/it, loss=0.6312, lr=1.46e-07]Steps:  93%|█████████▎| 4654/5000 [17:25:37<1:09:01, 11.97s/it, loss=0.6312, lr=1.46e-07]Steps:  93%|█████████▎| 4654/5000 [17:25:37<1:09:01, 11.97s/it, loss=1.1591, lr=1.45e-07]Steps:  93%|█████████▎| 4655/5000 [17:25:49<1:09:10, 12.03s/it, loss=1.1591, lr=1.45e-07]Steps:  93%|█████████▎| 4655/5000 [17:25:49<1:09:10, 12.03s/it, loss=0.6096, lr=1.44e-07]Steps:  93%|█████████▎| 4656/5000 [17:26:01<1:08:44, 11.99s/it, loss=0.6096, lr=1.44e-07]Steps:  93%|█████████▎| 4656/5000 [17:26:01<1:08:44, 11.99s/it, loss=0.5702, lr=1.43e-07]Steps:  93%|█████████▎| 4657/5000 [17:26:13<1:08:32, 11.99s/it, loss=0.5702, lr=1.43e-07]Steps:  93%|█████████▎| 4657/5000 [17:26:13<1:08:32, 11.99s/it, loss=0.3927, lr=1.43e-07]Steps:  93%|█████████▎| 4658/5000 [17:26:25<1:08:10, 11.96s/it, loss=0.3927, lr=1.43e-07]Steps:  93%|█████████▎| 4658/5000 [17:26:25<1:08:10, 11.96s/it, loss=0.8401, lr=1.42e-07]Steps:  93%|█████████▎| 4659/5000 [17:26:37<1:07:55, 11.95s/it, loss=0.8401, lr=1.42e-07]Steps:  93%|█████████▎| 4659/5000 [17:26:37<1:07:55, 11.95s/it, loss=1.0509, lr=1.41e-07]Steps:  93%|█████████▎| 4660/5000 [17:26:49<1:07:58, 12.00s/it, loss=1.0509, lr=1.41e-07]Steps:  93%|█████████▎| 4660/5000 [17:26:49<1:07:58, 12.00s/it, loss=0.9732, lr=1.40e-07]
[Step 4660] Training Debug Info:
  Loss: 1.099566
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0201, std: 0.9336
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0183, std: 1.3672
  Model pred mean: -0.0209, std: 0.8789
  Sigmas: [0.2470703125]... (timesteps: [247.0])

[Step 4660] Training Debug Info:
  Loss: 0.420288
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0139, std: 0.8672
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0125, std: 1.3203
  Model pred mean: -0.0159, std: 1.1484
  Sigmas: [0.76953125]... (timesteps: [769.0])

[Step 4660] Training Debug Info:
  Loss: 1.186220
  Latent shape: torch.Size([1, 32, 174, 48]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0192, std: 0.8555
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0200, std: 1.3125
  Model pred mean: 0.0209, std: 0.7383
  Sigmas: [0.2470703125]... (timesteps: [247.0])

[Step 4660] Training Debug Info:
  Loss: 0.480299
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9297
  Noise mean: -0.0037, std: 1.0000
  Target mean: -0.0035, std: 1.3672
  Model pred mean: 0.0015, std: 1.1797
  Sigmas: [0.63671875]... (timesteps: [636.0])
Steps:  93%|█████████▎| 4661/5000 [17:27:01<1:08:14, 12.08s/it, loss=0.9732, lr=1.40e-07]Steps:  93%|█████████▎| 4661/5000 [17:27:01<1:08:14, 12.08s/it, loss=0.4803, lr=1.39e-07]Steps:  93%|█████████▎| 4662/5000 [17:27:13<1:07:49, 12.04s/it, loss=0.4803, lr=1.39e-07]Steps:  93%|█████████▎| 4662/5000 [17:27:13<1:07:49, 12.04s/it, loss=0.4746, lr=1.39e-07]Steps:  93%|█████████▎| 4663/5000 [17:27:25<1:07:35, 12.03s/it, loss=0.4746, lr=1.39e-07]Steps:  93%|█████████▎| 4663/5000 [17:27:25<1:07:35, 12.03s/it, loss=1.0025, lr=1.38e-07]Steps:  93%|█████████▎| 4664/5000 [17:27:37<1:07:22, 12.03s/it, loss=1.0025, lr=1.38e-07]Steps:  93%|█████████▎| 4664/5000 [17:27:37<1:07:22, 12.03s/it, loss=0.3949, lr=1.37e-07]Steps:  93%|█████████▎| 4665/5000 [17:27:49<1:07:00, 12.00s/it, loss=0.3949, lr=1.37e-07]Steps:  93%|█████████▎| 4665/5000 [17:27:49<1:07:00, 12.00s/it, loss=0.6447, lr=1.36e-07]Steps:  93%|█████████▎| 4666/5000 [17:28:01<1:06:35, 11.96s/it, loss=0.6447, lr=1.36e-07]Steps:  93%|█████████▎| 4666/5000 [17:28:01<1:06:35, 11.96s/it, loss=0.4094, lr=1.35e-07]Steps:  93%|█████████▎| 4667/5000 [17:28:13<1:06:26, 11.97s/it, loss=0.4094, lr=1.35e-07]Steps:  93%|█████████▎| 4667/5000 [17:28:13<1:06:26, 11.97s/it, loss=1.1582, lr=1.35e-07]Steps:  93%|█████████▎| 4668/5000 [17:28:25<1:06:42, 12.06s/it, loss=1.1582, lr=1.35e-07]Steps:  93%|█████████▎| 4668/5000 [17:28:25<1:06:42, 12.06s/it, loss=0.3584, lr=1.34e-07]Steps:  93%|█████████▎| 4669/5000 [17:28:37<1:06:43, 12.10s/it, loss=0.3584, lr=1.34e-07]Steps:  93%|█████████▎| 4669/5000 [17:28:37<1:06:43, 12.10s/it, loss=0.5300, lr=1.33e-07]Steps:  93%|█████████▎| 4670/5000 [17:28:49<1:06:06, 12.02s/it, loss=0.5300, lr=1.33e-07]Steps:  93%|█████████▎| 4670/5000 [17:28:49<1:06:06, 12.02s/it, loss=0.5412, lr=1.32e-07]
[Step 4670] Training Debug Info:
  Loss: 1.122459
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0070, std: 0.8828
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0043, std: 1.3359
  Model pred mean: 0.0069, std: 0.8086
  Sigmas: [0.0830078125]... (timesteps: [83.0])

[Step 4670] Training Debug Info:
  Loss: 1.182343
  Latent shape: torch.Size([1, 32, 78, 108]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0064, std: 0.8672
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0065, std: 1.3203
  Model pred mean: 0.0057, std: 0.7539
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 4670] Training Debug Info:
  Loss: 0.794245
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0222, std: 0.9609
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0210, std: 1.3906
  Model pred mean: -0.0156, std: 1.0781
  Sigmas: [0.9921875]... (timesteps: [994.0])

[Step 4670] Training Debug Info:
  Loss: 0.628343
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0078, std: 0.9180
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0069, std: 1.3594
  Model pred mean: 0.0024, std: 1.0938
  Sigmas: [0.9765625]... (timesteps: [976.0])
Steps:  93%|█████████▎| 4671/5000 [17:29:01<1:05:48, 12.00s/it, loss=0.5412, lr=1.32e-07]Steps:  93%|█████████▎| 4671/5000 [17:29:01<1:05:48, 12.00s/it, loss=0.6283, lr=1.31e-07]Steps:  93%|█████████▎| 4672/5000 [17:29:13<1:05:32, 11.99s/it, loss=0.6283, lr=1.31e-07]Steps:  93%|█████████▎| 4672/5000 [17:29:13<1:05:32, 11.99s/it, loss=1.0977, lr=1.31e-07]Steps:  93%|█████████▎| 4673/5000 [17:29:25<1:05:16, 11.98s/it, loss=1.0977, lr=1.31e-07]Steps:  93%|█████████▎| 4673/5000 [17:29:25<1:05:16, 11.98s/it, loss=0.3507, lr=1.30e-07]Steps:  93%|█████████▎| 4674/5000 [17:29:37<1:04:59, 11.96s/it, loss=0.3507, lr=1.30e-07]Steps:  93%|█████████▎| 4674/5000 [17:29:37<1:04:59, 11.96s/it, loss=0.3774, lr=1.29e-07]Steps:  94%|█████████▎| 4675/5000 [17:29:49<1:05:15, 12.05s/it, loss=0.3774, lr=1.29e-07]Steps:  94%|█████████▎| 4675/5000 [17:29:49<1:05:15, 12.05s/it, loss=0.7229, lr=1.28e-07]Steps:  94%|█████████▎| 4676/5000 [17:30:01<1:04:50, 12.01s/it, loss=0.7229, lr=1.28e-07]Steps:  94%|█████████▎| 4676/5000 [17:30:01<1:04:50, 12.01s/it, loss=0.9882, lr=1.27e-07]Steps:  94%|█████████▎| 4677/5000 [17:30:13<1:04:36, 12.00s/it, loss=0.9882, lr=1.27e-07]Steps:  94%|█████████▎| 4677/5000 [17:30:13<1:04:36, 12.00s/it, loss=0.4600, lr=1.27e-07]Steps:  94%|█████████▎| 4678/5000 [17:30:25<1:04:28, 12.01s/it, loss=0.4600, lr=1.27e-07]Steps:  94%|█████████▎| 4678/5000 [17:30:25<1:04:28, 12.01s/it, loss=1.0387, lr=1.26e-07]Steps:  94%|█████████▎| 4679/5000 [17:30:37<1:04:11, 12.00s/it, loss=1.0387, lr=1.26e-07]Steps:  94%|█████████▎| 4679/5000 [17:30:37<1:04:11, 12.00s/it, loss=0.4446, lr=1.25e-07]Steps:  94%|█████████▎| 4680/5000 [17:30:49<1:03:51, 11.97s/it, loss=0.4446, lr=1.25e-07]Steps:  94%|█████████▎| 4680/5000 [17:30:49<1:03:51, 11.97s/it, loss=1.0853, lr=1.24e-07]
[Step 4680] Training Debug Info:
  Loss: 0.502546
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0256, std: 0.9062
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0225, std: 1.3516
  Model pred mean: 0.0221, std: 1.1484
  Sigmas: [0.671875]... (timesteps: [673.0])

[Step 4680] Training Debug Info:
  Loss: 0.840392
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0148, std: 0.9023
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0160, std: 1.3438
  Model pred mean: -0.0145, std: 0.9883
  Sigmas: [0.419921875]... (timesteps: [420.0])

[Step 4680] Training Debug Info:
  Loss: 1.038999
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0051, std: 0.8711
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0045, std: 1.3281
  Model pred mean: 0.0041, std: 0.8516
  Sigmas: [0.337890625]... (timesteps: [338.0])

[Step 4680] Training Debug Info:
  Loss: 1.117230
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0220, std: 0.9336
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0237, std: 1.3750
  Model pred mean: -0.0222, std: 0.8711
  Sigmas: [0.19140625]... (timesteps: [191.0])
Steps:  94%|█████████▎| 4681/5000 [17:31:01<1:03:40, 11.98s/it, loss=1.0853, lr=1.24e-07]Steps:  94%|█████████▎| 4681/5000 [17:31:01<1:03:40, 11.98s/it, loss=1.1172, lr=1.23e-07]Steps:  94%|█████████▎| 4682/5000 [17:31:13<1:03:46, 12.03s/it, loss=1.1172, lr=1.23e-07]Steps:  94%|█████████▎| 4682/5000 [17:31:13<1:03:46, 12.03s/it, loss=0.6813, lr=1.23e-07]Steps:  94%|█████████▎| 4683/5000 [17:31:25<1:03:19, 11.99s/it, loss=0.6813, lr=1.23e-07]Steps:  94%|█████████▎| 4683/5000 [17:31:25<1:03:19, 11.99s/it, loss=0.9316, lr=1.22e-07]Steps:  94%|█████████▎| 4684/5000 [17:31:37<1:03:02, 11.97s/it, loss=0.9316, lr=1.22e-07]Steps:  94%|█████████▎| 4684/5000 [17:31:37<1:03:02, 11.97s/it, loss=0.6599, lr=1.21e-07]Steps:  94%|█████████▎| 4685/5000 [17:31:49<1:02:58, 12.00s/it, loss=0.6599, lr=1.21e-07]Steps:  94%|█████████▎| 4685/5000 [17:31:49<1:02:58, 12.00s/it, loss=1.1484, lr=1.20e-07]Steps:  94%|█████████▎| 4686/5000 [17:32:01<1:02:44, 11.99s/it, loss=1.1484, lr=1.20e-07]Steps:  94%|█████████▎| 4686/5000 [17:32:01<1:02:44, 11.99s/it, loss=0.3616, lr=1.20e-07]Steps:  94%|█████████▎| 4687/5000 [17:32:13<1:02:38, 12.01s/it, loss=0.3616, lr=1.20e-07]Steps:  94%|█████████▎| 4687/5000 [17:32:13<1:02:38, 12.01s/it, loss=0.6188, lr=1.19e-07]Steps:  94%|█████████▍| 4688/5000 [17:32:26<1:02:50, 12.09s/it, loss=0.6188, lr=1.19e-07]Steps:  94%|█████████▍| 4688/5000 [17:32:26<1:02:50, 12.09s/it, loss=0.3972, lr=1.18e-07]Steps:  94%|█████████▍| 4689/5000 [17:32:37<1:02:26, 12.05s/it, loss=0.3972, lr=1.18e-07]Steps:  94%|█████████▍| 4689/5000 [17:32:37<1:02:26, 12.05s/it, loss=0.8420, lr=1.17e-07]Steps:  94%|█████████▍| 4690/5000 [17:32:49<1:02:06, 12.02s/it, loss=0.8420, lr=1.17e-07]Steps:  94%|█████████▍| 4690/5000 [17:32:49<1:02:06, 12.02s/it, loss=0.6941, lr=1.17e-07]
[Step 4690] Training Debug Info:
  Loss: 1.023642
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0254, std: 0.9336
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0276, std: 1.3672
  Model pred mean: -0.0253, std: 0.9180
  Sigmas: [0.01300048828125]... (timesteps: [13.0])

[Step 4690] Training Debug Info:
  Loss: 0.507689
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0019, std: 0.8711
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0052, std: 1.3281
  Model pred mean: 0.0097, std: 1.1094
  Sigmas: [0.94140625]... (timesteps: [941.0])

[Step 4690] Training Debug Info:
  Loss: 0.411202
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0021, std: 0.9141
  Noise mean: 0.0024, std: 1.0000
  Target mean: 0.0045, std: 1.3516
  Model pred mean: 0.0015, std: 1.1875
  Sigmas: [0.76171875]... (timesteps: [760.0])

[Step 4690] Training Debug Info:
  Loss: 0.526733
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0059, std: 0.9180
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0055, std: 1.3594
  Model pred mean: 0.0054, std: 1.1484
  Sigmas: [0.65234375]... (timesteps: [652.0])
Steps:  94%|█████████▍| 4691/5000 [17:33:01<1:01:52, 12.01s/it, loss=0.6941, lr=1.17e-07]Steps:  94%|█████████▍| 4691/5000 [17:33:01<1:01:52, 12.01s/it, loss=0.5267, lr=1.16e-07]Steps:  94%|█████████▍| 4692/5000 [17:33:13<1:01:37, 12.00s/it, loss=0.5267, lr=1.16e-07]Steps:  94%|█████████▍| 4692/5000 [17:33:13<1:01:37, 12.00s/it, loss=0.4753, lr=1.15e-07]Steps:  94%|█████████▍| 4693/5000 [17:33:25<1:01:20, 11.99s/it, loss=0.4753, lr=1.15e-07]Steps:  94%|█████████▍| 4693/5000 [17:33:25<1:01:20, 11.99s/it, loss=0.3845, lr=1.14e-07]Steps:  94%|█████████▍| 4694/5000 [17:33:37<1:01:05, 11.98s/it, loss=0.3845, lr=1.14e-07]Steps:  94%|█████████▍| 4694/5000 [17:33:37<1:01:05, 11.98s/it, loss=0.4111, lr=1.14e-07]Steps:  94%|█████████▍| 4695/5000 [17:33:50<1:01:20, 12.07s/it, loss=0.4111, lr=1.14e-07]Steps:  94%|█████████▍| 4695/5000 [17:33:50<1:01:20, 12.07s/it, loss=0.5008, lr=1.13e-07]Steps:  94%|█████████▍| 4696/5000 [17:34:02<1:01:04, 12.05s/it, loss=0.5008, lr=1.13e-07]Steps:  94%|█████████▍| 4696/5000 [17:34:02<1:01:04, 12.05s/it, loss=0.4034, lr=1.12e-07]Steps:  94%|█████████▍| 4697/5000 [17:34:14<1:00:40, 12.01s/it, loss=0.4034, lr=1.12e-07]Steps:  94%|█████████▍| 4697/5000 [17:34:14<1:00:40, 12.01s/it, loss=1.0464, lr=1.11e-07]Steps:  94%|█████████▍| 4698/5000 [17:34:25<1:00:15, 11.97s/it, loss=1.0464, lr=1.11e-07]Steps:  94%|█████████▍| 4698/5000 [17:34:25<1:00:15, 11.97s/it, loss=0.5779, lr=1.11e-07]Steps:  94%|█████████▍| 4699/5000 [17:34:37<1:00:00, 11.96s/it, loss=0.5779, lr=1.11e-07]Steps:  94%|█████████▍| 4699/5000 [17:34:37<1:00:00, 11.96s/it, loss=0.4538, lr=1.10e-07]Steps:  94%|█████████▍| 4700/5000 [17:34:49<59:46, 11.96s/it, loss=0.4538, lr=1.10e-07]  Steps:  94%|█████████▍| 4700/5000 [17:34:49<59:46, 11.96s/it, loss=0.6472, lr=1.09e-07]01/23/2026 01:20:36 - INFO - __main__ - 
[Step 4700] ✅ Loss in normal range (0.6472)
01/23/2026 01:20:36 - INFO - __main__ -   Loss avg (last 100): 0.7009
01/23/2026 01:20:36 - INFO - __main__ -   Loss range: [0.3432, 1.1794]

[Step 4700] Training Debug Info:
  Loss: 0.483942
  Latent shape: torch.Size([1, 32, 132, 66]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0208, std: 0.9102
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0203, std: 1.3516
  Model pred mean: 0.0239, std: 1.1562
  Sigmas: [0.66796875]... (timesteps: [668.0])

[Step 4700] Training Debug Info:
  Loss: 1.181888
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0118, std: 0.8945
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0133, std: 1.3438
  Model pred mean: 0.0117, std: 0.7891
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 4700] Training Debug Info:
  Loss: 0.725049
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0540, std: 0.9414
  Noise mean: -0.0027, std: 1.0000
  Target mean: -0.0569, std: 1.3750
  Model pred mean: -0.0289, std: 1.0859
  Sigmas: [0.96484375]... (timesteps: [965.0])

[Step 4700] Training Debug Info:
  Loss: 1.066120
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0610, std: 0.9492
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0610, std: 1.3828
  Model pred mean: 0.0623, std: 0.9102
  Sigmas: [0.09619140625]... (timesteps: [96.0])
Steps:  94%|█████████▍| 4701/5000 [17:35:01<59:34, 11.95s/it, loss=0.6472, lr=1.09e-07]Steps:  94%|█████████▍| 4701/5000 [17:35:01<59:34, 11.95s/it, loss=1.0661, lr=1.09e-07]Steps:  94%|█████████▍| 4702/5000 [17:35:13<59:36, 12.00s/it, loss=1.0661, lr=1.09e-07]Steps:  94%|█████████▍| 4702/5000 [17:35:13<59:36, 12.00s/it, loss=0.7874, lr=1.08e-07]Steps:  94%|█████████▍| 4703/5000 [17:35:25<59:14, 11.97s/it, loss=0.7874, lr=1.08e-07]Steps:  94%|█████████▍| 4703/5000 [17:35:25<59:14, 11.97s/it, loss=1.1446, lr=1.07e-07]Steps:  94%|█████████▍| 4704/5000 [17:35:37<59:02, 11.97s/it, loss=1.1446, lr=1.07e-07]Steps:  94%|█████████▍| 4704/5000 [17:35:37<59:02, 11.97s/it, loss=0.4323, lr=1.06e-07]Steps:  94%|█████████▍| 4705/5000 [17:35:49<59:15, 12.05s/it, loss=0.4323, lr=1.06e-07]Steps:  94%|█████████▍| 4705/5000 [17:35:49<59:15, 12.05s/it, loss=0.7570, lr=1.06e-07]Steps:  94%|█████████▍| 4706/5000 [17:36:01<58:58, 12.03s/it, loss=0.7570, lr=1.06e-07]Steps:  94%|█████████▍| 4706/5000 [17:36:01<58:58, 12.03s/it, loss=0.4332, lr=1.05e-07]Steps:  94%|█████████▍| 4707/5000 [17:36:13<58:39, 12.01s/it, loss=0.4332, lr=1.05e-07]Steps:  94%|█████████▍| 4707/5000 [17:36:13<58:39, 12.01s/it, loss=0.4492, lr=1.04e-07]Steps:  94%|█████████▍| 4708/5000 [17:36:25<58:21, 11.99s/it, loss=0.4492, lr=1.04e-07]Steps:  94%|█████████▍| 4708/5000 [17:36:25<58:21, 11.99s/it, loss=0.3908, lr=1.04e-07]Steps:  94%|█████████▍| 4709/5000 [17:36:38<58:23, 12.04s/it, loss=0.3908, lr=1.04e-07]Steps:  94%|█████████▍| 4709/5000 [17:36:38<58:23, 12.04s/it, loss=0.3811, lr=1.03e-07]Steps:  94%|█████████▍| 4710/5000 [17:36:49<58:05, 12.02s/it, loss=0.3811, lr=1.03e-07]Steps:  94%|█████████▍| 4710/5000 [17:36:49<58:05, 12.02s/it, loss=1.1075, lr=1.02e-07]
[Step 4710] Training Debug Info:
  Loss: 0.420953
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0103, std: 1.3359
  Model pred mean: -0.0046, std: 1.1719
  Sigmas: [0.75390625]... (timesteps: [753.0])

[Step 4710] Training Debug Info:
  Loss: 0.350590
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0134, std: 0.8555
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0112, std: 1.3125
  Model pred mean: 0.0115, std: 1.1797
  Sigmas: [0.9375]... (timesteps: [937.0])

[Step 4710] Training Debug Info:
  Loss: 1.157373
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0092, std: 0.8984
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0098, std: 1.3438
  Model pred mean: 0.0102, std: 0.8008
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 4710] Training Debug Info:
  Loss: 1.073764
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0347, std: 0.9180
  Noise mean: 0.0009, std: 1.0000
  Target mean: 0.0356, std: 1.3594
  Model pred mean: 0.0349, std: 0.8828
  Sigmas: [0.047119140625]... (timesteps: [47.0])
Steps:  94%|█████████▍| 4711/5000 [17:37:01<57:50, 12.01s/it, loss=1.1075, lr=1.02e-07]Steps:  94%|█████████▍| 4711/5000 [17:37:01<57:50, 12.01s/it, loss=1.0738, lr=1.01e-07]Steps:  94%|█████████▍| 4712/5000 [17:37:13<57:28, 11.97s/it, loss=1.0738, lr=1.01e-07]Steps:  94%|█████████▍| 4712/5000 [17:37:13<57:28, 11.97s/it, loss=0.8374, lr=1.01e-07]Steps:  94%|█████████▍| 4713/5000 [17:37:25<57:23, 12.00s/it, loss=0.8374, lr=1.01e-07]Steps:  94%|█████████▍| 4713/5000 [17:37:25<57:23, 12.00s/it, loss=0.6406, lr=1.00e-07]Steps:  94%|█████████▍| 4714/5000 [17:37:37<57:19, 12.03s/it, loss=0.6406, lr=1.00e-07]Steps:  94%|█████████▍| 4714/5000 [17:37:37<57:19, 12.03s/it, loss=1.0507, lr=9.93e-08]Steps:  94%|█████████▍| 4715/5000 [17:37:50<57:21, 12.08s/it, loss=1.0507, lr=9.93e-08]Steps:  94%|█████████▍| 4715/5000 [17:37:50<57:21, 12.08s/it, loss=0.9730, lr=9.86e-08]Steps:  94%|█████████▍| 4716/5000 [17:38:02<56:52, 12.02s/it, loss=0.9730, lr=9.86e-08]Steps:  94%|█████████▍| 4716/5000 [17:38:02<56:52, 12.02s/it, loss=1.1230, lr=9.80e-08]Steps:  94%|█████████▍| 4717/5000 [17:38:13<56:33, 11.99s/it, loss=1.1230, lr=9.80e-08]Steps:  94%|█████████▍| 4717/5000 [17:38:13<56:33, 11.99s/it, loss=0.7092, lr=9.73e-08]Steps:  94%|█████████▍| 4718/5000 [17:38:25<56:21, 11.99s/it, loss=0.7092, lr=9.73e-08]Steps:  94%|█████████▍| 4718/5000 [17:38:25<56:21, 11.99s/it, loss=0.3580, lr=9.66e-08]Steps:  94%|█████████▍| 4719/5000 [17:38:37<56:01, 11.96s/it, loss=0.3580, lr=9.66e-08]Steps:  94%|█████████▍| 4719/5000 [17:38:37<56:01, 11.96s/it, loss=1.1375, lr=9.59e-08]Steps:  94%|█████████▍| 4720/5000 [17:38:49<55:51, 11.97s/it, loss=1.1375, lr=9.59e-08]Steps:  94%|█████████▍| 4720/5000 [17:38:49<55:51, 11.97s/it, loss=1.1364, lr=9.52e-08]
[Step 4720] Training Debug Info:
  Loss: 1.189453
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0055, std: 0.8711
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0021, std: 1.3281
  Model pred mean: -0.0054, std: 0.7578
  Sigmas: [0.1962890625]... (timesteps: [196.0])

[Step 4720] Training Debug Info:
  Loss: 1.024738
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0249, std: 0.9570
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0264, std: 1.3828
  Model pred mean: -0.0255, std: 0.9453
  Sigmas: [0.2060546875]... (timesteps: [206.0])

[Step 4720] Training Debug Info:
  Loss: 0.487397
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0349, std: 0.9102
  Noise mean: 0.0042, std: 1.0000
  Target mean: -0.0308, std: 1.3516
  Model pred mean: -0.0366, std: 1.1641
  Sigmas: [0.74609375]... (timesteps: [746.0])

[Step 4720] Training Debug Info:
  Loss: 1.131503
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0088, std: 0.9062
  Noise mean: -0.0032, std: 1.0000
  Target mean: -0.0120, std: 1.3516
  Model pred mean: -0.0092, std: 0.8320
  Sigmas: [0.1259765625]... (timesteps: [126.0])
Steps:  94%|█████████▍| 4721/5000 [17:39:01<55:36, 11.96s/it, loss=1.1364, lr=9.52e-08]Steps:  94%|█████████▍| 4721/5000 [17:39:01<55:36, 11.96s/it, loss=1.1315, lr=9.45e-08]Steps:  94%|█████████▍| 4722/5000 [17:39:13<55:38, 12.01s/it, loss=1.1315, lr=9.45e-08]Steps:  94%|█████████▍| 4722/5000 [17:39:13<55:38, 12.01s/it, loss=1.1041, lr=9.39e-08]Steps:  94%|█████████▍| 4723/5000 [17:39:25<55:29, 12.02s/it, loss=1.1041, lr=9.39e-08]Steps:  94%|█████████▍| 4723/5000 [17:39:25<55:29, 12.02s/it, loss=0.7110, lr=9.32e-08]Steps:  94%|█████████▍| 4724/5000 [17:39:37<55:03, 11.97s/it, loss=0.7110, lr=9.32e-08]Steps:  94%|█████████▍| 4724/5000 [17:39:37<55:03, 11.97s/it, loss=1.1133, lr=9.25e-08]Steps:  94%|█████████▍| 4725/5000 [17:39:49<54:51, 11.97s/it, loss=1.1133, lr=9.25e-08]Steps:  94%|█████████▍| 4725/5000 [17:39:49<54:51, 11.97s/it, loss=0.6138, lr=9.19e-08]Steps:  95%|█████████▍| 4726/5000 [17:40:01<54:33, 11.95s/it, loss=0.6138, lr=9.19e-08]Steps:  95%|█████████▍| 4726/5000 [17:40:01<54:33, 11.95s/it, loss=1.1392, lr=9.12e-08]Steps:  95%|█████████▍| 4727/5000 [17:40:13<54:14, 11.92s/it, loss=1.1392, lr=9.12e-08]Steps:  95%|█████████▍| 4727/5000 [17:40:13<54:14, 11.92s/it, loss=0.5551, lr=9.05e-08]Steps:  95%|█████████▍| 4728/5000 [17:40:25<54:01, 11.92s/it, loss=0.5551, lr=9.05e-08]Steps:  95%|█████████▍| 4728/5000 [17:40:25<54:01, 11.92s/it, loss=0.4200, lr=8.99e-08]Steps:  95%|█████████▍| 4729/5000 [17:40:37<54:10, 12.00s/it, loss=0.4200, lr=8.99e-08]Steps:  95%|█████████▍| 4729/5000 [17:40:37<54:10, 12.00s/it, loss=0.6251, lr=8.92e-08]Steps:  95%|█████████▍| 4730/5000 [17:40:49<53:54, 11.98s/it, loss=0.6251, lr=8.92e-08]Steps:  95%|█████████▍| 4730/5000 [17:40:49<53:54, 11.98s/it, loss=1.0399, lr=8.86e-08]
[Step 4730] Training Debug Info:
  Loss: 0.486842
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0042, std: 0.8828
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0021, std: 1.3359
  Model pred mean: -0.0058, std: 1.1328
  Sigmas: [0.67578125]... (timesteps: [676.0])

[Step 4730] Training Debug Info:
  Loss: 0.544050
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0037, std: 1.0234
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0027, std: 1.4297
  Model pred mean: -0.0018, std: 1.2266
  Sigmas: [0.671875]... (timesteps: [670.0])

[Step 4730] Training Debug Info:
  Loss: 0.933060
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0144, std: 0.9258
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0131, std: 1.3594
  Model pred mean: -0.0134, std: 0.9570
  Sigmas: [0.32421875]... (timesteps: [324.0])

[Step 4730] Training Debug Info:
  Loss: 0.382223
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0181, std: 0.9492
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0187, std: 1.3828
  Model pred mean: 0.0192, std: 1.2344
  Sigmas: [0.84375]... (timesteps: [843.0])
Steps:  95%|█████████▍| 4731/5000 [17:41:01<53:42, 11.98s/it, loss=1.0399, lr=8.86e-08]Steps:  95%|█████████▍| 4731/5000 [17:41:01<53:42, 11.98s/it, loss=0.3822, lr=8.79e-08]Steps:  95%|█████████▍| 4732/5000 [17:41:13<53:34, 12.00s/it, loss=0.3822, lr=8.79e-08]Steps:  95%|█████████▍| 4732/5000 [17:41:13<53:34, 12.00s/it, loss=0.3822, lr=8.73e-08]Steps:  95%|█████████▍| 4733/5000 [17:41:25<53:19, 11.98s/it, loss=0.3822, lr=8.73e-08]Steps:  95%|█████████▍| 4733/5000 [17:41:25<53:19, 11.98s/it, loss=0.4277, lr=8.66e-08]Steps:  95%|█████████▍| 4734/5000 [17:41:37<53:10, 11.99s/it, loss=0.4277, lr=8.66e-08]Steps:  95%|█████████▍| 4734/5000 [17:41:37<53:10, 11.99s/it, loss=0.4343, lr=8.60e-08]Steps:  95%|█████████▍| 4735/5000 [17:41:49<52:57, 11.99s/it, loss=0.4343, lr=8.60e-08]Steps:  95%|█████████▍| 4735/5000 [17:41:49<52:57, 11.99s/it, loss=1.0385, lr=8.53e-08]Steps:  95%|█████████▍| 4736/5000 [17:42:01<53:01, 12.05s/it, loss=1.0385, lr=8.53e-08]Steps:  95%|█████████▍| 4736/5000 [17:42:01<53:01, 12.05s/it, loss=1.0428, lr=8.47e-08]Steps:  95%|█████████▍| 4737/5000 [17:42:13<52:32, 11.99s/it, loss=1.0428, lr=8.47e-08]Steps:  95%|█████████▍| 4737/5000 [17:42:13<52:32, 11.99s/it, loss=0.4006, lr=8.40e-08]Steps:  95%|█████████▍| 4738/5000 [17:42:25<52:16, 11.97s/it, loss=0.4006, lr=8.40e-08]Steps:  95%|█████████▍| 4738/5000 [17:42:25<52:16, 11.97s/it, loss=1.1296, lr=8.34e-08]Steps:  95%|█████████▍| 4739/5000 [17:42:37<52:00, 11.96s/it, loss=1.1296, lr=8.34e-08]Steps:  95%|█████████▍| 4739/5000 [17:42:37<52:00, 11.96s/it, loss=0.4943, lr=8.28e-08]Steps:  95%|█████████▍| 4740/5000 [17:42:49<51:44, 11.94s/it, loss=0.4943, lr=8.28e-08]Steps:  95%|█████████▍| 4740/5000 [17:42:49<51:44, 11.94s/it, loss=0.5957, lr=8.21e-08]
[Step 4740] Training Debug Info:
  Loss: 0.485924
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0190, std: 0.9453
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0190, std: 1.3750
  Model pred mean: -0.0221, std: 1.1797
  Sigmas: [0.76953125]... (timesteps: [769.0])

[Step 4740] Training Debug Info:
  Loss: 1.019493
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0154, std: 0.9258
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0167, std: 1.3672
  Model pred mean: -0.0173, std: 0.9180
  Sigmas: [0.00799560546875]... (timesteps: [8.0])

[Step 4740] Training Debug Info:
  Loss: 1.098861
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0033, std: 0.9297
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0034, std: 1.3672
  Model pred mean: 0.0034, std: 0.8750
  Sigmas: [0.09423828125]... (timesteps: [94.0])

[Step 4740] Training Debug Info:
  Loss: 1.065541
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0148, std: 0.9414
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0164, std: 1.3750
  Model pred mean: -0.0143, std: 0.9102
  Sigmas: [0.2373046875]... (timesteps: [237.0])
Steps:  95%|█████████▍| 4741/5000 [17:43:01<51:40, 11.97s/it, loss=0.5957, lr=8.21e-08]Steps:  95%|█████████▍| 4741/5000 [17:43:01<51:40, 11.97s/it, loss=1.0655, lr=8.15e-08]Steps:  95%|█████████▍| 4742/5000 [17:43:13<51:38, 12.01s/it, loss=1.0655, lr=8.15e-08]Steps:  95%|█████████▍| 4742/5000 [17:43:13<51:38, 12.01s/it, loss=0.5533, lr=8.09e-08]Steps:  95%|█████████▍| 4743/5000 [17:43:25<51:21, 11.99s/it, loss=0.5533, lr=8.09e-08]Steps:  95%|█████████▍| 4743/5000 [17:43:25<51:21, 11.99s/it, loss=1.1044, lr=8.03e-08]Steps:  95%|█████████▍| 4744/5000 [17:43:37<50:57, 11.95s/it, loss=1.1044, lr=8.03e-08]Steps:  95%|█████████▍| 4744/5000 [17:43:37<50:57, 11.95s/it, loss=0.4437, lr=7.96e-08]Steps:  95%|█████████▍| 4745/5000 [17:43:49<50:47, 11.95s/it, loss=0.4437, lr=7.96e-08]Steps:  95%|█████████▍| 4745/5000 [17:43:49<50:47, 11.95s/it, loss=1.1707, lr=7.90e-08]Steps:  95%|█████████▍| 4746/5000 [17:44:01<50:36, 11.96s/it, loss=1.1707, lr=7.90e-08]Steps:  95%|█████████▍| 4746/5000 [17:44:01<50:36, 11.96s/it, loss=1.0173, lr=7.84e-08]Steps:  95%|█████████▍| 4747/5000 [17:44:13<50:23, 11.95s/it, loss=1.0173, lr=7.84e-08]Steps:  95%|█████████▍| 4747/5000 [17:44:13<50:23, 11.95s/it, loss=0.6239, lr=7.78e-08]Steps:  95%|█████████▍| 4748/5000 [17:44:25<50:07, 11.93s/it, loss=0.6239, lr=7.78e-08]Steps:  95%|█████████▍| 4748/5000 [17:44:25<50:07, 11.93s/it, loss=1.0487, lr=7.72e-08]Steps:  95%|█████████▍| 4749/5000 [17:44:37<50:10, 11.99s/it, loss=1.0487, lr=7.72e-08]Steps:  95%|█████████▍| 4749/5000 [17:44:37<50:10, 11.99s/it, loss=0.8449, lr=7.66e-08]Steps:  95%|█████████▌| 4750/5000 [17:44:49<50:01, 12.01s/it, loss=0.8449, lr=7.66e-08]Steps:  95%|█████████▌| 4750/5000 [17:44:49<50:01, 12.01s/it, loss=0.4664, lr=7.60e-08]
[Step 4750] Training Debug Info:
  Loss: 0.731655
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0364, std: 0.9297
  Noise mean: 0.0048, std: 1.0000
  Target mean: -0.0315, std: 1.3672
  Model pred mean: -0.0337, std: 1.0625
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 4750] Training Debug Info:
  Loss: 1.024007
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0110, std: 0.9258
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0109, std: 1.3594
  Model pred mean: 0.0118, std: 0.9062
  Sigmas: [0.01397705078125]... (timesteps: [14.0])

[Step 4750] Training Debug Info:
  Loss: 1.168622
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0162, std: 0.9453
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0165, std: 1.3750
  Model pred mean: -0.0157, std: 0.8477
  Sigmas: [0.1708984375]... (timesteps: [171.0])

[Step 4750] Training Debug Info:
  Loss: 1.037512
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0073, std: 0.8477
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0093, std: 1.3125
  Model pred mean: 0.0060, std: 0.8281
  Sigmas: [0.36328125]... (timesteps: [364.0])
Steps:  95%|█████████▌| 4751/5000 [17:45:01<49:38, 11.96s/it, loss=0.4664, lr=7.60e-08]Steps:  95%|█████████▌| 4751/5000 [17:45:01<49:38, 11.96s/it, loss=1.0375, lr=7.54e-08]Steps:  95%|█████████▌| 4752/5000 [17:45:12<49:19, 11.93s/it, loss=1.0375, lr=7.54e-08]Steps:  95%|█████████▌| 4752/5000 [17:45:12<49:19, 11.93s/it, loss=1.0944, lr=7.48e-08]Steps:  95%|█████████▌| 4753/5000 [17:45:24<49:09, 11.94s/it, loss=1.0944, lr=7.48e-08]Steps:  95%|█████████▌| 4753/5000 [17:45:24<49:09, 11.94s/it, loss=0.3619, lr=7.42e-08]Steps:  95%|█████████▌| 4754/5000 [17:45:36<48:57, 11.94s/it, loss=0.3619, lr=7.42e-08]Steps:  95%|█████████▌| 4754/5000 [17:45:36<48:57, 11.94s/it, loss=1.1124, lr=7.36e-08]Steps:  95%|█████████▌| 4755/5000 [17:45:48<48:44, 11.94s/it, loss=1.1124, lr=7.36e-08]Steps:  95%|█████████▌| 4755/5000 [17:45:48<48:44, 11.94s/it, loss=0.5198, lr=7.30e-08]Steps:  95%|█████████▌| 4756/5000 [17:46:00<48:55, 12.03s/it, loss=0.5198, lr=7.30e-08]Steps:  95%|█████████▌| 4756/5000 [17:46:00<48:55, 12.03s/it, loss=0.8595, lr=7.24e-08]Steps:  95%|█████████▌| 4757/5000 [17:46:12<48:35, 12.00s/it, loss=0.8595, lr=7.24e-08]Steps:  95%|█████████▌| 4757/5000 [17:46:12<48:35, 12.00s/it, loss=0.4143, lr=7.18e-08]Steps:  95%|█████████▌| 4758/5000 [17:46:24<48:24, 12.00s/it, loss=0.4143, lr=7.18e-08]Steps:  95%|█████████▌| 4758/5000 [17:46:24<48:24, 12.00s/it, loss=0.9163, lr=7.12e-08]Steps:  95%|█████████▌| 4759/5000 [17:46:36<48:14, 12.01s/it, loss=0.9163, lr=7.12e-08]Steps:  95%|█████████▌| 4759/5000 [17:46:36<48:14, 12.01s/it, loss=0.6806, lr=7.06e-08]Steps:  95%|█████████▌| 4760/5000 [17:46:48<47:59, 12.00s/it, loss=0.6806, lr=7.06e-08]Steps:  95%|█████████▌| 4760/5000 [17:46:48<47:59, 12.00s/it, loss=0.4420, lr=7.00e-08]
[Step 4760] Training Debug Info:
  Loss: 0.605710
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0200, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0199, std: 1.3672
  Model pred mean: 0.0232, std: 1.1250
  Sigmas: [0.58984375]... (timesteps: [589.0])

[Step 4760] Training Debug Info:
  Loss: 0.486155
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0032, std: 0.9219
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0052, std: 1.3594
  Model pred mean: 0.0166, std: 1.1797
  Sigmas: [0.94921875]... (timesteps: [948.0])

[Step 4760] Training Debug Info:
  Loss: 1.058231
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0197, std: 0.8828
  Noise mean: -0.0039, std: 1.0000
  Target mean: -0.0236, std: 1.3359
  Model pred mean: -0.0209, std: 0.8516
  Sigmas: [0.033935546875]... (timesteps: [34.0])

[Step 4760] Training Debug Info:
  Loss: 1.156239
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0130, std: 0.9102
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0142, std: 1.3516
  Model pred mean: 0.0137, std: 0.8164
  Sigmas: [0.1396484375]... (timesteps: [140.0])
Steps:  95%|█████████▌| 4761/5000 [17:47:00<47:45, 11.99s/it, loss=0.4420, lr=7.00e-08]Steps:  95%|█████████▌| 4761/5000 [17:47:00<47:45, 11.99s/it, loss=1.1562, lr=6.94e-08]Steps:  95%|█████████▌| 4762/5000 [17:47:12<47:28, 11.97s/it, loss=1.1562, lr=6.94e-08]Steps:  95%|█████████▌| 4762/5000 [17:47:12<47:28, 11.97s/it, loss=1.1274, lr=6.89e-08]Steps:  95%|█████████▌| 4763/5000 [17:47:24<47:27, 12.01s/it, loss=1.1274, lr=6.89e-08]Steps:  95%|█████████▌| 4763/5000 [17:47:24<47:27, 12.01s/it, loss=0.3781, lr=6.83e-08]Steps:  95%|█████████▌| 4764/5000 [17:47:36<47:05, 11.97s/it, loss=0.3781, lr=6.83e-08]Steps:  95%|█████████▌| 4764/5000 [17:47:36<47:05, 11.97s/it, loss=1.1677, lr=6.77e-08]Steps:  95%|█████████▌| 4765/5000 [17:47:48<46:50, 11.96s/it, loss=1.1677, lr=6.77e-08]Steps:  95%|█████████▌| 4765/5000 [17:47:48<46:50, 11.96s/it, loss=1.1511, lr=6.71e-08]Steps:  95%|█████████▌| 4766/5000 [17:48:00<46:37, 11.96s/it, loss=1.1511, lr=6.71e-08]Steps:  95%|█████████▌| 4766/5000 [17:48:00<46:37, 11.96s/it, loss=1.0895, lr=6.66e-08]Steps:  95%|█████████▌| 4767/5000 [17:48:12<46:24, 11.95s/it, loss=1.0895, lr=6.66e-08]Steps:  95%|█████████▌| 4767/5000 [17:48:12<46:24, 11.95s/it, loss=1.0057, lr=6.60e-08]Steps:  95%|█████████▌| 4768/5000 [17:48:24<46:16, 11.97s/it, loss=1.0057, lr=6.60e-08]Steps:  95%|█████████▌| 4768/5000 [17:48:24<46:16, 11.97s/it, loss=0.4148, lr=6.54e-08]Steps:  95%|█████████▌| 4769/5000 [17:48:36<46:23, 12.05s/it, loss=0.4148, lr=6.54e-08]Steps:  95%|█████████▌| 4769/5000 [17:48:36<46:23, 12.05s/it, loss=1.0310, lr=6.49e-08]Steps:  95%|█████████▌| 4770/5000 [17:48:48<45:56, 11.99s/it, loss=1.0310, lr=6.49e-08]Steps:  95%|█████████▌| 4770/5000 [17:48:48<45:56, 11.99s/it, loss=0.4564, lr=6.43e-08]
[Step 4770] Training Debug Info:
  Loss: 0.417034
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0084, std: 0.9336
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0073, std: 1.3672
  Model pred mean: -0.0134, std: 1.2031
  Sigmas: [0.921875]... (timesteps: [921.0])

[Step 4770] Training Debug Info:
  Loss: 0.521568
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0070, std: 0.8867
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0096, std: 1.3359
  Model pred mean: 0.0094, std: 1.1250
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 4770] Training Debug Info:
  Loss: 0.400891
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0046, std: 0.8945
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0026, std: 1.3438
  Model pred mean: 0.0003, std: 1.1797
  Sigmas: [0.921875]... (timesteps: [921.0])

[Step 4770] Training Debug Info:
  Loss: 1.074198
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0247, std: 0.9336
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0244, std: 1.3672
  Model pred mean: -0.0261, std: 0.8906
  Sigmas: [0.197265625]... (timesteps: [197.0])
Steps:  95%|█████████▌| 4771/5000 [17:49:00<45:41, 11.97s/it, loss=0.4564, lr=6.43e-08]Steps:  95%|█████████▌| 4771/5000 [17:49:00<45:41, 11.97s/it, loss=1.0742, lr=6.38e-08]Steps:  95%|█████████▌| 4772/5000 [17:49:12<45:30, 11.97s/it, loss=1.0742, lr=6.38e-08]Steps:  95%|█████████▌| 4772/5000 [17:49:12<45:30, 11.97s/it, loss=1.1273, lr=6.32e-08]Steps:  95%|█████████▌| 4773/5000 [17:49:24<45:16, 11.97s/it, loss=1.1273, lr=6.32e-08]Steps:  95%|█████████▌| 4773/5000 [17:49:24<45:16, 11.97s/it, loss=0.6724, lr=6.27e-08]Steps:  95%|█████████▌| 4774/5000 [17:49:36<45:03, 11.96s/it, loss=0.6724, lr=6.27e-08]Steps:  95%|█████████▌| 4774/5000 [17:49:36<45:03, 11.96s/it, loss=0.3812, lr=6.21e-08]Steps:  96%|█████████▌| 4775/5000 [17:49:48<44:49, 11.96s/it, loss=0.3812, lr=6.21e-08]Steps:  96%|█████████▌| 4775/5000 [17:49:48<44:49, 11.96s/it, loss=0.6301, lr=6.16e-08]Steps:  96%|█████████▌| 4776/5000 [17:50:00<44:49, 12.01s/it, loss=0.6301, lr=6.16e-08]Steps:  96%|█████████▌| 4776/5000 [17:50:00<44:49, 12.01s/it, loss=1.1506, lr=6.10e-08]Steps:  96%|█████████▌| 4777/5000 [17:50:12<44:34, 11.99s/it, loss=1.1506, lr=6.10e-08]Steps:  96%|█████████▌| 4777/5000 [17:50:12<44:34, 11.99s/it, loss=0.7251, lr=6.05e-08]Steps:  96%|█████████▌| 4778/5000 [17:50:24<44:19, 11.98s/it, loss=0.7251, lr=6.05e-08]Steps:  96%|█████████▌| 4778/5000 [17:50:24<44:19, 11.98s/it, loss=1.1327, lr=5.99e-08]Steps:  96%|█████████▌| 4779/5000 [17:50:36<44:01, 11.95s/it, loss=1.1327, lr=5.99e-08]Steps:  96%|█████████▌| 4779/5000 [17:50:36<44:01, 11.95s/it, loss=0.9921, lr=5.94e-08]Steps:  96%|█████████▌| 4780/5000 [17:50:48<43:51, 11.96s/it, loss=0.9921, lr=5.94e-08]Steps:  96%|█████████▌| 4780/5000 [17:50:48<43:51, 11.96s/it, loss=0.6180, lr=5.89e-08]
[Step 4780] Training Debug Info:
  Loss: 1.173802
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0142, std: 0.9336
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0167, std: 1.3672
  Model pred mean: -0.0121, std: 0.8359
  Sigmas: [0.1806640625]... (timesteps: [181.0])

[Step 4780] Training Debug Info:
  Loss: 0.993222
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0211, std: 0.9023
  Noise mean: -0.0019, std: 0.9961
  Target mean: -0.0231, std: 1.3438
  Model pred mean: -0.0217, std: 0.9062
  Sigmas: [0.3046875]... (timesteps: [304.0])

[Step 4780] Training Debug Info:
  Loss: 1.044324
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0140, std: 0.9023
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0135, std: 1.3438
  Model pred mean: -0.0136, std: 0.8750
  Sigmas: [0.2890625]... (timesteps: [289.0])

[Step 4780] Training Debug Info:
  Loss: 0.475483
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0129, std: 0.8477
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0132, std: 1.3125
  Model pred mean: 0.0160, std: 1.1094
  Sigmas: [0.7265625]... (timesteps: [725.0])
Steps:  96%|█████████▌| 4781/5000 [17:51:00<43:44, 11.98s/it, loss=0.6180, lr=5.89e-08]Steps:  96%|█████████▌| 4781/5000 [17:51:00<43:44, 11.98s/it, loss=0.4755, lr=5.83e-08]Steps:  96%|█████████▌| 4782/5000 [17:51:12<43:38, 12.01s/it, loss=0.4755, lr=5.83e-08]Steps:  96%|█████████▌| 4782/5000 [17:51:12<43:38, 12.01s/it, loss=1.1169, lr=5.78e-08]Steps:  96%|█████████▌| 4783/5000 [17:51:24<43:34, 12.05s/it, loss=1.1169, lr=5.78e-08]Steps:  96%|█████████▌| 4783/5000 [17:51:24<43:34, 12.05s/it, loss=1.1524, lr=5.73e-08]Steps:  96%|█████████▌| 4784/5000 [17:51:36<43:22, 12.05s/it, loss=1.1524, lr=5.73e-08]Steps:  96%|█████████▌| 4784/5000 [17:51:36<43:22, 12.05s/it, loss=0.9401, lr=5.67e-08]Steps:  96%|█████████▌| 4785/5000 [17:51:48<43:01, 12.01s/it, loss=0.9401, lr=5.67e-08]Steps:  96%|█████████▌| 4785/5000 [17:51:48<43:01, 12.01s/it, loss=1.1542, lr=5.62e-08]Steps:  96%|█████████▌| 4786/5000 [17:52:00<42:51, 12.02s/it, loss=1.1542, lr=5.62e-08]Steps:  96%|█████████▌| 4786/5000 [17:52:00<42:51, 12.02s/it, loss=1.0561, lr=5.57e-08]Steps:  96%|█████████▌| 4787/5000 [17:52:12<42:36, 12.00s/it, loss=1.0561, lr=5.57e-08]Steps:  96%|█████████▌| 4787/5000 [17:52:12<42:36, 12.00s/it, loss=0.7791, lr=5.52e-08]Steps:  96%|█████████▌| 4788/5000 [17:52:24<42:22, 11.99s/it, loss=0.7791, lr=5.52e-08]Steps:  96%|█████████▌| 4788/5000 [17:52:24<42:22, 11.99s/it, loss=0.8850, lr=5.47e-08]Steps:  96%|█████████▌| 4789/5000 [17:52:36<42:08, 11.98s/it, loss=0.8850, lr=5.47e-08]Steps:  96%|█████████▌| 4789/5000 [17:52:36<42:08, 11.98s/it, loss=1.0872, lr=5.41e-08]Steps:  96%|█████████▌| 4790/5000 [17:52:48<42:07, 12.03s/it, loss=1.0872, lr=5.41e-08]Steps:  96%|█████████▌| 4790/5000 [17:52:48<42:07, 12.03s/it, loss=0.5279, lr=5.36e-08]
[Step 4790] Training Debug Info:
  Loss: 1.010096
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0093, std: 0.8672
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0096, std: 1.3203
  Model pred mean: 0.0094, std: 0.8594
  Sigmas: [0.0050048828125]... (timesteps: [5.0])

[Step 4790] Training Debug Info:
  Loss: 0.886983
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0265, std: 0.8828
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0276, std: 1.3359
  Model pred mean: -0.0253, std: 0.9414
  Sigmas: [0.365234375]... (timesteps: [365.0])

[Step 4790] Training Debug Info:
  Loss: 0.428083
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0151, std: 0.8906
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0160, std: 1.3438
  Model pred mean: -0.0150, std: 1.1719
  Sigmas: [0.7109375]... (timesteps: [712.0])

[Step 4790] Training Debug Info:
  Loss: 0.439269
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0090, std: 0.8867
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0108, std: 1.3359
  Model pred mean: 0.0092, std: 1.1562
  Sigmas: [0.7265625]... (timesteps: [726.0])
Steps:  96%|█████████▌| 4791/5000 [17:53:00<41:48, 12.00s/it, loss=0.5279, lr=5.36e-08]Steps:  96%|█████████▌| 4791/5000 [17:53:00<41:48, 12.00s/it, loss=0.4393, lr=5.31e-08]Steps:  96%|█████████▌| 4792/5000 [17:53:12<41:31, 11.98s/it, loss=0.4393, lr=5.31e-08]Steps:  96%|█████████▌| 4792/5000 [17:53:12<41:31, 11.98s/it, loss=0.8191, lr=5.26e-08]Steps:  96%|█████████▌| 4793/5000 [17:53:24<41:16, 11.96s/it, loss=0.8191, lr=5.26e-08]Steps:  96%|█████████▌| 4793/5000 [17:53:24<41:16, 11.96s/it, loss=0.7062, lr=5.21e-08]Steps:  96%|█████████▌| 4794/5000 [17:53:36<41:00, 11.94s/it, loss=0.7062, lr=5.21e-08]Steps:  96%|█████████▌| 4794/5000 [17:53:36<41:00, 11.94s/it, loss=1.0981, lr=5.16e-08]Steps:  96%|█████████▌| 4795/5000 [17:53:48<40:57, 11.99s/it, loss=1.0981, lr=5.16e-08]Steps:  96%|█████████▌| 4795/5000 [17:53:48<40:57, 11.99s/it, loss=0.7348, lr=5.11e-08]Steps:  96%|█████████▌| 4796/5000 [17:54:00<40:58, 12.05s/it, loss=0.7348, lr=5.11e-08]Steps:  96%|█████████▌| 4796/5000 [17:54:00<40:58, 12.05s/it, loss=0.3859, lr=5.06e-08]Steps:  96%|█████████▌| 4797/5000 [17:54:12<40:41, 12.03s/it, loss=0.3859, lr=5.06e-08]Steps:  96%|█████████▌| 4797/5000 [17:54:12<40:41, 12.03s/it, loss=0.3957, lr=5.01e-08]Steps:  96%|█████████▌| 4798/5000 [17:54:24<40:21, 11.99s/it, loss=0.3957, lr=5.01e-08]Steps:  96%|█████████▌| 4798/5000 [17:54:24<40:21, 11.99s/it, loss=0.5000, lr=4.96e-08]Steps:  96%|█████████▌| 4799/5000 [17:54:36<40:05, 11.97s/it, loss=0.5000, lr=4.96e-08]Steps:  96%|█████████▌| 4799/5000 [17:54:36<40:05, 11.97s/it, loss=1.0154, lr=4.91e-08]Steps:  96%|█████████▌| 4800/5000 [17:54:48<39:54, 11.97s/it, loss=1.0154, lr=4.91e-08]Steps:  96%|█████████▌| 4800/5000 [17:54:48<39:54, 11.97s/it, loss=1.0416, lr=4.87e-08]01/23/2026 01:40:35 - INFO - __main__ - 
[Step 4800] ✅ Loss in normal range (1.0416)
01/23/2026 01:40:35 - INFO - __main__ -   Loss avg (last 100): 0.8034
01/23/2026 01:40:35 - INFO - __main__ -   Loss range: [0.3580, 1.1707]
01/23/2026 01:40:35 - INFO - __main__ - 
🔍 Running validation at step 4800...
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4800 (parquet mode)...
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 4800...
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/23/2026 01:40:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.20it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.45it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.46it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/23/2026 01:41:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/23/2026 01:41:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.43it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/23/2026 01:41:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/23/2026 01:41:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.40it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.40it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.40it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.40it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.40it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.40it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.40it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.40it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.40it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 01:41:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/23/2026 01:41:40 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 01:42:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/23/2026 01:42:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/23/2026 01:42:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/23/2026 01:42:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 01:42:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/23/2026 01:42:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 01:43:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/23/2026 01:43:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:05<00:16,  1.27it/s][A
 29%|██▊       | 8/28 [00:05<00:15,  1.30it/s][A
 32%|███▏      | 9/28 [00:06<00:14,  1.33it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.34it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.35it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.36it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.36it/s][A
 50%|█████     | 14/28 [00:10<00:10,  1.37it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.37it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:13<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.37it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:18<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.38it/s]
01/23/2026 01:43:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/23/2026 01:43:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.08it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.37it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 01:43:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/23/2026 01:43:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 01:44:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/23/2026 01:44:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.48it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.43it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/23/2026 01:44:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/23/2026 01:44:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/23/2026 01:44:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800/step004800_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/23/2026 01:44:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/23/2026 01:44:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/23/2026 01:44:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_004800
01/23/2026 01:44:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 4800] Training Debug Info:
  Loss: 1.058814
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0291, std: 0.9219
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0310, std: 1.3594
  Model pred mean: -0.0289, std: 0.8906
  Sigmas: [0.2392578125]... (timesteps: [239.0])

[Step 4800] Training Debug Info:
  Loss: 0.488416
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0140, std: 0.8750
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0123, std: 1.3281
  Model pred mean: -0.0112, std: 1.1250
  Sigmas: [0.671875]... (timesteps: [673.0])

[Step 4800] Training Debug Info:
  Loss: 0.422501
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0845, std: 0.9531
  Noise mean: 0.0042, std: 1.0000
  Target mean: -0.0801, std: 1.3828
  Model pred mean: -0.0786, std: 1.2188
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 4800] Training Debug Info:
  Loss: 0.712982
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0128, std: 0.9141
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0126, std: 1.3516
  Model pred mean: -0.0117, std: 1.0625
  Sigmas: [0.50390625]... (timesteps: [504.0])
Steps:  96%|█████████▌| 4801/5000 [17:59:23<5:01:06, 90.79s/it, loss=1.0416, lr=4.87e-08]Steps:  96%|█████████▌| 4801/5000 [17:59:23<5:01:06, 90.79s/it, loss=0.7130, lr=4.82e-08]Steps:  96%|█████████▌| 4802/5000 [17:59:34<3:41:29, 67.12s/it, loss=0.7130, lr=4.82e-08]Steps:  96%|█████████▌| 4802/5000 [17:59:34<3:41:29, 67.12s/it, loss=1.1080, lr=4.77e-08]Steps:  96%|█████████▌| 4803/5000 [17:59:47<2:46:14, 50.63s/it, loss=1.1080, lr=4.77e-08]Steps:  96%|█████████▌| 4803/5000 [17:59:47<2:46:14, 50.63s/it, loss=0.5638, lr=4.72e-08]Steps:  96%|█████████▌| 4804/5000 [17:59:59<2:07:30, 39.03s/it, loss=0.5638, lr=4.72e-08]Steps:  96%|█████████▌| 4804/5000 [17:59:59<2:07:30, 39.03s/it, loss=1.0819, lr=4.67e-08]Steps:  96%|█████████▌| 4805/5000 [18:00:11<1:40:25, 30.90s/it, loss=1.0819, lr=4.67e-08]Steps:  96%|█████████▌| 4805/5000 [18:00:11<1:40:25, 30.90s/it, loss=0.7097, lr=4.63e-08]Steps:  96%|█████████▌| 4806/5000 [18:00:22<1:21:31, 25.21s/it, loss=0.7097, lr=4.63e-08]Steps:  96%|█████████▌| 4806/5000 [18:00:22<1:21:31, 25.21s/it, loss=1.0683, lr=4.58e-08]Steps:  96%|█████████▌| 4807/5000 [18:00:34<1:08:17, 21.23s/it, loss=1.0683, lr=4.58e-08]Steps:  96%|█████████▌| 4807/5000 [18:00:34<1:08:17, 21.23s/it, loss=1.1724, lr=4.53e-08]Steps:  96%|█████████▌| 4808/5000 [18:00:46<59:00, 18.44s/it, loss=1.1724, lr=4.53e-08]  Steps:  96%|█████████▌| 4808/5000 [18:00:46<59:00, 18.44s/it, loss=0.4231, lr=4.49e-08]Steps:  96%|█████████▌| 4809/5000 [18:00:58<52:26, 16.48s/it, loss=0.4231, lr=4.49e-08]Steps:  96%|█████████▌| 4809/5000 [18:00:58<52:26, 16.48s/it, loss=0.4706, lr=4.44e-08]Steps:  96%|█████████▌| 4810/5000 [18:01:11<48:10, 15.21s/it, loss=0.4706, lr=4.44e-08]Steps:  96%|█████████▌| 4810/5000 [18:01:11<48:10, 15.21s/it, loss=0.7188, lr=4.39e-08]
[Step 4810] Training Debug Info:
  Loss: 1.145735
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0088, std: 0.8828
  Noise mean: 0.0038, std: 1.0000
  Target mean: -0.0050, std: 1.3359
  Model pred mean: -0.0082, std: 0.7930
  Sigmas: [0.248046875]... (timesteps: [248.0])

[Step 4810] Training Debug Info:
  Loss: 1.059985
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0135, std: 0.8789
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0137, std: 1.3359
  Model pred mean: -0.0140, std: 0.8398
  Sigmas: [0.031982421875]... (timesteps: [32.0])

[Step 4810] Training Debug Info:
  Loss: 1.173524
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0001, std: 0.8828
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0013, std: 1.3359
  Model pred mean: 0.0006, std: 0.7812
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 4810] Training Debug Info:
  Loss: 0.362285
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0131, std: 0.8438
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0145, std: 1.3125
  Model pred mean: 0.0098, std: 1.1641
  Sigmas: [0.91015625]... (timesteps: [911.0])
Steps:  96%|█████████▌| 4811/5000 [18:01:22<44:47, 14.22s/it, loss=0.7188, lr=4.39e-08]Steps:  96%|█████████▌| 4811/5000 [18:01:22<44:47, 14.22s/it, loss=0.3623, lr=4.35e-08]Steps:  96%|█████████▌| 4812/5000 [18:01:34<42:19, 13.51s/it, loss=0.3623, lr=4.35e-08]Steps:  96%|█████████▌| 4812/5000 [18:01:34<42:19, 13.51s/it, loss=0.8520, lr=4.30e-08]Steps:  96%|█████████▋| 4813/5000 [18:01:46<40:37, 13.03s/it, loss=0.8520, lr=4.30e-08]Steps:  96%|█████████▋| 4813/5000 [18:01:46<40:37, 13.03s/it, loss=1.2223, lr=4.25e-08]Steps:  96%|█████████▋| 4814/5000 [18:01:58<39:22, 12.70s/it, loss=1.2223, lr=4.25e-08]Steps:  96%|█████████▋| 4814/5000 [18:01:58<39:22, 12.70s/it, loss=1.1449, lr=4.21e-08]Steps:  96%|█████████▋| 4815/5000 [18:02:10<38:28, 12.48s/it, loss=1.1449, lr=4.21e-08]Steps:  96%|█████████▋| 4815/5000 [18:02:10<38:28, 12.48s/it, loss=0.4019, lr=4.16e-08]Steps:  96%|█████████▋| 4816/5000 [18:02:22<37:46, 12.32s/it, loss=0.4019, lr=4.16e-08]Steps:  96%|█████████▋| 4816/5000 [18:02:22<37:46, 12.32s/it, loss=1.1305, lr=4.12e-08]Steps:  96%|█████████▋| 4817/5000 [18:02:34<37:26, 12.28s/it, loss=1.1305, lr=4.12e-08]Steps:  96%|█████████▋| 4817/5000 [18:02:34<37:26, 12.28s/it, loss=0.5718, lr=4.07e-08]Steps:  96%|█████████▋| 4818/5000 [18:02:46<36:53, 12.16s/it, loss=0.5718, lr=4.07e-08]Steps:  96%|█████████▋| 4818/5000 [18:02:46<36:53, 12.16s/it, loss=0.5204, lr=4.03e-08]Steps:  96%|█████████▋| 4819/5000 [18:02:58<36:31, 12.11s/it, loss=0.5204, lr=4.03e-08]Steps:  96%|█████████▋| 4819/5000 [18:02:58<36:31, 12.11s/it, loss=1.0494, lr=3.99e-08]Steps:  96%|█████████▋| 4820/5000 [18:03:10<36:08, 12.05s/it, loss=1.0494, lr=3.99e-08]Steps:  96%|█████████▋| 4820/5000 [18:03:10<36:08, 12.05s/it, loss=1.0215, lr=3.94e-08]
[Step 4820] Training Debug Info:
  Loss: 0.505415
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: -0.0190, std: 0.9453
  Noise mean: -0.0035, std: 1.0000
  Target mean: 0.0156, std: 1.3750
  Model pred mean: 0.0233, std: 1.1797
  Sigmas: [0.65625]... (timesteps: [655.0])

[Step 4820] Training Debug Info:
  Loss: 1.088924
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0092, std: 0.9375
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0088, std: 1.3672
  Model pred mean: 0.0102, std: 0.8867
  Sigmas: [0.0732421875]... (timesteps: [73.0])

[Step 4820] Training Debug Info:
  Loss: 1.186541
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0117, std: 0.8867
  Noise mean: 0.0041, std: 1.0000
  Target mean: -0.0076, std: 1.3359
  Model pred mean: -0.0128, std: 0.7734
  Sigmas: [0.1669921875]... (timesteps: [167.0])

[Step 4820] Training Debug Info:
  Loss: 0.550307
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0146, std: 0.8828
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0129, std: 1.3359
  Model pred mean: -0.0062, std: 1.1094
  Sigmas: [0.9921875]... (timesteps: [991.0])
Steps:  96%|█████████▋| 4821/5000 [18:03:22<35:51, 12.02s/it, loss=1.0215, lr=3.94e-08]Steps:  96%|█████████▋| 4821/5000 [18:03:22<35:51, 12.02s/it, loss=0.5503, lr=3.90e-08]Steps:  96%|█████████▋| 4822/5000 [18:03:34<35:36, 12.00s/it, loss=0.5503, lr=3.90e-08]Steps:  96%|█████████▋| 4822/5000 [18:03:34<35:36, 12.00s/it, loss=0.8728, lr=3.86e-08]Steps:  96%|█████████▋| 4823/5000 [18:03:46<35:31, 12.04s/it, loss=0.8728, lr=3.86e-08]Steps:  96%|█████████▋| 4823/5000 [18:03:46<35:31, 12.04s/it, loss=1.0513, lr=3.81e-08]Steps:  96%|█████████▋| 4824/5000 [18:03:58<35:12, 12.00s/it, loss=1.0513, lr=3.81e-08]Steps:  96%|█████████▋| 4824/5000 [18:03:58<35:12, 12.00s/it, loss=0.3803, lr=3.77e-08]Steps:  96%|█████████▋| 4825/5000 [18:04:10<34:55, 11.98s/it, loss=0.3803, lr=3.77e-08]Steps:  96%|█████████▋| 4825/5000 [18:04:10<34:55, 11.98s/it, loss=0.5182, lr=3.73e-08]Steps:  97%|█████████▋| 4826/5000 [18:04:22<34:40, 11.95s/it, loss=0.5182, lr=3.73e-08]Steps:  97%|█████████▋| 4826/5000 [18:04:22<34:40, 11.95s/it, loss=1.0481, lr=3.68e-08]Steps:  97%|█████████▋| 4827/5000 [18:04:34<34:23, 11.93s/it, loss=1.0481, lr=3.68e-08]Steps:  97%|█████████▋| 4827/5000 [18:04:34<34:23, 11.93s/it, loss=0.9415, lr=3.64e-08]Steps:  97%|█████████▋| 4828/5000 [18:04:46<34:09, 11.92s/it, loss=0.9415, lr=3.64e-08]Steps:  97%|█████████▋| 4828/5000 [18:04:46<34:09, 11.92s/it, loss=1.1579, lr=3.60e-08]Steps:  97%|█████████▋| 4829/5000 [18:04:57<33:57, 11.92s/it, loss=1.1579, lr=3.60e-08]Steps:  97%|█████████▋| 4829/5000 [18:04:57<33:57, 11.92s/it, loss=0.3816, lr=3.56e-08]Steps:  97%|█████████▋| 4830/5000 [18:05:10<33:58, 11.99s/it, loss=0.3816, lr=3.56e-08]Steps:  97%|█████████▋| 4830/5000 [18:05:10<33:58, 11.99s/it, loss=1.1675, lr=3.52e-08]
[Step 4830] Training Debug Info:
  Loss: 0.376223
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0025, std: 0.8984
  Noise mean: 0.0052, std: 1.0000
  Target mean: 0.0077, std: 1.3438
  Model pred mean: 0.0074, std: 1.1953
  Sigmas: [0.7890625]... (timesteps: [788.0])

[Step 4830] Training Debug Info:
  Loss: 1.080965
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0138, std: 0.9258
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0143, std: 1.3594
  Model pred mean: 0.0138, std: 0.8789
  Sigmas: [0.054931640625]... (timesteps: [55.0])

[Step 4830] Training Debug Info:
  Loss: 0.713019
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0064, std: 0.9492
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0051, std: 1.3750
  Model pred mean: 0.0081, std: 1.1016
  Sigmas: [0.953125]... (timesteps: [952.0])

[Step 4830] Training Debug Info:
  Loss: 0.861853
  Latent shape: torch.Size([1, 32, 126, 72]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0415, std: 0.9531
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0422, std: 1.3828
  Model pred mean: -0.0403, std: 1.0234
  Sigmas: [0.3359375]... (timesteps: [336.0])
Steps:  97%|█████████▋| 4831/5000 [18:05:22<33:47, 12.00s/it, loss=1.1675, lr=3.52e-08]Steps:  97%|█████████▋| 4831/5000 [18:05:22<33:47, 12.00s/it, loss=0.8619, lr=3.48e-08]Steps:  97%|█████████▋| 4832/5000 [18:05:34<33:32, 11.98s/it, loss=0.8619, lr=3.48e-08]Steps:  97%|█████████▋| 4832/5000 [18:05:34<33:32, 11.98s/it, loss=0.5492, lr=3.44e-08]Steps:  97%|█████████▋| 4833/5000 [18:05:45<33:17, 11.96s/it, loss=0.5492, lr=3.44e-08]Steps:  97%|█████████▋| 4833/5000 [18:05:45<33:17, 11.96s/it, loss=0.3996, lr=3.39e-08]Steps:  97%|█████████▋| 4834/5000 [18:05:57<33:07, 11.97s/it, loss=0.3996, lr=3.39e-08]Steps:  97%|█████████▋| 4834/5000 [18:05:57<33:07, 11.97s/it, loss=1.1453, lr=3.35e-08]Steps:  97%|█████████▋| 4835/5000 [18:06:09<32:56, 11.98s/it, loss=1.1453, lr=3.35e-08]Steps:  97%|█████████▋| 4835/5000 [18:06:09<32:56, 11.98s/it, loss=0.7269, lr=3.31e-08]Steps:  97%|█████████▋| 4836/5000 [18:06:21<32:43, 11.97s/it, loss=0.7269, lr=3.31e-08]Steps:  97%|█████████▋| 4836/5000 [18:06:21<32:43, 11.97s/it, loss=0.9393, lr=3.27e-08]Steps:  97%|█████████▋| 4837/5000 [18:06:34<32:38, 12.02s/it, loss=0.9393, lr=3.27e-08]Steps:  97%|█████████▋| 4837/5000 [18:06:34<32:38, 12.02s/it, loss=0.5436, lr=3.23e-08]Steps:  97%|█████████▋| 4838/5000 [18:06:45<32:20, 11.98s/it, loss=0.5436, lr=3.23e-08]Steps:  97%|█████████▋| 4838/5000 [18:06:45<32:20, 11.98s/it, loss=0.5036, lr=3.19e-08]Steps:  97%|█████████▋| 4839/5000 [18:06:57<32:09, 11.99s/it, loss=0.5036, lr=3.19e-08]Steps:  97%|█████████▋| 4839/5000 [18:06:57<32:09, 11.99s/it, loss=0.5758, lr=3.16e-08]Steps:  97%|█████████▋| 4840/5000 [18:07:09<31:53, 11.96s/it, loss=0.5758, lr=3.16e-08]Steps:  97%|█████████▋| 4840/5000 [18:07:09<31:53, 11.96s/it, loss=0.3290, lr=3.12e-08]
[Step 4840] Training Debug Info:
  Loss: 0.494645
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0243, std: 0.9141
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0236, std: 1.3594
  Model pred mean: -0.0253, std: 1.1562
  Sigmas: [0.8671875]... (timesteps: [866.0])

[Step 4840] Training Debug Info:
  Loss: 0.431157
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0173, std: 0.8828
  Noise mean: 0.0041, std: 0.9961
  Target mean: -0.0132, std: 1.3359
  Model pred mean: -0.0112, std: 1.1641
  Sigmas: [0.90234375]... (timesteps: [904.0])

[Step 4840] Training Debug Info:
  Loss: 1.077832
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0033, std: 0.9414
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0035, std: 1.3750
  Model pred mean: 0.0035, std: 0.8984
  Sigmas: [0.11376953125]... (timesteps: [114.0])

[Step 4840] Training Debug Info:
  Loss: 0.432650
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0332, std: 0.8984
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0320, std: 1.3516
  Model pred mean: -0.0309, std: 1.1719
  Sigmas: [0.71484375]... (timesteps: [716.0])
Steps:  97%|█████████▋| 4841/5000 [18:07:21<31:39, 11.94s/it, loss=0.3290, lr=3.12e-08]Steps:  97%|█████████▋| 4841/5000 [18:07:21<31:39, 11.94s/it, loss=0.4326, lr=3.08e-08]Steps:  97%|█████████▋| 4842/5000 [18:07:33<31:28, 11.95s/it, loss=0.4326, lr=3.08e-08]Steps:  97%|█████████▋| 4842/5000 [18:07:33<31:28, 11.95s/it, loss=0.5317, lr=3.04e-08]Steps:  97%|█████████▋| 4843/5000 [18:07:45<31:16, 11.95s/it, loss=0.5317, lr=3.04e-08]Steps:  97%|█████████▋| 4843/5000 [18:07:45<31:16, 11.95s/it, loss=1.0119, lr=3.00e-08]Steps:  97%|█████████▋| 4844/5000 [18:07:57<31:20, 12.06s/it, loss=1.0119, lr=3.00e-08]Steps:  97%|█████████▋| 4844/5000 [18:07:57<31:20, 12.06s/it, loss=0.4685, lr=2.96e-08]Steps:  97%|█████████▋| 4845/5000 [18:08:09<31:05, 12.03s/it, loss=0.4685, lr=2.96e-08]Steps:  97%|█████████▋| 4845/5000 [18:08:09<31:05, 12.03s/it, loss=1.1059, lr=2.92e-08]Steps:  97%|█████████▋| 4846/5000 [18:08:21<30:44, 11.98s/it, loss=1.1059, lr=2.92e-08]Steps:  97%|█████████▋| 4846/5000 [18:08:21<30:44, 11.98s/it, loss=0.5700, lr=2.89e-08]Steps:  97%|█████████▋| 4847/5000 [18:08:33<30:32, 11.98s/it, loss=0.5700, lr=2.89e-08]Steps:  97%|█████████▋| 4847/5000 [18:08:33<30:32, 11.98s/it, loss=0.7551, lr=2.85e-08]Steps:  97%|█████████▋| 4848/5000 [18:08:45<30:17, 11.95s/it, loss=0.7551, lr=2.85e-08]Steps:  97%|█████████▋| 4848/5000 [18:08:45<30:17, 11.95s/it, loss=0.5223, lr=2.81e-08]Steps:  97%|█████████▋| 4849/5000 [18:08:57<30:05, 11.95s/it, loss=0.5223, lr=2.81e-08]Steps:  97%|█████████▋| 4849/5000 [18:08:57<30:05, 11.95s/it, loss=1.1206, lr=2.78e-08]Steps:  97%|█████████▋| 4850/5000 [18:09:09<30:03, 12.02s/it, loss=1.1206, lr=2.78e-08]Steps:  97%|█████████▋| 4850/5000 [18:09:09<30:03, 12.02s/it, loss=0.9344, lr=2.74e-08]
[Step 4850] Training Debug Info:
  Loss: 0.395027
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0435, std: 0.8867
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0442, std: 1.3359
  Model pred mean: 0.0405, std: 1.1797
  Sigmas: [0.796875]... (timesteps: [798.0])

[Step 4850] Training Debug Info:
  Loss: 0.584593
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0170, std: 0.9062
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0189, std: 1.3516
  Model pred mean: -0.0175, std: 1.0938
  Sigmas: [0.99609375]... (timesteps: [996.0])

[Step 4850] Training Debug Info:
  Loss: 1.211291
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0344, std: 0.8633
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0352, std: 1.3203
  Model pred mean: 0.0322, std: 0.7305
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 4850] Training Debug Info:
  Loss: 0.483182
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0052, std: 0.9453
  Noise mean: 0.0044, std: 1.0000
  Target mean: 0.0096, std: 1.3750
  Model pred mean: 0.0103, std: 1.1875
  Sigmas: [0.625]... (timesteps: [626.0])
Steps:  97%|█████████▋| 4851/5000 [18:09:21<29:46, 11.99s/it, loss=0.9344, lr=2.74e-08]Steps:  97%|█████████▋| 4851/5000 [18:09:21<29:46, 11.99s/it, loss=0.4832, lr=2.70e-08]Steps:  97%|█████████▋| 4852/5000 [18:09:33<29:32, 11.98s/it, loss=0.4832, lr=2.70e-08]Steps:  97%|█████████▋| 4852/5000 [18:09:33<29:32, 11.98s/it, loss=0.4095, lr=2.67e-08]Steps:  97%|█████████▋| 4853/5000 [18:09:45<29:19, 11.97s/it, loss=0.4095, lr=2.67e-08]Steps:  97%|█████████▋| 4853/5000 [18:09:45<29:19, 11.97s/it, loss=0.6506, lr=2.63e-08]Steps:  97%|█████████▋| 4854/5000 [18:09:57<29:02, 11.93s/it, loss=0.6506, lr=2.63e-08]Steps:  97%|█████████▋| 4854/5000 [18:09:57<29:02, 11.93s/it, loss=0.5034, lr=2.60e-08]Steps:  97%|█████████▋| 4855/5000 [18:10:09<28:49, 11.93s/it, loss=0.5034, lr=2.60e-08]Steps:  97%|█████████▋| 4855/5000 [18:10:09<28:49, 11.93s/it, loss=1.0272, lr=2.56e-08]Steps:  97%|█████████▋| 4856/5000 [18:10:21<28:42, 11.96s/it, loss=1.0272, lr=2.56e-08]Steps:  97%|█████████▋| 4856/5000 [18:10:21<28:42, 11.96s/it, loss=0.8674, lr=2.52e-08]Steps:  97%|█████████▋| 4857/5000 [18:10:33<28:37, 12.01s/it, loss=0.8674, lr=2.52e-08]Steps:  97%|█████████▋| 4857/5000 [18:10:33<28:37, 12.01s/it, loss=0.5935, lr=2.49e-08]Steps:  97%|█████████▋| 4858/5000 [18:10:45<28:18, 11.96s/it, loss=0.5935, lr=2.49e-08]Steps:  97%|█████████▋| 4858/5000 [18:10:45<28:18, 11.96s/it, loss=1.1749, lr=2.45e-08]Steps:  97%|█████████▋| 4859/5000 [18:10:57<28:02, 11.93s/it, loss=1.1749, lr=2.45e-08]Steps:  97%|█████████▋| 4859/5000 [18:10:57<28:02, 11.93s/it, loss=0.6064, lr=2.42e-08]Steps:  97%|█████████▋| 4860/5000 [18:11:09<27:52, 11.94s/it, loss=0.6064, lr=2.42e-08]Steps:  97%|█████████▋| 4860/5000 [18:11:09<27:52, 11.94s/it, loss=1.1891, lr=2.39e-08]
[Step 4860] Training Debug Info:
  Loss: 1.048144
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0267, std: 0.9414
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0275, std: 1.3750
  Model pred mean: -0.0269, std: 0.9141
  Sigmas: [0.1943359375]... (timesteps: [194.0])

[Step 4860] Training Debug Info:
  Loss: 0.677012
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0159, std: 0.8867
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0173, std: 1.3359
  Model pred mean: 0.0171, std: 1.0547
  Sigmas: [0.55859375]... (timesteps: [559.0])

[Step 4860] Training Debug Info:
  Loss: 0.534252
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: 0.0260, std: 0.9062
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0292, std: 1.3516
  Model pred mean: -0.0221, std: 1.1328
  Sigmas: [0.6015625]... (timesteps: [601.0])

[Step 4860] Training Debug Info:
  Loss: 1.133350
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0159, std: 0.8828
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0134, std: 1.3359
  Model pred mean: 0.0168, std: 0.8047
  Sigmas: [0.27734375]... (timesteps: [278.0])
Steps:  97%|█████████▋| 4861/5000 [18:11:21<27:37, 11.92s/it, loss=1.1891, lr=2.39e-08]Steps:  97%|█████████▋| 4861/5000 [18:11:21<27:37, 11.92s/it, loss=1.1334, lr=2.35e-08]Steps:  97%|█████████▋| 4862/5000 [18:11:33<27:25, 11.92s/it, loss=1.1334, lr=2.35e-08]Steps:  97%|█████████▋| 4862/5000 [18:11:33<27:25, 11.92s/it, loss=0.3894, lr=2.32e-08]Steps:  97%|█████████▋| 4863/5000 [18:11:44<27:11, 11.91s/it, loss=0.3894, lr=2.32e-08]Steps:  97%|█████████▋| 4863/5000 [18:11:44<27:11, 11.91s/it, loss=0.4012, lr=2.29e-08]Steps:  97%|█████████▋| 4864/5000 [18:11:57<27:09, 11.98s/it, loss=0.4012, lr=2.29e-08]Steps:  97%|█████████▋| 4864/5000 [18:11:57<27:09, 11.98s/it, loss=0.3790, lr=2.25e-08]Steps:  97%|█████████▋| 4865/5000 [18:12:09<27:03, 12.02s/it, loss=0.3790, lr=2.25e-08]Steps:  97%|█████████▋| 4865/5000 [18:12:09<27:03, 12.02s/it, loss=0.7245, lr=2.22e-08]Steps:  97%|█████████▋| 4866/5000 [18:12:21<26:49, 12.01s/it, loss=0.7245, lr=2.22e-08]Steps:  97%|█████████▋| 4866/5000 [18:12:21<26:49, 12.01s/it, loss=1.0836, lr=2.19e-08]Steps:  97%|█████████▋| 4867/5000 [18:12:33<26:36, 12.00s/it, loss=1.0836, lr=2.19e-08]Steps:  97%|█████████▋| 4867/5000 [18:12:33<26:36, 12.00s/it, loss=0.5237, lr=2.15e-08]Steps:  97%|█████████▋| 4868/5000 [18:12:45<26:20, 11.97s/it, loss=0.5237, lr=2.15e-08]Steps:  97%|█████████▋| 4868/5000 [18:12:45<26:20, 11.97s/it, loss=0.3887, lr=2.12e-08]Steps:  97%|█████████▋| 4869/5000 [18:12:56<26:04, 11.94s/it, loss=0.3887, lr=2.12e-08]Steps:  97%|█████████▋| 4869/5000 [18:12:56<26:04, 11.94s/it, loss=1.0199, lr=2.09e-08]Steps:  97%|█████████▋| 4870/5000 [18:13:08<25:51, 11.93s/it, loss=1.0199, lr=2.09e-08]Steps:  97%|█████████▋| 4870/5000 [18:13:08<25:51, 11.93s/it, loss=0.3313, lr=2.06e-08]
[Step 4870] Training Debug Info:
  Loss: 0.351683
  Latent shape: torch.Size([1, 32, 108, 78]), Packed shape: torch.Size([1, 2106, 128])
  Latent mean: -0.0264, std: 0.8633
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0260, std: 1.3203
  Model pred mean: 0.0126, std: 1.1797
  Sigmas: [0.91796875]... (timesteps: [917.0])

[Step 4870] Training Debug Info:
  Loss: 0.755407
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0171, std: 0.9453
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0184, std: 1.3750
  Model pred mean: -0.0192, std: 1.0625
  Sigmas: [0.474609375]... (timesteps: [475.0])

[Step 4870] Training Debug Info:
  Loss: 0.333789
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0097, std: 0.9062
  Noise mean: -0.0019, std: 1.0000
  Target mean: 0.0078, std: 1.3516
  Model pred mean: 0.0056, std: 1.2266
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 4870] Training Debug Info:
  Loss: 1.087027
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0187, std: 0.9180
  Noise mean: -0.0040, std: 1.0000
  Target mean: 0.0146, std: 1.3594
  Model pred mean: 0.0183, std: 0.8672
  Sigmas: [0.053955078125]... (timesteps: [54.0])
Steps:  97%|█████████▋| 4871/5000 [18:13:20<25:48, 12.00s/it, loss=0.3313, lr=2.06e-08]Steps:  97%|█████████▋| 4871/5000 [18:13:20<25:48, 12.00s/it, loss=1.0870, lr=2.03e-08]Steps:  97%|█████████▋| 4872/5000 [18:13:32<25:31, 11.96s/it, loss=1.0870, lr=2.03e-08]Steps:  97%|█████████▋| 4872/5000 [18:13:32<25:31, 11.96s/it, loss=0.5045, lr=2.00e-08]Steps:  97%|█████████▋| 4873/5000 [18:13:44<25:19, 11.97s/it, loss=0.5045, lr=2.00e-08]Steps:  97%|█████████▋| 4873/5000 [18:13:44<25:19, 11.97s/it, loss=0.6007, lr=1.96e-08]Steps:  97%|█████████▋| 4874/5000 [18:13:57<25:15, 12.03s/it, loss=0.6007, lr=1.96e-08]Steps:  97%|█████████▋| 4874/5000 [18:13:57<25:15, 12.03s/it, loss=0.4947, lr=1.93e-08]Steps:  98%|█████████▊| 4875/5000 [18:14:08<25:00, 12.01s/it, loss=0.4947, lr=1.93e-08]Steps:  98%|█████████▊| 4875/5000 [18:14:08<25:00, 12.01s/it, loss=0.5803, lr=1.90e-08]Steps:  98%|█████████▊| 4876/5000 [18:14:20<24:47, 11.99s/it, loss=0.5803, lr=1.90e-08]Steps:  98%|█████████▊| 4876/5000 [18:14:20<24:47, 11.99s/it, loss=0.4105, lr=1.87e-08]Steps:  98%|█████████▊| 4877/5000 [18:14:33<24:43, 12.06s/it, loss=0.4105, lr=1.87e-08]Steps:  98%|█████████▊| 4877/5000 [18:14:33<24:43, 12.06s/it, loss=0.5244, lr=1.84e-08]Steps:  98%|█████████▊| 4878/5000 [18:14:45<24:26, 12.02s/it, loss=0.5244, lr=1.84e-08]Steps:  98%|█████████▊| 4878/5000 [18:14:45<24:26, 12.02s/it, loss=1.1100, lr=1.81e-08]Steps:  98%|█████████▊| 4879/5000 [18:14:57<24:14, 12.02s/it, loss=1.1100, lr=1.81e-08]Steps:  98%|█████████▊| 4879/5000 [18:14:57<24:14, 12.02s/it, loss=0.6208, lr=1.78e-08]Steps:  98%|█████████▊| 4880/5000 [18:15:09<24:02, 12.02s/it, loss=0.6208, lr=1.78e-08]Steps:  98%|█████████▊| 4880/5000 [18:15:09<24:02, 12.02s/it, loss=1.1653, lr=1.75e-08]
[Step 4880] Training Debug Info:
  Loss: 0.684382
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: 0.0547, std: 0.9297
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0542, std: 1.3672
  Model pred mean: -0.0530, std: 1.0859
  Sigmas: [0.462890625]... (timesteps: [462.0])

[Step 4880] Training Debug Info:
  Loss: 0.386616
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0074, std: 0.8750
  Noise mean: -0.0012, std: 0.9961
  Target mean: 0.0062, std: 1.3281
  Model pred mean: 0.0057, std: 1.1719
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 4880] Training Debug Info:
  Loss: 0.791063
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0021, std: 0.9023
  Noise mean: 0.0027, std: 0.9961
  Target mean: 0.0006, std: 1.3438
  Model pred mean: -0.0030, std: 1.0156
  Sigmas: [0.4453125]... (timesteps: [446.0])

[Step 4880] Training Debug Info:
  Loss: 0.524424
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0153, std: 0.9492
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0151, std: 1.3828
  Model pred mean: -0.0143, std: 1.1719
  Sigmas: [0.53125]... (timesteps: [531.0])
Steps:  98%|█████████▊| 4881/5000 [18:15:21<23:46, 11.98s/it, loss=1.1653, lr=1.75e-08]Steps:  98%|█████████▊| 4881/5000 [18:15:21<23:46, 11.98s/it, loss=0.5244, lr=1.72e-08]Steps:  98%|█████████▊| 4882/5000 [18:15:32<23:31, 11.96s/it, loss=0.5244, lr=1.72e-08]Steps:  98%|█████████▊| 4882/5000 [18:15:32<23:31, 11.96s/it, loss=0.6982, lr=1.70e-08]Steps:  98%|█████████▊| 4883/5000 [18:15:45<23:27, 12.03s/it, loss=0.6982, lr=1.70e-08]Steps:  98%|█████████▊| 4883/5000 [18:15:45<23:27, 12.03s/it, loss=0.5386, lr=1.67e-08]Steps:  98%|█████████▊| 4884/5000 [18:15:57<23:20, 12.08s/it, loss=0.5386, lr=1.67e-08]Steps:  98%|█████████▊| 4884/5000 [18:15:57<23:20, 12.08s/it, loss=0.4609, lr=1.64e-08]Steps:  98%|█████████▊| 4885/5000 [18:16:09<23:04, 12.04s/it, loss=0.4609, lr=1.64e-08]Steps:  98%|█████████▊| 4885/5000 [18:16:09<23:04, 12.04s/it, loss=0.6598, lr=1.61e-08]Steps:  98%|█████████▊| 4886/5000 [18:16:21<22:49, 12.01s/it, loss=0.6598, lr=1.61e-08]Steps:  98%|█████████▊| 4886/5000 [18:16:21<22:49, 12.01s/it, loss=0.5855, lr=1.58e-08]Steps:  98%|█████████▊| 4887/5000 [18:16:33<22:34, 11.99s/it, loss=0.5855, lr=1.58e-08]Steps:  98%|█████████▊| 4887/5000 [18:16:33<22:34, 11.99s/it, loss=1.0486, lr=1.56e-08]Steps:  98%|█████████▊| 4888/5000 [18:16:44<22:17, 11.94s/it, loss=1.0486, lr=1.56e-08]Steps:  98%|█████████▊| 4888/5000 [18:16:44<22:17, 11.94s/it, loss=1.1163, lr=1.53e-08]Steps:  98%|█████████▊| 4889/5000 [18:16:56<22:04, 11.93s/it, loss=1.1163, lr=1.53e-08]Steps:  98%|█████████▊| 4889/5000 [18:16:56<22:04, 11.93s/it, loss=0.4460, lr=1.50e-08]Steps:  98%|█████████▊| 4890/5000 [18:17:08<21:50, 11.91s/it, loss=0.4460, lr=1.50e-08]Steps:  98%|█████████▊| 4890/5000 [18:17:08<21:50, 11.91s/it, loss=0.8145, lr=1.47e-08]
[Step 4890] Training Debug Info:
  Loss: 0.415626
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0025, std: 0.8750
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0041, std: 1.3281
  Model pred mean: -0.0028, std: 1.1641
  Sigmas: [0.9140625]... (timesteps: [916.0])

[Step 4890] Training Debug Info:
  Loss: 0.708319
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0024, std: 0.9180
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0038, std: 1.3594
  Model pred mean: -0.0047, std: 1.0625
  Sigmas: [0.498046875]... (timesteps: [498.0])

[Step 4890] Training Debug Info:
  Loss: 0.396472
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0029, std: 0.9258
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0049, std: 1.3672
  Model pred mean: -0.0005, std: 1.2109
  Sigmas: [0.90234375]... (timesteps: [901.0])

[Step 4890] Training Debug Info:
  Loss: 0.428801
  Latent shape: torch.Size([1, 32, 144, 60]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0215, std: 0.9297
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0212, std: 1.3672
  Model pred mean: -0.0188, std: 1.1953
  Sigmas: [0.625]... (timesteps: [626.0])
Steps:  98%|█████████▊| 4891/5000 [18:17:20<21:45, 11.98s/it, loss=0.8145, lr=1.47e-08]Steps:  98%|█████████▊| 4891/5000 [18:17:20<21:45, 11.98s/it, loss=0.4288, lr=1.45e-08]Steps:  98%|█████████▊| 4892/5000 [18:17:32<21:34, 11.99s/it, loss=0.4288, lr=1.45e-08]Steps:  98%|█████████▊| 4892/5000 [18:17:32<21:34, 11.99s/it, loss=0.6969, lr=1.42e-08]Steps:  98%|█████████▊| 4893/5000 [18:17:44<21:21, 11.98s/it, loss=0.6969, lr=1.42e-08]Steps:  98%|█████████▊| 4893/5000 [18:17:44<21:21, 11.98s/it, loss=0.6138, lr=1.39e-08]Steps:  98%|█████████▊| 4894/5000 [18:17:56<21:07, 11.96s/it, loss=0.6138, lr=1.39e-08]Steps:  98%|█████████▊| 4894/5000 [18:17:56<21:07, 11.96s/it, loss=0.4044, lr=1.37e-08]Steps:  98%|█████████▊| 4895/5000 [18:18:08<20:55, 11.96s/it, loss=0.4044, lr=1.37e-08]Steps:  98%|█████████▊| 4895/5000 [18:18:08<20:55, 11.96s/it, loss=0.9013, lr=1.34e-08]Steps:  98%|█████████▊| 4896/5000 [18:18:20<20:43, 11.96s/it, loss=0.9013, lr=1.34e-08]Steps:  98%|█████████▊| 4896/5000 [18:18:20<20:43, 11.96s/it, loss=1.0837, lr=1.32e-08]Steps:  98%|█████████▊| 4897/5000 [18:18:32<20:31, 11.96s/it, loss=1.0837, lr=1.32e-08]Steps:  98%|█████████▊| 4897/5000 [18:18:32<20:31, 11.96s/it, loss=0.6825, lr=1.29e-08]Steps:  98%|█████████▊| 4898/5000 [18:18:44<20:26, 12.02s/it, loss=0.6825, lr=1.29e-08]Steps:  98%|█████████▊| 4898/5000 [18:18:44<20:26, 12.02s/it, loss=1.1711, lr=1.27e-08]Steps:  98%|█████████▊| 4899/5000 [18:18:56<20:12, 12.00s/it, loss=1.1711, lr=1.27e-08]Steps:  98%|█████████▊| 4899/5000 [18:18:56<20:12, 12.00s/it, loss=0.9006, lr=1.24e-08]Steps:  98%|█████████▊| 4900/5000 [18:19:08<19:56, 11.96s/it, loss=0.9006, lr=1.24e-08]Steps:  98%|█████████▊| 4900/5000 [18:19:08<19:56, 11.96s/it, loss=0.9034, lr=1.22e-08]01/23/2026 02:04:55 - INFO - __main__ - 
[Step 4900] ✅ Loss in normal range (0.9034)
01/23/2026 02:04:55 - INFO - __main__ -   Loss avg (last 100): 0.7406
01/23/2026 02:04:55 - INFO - __main__ -   Loss range: [0.3290, 1.2223]

[Step 4900] Training Debug Info:
  Loss: 0.614559
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0410, std: 0.9688
  Noise mean: -0.0045, std: 1.0000
  Target mean: -0.0457, std: 1.3906
  Model pred mean: -0.0432, std: 1.1484
  Sigmas: [0.50390625]... (timesteps: [505.0])

[Step 4900] Training Debug Info:
  Loss: 0.482005
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0082, std: 0.9727
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0112, std: 1.3906
  Model pred mean: -0.0116, std: 1.2109
  Sigmas: [0.60546875]... (timesteps: [604.0])

[Step 4900] Training Debug Info:
  Loss: 0.653543
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0090, std: 0.9297
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0066, std: 1.3672
  Model pred mean: 0.0059, std: 1.0938
  Sigmas: [0.9921875]... (timesteps: [993.0])

[Step 4900] Training Debug Info:
  Loss: 0.375685
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: 0.0242, std: 0.8867
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0260, std: 1.3359
  Model pred mean: -0.0195, std: 1.1875
  Sigmas: [0.828125]... (timesteps: [830.0])
Steps:  98%|█████████▊| 4901/5000 [18:19:20<19:47, 12.00s/it, loss=0.9034, lr=1.22e-08]Steps:  98%|█████████▊| 4901/5000 [18:19:20<19:47, 12.00s/it, loss=0.3757, lr=1.19e-08]Steps:  98%|█████████▊| 4902/5000 [18:19:32<19:34, 11.98s/it, loss=0.3757, lr=1.19e-08]Steps:  98%|█████████▊| 4902/5000 [18:19:32<19:34, 11.98s/it, loss=0.6845, lr=1.17e-08]Steps:  98%|█████████▊| 4903/5000 [18:19:44<19:19, 11.95s/it, loss=0.6845, lr=1.17e-08]Steps:  98%|█████████▊| 4903/5000 [18:19:44<19:19, 11.95s/it, loss=0.6377, lr=1.15e-08]Steps:  98%|█████████▊| 4904/5000 [18:19:56<19:13, 12.02s/it, loss=0.6377, lr=1.15e-08]Steps:  98%|█████████▊| 4904/5000 [18:19:56<19:13, 12.02s/it, loss=0.6245, lr=1.12e-08]Steps:  98%|█████████▊| 4905/5000 [18:20:08<18:59, 11.99s/it, loss=0.6245, lr=1.12e-08]Steps:  98%|█████████▊| 4905/5000 [18:20:08<18:59, 11.99s/it, loss=0.3689, lr=1.10e-08]Steps:  98%|█████████▊| 4906/5000 [18:20:20<18:44, 11.97s/it, loss=0.3689, lr=1.10e-08]Steps:  98%|█████████▊| 4906/5000 [18:20:20<18:44, 11.97s/it, loss=0.4485, lr=1.08e-08]Steps:  98%|█████████▊| 4907/5000 [18:20:32<18:32, 11.96s/it, loss=0.4485, lr=1.08e-08]Steps:  98%|█████████▊| 4907/5000 [18:20:32<18:32, 11.96s/it, loss=1.1988, lr=1.05e-08]Steps:  98%|█████████▊| 4908/5000 [18:20:44<18:19, 11.95s/it, loss=1.1988, lr=1.05e-08]Steps:  98%|█████████▊| 4908/5000 [18:20:44<18:19, 11.95s/it, loss=0.6719, lr=1.03e-08]Steps:  98%|█████████▊| 4909/5000 [18:20:56<18:07, 11.95s/it, loss=0.6719, lr=1.03e-08]Steps:  98%|█████████▊| 4909/5000 [18:20:56<18:07, 11.95s/it, loss=0.6578, lr=1.01e-08]Steps:  98%|█████████▊| 4910/5000 [18:21:08<17:57, 11.97s/it, loss=0.6578, lr=1.01e-08]Steps:  98%|█████████▊| 4910/5000 [18:21:08<17:57, 11.97s/it, loss=1.0836, lr=9.87e-09]
[Step 4910] Training Debug Info:
  Loss: 1.092445
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0057, std: 0.8789
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0052, std: 1.3281
  Model pred mean: -0.0039, std: 0.8203
  Sigmas: [0.30078125]... (timesteps: [300.0])

[Step 4910] Training Debug Info:
  Loss: 0.861703
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0630, std: 1.0234
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0598, std: 1.4297
  Model pred mean: -0.0649, std: 1.0938
  Sigmas: [0.294921875]... (timesteps: [294.0])

[Step 4910] Training Debug Info:
  Loss: 1.094986
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0157, std: 0.9102
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0177, std: 1.3516
  Model pred mean: -0.0145, std: 0.8555
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 4910] Training Debug Info:
  Loss: 0.831722
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0262, std: 0.9336
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0273, std: 1.3672
  Model pred mean: -0.0266, std: 1.0234
  Sigmas: [0.421875]... (timesteps: [421.0])
Steps:  98%|█████████▊| 4911/5000 [18:21:20<17:50, 12.03s/it, loss=1.0836, lr=9.87e-09]Steps:  98%|█████████▊| 4911/5000 [18:21:20<17:50, 12.03s/it, loss=0.8317, lr=9.65e-09]Steps:  98%|█████████▊| 4912/5000 [18:21:32<17:37, 12.01s/it, loss=0.8317, lr=9.65e-09]Steps:  98%|█████████▊| 4912/5000 [18:21:32<17:37, 12.01s/it, loss=1.1894, lr=9.43e-09]Steps:  98%|█████████▊| 4913/5000 [18:21:44<17:23, 11.99s/it, loss=1.1894, lr=9.43e-09]Steps:  98%|█████████▊| 4913/5000 [18:21:44<17:23, 11.99s/it, loss=1.1088, lr=9.22e-09]Steps:  98%|█████████▊| 4914/5000 [18:21:56<17:06, 11.94s/it, loss=1.1088, lr=9.22e-09]Steps:  98%|█████████▊| 4914/5000 [18:21:56<17:06, 11.94s/it, loss=0.3949, lr=9.01e-09]Steps:  98%|█████████▊| 4915/5000 [18:22:08<16:52, 11.92s/it, loss=0.3949, lr=9.01e-09]Steps:  98%|█████████▊| 4915/5000 [18:22:08<16:52, 11.92s/it, loss=0.7422, lr=8.80e-09]Steps:  98%|█████████▊| 4916/5000 [18:22:20<16:40, 11.91s/it, loss=0.7422, lr=8.80e-09]Steps:  98%|█████████▊| 4916/5000 [18:22:20<16:40, 11.91s/it, loss=0.7280, lr=8.60e-09]Steps:  98%|█████████▊| 4917/5000 [18:22:31<16:28, 11.91s/it, loss=0.7280, lr=8.60e-09]Steps:  98%|█████████▊| 4917/5000 [18:22:31<16:28, 11.91s/it, loss=1.0711, lr=8.39e-09]Steps:  98%|█████████▊| 4918/5000 [18:22:44<16:20, 11.96s/it, loss=1.0711, lr=8.39e-09]Steps:  98%|█████████▊| 4918/5000 [18:22:44<16:20, 11.96s/it, loss=1.1230, lr=8.19e-09]Steps:  98%|█████████▊| 4919/5000 [18:22:56<16:10, 11.98s/it, loss=1.1230, lr=8.19e-09]Steps:  98%|█████████▊| 4919/5000 [18:22:56<16:10, 11.98s/it, loss=0.3715, lr=7.99e-09]Steps:  98%|█████████▊| 4920/5000 [18:23:08<15:57, 11.97s/it, loss=0.3715, lr=7.99e-09]Steps:  98%|█████████▊| 4920/5000 [18:23:08<15:57, 11.97s/it, loss=1.0214, lr=7.80e-09]
[Step 4920] Training Debug Info:
  Loss: 0.450819
  Latent shape: torch.Size([1, 32, 114, 78]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0349, std: 0.9141
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0371, std: 1.3516
  Model pred mean: -0.0344, std: 1.1797
  Sigmas: [0.7265625]... (timesteps: [726.0])

[Step 4920] Training Debug Info:
  Loss: 1.177786
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0077, std: 0.9609
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0082, std: 1.3906
  Model pred mean: 0.0078, std: 0.8672
  Sigmas: [0.2236328125]... (timesteps: [224.0])

[Step 4920] Training Debug Info:
  Loss: 1.041746
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0461, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0449, std: 1.3594
  Model pred mean: -0.0461, std: 0.8984
  Sigmas: [0.177734375]... (timesteps: [178.0])

[Step 4920] Training Debug Info:
  Loss: 0.421126
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0011, std: 0.8828
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0031, std: 1.3359
  Model pred mean: -0.0031, std: 1.1641
  Sigmas: [0.765625]... (timesteps: [766.0])
Steps:  98%|█████████▊| 4921/5000 [18:23:19<15:46, 11.98s/it, loss=1.0214, lr=7.80e-09]Steps:  98%|█████████▊| 4921/5000 [18:23:19<15:46, 11.98s/it, loss=0.4211, lr=7.60e-09]Steps:  98%|█████████▊| 4922/5000 [18:23:31<15:33, 11.97s/it, loss=0.4211, lr=7.60e-09]Steps:  98%|█████████▊| 4922/5000 [18:23:31<15:33, 11.97s/it, loss=1.0224, lr=7.41e-09]Steps:  98%|█████████▊| 4923/5000 [18:23:43<15:21, 11.97s/it, loss=1.0224, lr=7.41e-09]Steps:  98%|█████████▊| 4923/5000 [18:23:43<15:21, 11.97s/it, loss=0.6312, lr=7.22e-09]Steps:  98%|█████████▊| 4924/5000 [18:23:55<15:08, 11.95s/it, loss=0.6312, lr=7.22e-09]Steps:  98%|█████████▊| 4924/5000 [18:23:55<15:08, 11.95s/it, loss=0.4027, lr=7.04e-09]Steps:  98%|█████████▊| 4925/5000 [18:24:08<15:01, 12.03s/it, loss=0.4027, lr=7.04e-09]Steps:  98%|█████████▊| 4925/5000 [18:24:08<15:01, 12.03s/it, loss=0.4799, lr=6.85e-09]Steps:  99%|█████████▊| 4926/5000 [18:24:20<14:49, 12.01s/it, loss=0.4799, lr=6.85e-09]Steps:  99%|█████████▊| 4926/5000 [18:24:20<14:49, 12.01s/it, loss=0.9901, lr=6.67e-09]Steps:  99%|█████████▊| 4927/5000 [18:24:31<14:35, 11.99s/it, loss=0.9901, lr=6.67e-09]Steps:  99%|█████████▊| 4927/5000 [18:24:31<14:35, 11.99s/it, loss=0.8462, lr=6.49e-09]Steps:  99%|█████████▊| 4928/5000 [18:24:43<14:23, 12.00s/it, loss=0.8462, lr=6.49e-09]Steps:  99%|█████████▊| 4928/5000 [18:24:43<14:23, 12.00s/it, loss=0.4694, lr=6.32e-09]Steps:  99%|█████████▊| 4929/5000 [18:24:55<14:09, 11.97s/it, loss=0.4694, lr=6.32e-09]Steps:  99%|█████████▊| 4929/5000 [18:24:55<14:09, 11.97s/it, loss=0.7356, lr=6.14e-09]Steps:  99%|█████████▊| 4930/5000 [18:25:07<13:58, 11.98s/it, loss=0.7356, lr=6.14e-09]Steps:  99%|█████████▊| 4930/5000 [18:25:07<13:58, 11.98s/it, loss=0.4562, lr=5.97e-09]
[Step 4930] Training Debug Info:
  Loss: 1.127274
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0143, std: 0.8750
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0131, std: 1.3281
  Model pred mean: 0.0137, std: 0.8047
  Sigmas: [0.08203125]... (timesteps: [82.0])

[Step 4930] Training Debug Info:
  Loss: 0.517470
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0075, std: 0.8984
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0077, std: 1.3438
  Model pred mean: 0.0109, std: 1.1328
  Sigmas: [0.62890625]... (timesteps: [630.0])

[Step 4930] Training Debug Info:
  Loss: 0.450661
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0050, std: 0.9102
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0077, std: 1.3516
  Model pred mean: -0.0050, std: 1.1719
  Sigmas: [0.66015625]... (timesteps: [660.0])

[Step 4930] Training Debug Info:
  Loss: 0.676660
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0156, std: 0.8711
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0144, std: 1.3281
  Model pred mean: 0.0146, std: 1.0391
  Sigmas: [0.55078125]... (timesteps: [549.0])
Steps:  99%|█████████▊| 4931/5000 [18:25:19<13:49, 12.02s/it, loss=0.4562, lr=5.97e-09]Steps:  99%|█████████▊| 4931/5000 [18:25:19<13:49, 12.02s/it, loss=0.6767, lr=5.80e-09]Steps:  99%|█████████▊| 4932/5000 [18:25:31<13:35, 11.99s/it, loss=0.6767, lr=5.80e-09]Steps:  99%|█████████▊| 4932/5000 [18:25:31<13:35, 11.99s/it, loss=1.1449, lr=5.63e-09]Steps:  99%|█████████▊| 4933/5000 [18:25:43<13:22, 11.98s/it, loss=1.1449, lr=5.63e-09]Steps:  99%|█████████▊| 4933/5000 [18:25:43<13:22, 11.98s/it, loss=1.1742, lr=5.47e-09]Steps:  99%|█████████▊| 4934/5000 [18:25:55<13:10, 11.97s/it, loss=1.1742, lr=5.47e-09]Steps:  99%|█████████▊| 4934/5000 [18:25:55<13:10, 11.97s/it, loss=1.0999, lr=5.31e-09]Steps:  99%|█████████▊| 4935/5000 [18:26:07<12:57, 11.96s/it, loss=1.0999, lr=5.31e-09]Steps:  99%|█████████▊| 4935/5000 [18:26:07<12:57, 11.96s/it, loss=0.4799, lr=5.15e-09]Steps:  99%|█████████▊| 4936/5000 [18:26:19<12:44, 11.94s/it, loss=0.4799, lr=5.15e-09]Steps:  99%|█████████▊| 4936/5000 [18:26:19<12:44, 11.94s/it, loss=1.0120, lr=4.99e-09]Steps:  99%|█████████▊| 4937/5000 [18:26:31<12:34, 11.98s/it, loss=1.0120, lr=4.99e-09]Steps:  99%|█████████▊| 4937/5000 [18:26:31<12:34, 11.98s/it, loss=0.4597, lr=4.84e-09]Steps:  99%|█████████▉| 4938/5000 [18:26:43<12:25, 12.02s/it, loss=0.4597, lr=4.84e-09]Steps:  99%|█████████▉| 4938/5000 [18:26:43<12:25, 12.02s/it, loss=0.5115, lr=4.68e-09]Steps:  99%|█████████▉| 4939/5000 [18:26:55<12:12, 12.00s/it, loss=0.5115, lr=4.68e-09]Steps:  99%|█████████▉| 4939/5000 [18:26:55<12:12, 12.00s/it, loss=0.4753, lr=4.53e-09]Steps:  99%|█████████▉| 4940/5000 [18:27:07<11:58, 11.97s/it, loss=0.4753, lr=4.53e-09]Steps:  99%|█████████▉| 4940/5000 [18:27:07<11:58, 11.97s/it, loss=0.4764, lr=4.39e-09]
[Step 4940] Training Debug Info:
  Loss: 0.816390
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0125, std: 0.9023
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0106, std: 1.3438
  Model pred mean: 0.0116, std: 0.9961
  Sigmas: [0.4453125]... (timesteps: [445.0])

[Step 4940] Training Debug Info:
  Loss: 1.122504
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0001, std: 0.9336
  Noise mean: -0.0043, std: 1.0000
  Target mean: -0.0044, std: 1.3672
  Model pred mean: -0.0015, std: 0.8594
  Sigmas: [0.1171875]... (timesteps: [117.0])

[Step 4940] Training Debug Info:
  Loss: 0.902003
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0225, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0212, std: 1.3672
  Model pred mean: -0.0233, std: 0.9805
  Sigmas: [0.34765625]... (timesteps: [347.0])

[Step 4940] Training Debug Info:
  Loss: 0.928943
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0132, std: 0.8906
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0111, std: 1.3359
  Model pred mean: -0.0132, std: 0.9297
  Sigmas: [0.390625]... (timesteps: [391.0])
Steps:  99%|█████████▉| 4941/5000 [18:27:19<11:46, 11.97s/it, loss=0.4764, lr=4.39e-09]Steps:  99%|█████████▉| 4941/5000 [18:27:19<11:46, 11.97s/it, loss=0.9289, lr=4.24e-09]Steps:  99%|█████████▉| 4942/5000 [18:27:31<11:34, 11.97s/it, loss=0.9289, lr=4.24e-09]Steps:  99%|█████████▉| 4942/5000 [18:27:31<11:34, 11.97s/it, loss=1.0491, lr=4.10e-09]Steps:  99%|█████████▉| 4943/5000 [18:27:43<11:22, 11.97s/it, loss=1.0491, lr=4.10e-09]Steps:  99%|█████████▉| 4943/5000 [18:27:43<11:22, 11.97s/it, loss=0.3880, lr=3.96e-09]Steps:  99%|█████████▉| 4944/5000 [18:27:55<11:09, 11.96s/it, loss=0.3880, lr=3.96e-09]Steps:  99%|█████████▉| 4944/5000 [18:27:55<11:09, 11.96s/it, loss=0.3573, lr=3.82e-09]Steps:  99%|█████████▉| 4945/5000 [18:28:07<11:01, 12.02s/it, loss=0.3573, lr=3.82e-09]Steps:  99%|█████████▉| 4945/5000 [18:28:07<11:01, 12.02s/it, loss=0.8290, lr=3.69e-09]Steps:  99%|█████████▉| 4946/5000 [18:28:19<10:50, 12.04s/it, loss=0.8290, lr=3.69e-09]Steps:  99%|█████████▉| 4946/5000 [18:28:19<10:50, 12.04s/it, loss=0.7959, lr=3.55e-09]Steps:  99%|█████████▉| 4947/5000 [18:28:31<10:37, 12.02s/it, loss=0.7959, lr=3.55e-09]Steps:  99%|█████████▉| 4947/5000 [18:28:31<10:37, 12.02s/it, loss=0.5844, lr=3.42e-09]Steps:  99%|█████████▉| 4948/5000 [18:28:43<10:22, 11.97s/it, loss=0.5844, lr=3.42e-09]Steps:  99%|█████████▉| 4948/5000 [18:28:43<10:22, 11.97s/it, loss=0.6081, lr=3.29e-09]Steps:  99%|█████████▉| 4949/5000 [18:28:55<10:10, 11.98s/it, loss=0.6081, lr=3.29e-09]Steps:  99%|█████████▉| 4949/5000 [18:28:55<10:10, 11.98s/it, loss=0.3672, lr=3.17e-09]Steps:  99%|█████████▉| 4950/5000 [18:29:07<09:58, 11.96s/it, loss=0.3672, lr=3.17e-09]Steps:  99%|█████████▉| 4950/5000 [18:29:07<09:58, 11.96s/it, loss=0.3999, lr=3.05e-09]
[Step 4950] Training Debug Info:
  Loss: 0.672616
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0036, std: 0.9414
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0014, std: 1.3750
  Model pred mean: -0.0205, std: 1.1016
  Sigmas: [0.91015625]... (timesteps: [911.0])

[Step 4950] Training Debug Info:
  Loss: 0.471452
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0442, std: 0.8633
  Noise mean: 0.0013, std: 1.0000
  Target mean: 0.0454, std: 1.3203
  Model pred mean: 0.0466, std: 1.1250
  Sigmas: [0.71875]... (timesteps: [720.0])

[Step 4950] Training Debug Info:
  Loss: 1.080495
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0175, std: 0.9492
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0168, std: 1.3828
  Model pred mean: -0.0170, std: 0.9062
  Sigmas: [0.053955078125]... (timesteps: [54.0])

[Step 4950] Training Debug Info:
  Loss: 0.431577
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0081, std: 0.8867
  Noise mean: -0.0054, std: 1.0000
  Target mean: -0.0135, std: 1.3359
  Model pred mean: -0.0132, std: 1.1641
  Sigmas: [0.93359375]... (timesteps: [935.0])
Steps:  99%|█████████▉| 4951/5000 [18:29:19<09:44, 11.94s/it, loss=0.3999, lr=3.05e-09]Steps:  99%|█████████▉| 4951/5000 [18:29:19<09:44, 11.94s/it, loss=0.4316, lr=2.93e-09]Steps:  99%|█████████▉| 4952/5000 [18:29:31<09:35, 12.00s/it, loss=0.4316, lr=2.93e-09]Steps:  99%|█████████▉| 4952/5000 [18:29:31<09:35, 12.00s/it, loss=0.9176, lr=2.81e-09]Steps:  99%|█████████▉| 4953/5000 [18:29:43<09:22, 11.98s/it, loss=0.9176, lr=2.81e-09]Steps:  99%|█████████▉| 4953/5000 [18:29:43<09:22, 11.98s/it, loss=0.6115, lr=2.69e-09]Steps:  99%|█████████▉| 4954/5000 [18:29:55<09:10, 11.97s/it, loss=0.6115, lr=2.69e-09]Steps:  99%|█████████▉| 4954/5000 [18:29:55<09:10, 11.97s/it, loss=1.1861, lr=2.58e-09]Steps:  99%|█████████▉| 4955/5000 [18:30:07<09:00, 12.00s/it, loss=1.1861, lr=2.58e-09]Steps:  99%|█████████▉| 4955/5000 [18:30:07<09:00, 12.00s/it, loss=0.9360, lr=2.47e-09]Steps:  99%|█████████▉| 4956/5000 [18:30:19<08:47, 11.98s/it, loss=0.9360, lr=2.47e-09]Steps:  99%|█████████▉| 4956/5000 [18:30:19<08:47, 11.98s/it, loss=1.0986, lr=2.36e-09]Steps:  99%|█████████▉| 4957/5000 [18:30:31<08:33, 11.94s/it, loss=1.0986, lr=2.36e-09]Steps:  99%|█████████▉| 4957/5000 [18:30:31<08:33, 11.94s/it, loss=0.7024, lr=2.25e-09]Steps:  99%|█████████▉| 4958/5000 [18:30:43<08:24, 12.00s/it, loss=0.7024, lr=2.25e-09]Steps:  99%|█████████▉| 4958/5000 [18:30:43<08:24, 12.00s/it, loss=1.0267, lr=2.15e-09]Steps:  99%|█████████▉| 4959/5000 [18:30:55<08:11, 11.99s/it, loss=1.0267, lr=2.15e-09]Steps:  99%|█████████▉| 4959/5000 [18:30:55<08:11, 11.99s/it, loss=1.0310, lr=2.05e-09]Steps:  99%|█████████▉| 4960/5000 [18:31:07<07:58, 11.97s/it, loss=1.0310, lr=2.05e-09]Steps:  99%|█████████▉| 4960/5000 [18:31:07<07:58, 11.97s/it, loss=0.3743, lr=1.95e-09]
[Step 4960] Training Debug Info:
  Loss: 1.156750
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0085, std: 0.9023
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0093, std: 1.3516
  Model pred mean: 0.0074, std: 0.8086
  Sigmas: [0.1357421875]... (timesteps: [136.0])

[Step 4960] Training Debug Info:
  Loss: 0.877051
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0515, std: 0.9727
  Noise mean: -0.0002, std: 0.9961
  Target mean: -0.0518, std: 1.3984
  Model pred mean: -0.0525, std: 1.0312
  Sigmas: [0.400390625]... (timesteps: [400.0])

[Step 4960] Training Debug Info:
  Loss: 0.479682
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0010, std: 0.9727
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0015, std: 1.3984
  Model pred mean: -0.0023, std: 1.2109
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 4960] Training Debug Info:
  Loss: 0.433168
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0122, std: 0.9258
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0132, std: 1.3672
  Model pred mean: 0.0022, std: 1.1875
  Sigmas: [0.94140625]... (timesteps: [943.0])
Steps:  99%|█████████▉| 4961/5000 [18:31:19<07:45, 11.94s/it, loss=0.3743, lr=1.95e-09]Steps:  99%|█████████▉| 4961/5000 [18:31:19<07:45, 11.94s/it, loss=0.4332, lr=1.85e-09]Steps:  99%|█████████▉| 4962/5000 [18:31:31<07:32, 11.92s/it, loss=0.4332, lr=1.85e-09]Steps:  99%|█████████▉| 4962/5000 [18:31:31<07:32, 11.92s/it, loss=0.3738, lr=1.76e-09]Steps:  99%|█████████▉| 4963/5000 [18:31:43<07:23, 12.00s/it, loss=0.3738, lr=1.76e-09]Steps:  99%|█████████▉| 4963/5000 [18:31:43<07:23, 12.00s/it, loss=1.0757, lr=1.67e-09]Steps:  99%|█████████▉| 4964/5000 [18:31:55<07:10, 11.96s/it, loss=1.0757, lr=1.67e-09]Steps:  99%|█████████▉| 4964/5000 [18:31:55<07:10, 11.96s/it, loss=1.1381, lr=1.58e-09]Steps:  99%|█████████▉| 4965/5000 [18:32:07<07:00, 12.02s/it, loss=1.1381, lr=1.58e-09]Steps:  99%|█████████▉| 4965/5000 [18:32:07<07:00, 12.02s/it, loss=0.4294, lr=1.49e-09]Steps:  99%|█████████▉| 4966/5000 [18:32:19<06:47, 11.99s/it, loss=0.4294, lr=1.49e-09]Steps:  99%|█████████▉| 4966/5000 [18:32:19<06:47, 11.99s/it, loss=1.1063, lr=1.41e-09]Steps:  99%|█████████▉| 4967/5000 [18:32:31<06:34, 11.95s/it, loss=1.1063, lr=1.41e-09]Steps:  99%|█████████▉| 4967/5000 [18:32:31<06:34, 11.95s/it, loss=0.6127, lr=1.33e-09]Steps:  99%|█████████▉| 4968/5000 [18:32:42<06:21, 11.93s/it, loss=0.6127, lr=1.33e-09]Steps:  99%|█████████▉| 4968/5000 [18:32:42<06:21, 11.93s/it, loss=0.3863, lr=1.25e-09]Steps:  99%|█████████▉| 4969/5000 [18:32:54<06:09, 11.92s/it, loss=0.3863, lr=1.25e-09]Steps:  99%|█████████▉| 4969/5000 [18:32:54<06:09, 11.92s/it, loss=0.4789, lr=1.17e-09]Steps:  99%|█████████▉| 4970/5000 [18:33:06<05:57, 11.93s/it, loss=0.4789, lr=1.17e-09]Steps:  99%|█████████▉| 4970/5000 [18:33:06<05:57, 11.93s/it, loss=0.6047, lr=1.10e-09]
[Step 4970] Training Debug Info:
  Loss: 0.389619
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0096, std: 0.9375
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0096, std: 1.3672
  Model pred mean: -0.0084, std: 1.2266
  Sigmas: [0.8828125]... (timesteps: [882.0])

[Step 4970] Training Debug Info:
  Loss: 0.457380
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0193, std: 0.8789
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0166, std: 1.3281
  Model pred mean: 0.0225, std: 1.1406
  Sigmas: [0.72265625]... (timesteps: [723.0])

[Step 4970] Training Debug Info:
  Loss: 0.484729
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0183, std: 0.8711
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0194, std: 1.3281
  Model pred mean: 0.0189, std: 1.1250
  Sigmas: [0.69921875]... (timesteps: [698.0])

[Step 4970] Training Debug Info:
  Loss: 0.411019
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0027, std: 0.9023
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0022, std: 1.3438
  Model pred mean: -0.0002, std: 1.1875
  Sigmas: [0.80078125]... (timesteps: [802.0])
Steps:  99%|█████████▉| 4971/5000 [18:33:18<05:46, 11.94s/it, loss=0.6047, lr=1.10e-09]Steps:  99%|█████████▉| 4971/5000 [18:33:18<05:46, 11.94s/it, loss=0.4110, lr=1.02e-09]Steps:  99%|█████████▉| 4972/5000 [18:33:30<05:35, 12.00s/it, loss=0.4110, lr=1.02e-09]Steps:  99%|█████████▉| 4972/5000 [18:33:30<05:35, 12.00s/it, loss=0.5443, lr=9.55e-10]Steps:  99%|█████████▉| 4973/5000 [18:33:42<05:22, 11.96s/it, loss=0.5443, lr=9.55e-10]Steps:  99%|█████████▉| 4973/5000 [18:33:42<05:22, 11.96s/it, loss=1.1142, lr=8.88e-10]Steps:  99%|█████████▉| 4974/5000 [18:33:54<05:11, 11.97s/it, loss=1.1142, lr=8.88e-10]Steps:  99%|█████████▉| 4974/5000 [18:33:54<05:11, 11.97s/it, loss=1.0908, lr=8.24e-10]Steps: 100%|█████████▉| 4975/5000 [18:34:06<04:58, 11.95s/it, loss=1.0908, lr=8.24e-10]Steps: 100%|█████████▉| 4975/5000 [18:34:06<04:58, 11.95s/it, loss=1.0851, lr=7.62e-10]Steps: 100%|█████████▉| 4976/5000 [18:34:18<04:46, 11.95s/it, loss=1.0851, lr=7.62e-10]Steps: 100%|█████████▉| 4976/5000 [18:34:18<04:46, 11.95s/it, loss=0.4350, lr=7.02e-10]Steps: 100%|█████████▉| 4977/5000 [18:34:30<04:34, 11.95s/it, loss=0.4350, lr=7.02e-10]Steps: 100%|█████████▉| 4977/5000 [18:34:30<04:34, 11.95s/it, loss=0.8059, lr=6.45e-10]Steps: 100%|█████████▉| 4978/5000 [18:34:42<04:23, 11.96s/it, loss=0.8059, lr=6.45e-10]Steps: 100%|█████████▉| 4978/5000 [18:34:42<04:23, 11.96s/it, loss=0.4009, lr=5.90e-10]Steps: 100%|█████████▉| 4979/5000 [18:34:54<04:12, 12.03s/it, loss=0.4009, lr=5.90e-10]Steps: 100%|█████████▉| 4979/5000 [18:34:54<04:12, 12.03s/it, loss=0.3785, lr=5.37e-10]Steps: 100%|█████████▉| 4980/5000 [18:35:06<03:59, 11.97s/it, loss=0.3785, lr=5.37e-10]Steps: 100%|█████████▉| 4980/5000 [18:35:06<03:59, 11.97s/it, loss=0.3275, lr=4.87e-10]
[Step 4980] Training Debug Info:
  Loss: 1.050106
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0359, std: 0.9258
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0356, std: 1.3672
  Model pred mean: -0.0354, std: 0.9023
  Sigmas: [0.0279541015625]... (timesteps: [28.0])

[Step 4980] Training Debug Info:
  Loss: 0.658957
  Latent shape: torch.Size([1, 32, 54, 162]), Packed shape: torch.Size([1, 2187, 128])
  Latent mean: 0.0327, std: 0.9648
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0330, std: 1.3906
  Model pred mean: -0.0309, std: 1.1250
  Sigmas: [0.484375]... (timesteps: [484.0])

[Step 4980] Training Debug Info:
  Loss: 1.014646
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: 0.0522, std: 0.9453
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0547, std: 1.3750
  Model pred mean: -0.0505, std: 0.9375
  Sigmas: [0.2060546875]... (timesteps: [206.0])

[Step 4980] Training Debug Info:
  Loss: 0.490192
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0000, std: 0.8672
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0015, std: 1.3203
  Model pred mean: -0.0056, std: 1.1094
  Sigmas: [0.953125]... (timesteps: [953.0])
Steps: 100%|█████████▉| 4981/5000 [18:35:18<03:47, 11.96s/it, loss=0.3275, lr=4.87e-10]Steps: 100%|█████████▉| 4981/5000 [18:35:18<03:47, 11.96s/it, loss=0.4902, lr=4.40e-10]Steps: 100%|█████████▉| 4982/5000 [18:35:30<03:35, 11.96s/it, loss=0.4902, lr=4.40e-10]Steps: 100%|█████████▉| 4982/5000 [18:35:30<03:35, 11.96s/it, loss=1.1800, lr=3.95e-10]Steps: 100%|█████████▉| 4983/5000 [18:35:42<03:23, 11.95s/it, loss=1.1800, lr=3.95e-10]Steps: 100%|█████████▉| 4983/5000 [18:35:42<03:23, 11.95s/it, loss=0.6613, lr=3.52e-10]Steps: 100%|█████████▉| 4984/5000 [18:35:54<03:11, 11.96s/it, loss=0.6613, lr=3.52e-10]Steps: 100%|█████████▉| 4984/5000 [18:35:54<03:11, 11.96s/it, loss=0.3753, lr=3.12e-10]Steps: 100%|█████████▉| 4985/5000 [18:36:06<03:00, 12.05s/it, loss=0.3753, lr=3.12e-10]Steps: 100%|█████████▉| 4985/5000 [18:36:06<03:00, 12.05s/it, loss=1.1220, lr=2.74e-10]Steps: 100%|█████████▉| 4986/5000 [18:36:18<02:48, 12.01s/it, loss=1.1220, lr=2.74e-10]Steps: 100%|█████████▉| 4986/5000 [18:36:18<02:48, 12.01s/it, loss=0.5901, lr=2.39e-10]Steps: 100%|█████████▉| 4987/5000 [18:36:30<02:35, 11.99s/it, loss=0.5901, lr=2.39e-10]Steps: 100%|█████████▉| 4987/5000 [18:36:30<02:35, 11.99s/it, loss=0.4718, lr=2.06e-10]Steps: 100%|█████████▉| 4988/5000 [18:36:42<02:23, 11.96s/it, loss=0.4718, lr=2.06e-10]Steps: 100%|█████████▉| 4988/5000 [18:36:42<02:23, 11.96s/it, loss=0.8420, lr=1.75e-10]Steps: 100%|█████████▉| 4989/5000 [18:36:54<02:11, 11.95s/it, loss=0.8420, lr=1.75e-10]Steps: 100%|█████████▉| 4989/5000 [18:36:54<02:11, 11.95s/it, loss=0.9861, lr=1.47e-10]Steps: 100%|█████████▉| 4990/5000 [18:37:06<01:59, 11.92s/it, loss=0.9861, lr=1.47e-10]Steps: 100%|█████████▉| 4990/5000 [18:37:06<01:59, 11.92s/it, loss=0.4383, lr=1.22e-10]
[Step 4990] Training Debug Info:
  Loss: 1.110203
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0003, std: 0.9297
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0020, std: 1.3672
  Model pred mean: -0.0005, std: 0.8672
  Sigmas: [0.1279296875]... (timesteps: [128.0])

[Step 4990] Training Debug Info:
  Loss: 0.450904
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0217, std: 0.9727
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0206, std: 1.3984
  Model pred mean: -0.0243, std: 1.2188
  Sigmas: [0.640625]... (timesteps: [640.0])

[Step 4990] Training Debug Info:
  Loss: 1.132028
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0032, std: 0.9062
  Noise mean: 0.0007, std: 1.0078
  Target mean: -0.0025, std: 1.3516
  Model pred mean: -0.0027, std: 0.8359
  Sigmas: [0.0859375]... (timesteps: [86.0])

[Step 4990] Training Debug Info:
  Loss: 0.533421
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0062, std: 0.8750
  Noise mean: 0.0056, std: 1.0000
  Target mean: -0.0006, std: 1.3281
  Model pred mean: -0.0047, std: 1.1094
  Sigmas: [0.98828125]... (timesteps: [990.0])
Steps: 100%|█████████▉| 4991/5000 [18:37:18<01:47, 11.90s/it, loss=0.4383, lr=1.22e-10]Steps: 100%|█████████▉| 4991/5000 [18:37:18<01:47, 11.90s/it, loss=0.5334, lr=9.87e-11]Steps: 100%|█████████▉| 4992/5000 [18:37:30<01:35, 11.98s/it, loss=0.5334, lr=9.87e-11]Steps: 100%|█████████▉| 4992/5000 [18:37:30<01:35, 11.98s/it, loss=0.5103, lr=7.80e-11]Steps: 100%|█████████▉| 4993/5000 [18:37:42<01:23, 11.95s/it, loss=0.5103, lr=7.80e-11]Steps: 100%|█████████▉| 4993/5000 [18:37:42<01:23, 11.95s/it, loss=1.1178, lr=5.97e-11]Steps: 100%|█████████▉| 4994/5000 [18:37:54<01:11, 11.96s/it, loss=1.1178, lr=5.97e-11]Steps: 100%|█████████▉| 4994/5000 [18:37:54<01:11, 11.96s/it, loss=0.5441, lr=4.39e-11]Steps: 100%|█████████▉| 4995/5000 [18:38:05<00:59, 11.95s/it, loss=0.5441, lr=4.39e-11]Steps: 100%|█████████▉| 4995/5000 [18:38:05<00:59, 11.95s/it, loss=0.9720, lr=3.05e-11]Steps: 100%|█████████▉| 4996/5000 [18:38:17<00:47, 11.93s/it, loss=0.9720, lr=3.05e-11]Steps: 100%|█████████▉| 4996/5000 [18:38:17<00:47, 11.93s/it, loss=1.0500, lr=1.95e-11]Steps: 100%|█████████▉| 4997/5000 [18:38:29<00:35, 11.93s/it, loss=1.0500, lr=1.95e-11]Steps: 100%|█████████▉| 4997/5000 [18:38:29<00:35, 11.93s/it, loss=1.1002, lr=1.10e-11]Steps: 100%|█████████▉| 4998/5000 [18:38:41<00:23, 11.93s/it, loss=1.1002, lr=1.10e-11]Steps: 100%|█████████▉| 4998/5000 [18:38:41<00:23, 11.93s/it, loss=0.6174, lr=4.87e-12]Steps: 100%|█████████▉| 4999/5000 [18:38:54<00:12, 12.07s/it, loss=0.6174, lr=4.87e-12]Steps: 100%|█████████▉| 4999/5000 [18:38:54<00:12, 12.07s/it, loss=1.1600, lr=1.22e-12]Steps: 100%|██████████| 5000/5000 [18:39:05<00:00, 12.02s/it, loss=1.1600, lr=1.22e-12]Steps: 100%|██████████| 5000/5000 [18:39:05<00:00, 12.02s/it, loss=0.5330, lr=0.00e+00]01/23/2026 02:24:52 - INFO - __main__ - 
[Step 5000] ✅ Loss in normal range (0.5330)
01/23/2026 02:24:52 - INFO - __main__ -   Loss avg (last 100): 0.7245
01/23/2026 02:24:52 - INFO - __main__ -   Loss range: [0.3275, 1.1988]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/transformer/diffusion_pytorch_model.safetensors
01/23/2026 02:25:41 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000
01/23/2026 02:25:41 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/accelerator
01/23/2026 02:25:41 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/23/2026 02:28:14 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/accelerator/pytorch_model
01/23/2026 02:28:14 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/accelerator/scheduler.bin
01/23/2026 02:28:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/accelerator/sampler.bin
01/23/2026 02:28:14 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/checkpoint-5000/accelerator/random_states_0.pkl
01/23/2026 02:28:14 - INFO - __main__ - Removing 1 old checkpoints
01/23/2026 02:28:25 - INFO - __main__ - 
🔍 Running validation at step 5000...
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 5000 (parquet mode)...
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 5000...
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/23/2026 02:28:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.71it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.59it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.54it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.51it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.49it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.48it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.47it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.47it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.47it/s][A
 43%|████▎     | 12/28 [00:07<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.46it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.46it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.46it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.46it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.46it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:18<00:00,  1.45it/s][A100%|██████████| 28/28 [00:18<00:00,  1.48it/s]
01/23/2026 02:28:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/23/2026 02:28:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.69it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.47it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.45it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.45it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.45it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/23/2026 02:29:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/23/2026 02:29:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.12it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.63it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.52it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.45it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.43it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.41it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:13,  1.30it/s][A
 43%|████▎     | 12/28 [00:08<00:12,  1.33it/s][A
 46%|████▋     | 13/28 [00:09<00:11,  1.35it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.36it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.37it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/23/2026 02:29:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/23/2026 02:29:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 02:29:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/23/2026 02:29:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/23/2026 02:30:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/23/2026 02:30:12 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.40it/s]
01/23/2026 02:30:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/23/2026 02:30:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:12,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:30:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/23/2026 02:30:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:31:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/23/2026 02:31:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:31:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/23/2026 02:31:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:31:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/23/2026 02:31:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.14it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/23/2026 02:32:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/23/2026 02:32:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/23/2026 02:32:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/23/2026 02:32:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/23/2026 02:32:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/23/2026 02:32:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000
01/23/2026 02:32:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

01/23/2026 02:32:47 - INFO - __main__ - 
==================================================
01/23/2026 02:32:47 - INFO - __main__ - Epoch 1 completed: avg_loss = 0.7465
01/23/2026 02:32:47 - INFO - __main__ - ==================================================

Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/transformer/diffusion_pytorch_model.safetensors
01/23/2026 02:33:22 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model
01/23/2026 02:33:22 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/accelerator
01/23/2026 02:33:22 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/23/2026 02:35:41 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/accelerator/pytorch_model
01/23/2026 02:35:41 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/accelerator/scheduler.bin
01/23/2026 02:35:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/accelerator/sampler.bin
01/23/2026 02:35:41 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/final_model/accelerator/random_states_0.pkl
01/23/2026 02:35:41 - INFO - __main__ - 
🎯 Running final validation...
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 5000 (parquet mode)...
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 5000...
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/23/2026 02:35:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.22it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.70it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.58it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.53it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.50it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.49it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.48it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.47it/s][A
 32%|███▏      | 9/28 [00:05<00:12,  1.46it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.46it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.46it/s][A
 43%|████▎     | 12/28 [00:08<00:10,  1.46it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.46it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.46it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.45it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.46it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.46it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.45it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.45it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.46it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.45it/s][A
 79%|███████▊  | 22/28 [00:14<00:04,  1.45it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.45it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.45it/s][A
 89%|████████▉ | 25/28 [00:16<00:02,  1.45it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.45it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.45it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.45it/s][A100%|██████████| 28/28 [00:19<00:00,  1.47it/s]
01/23/2026 02:36:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/23/2026 02:36:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.19it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.68it/s][A
 11%|█         | 3/28 [00:01<00:15,  1.57it/s][A
 14%|█▍        | 4/28 [00:02<00:15,  1.52it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.49it/s][A
 21%|██▏       | 6/28 [00:03<00:14,  1.48it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.46it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.46it/s][A
 32%|███▏      | 9/28 [00:05<00:13,  1.45it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.45it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.45it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.45it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.45it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.44it/s][A
 54%|█████▎    | 15/28 [00:10<00:08,  1.44it/s][A
 57%|█████▋    | 16/28 [00:10<00:08,  1.44it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.44it/s][A
 64%|██████▍   | 18/28 [00:12<00:06,  1.44it/s][A
 68%|██████▊   | 19/28 [00:12<00:06,  1.44it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.44it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.44it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.44it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.44it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.44it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.44it/s][A
 93%|█████████▎| 26/28 [00:17<00:01,  1.44it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.44it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.44it/s][A100%|██████████| 28/28 [00:19<00:00,  1.46it/s]
01/23/2026 02:36:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/23/2026 02:36:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.47it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.42it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.41it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.40it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.40it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.40it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.40it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.40it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.40it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.40it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.40it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.40it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 02:36:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/23/2026 02:36:44 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.11it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.62it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.51it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.44it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.42it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.41it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.40it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.40it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.39it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.39it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.39it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.39it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.39it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.39it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.39it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.39it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.39it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.39it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.39it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.39it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.39it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.39it/s][A100%|██████████| 28/28 [00:19<00:00,  1.41it/s]
01/23/2026 02:37:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/23/2026 02:37:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.10it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.50it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.46it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.43it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.40it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.39it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.39it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.39it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.39it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.38it/s][A100%|██████████| 28/28 [00:19<00:00,  1.40it/s]
01/23/2026 02:37:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/23/2026 02:37:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.61it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.39it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:09,  1.29it/s][A
 61%|██████    | 17/28 [00:12<00:08,  1.31it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.33it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.34it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.36it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.36it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:18<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.38it/s]
01/23/2026 02:37:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/23/2026 02:37:46 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:38:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/23/2026 02:38:07 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.38it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.37it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.37it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.37it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.37it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.37it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.37it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.37it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.37it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:38:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/23/2026 02:38:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.44it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.40it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.39it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:15<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.37it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.37it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:38:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/23/2026 02:38:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.09it/s][A
  7%|▋         | 2/28 [00:01<00:16,  1.60it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.49it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.45it/s][A
 18%|█▊        | 5/28 [00:03<00:16,  1.42it/s][A
 21%|██▏       | 6/28 [00:04<00:15,  1.41it/s][A
 25%|██▌       | 7/28 [00:04<00:15,  1.40it/s][A
 29%|██▊       | 8/28 [00:05<00:14,  1.39it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.39it/s][A
 36%|███▌      | 10/28 [00:07<00:13,  1.38it/s][A
 39%|███▉      | 11/28 [00:07<00:12,  1.38it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.38it/s][A
 46%|████▋     | 13/28 [00:09<00:10,  1.38it/s][A
 50%|█████     | 14/28 [00:09<00:10,  1.38it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.38it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.38it/s][A
 61%|██████    | 17/28 [00:12<00:07,  1.38it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.38it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.38it/s][A
 71%|███████▏  | 20/28 [00:14<00:05,  1.38it/s][A
 75%|███████▌  | 21/28 [00:14<00:05,  1.38it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.38it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.38it/s][A
 86%|████████▌ | 24/28 [00:17<00:02,  1.38it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.38it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.38it/s][A
 96%|█████████▋| 27/28 [00:19<00:00,  1.38it/s][A
100%|██████████| 28/28 [00:20<00:00,  1.38it/s][A100%|██████████| 28/28 [00:20<00:00,  1.39it/s]
01/23/2026 02:39:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/23/2026 02:39:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.64it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.53it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.48it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.44it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.42it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.42it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.41it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:16<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.43it/s]
01/23/2026 02:39:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/23/2026 02:39:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:12,  2.15it/s][A
  7%|▋         | 2/28 [00:01<00:15,  1.65it/s][A
 11%|█         | 3/28 [00:01<00:16,  1.54it/s][A
 14%|█▍        | 4/28 [00:02<00:16,  1.49it/s][A
 18%|█▊        | 5/28 [00:03<00:15,  1.46it/s][A
 21%|██▏       | 6/28 [00:03<00:15,  1.45it/s][A
 25%|██▌       | 7/28 [00:04<00:14,  1.44it/s][A
 29%|██▊       | 8/28 [00:05<00:13,  1.43it/s][A
 32%|███▏      | 9/28 [00:06<00:13,  1.43it/s][A
 36%|███▌      | 10/28 [00:06<00:12,  1.43it/s][A
 39%|███▉      | 11/28 [00:07<00:11,  1.42it/s][A
 43%|████▎     | 12/28 [00:08<00:11,  1.42it/s][A
 46%|████▋     | 13/28 [00:08<00:10,  1.42it/s][A
 50%|█████     | 14/28 [00:09<00:09,  1.42it/s][A
 54%|█████▎    | 15/28 [00:10<00:09,  1.42it/s][A
 57%|█████▋    | 16/28 [00:11<00:08,  1.42it/s][A
 61%|██████    | 17/28 [00:11<00:07,  1.42it/s][A
 64%|██████▍   | 18/28 [00:12<00:07,  1.42it/s][A
 68%|██████▊   | 19/28 [00:13<00:06,  1.42it/s][A
 71%|███████▏  | 20/28 [00:13<00:05,  1.42it/s][A
 75%|███████▌  | 21/28 [00:14<00:04,  1.42it/s][A
 79%|███████▊  | 22/28 [00:15<00:04,  1.42it/s][A
 82%|████████▏ | 23/28 [00:15<00:03,  1.42it/s][A
 86%|████████▌ | 24/28 [00:16<00:02,  1.42it/s][A
 89%|████████▉ | 25/28 [00:17<00:02,  1.42it/s][A
 93%|█████████▎| 26/28 [00:18<00:01,  1.42it/s][A
 96%|█████████▋| 27/28 [00:18<00:00,  1.42it/s][A
100%|██████████| 28/28 [00:19<00:00,  1.42it/s][A100%|██████████| 28/28 [00:19<00:00,  1.44it/s]
01/23/2026 02:39:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000/step005000_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/23/2026 02:39:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/23/2026 02:39:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/23/2026 02:39:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_fulltune_5000/validation_images/step_005000
01/23/2026 02:39:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:    epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████
wandb:     loss ▃▅▇▂▁▄██▄▇▃▂▇▃▂▇▇▇▃▄▂▂▁▃█▃▁█▇▇▇▇▁▂▂▂█▇▆▆
wandb: loss_avg █▆█▆▅▅▆▆▃▃▄▆▆▃▃▅▆▅▄▅▅▃▁▄▅▆▅▅▃▃▃▅▆▆▄▅▅██▃
wandb: loss_min █▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       lr ▂▂▆▇▇█████▇▇▇▇▇▆▆▆▆▅▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁
wandb:     step ▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:    epoch 1
wandb:     loss 0.53295
wandb: loss_avg 0.7245
wandb: loss_min 0.29365
wandb:       lr 0
wandb:     step 5000
wandb: 
wandb: 🚀 View run flux2klein_9b_fulltune_5000steps at: https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-FullTune/runs/srfc5mxw
wandb: ⭐️ View project at: https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-FullTune
wandb: Synced 8 W&B file(s), 312 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260122_074548-srfc5mxw/logs
01/23/2026 02:39:58 - INFO - __main__ - 🎉 Training completed successfully!
Steps: 100%|██████████| 5000/5000 [18:54:12<00:00, 13.61s/it, loss=0.5330, lr=0.00e+00]
