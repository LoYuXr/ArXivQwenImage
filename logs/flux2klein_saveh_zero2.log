W0130 07:17:02.919000 2378129 site-packages/torch/distributed/run.py:793] 
W0130 07:17:02.919000 2378129 site-packages/torch/distributed/run.py:793] *****************************************
W0130 07:17:02.919000 2378129 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0130 07:17:02.919000 2378129 site-packages/torch/distributed/run.py:793] *****************************************
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 50, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application's source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet's denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure's caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 50, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application's source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet's denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure's caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 50, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application's source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet's denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure's caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 50, 'num_inference_steps': 28, 'validation_prompts': ["The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime. The global layout is a top-down flowchart depicting the sequence of interactions from environment setup to data analysis. At the top, a light blue rectangular box labeled 'Environment Variable: LD_PRELOAD=siren.so' initiates the process. This points downward to a green rectangle labeled 'Dynamic Linker: ld.so', which branches into two paths: one to a light blue box 'Injected Library: siren.so' and another to a green box 'Shared Libraries: DT_NEEDED'. Both converge into a large green rectangular container labeled 'ELF Binary Executable', which contains three internal components arranged vertically. The first is a light blue hexagon labeled 'Constructor: Data Collection and UDP Sender', followed by a green rectangle 'Application Code: main()', and then another light blue hexagon 'Destructor: Data Collection and UDP Sender'. These indicate that the injected library's data collection routines are triggered at both process startup (via constructor) and shutdown (via destructor). An arrow from the destructor leads to a light blue rectangle 'Message Receiver: UDP Server', which in turn connects to a light blue cylinder labeled 'Database: SQLite'. From the database, a downward arrow leads to a light blue rectangle 'Post-processing and Consolidation: Python', which then connects leftward to another light blue rectangle 'Statistics and Similarity Analysis: Python'. All elements shaded in light blue represent components of the SIREN architecture, while green elements denote standard system or application components. The arrows indicate the direction of control flow and data transmission, showing how injected data is sent via UDP, received, stored, processed, and finally analyzed. The diagram emphasizes the non-intrusive nature of the hooking mechanism, leveraging dynamic linking to collect runtime data without modifying the target application's source code.", "The figure presents an overview of four distinct end-to-end Task-Oriented Dialogue (TOD) approaches, arranged vertically as subfigures (a) through (d), each illustrating a different methodology for integrating language models into dialogue systems.\n\n[1] Global Layout and Structure:\nThe figure is divided into four horizontal sections, each representing a different approach. Each section contains a central model component at the top, with input/output modules below or connected via arrows. The layout follows a top-down flow, where user inputs lead to model processing and then to outputs such as actions or responses. Subfigure labels (a), (b), (c), and (d) are placed beneath each section, along with descriptive captions explaining the approach.\n\n[2] Visual Modules and Attributes:\nIn subfigure (a), labeled 'Full-shot approach with fine-tuning LM', a large light green rounded rectangle at the top represents a 'Pre-trained Language Model (e.g., GPT2, T5)', marked with a red flame icon. Below it, five light blue rectangular boxes labeled 'User', 'Belief State', 'DB', 'Action', and 'Resp' are aligned horizontally. Arrows connect these boxes to the model, indicating bidirectional interaction between the model and all components except 'Resp', which receives output from the model.\n\nSubfigure (b), titled 'Zero-shot approach via schema-guided prompting LLM', features a similar light green rounded rectangle labeled 'Large Language Model (e.g., GPT 3.5, GPT-4)', marked with a blue snowflake icon. Below, two yellow rounded rectangles labeled 'DST Prompter' and 'Policy Prompter' receive input from 'User' and 'DB' respectively, and feed into the LLM. The LLM outputs to 'Action' and 'Resp', both light blue boxes.\n\nSubfigure (c), 'Zero-shot approach via autonomous Agent LLM', shows a light green rounded rectangle containing a robot icon and a pink rounded rectangle labeled 'Instruction following LLM'. This module is labeled 'Large Language Model' and marked with a blue snowflake. A bidirectional arrow connects the 'User' box to the LLM, with 'Resp' labeled on the return path. To the right, a set of yellow boxes labeled 'API tool-1' through 'API tool-n' are connected to the LLM via a blue circular arrow, indicating iterative interaction.\n\nSubfigure (d), 'Spec-TOD (ours): Few-shot approach with specialized instruction-tuned LLM', displays a light green rounded rectangle labeled 'Specialized Task-Oriented LLM', marked with a red flame icon. Inside, a robot icon with a gear symbol is adjacent to a pink rounded rectangle labeled 'Specified-Task Instruct.'. A bidirectional arrow connects the 'User' box to this module, with 'Resp' labeled on the return path. To the right, a vertical stack of yellow boxes labeled 'Task-1 Spec. Rep.', 'Task-2 Spec. Rep.', ..., 'Task-m Spec. Rep.' is connected to the 'Specified-Task Instruct.' box via a blue circular arrow, indicating iterative refinement using task-specific representations.\n\n[3] Connections and Arrows:\nIn (a), arrows show bidirectional communication between the pre-trained LM and 'User', 'Belief State', and 'DB', while unidirectional arrows point from the LM to 'Action' and 'Resp'.\n\nIn (b), arrows go from 'User' to 'DST Prompter', from 'DB' to 'Policy Prompter', and from both prompters to the LLM. The LLM sends outputs to 'Action' and 'Resp'.\n\nIn (c), a bidirectional arrow links 'User' and the LLM, with 'Resp' labeled on the response path. A blue circular arrow connects the LLM to the API tools, indicating iterative tool calling.\n\nIn (d), a bidirectional arrow connects 'User' and the LLM, with 'Resp' on the return path. A blue circular arrow links the 'Specified-Task Instruct.' box to the stack of task-specific representations, suggesting iterative refinement using these representations.", "The figure illustrates a network architecture for a single-step diffusion model with an enhanced decoder. The global layout is horizontal, progressing from left to right, with multiple parallel input streams converging into a central processing unit before diverging again toward the output. On the far left, three distinct input conditioning vectors, labeled c₁, c₂, and c₃, are represented as gray rounded rectangles. Each of these inputs is processed by a separate blue parallelogram-shaped module labeled ε, indicating an encoder or feature extraction component. These encoders are marked as 'Frozen' according to the legend at the bottom right, which uses a blue snowflake icon to denote frozen modules. The outputs of these encoders are combined via two circular summation nodes (⊕), where the first summation node receives the output of ε(c₁) and ε(c₂), and the second summation node combines the result with ε(c₃). Additionally, a noise latent vector z_T, shown as a gray rounded rectangle, is fed directly into the first summation node. The combined feature representation from both summation nodes is then passed into a large, centrally located orange bowtie-shaped module labeled 'UNet'. This UNet is marked as 'Trained' in the legend, indicated by an orange flame icon, signifying it is the primary trainable component of the architecture. The UNet outputs a denoised latent representation, denoted as -ẑ₀, shown as a gray rounded rectangle. This output is then fed into a blue parallelogram-shaped decoder module labeled D, also marked as 'Frozen'. Prior to entering the decoder, an additional orange parallelogram-shaped module labeled ε_f, which is trained, provides auxiliary features that are concatenated or fused with the main latent stream before decoding. The final output emerges from the decoder D. The connections between all components are depicted using gray arrows, indicating the flow of data. The overall structure emphasizes a multi-scale feature fusion strategy, where conditioned features from multiple encoders are aggregated and combined with noise to guide the UNet's denoising process, followed by reconstruction through a frozen decoder enhanced by an additional trained feature extractor ε_f.", "The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies. The global layout consists of four vertically aligned workflows side-by-side, each depicting a distinct approach to processing RGB and 3D data inputs for defect detection. At the top of the diagram, a legend indicates that pink circles represent RGB Data and light green circles represent 3D Data, which are visually represented as cylindrical containers feeding into processing modules.\n\nIn workflow (a) ISDD, a single pink cylinder (RGB Data) feeds into a rectangular 'Model' box with a pale yellow fill and black border, which then outputs 'Defect'. This represents a unimodal approach using only RGB data.\n\nWorkflow (b) MISDD shows two parallel inputs: one pink cylinder (RGB Data) and one light green cylinder (3D Data), each feeding into separate 'Model' boxes. The outputs from both models converge into a 'Fusion' box (light gray fill, rounded rectangle), which then produces the 'Defect' output. This illustrates a multimodal setup where both modalities are fully available.\n\nWorkflow (c) MIISDD features a smaller pink cylinder (RGB Data) and a full-sized light green cylinder (3D Data), indicating a static, incomplete modality scenario where RGB data is reduced or partially missing. Both inputs feed into separate 'Model' boxes, whose outputs are fused in a 'Fusion' box before producing the 'Defect' result. This highlights a fixed modality incompleteness.\n\nWorkflow (d) MISDD-MM, the proposed method, includes two dashed-line cylinders above the actual input cylinders—one pink and one light green—symbolizing dynamic, potentially missing modalities. The actual pink and green cylinders feed into separate 'Model' boxes, which are connected by bidirectional dashed arrows labeled with an equals sign, suggesting alignment or interaction between the models. The outputs from these models are combined via a 'Text-guided Fusion' module (light gray, elongated rounded rectangle), which then generates the final 'Defect' output. This emphasizes multimodal learning under dynamic missing conditions, guided by textual information.\n\nAll 'Model' boxes are uniformly styled with pale yellow fill and black borders, while 'Fusion' and 'Text-guided Fusion' boxes use light gray fills with rounded corners. All connections are solid black arrows pointing downward, except for the bidirectional dashed arrows between models in (d). The figure's caption clarifies that MISDD-MM differs from MIISDD by addressing dynamic missing modalities rather than static incompleteness.", "The figure illustrates a model evaluation framework for a diffusion-based prediction system, structured as a horizontal workflow from left to right. The global layout consists of an input stage on the far left, a central processing module, multiple inference outputs, and a comparison stage on the right for evaluating predictions against targets.\n\nAt the center is a rounded rectangular box labeled 'Diffusion Model' in bold black text, filled with light purple color and outlined in dark blue. This module receives two inputs: one from the left, labeled 'x_n', represented as a black square containing a white, irregularly shaped cluster resembling a cloud or porous structure; and another from above, labeled 'noise', indicated by a downward arrow. From the Diffusion Model, multiple downward arrows emerge, labeled collectively as 'Multiple inference', pointing to a sequence of output images arranged horizontally. These outputs are denoted as 'x̂_{n+1}^{(1)}', 'x̂_{n+1}^{(2)}', 'x̂_{n+1}^{(3)}', 'x̂_{n+1}^{(4)}', ..., up to 'x̂_{n+1}^{(m)}', each shown as a black square with a similar white cluster pattern, suggesting multiple stochastic realizations generated by the model.\n\nTo the right of these outputs, a large gray arrow points toward a comparison section enclosed in two dashed boxes stacked vertically. The top box, outlined in blue dashed lines and labeled 'target' in blue text at the top right, contains two side-by-side images: on the left, a black square with a white cluster labeled 'x_{n+1}', and on the right, a pinkish-red square with a red cluster. The bottom box, outlined in green dashed lines and labeled 'prediction' in green text at the bottom right, mirrors this layout with identical images, but labeled 'x̂_{n+1}^{en}' below them. This indicates that the ensemble prediction (denoted by 'en') is compared against the actual target data for evaluation.\n\nAll connections are represented by solid blue arrows, except for the final comparison arrow which is gray and thicker. Text labels are in black unless specified otherwise, with key terms like 'target' and 'prediction' colored to match their respective bounding boxes. The overall design emphasizes the stochastic nature of the diffusion model through multiple inference paths and highlights the evaluation process by visually contrasting predicted and actual outcomes.", "The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers, specifically focusing on the last-token representation at layer k. The diagram is divided into two main sections: 'Linear Prob Training' (top) and 'Linear Prob Testing' (bottom), each depicting a distinct phase of the evaluation pipeline.\n\nIn the training phase, a training image (depicted as a photo of a German Shepherd in a field) is fed into a pink rounded rectangle labeled 'Vision Encoder', which is stacked above a 'Projector' module; both components are marked with blue snowflake icons indicating they are frozen during training. Simultaneously, an 'Anchor Question' is processed by a light green rounded rectangle labeled 'Tokenizer'. The outputs from the Vision Encoder and Tokenizer are represented as sequences of colored squares—red for visual features and green for textual tokens—which are then concatenated and passed through a series of vertical purple rectangles labeled 'Decoder Layer 1', 'Decoder Layer 2', ..., 'Decoder Layer k', each also marked with a blue snowflake icon to denote freezing. At the final layer, the last token (highlighted with a darker border) is extracted and fed into a yellow rounded rectangle labeled 'Linear', which has a small orange flame icon, symbolizing the trainable linear probe. This probe is connected to a 'CE Loss' (Cross-Entropy Loss) node, indicating the optimization objective during training.\n\nIn the testing phase, a different image (a German Shepherd lying on a wooden surface) is processed through the same frozen Vision Encoder and Projector modules. A 'Prompt Variant' (e.g., a modified or semantically altered version of the original question) is tokenized using the same Tokenizer. The resulting feature sequences again flow through the identical frozen decoder layers. The last token from the final decoder layer is extracted and passed to a second 'Linear' module, this time marked with a blue snowflake icon to indicate it is kept fixed (i.e., not retrained). This fixed probe outputs a prediction, which is evaluated against ground truth to compute 'Accuracy'. A dashed vertical line connects the training and testing Linear probes, emphasizing that the same probe weights are used in both phases.\n\nThe overall layout is horizontal, with data flowing left to right, and the two phases are vertically stacked. The visual modules are color-coded: pink for vision processing, green for text tokenization, purple for decoder layers, and yellow for the linear probe. All modules are rounded rectangles, except for the input images and text labels. The connections are solid arrows for data flow and a dashed arrow for parameter sharing between training and testing probes. The figure visually conveys the process of training a linear classifier on features extracted from a specific decoder layer and then evaluating its performance on new data under varied prompts, enabling layer-wise analysis of the model's learned representations.", "The figure presents a comparative architectural diagram illustrating two different approaches to managing heap growth in a system utilizing CXL (Compute Express Link) memory, labeled as (a) Vanilla DAX and (b) Our system. The global layout is split into two side-by-side panels, each depicting a virtual address space and associated CXL memory structure, with a shared caption at the bottom explaining the context: 'The result of heap growth during execution after restoring the heap area of function X on CXL memory.'\n\nIn panel (a), 'Vanilla DAX', the left side shows the 'Virtual Address Space of X' as a vertical stack of rectangular regions. The top region is blank, followed by a gray-shaded rectangle labeled 'Heap X' with diagonal black stripes. Below it is a red-shaded rectangle labeled 'Heap Growth' with red diagonal stripes. A dashed blue arrow extends from the 'Heap X' region to a 'CXL Memory' block on the right, which contains two gray rectangles labeled 'Image X' and 'Image Y'. A solid red arrow points downward from the 'Heap Growth' region to a label 'Leakage' in red text, indicating that uncontrolled heap expansion causes data to spill over into unintended memory areas.\n\nIn panel (b), 'Our system', the same 'Virtual Address Space of X' is shown, with 'Heap X' (gray, diagonal black stripes) and 'Heap Growth' (red, diagonal red stripes) stacked vertically. However, the 'Heap Growth' region now connects via a dashed red arrow to a new memory component labeled 'Local Memory' below the CXL Memory block. This 'Local Memory' is a red-shaded rectangle labeled 'Private', signifying dedicated private memory for heap expansion. The CXL Memory block above still contains 'Image X' and 'Image Y', but the dashed blue arrow from 'Heap X' to 'Image X' remains, while the 'Heap Growth' is now isolated to the private local memory, preventing leakage.\n\nThe visual modules are primarily rectangular blocks with distinct fill patterns: gray with black diagonal lines for 'Heap X', red with red diagonal lines for 'Heap Growth', and solid red for 'Private' memory. Text labels are black except for 'Leakage', which is red. Arrows are dashed (blue for mapping to CXL, red for growth to local memory) or solid (red for leakage). The connections show a clear contrast: in Vanilla DAX, heap growth leads to leakage into CXL memory, whereas in the proposed system, heap growth is directed to a private local memory, thus avoiding leakage and improving memory safety.", "The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep learning network designed for image processing tasks, likely involving background estimation, target extraction, noise reduction, and image reconstruction. The global layout consists of a top-level pipeline showing K sequential stages (Stage 1, Stage k, Stage K), each containing four modular components: SEBEM (Squeeze-and-Excitation Background Estimation Module), SETEM (Squeeze-and-Excitation Target Extraction Module), SENRM (Squeeze-and-Excitation Noise Reduction Module), and SEIRM (Squeeze-and-Excitation Image Reconstruction Module). These modules are arranged horizontally within each stage, forming a consistent processing flow from left to right. The entire pipeline begins with an 'Original' grayscale input image on the far left and ends with a 'Target' output image on the far right. Each stage outputs intermediate representations labeled B^k, T^k, N^k, D^k, corresponding to background, target, noise, and reconstructed image features respectively.\n\nBelow the main pipeline, a detailed breakdown of a single stage is shown, enclosed in a dashed box. This expanded view reveals the internal structure of each module. SEBEM is depicted in light blue, SETEM in light green, SENRM in pale yellow, and SEIRM in gray. Each module contains convolutional layers (represented by rectangular blocks with varying colors indicating kernel size and channel dimensions), activation functions (light yellow blocks), batch normalization (pink blocks), and a Squeeze-and-Excitation Network (gray block with 'Squeeze-and-Excitation Network' label). The modules are interconnected via element-wise addition operations (⊕ symbols) and feature transmission paths. Specifically, SEBEM receives inputs from previous stage outputs (D^{k-1}, T^{k-1}, N^{k-1}) and produces B^k; SETEM takes B^k and generates T^k; SENRM processes T^k to produce N^k; and SEIRM uses N^k to generate D^k.\n\nConnections between modules and stages are indicated by arrows with distinct colors and labels in a legend below the main pipeline: black arrows denote 'module transmission path', red arrows represent 'ε^k transmission path', purple arrows indicate 'σ^k transmission path', and orange arrows show 'stage transmission path'. These paths illustrate how features are propagated across modules and stages, including residual or skip connections.\n\nIn the bottom-right corner, a schematic of the Squeeze-and-Excitation Network (SENet) is provided. It shows an input tensor X of dimensions C' × H' × W' being transformed through a function F_tr to output U of dimensions C × H × W. This is followed by a squeeze operation producing a 1×1×C vector, which is then processed by F_scale to generate scaling weights. These weights are applied to the original feature map to produce the final output X̄, demonstrating the channel-wise attention mechanism.\n\nThe figure also includes a legend at the bottom-left explaining the visual attributes: pink blocks represent Batch Normalization, light yellow blocks represent Activation Functions, and various shades of red/brown blocks represent convolutional layers with specified kernel sizes (3×3) and channel dimensions (e.g., 1-BC, BC-BC, C-1). The overall design emphasizes modularity, hierarchical processing, and the integration of attention mechanisms via SENets within each functional module.", "The figure illustrates the complete pipeline of a 3D scene reconstruction system, divided into two main stages: Tracking and Mapping, with an initial preprocessing step of Tri-view Matching. The global layout is structured from left to right and top to bottom, beginning with an input Image Sequence represented as a stack of frames along the time axis T, with spatial axes x and y indicated. This sequence feeds into the Tri-view Matching module, depicted below, where three consecutive frames (k-1, k, k+1) are shown with yellow lines connecting corresponding feature points across them, forming a triangular matching pattern. This module outputs robust correspondences used in subsequent steps.\n\nIn the Tracking stage, located at the top-right, the system estimates camera poses (T_k, T_{k-1}) for each frame using Hybrid Geometric Constraints. A 3D Pointmap is shown with red dots representing feature points, blue dots re-projection points, and red stars 3D points, connected via dashed lines indicating geometric relationships between frames. The tracking process involves a decision node labeled 'Keyframe?' which determines whether the current frame should be added to the map. If yes, it proceeds to the Mapping stage. The tracking loss function L_track is defined as a weighted sum of photometric loss (L_photo), 2D geometric loss (L_2D), and 3D geometric loss (L_3D), with explicit formulas provided: L_2D sums squared differences between projected and observed 2D points; L_3D computes the distance between transformed 3D points and their ground-truth positions; and L_track combines these with hyperparameters λ_p, λ_2D, λ_3D.\n\nThe Mapping stage, shown at the bottom-right, begins with the TUGI (Tri-view Uncertainty-guided Gaussian Initialization) module. This takes the tri-view matches and initializes 3D Gaussians, visualized as colored spheres with parameters (μ_xyz, σ²) indicating mean position and variance. These Gaussians are then rasterized into a 3D Gaussian Representation, shown as a dense, textured point cloud model of the scene. The photometric loss L_photo is computed by comparing the rendered image from this Gaussian model with the ground truth image, using a combination of L1 and SSIM metrics: L_photo = (1−γ)L1(I_t, Î_t) + γL_SSIM(I_t, Î_t), where γ is a weighting factor.\n\nVisual elements include rectangular boxes for modules (e.g., 'Image Sequence', 'Tri-view Matching'), dashed-line arrows for data flow, and a legend specifying point types (red circle: feature points, blue circle: re-projection points, red star: 3D points). The keyframe decision is marked with a diamond-shaped node. Equations are enclosed in rounded rectangles with light blue backgrounds. The overall structure emphasizes a real-time, incremental processing flow from raw images to a high-fidelity 3D representation through robust geometric constraints and uncertainty-aware initialization.", "The figure presents seven distinct architectural patterns for fusing multi-modal inputs using attention mechanisms, arranged in two rows. The top row contains diagrams (a) through (c), and the bottom row contains (d) through (g). Each diagram illustrates a different fusion strategy, with blue and orange rectangular blocks representing input feature sequences from two different modalities. Green rectangular blocks denote output representations, such as classification scores or generative outputs; a single green block indicates a scalar or simple output, while multiple green blocks suggest a sequence or multi-modal output. Dashed boxes represent modules with arbitrary internal architectures.\n\nIn diagram (a) 'Early Summation', three blue and three orange input blocks are summed element-wise via '+' operations, producing a single fused representation that is fed into an 'Attention-based Model' which outputs a single green block.\n\nDiagram (b) 'Early Concatenation' shows the same blue and orange input blocks being concatenated via a '||' operator into a single sequence, which is then processed by an 'Attention-based Model' to produce a single green output block.\n\nDiagram (c) 'Hierarchical' features two separate 'Attention Module' blocks, each processing one modality's input (blue or orange). Their outputs feed into a higher-level 'Model' (dashed box), which produces a single green output. This structure implies a hierarchical processing flow.\n\nDiagram (d) 'Single Cross-attention branch' introduces a cross-attention mechanism. The blue input provides keys (K_i) and values (V_i), while the orange input provides queries (Q_j). These are fed into a 'Cross-attention Module' that generates a single green output block.\n\nDiagram (e) 'Multi-cross attention' extends this by having two cross-attention modules. The first takes K_i, V_i from blue and Q_i from orange; the second takes K_j, V_j from orange and Q_j from blue. Both modules feed into a dashed box labeled 'Multiple output streams or other intermediate modules', indicating flexible downstream processing.\n\nDiagram (f) 'Single-stream to generative output' shows blue inputs going through an 'Attention-based Model' to produce a sequence of green blocks, suggesting a generative output like a text sequence.\n\nFinally, diagram (g) 'Modular multi-stream' shows two 'Attention Module' blocks processing blue and orange inputs respectively. Their outputs feed into 'Module A' (dashed), which in turn feeds into 'Module B' (dashed), producing a single green output. This represents a modular, multi-stream pipeline.\n\nAll connections are directed arrows indicating data flow. The figure uses consistent color coding: blue and orange for inputs, green for outputs, and black text for module labels. The layout is clean and modular, emphasizing the logical progression of data through each fusion type.", "The figure presents a comparative analysis between a baseline method and the proposed VCAR (Visual Comprehension Augmented Reasoning) framework for solving a multimodal question involving visual and textual data. The global layout is divided into two main horizontal sections: the top section illustrates the baseline approach, and the bottom section details the VCAR approach. Each section contains a left-side diagram of the model workflow and a right-side box displaying the generated rationale and description, with a dashed line separating the two methods.\n\nIn the baseline section, two robot-like icons represent models: one gray and one orange. Both receive 'Rationales' as input, indicated by red arrows from a yellow box labeled 'Rationales'. A gray arrow points from these models to a large beige box on the right containing the generated rationale. This rationale incorrectly states that grilled steak costs $10 and mushroom pizza costs $8, leading to a total of $18, marked with a red 'X' to indicate error. The multimodal question at the top asks: 'How much money does Damon need to buy a grilled steak and a mushroom pizza?' with a price list image showing pasta with white sauce ($15), mushroom pizza ($11), grilled steak ($13), and pasta with meat sauce ($12).\n\nIn the VCAR section, the same two robot icons appear, but now they receive different inputs. The gray robot receives 'Descriptions' from a blue box, while the orange robot receives both 'Descriptions' and 'Rationales' from stacked blue and yellow boxes. Blue arrows indicate the flow of descriptions, and a red arrow indicates the flow of rationales. Two gray arrows point from the robots to two boxes on the right: a light blue box labeled 'Description' and a beige box labeled 'Rationale'. The description accurately lists the food items and their correct prices: $15, $11, $13, and $12. The rationale correctly identifies the cost of grilled steak as $13 and mushroom pizza as $11, summing to $24, marked with a green checkmark to indicate correctness.\n\nThe figure visually emphasizes that the baseline method, which only uses rationales, fails due to incorrect visual interpretation, whereas VCAR, which incorporates visual description training, achieves accurate results. The caption explains that VCAR includes an additional visual comprehension task alongside mathematical reasoning, preventing errors from inaccurate visual understanding.", "The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout. The top row contrasts supervised and unpaired methods, while the bottom row compares weakly-supervised and the proposed self-supervised approach. Each panel contains a central deep neural network (DNN) block, depicted as a rounded rectangle with a light blue-to-lavender gradient fill and gray border, labeled 'DNN'. Above each DNN is the predicted output, denoted as \\(\\hat{y}^{(i)}\\), and below is the input, denoted as \\(x^{(i)}\\) or its variants. The panels are labeled (a) through (d) with corresponding descriptive subcaptions.\n\nIn panel (a) 'supervised', a single input \\(x^{(i)}\\) is fed into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow connects \\(\\hat{y}^{(i)}\\) to the ground truth \\(y^{(i)}\\), labeled 'matching loss', indicating supervision via direct comparison between prediction and true complete point cloud.\n\nPanel (b) 'unpaired' shows two inputs: \\(x^{(i)}\\) (partial) and \\(y^{(j)}\\) (complete, possibly from a different object), both feeding into the DNN. Two dashed orange curved arrows emerge: one from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\) labeled 'matching loss', enforcing shape consistency with the input, and another from \\(\\hat{y}^{(i)}\\) to \\(y^{(j)}\\) labeled 'adversarial loss', guiding the prediction to follow the distribution of complete shapes.\n\nPanel (c) 'weakly-supervised' features multiple inputs \\(x_1^{(i)}, x_2^{(i)}, ..., x_k^{(i)}\\) — different partial views of the same object — all processed by the DNN to produce multiple outputs \\(\\hat{y}_1^{(i)}, \\hat{y}_2^{(i)}, ..., \\hat{y}_k^{(i)}\\). A dashed orange curved arrow connects these outputs, labeled 'view-consistency loss', enforcing agreement among completions derived from different views of the same object.\n\nPanel (d) 'Ours' shows a single input \\(x^{(i)}\\) going into the DNN, producing \\(\\hat{y}^{(i)}\\). A dashed orange curved arrow loops back from \\(\\hat{y}^{(i)}\\) to \\(x^{(i)}\\), labeled 'self-supervised loss', indicating that the model is trained using a self-supervised signal derived from the prediction itself, without any external ground truth or additional views. This setup reflects the core contribution: learning from a single partial observation per object instance.\n\nAll connections are represented by solid gray arrows for data flow and dashed orange curved arrows for loss functions. The figure uses consistent visual elements across panels to highlight differences in training signals and data requirements."], 'resolution_list': [[576, 960], [576, 960], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [1008, 576], [768, 720], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
01/30/2026 07:17:11 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 07:17:11 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 07:17:11 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 07:17:11 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 07:17:11 - INFO - __main__ - [INFO] Using model type: Flux2Klein
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory - 🏭 Model Factory Initialized
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Model Type: Flux2Klein
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Pretrained Path: black-forest-labs/FLUX.2-klein-base-9B
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Cache Dir: None
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    VAE Class: AutoencoderKLFlux2
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Transformer Class: Flux2Transformer2DModel
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Text Encoder Class: Qwen3ForCausalLM
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory -    Pipeline Class: Flux2KleinPipeline
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading tokenizer: Qwen2TokenizerFast
01/30/2026 07:17:11 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoder: Qwen3ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 58.25it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 55.81it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 58.05it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 57.80it/s]
01/30/2026 07:17:12 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading VAE: AutoencoderKLFlux2
All model checkpoint weights were used when initializing AutoencoderKLFlux2.

All the weights of AutoencoderKLFlux2 were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKLFlux2 for predictions without further training.
01/30/2026 07:17:12 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading transformer: Flux2Transformer2DModel
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 11915.64it/s]
Instantiating Flux2Transformer2DModel model under default dtype torch.bfloat16.
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 6345.39it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 81.36it/s]
All model checkpoint weights were used when initializing Flux2Transformer2DModel.

All the weights of Flux2Transformer2DModel were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Flux2Transformer2DModel for predictions without further training.
01/30/2026 07:17:13 - INFO - OpenSciDraw.utils.model_factory - [INFO] Fine-tuning the full model ...
01/30/2026 07:17:13 - INFO - OpenSciDraw.utils.model_factory - [INFO] Enabling gradient checkpointing for transformer
01/30/2026 07:17:13 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading scheduler: FlowMatchEulerDiscreteScheduler
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 6579.30it/s]
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 5878.49it/s]
01/30/2026 07:17:13 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoding pipeline: Flux2KleinPipeline
{'is_distilled'} was not found in config. Values will be initialized to default values.
Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00, 4282.09it/s]
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
01/30/2026 07:17:13 - INFO - OpenSciDraw.utils.model_factory - [INFO] VAE scale factor: 16
01/30/2026 07:17:13 - INFO - __main__ - [INFO] DeepSpeed detected - keeping transformer in bf16 for ZeRO-3
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Configuring model devices and offloading
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Using parquet dataset - VAE and text encoder remain on CPU
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
01/30/2026 07:17:13 - INFO - __main__ - [INFO] DeepSpeed mode: transformer stays on CPU, ZeRO-3 will handle placement
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Gradient checkpointing enabled
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Number of trainable parameters: 9078.58M
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Loading dataset
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
⏳ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
⏳ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]Scanning Parquet Files: 100%|██████████| 4/4 [00:00<00:00, 76.06it/s]
✅ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
📊 Data Statistics:
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
01/30/2026 07:17:13 - INFO - __main__ - [INFO] Set DeepSpeed train_micro_batch_size_per_gpu to 1
01/30/2026 07:17:13 - INFO - __main__ - [INFO] No checkpoints found in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k, starting fresh
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
⏳ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]Scanning Parquet Files: 100%|██████████| 4/4 [00:00<00:00, 75.52it/s]
✅ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
📊 Data Statistics:
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
🔍 Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
⏳ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]Scanning Parquet Files: 100%|██████████| 4/4 [00:00<00:00, 70.96it/s]
✅ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
📊 Data Statistics:
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Scanning Parquet Files: 100%|██████████| 4/4 [00:00<00:00, 73.39it/s]
✅ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
📊 Data Statistics:
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Before initializing optimizer states
MA 25.37 GB         Max_MA 29.59 GB         CA 29.6 GB         Max_CA 30 GB 
CPU Virtual Memory:  used = 144.13 GB, percent = 16.6%
After initializing optimizer states
MA 25.37 GB         Max_MA 33.82 GB         CA 38.06 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 145.35 GB, percent = 16.8%
After initializing ZeRO optimizer
MA 25.37 GB         Max_MA 25.37 GB         CA 38.06 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 146.52 GB, percent = 16.9%
01/30/2026 07:17:29 - INFO - __main__ - ***** Running training *****
01/30/2026 07:17:29 - INFO - __main__ -   Num examples = 4803
01/30/2026 07:17:29 - INFO - __main__ -   Num Epochs = 67
01/30/2026 07:17:29 - INFO - __main__ -   Instantaneous batch size per device = 1
01/30/2026 07:17:29 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
01/30/2026 07:17:29 - INFO - __main__ -   Gradient Accumulation steps = 4
01/30/2026 07:17:29 - INFO - __main__ -   Total optimization steps = 5000
Steps:   0%|          | 0/5000 [00:00<?, ?it/s]01/30/2026 07:17:29 - INFO - __main__ - [INFO] Using training iteration function: Flux2Klein_fulltune_train_iteration
01/30/2026 07:17:30 - INFO - __main__ - [INFO] Using validation function: Flux2Klein_fulltune_validation_func_parquet
01/30/2026 07:17:30 - INFO - __main__ - [INFO] Validation every 50 steps
wandb: Loaded settings from
wandb:   /home/v-yuxluo/.config/wandb/settings
wandb: [wandb.login()] Loaded credentials for https://microsoft-research.wandb.io from WANDB_API_KEY.
wandb: Currently logged in as: v-yuxluo to https://microsoft-research.wandb.io. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /home/v-yuxluo/WORK_local/ArXivQwenImage/wandb/run-20260130_071730-5d66cjii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flux2klein_9b_saveh_2015_5k
wandb: ⭐️ View project at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-SaveH
wandb: 🚀 View run at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-SaveH/runs/5d66cjii
01/30/2026 07:17:31 - INFO - __main__ - 
======================================================================
01/30/2026 07:17:31 - INFO - __main__ - Starting Training Loop
01/30/2026 07:17:31 - INFO - __main__ - ======================================================================

[Step 0] Training Debug Info:
  Loss: 0.611523
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0128, std: 0.8984
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0122, std: 1.3438
  Model pred mean: -0.0041, std: 1.2500
  Sigmas: [0.6171875]... (timesteps: [618.0])

[Step 0] Training Debug Info:
  Loss: 1.127975
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0330, std: 1.0000
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0330, std: 1.4141
  Model pred mean: -0.0138, std: 0.9336
  Sigmas: [0.041015625]... (timesteps: [41.0])

[Step 0] Training Debug Info:
  Loss: 0.690811
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0366, std: 0.8711
  Noise mean: 0.0034, std: 0.9961
  Target mean: 0.0400, std: 1.3281
  Model pred mean: 0.0464, std: 1.2266
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 0] Training Debug Info:
  Loss: 1.149871
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0140, std: 1.3750
  Model pred mean: 0.0030, std: 1.3281
  Sigmas: [0.400390625]... (timesteps: [400.0])
Steps:   0%|          | 1/5000 [00:15<22:09:39, 15.96s/it]Steps:   0%|          | 1/5000 [00:15<22:09:39, 15.96s/it, loss=1.1499, lr=2.00e-08]01/30/2026 07:17:45 - INFO - __main__ - 
🔍 Running validation at step 1...
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1 (parquet mode)...
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1...
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 07:17:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.28it/s][A
 11%|█         | 3/28 [00:02<00:20,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.11it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.10it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:10,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:17<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.09it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.09it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.09it/s][A100%|██████████| 28/28 [00:25<00:00,  1.11it/s]
01/30/2026 07:18:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 07:18:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.64it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.14it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.10it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.08it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 07:18:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 07:18:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.57it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:19:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 07:19:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.02it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:19:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 07:19:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:20:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 07:20:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:20:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 07:20:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:21:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 07:21:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:21:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 07:21:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:21:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 07:21:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.02it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:22:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 07:22:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 07:22:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 07:22:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 07:23:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 07:23:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 07:23:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 07:23:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001
01/30/2026 07:23:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

Steps:   0%|          | 2/5000 [06:05<294:18:09, 211.98s/it, loss=1.1499, lr=2.00e-08]Steps:   0%|          | 2/5000 [06:05<294:18:09, 211.98s/it, loss=0.4527, lr=4.00e-08]Steps:   0%|          | 3/5000 [06:14<165:52:31, 119.50s/it, loss=0.4527, lr=4.00e-08]Steps:   0%|          | 3/5000 [06:14<165:52:31, 119.50s/it, loss=1.1278, lr=6.00e-08]Steps:   0%|          | 4/5000 [06:23<105:27:14, 75.99s/it, loss=1.1278, lr=6.00e-08] Steps:   0%|          | 4/5000 [06:23<105:27:14, 75.99s/it, loss=1.0302, lr=8.00e-08]Steps:   0%|          | 5/5000 [06:33<72:16:24, 52.09s/it, loss=1.0302, lr=8.00e-08] Steps:   0%|          | 5/5000 [06:33<72:16:24, 52.09s/it, loss=0.7338, lr=1.00e-07]Steps:   0%|          | 6/5000 [06:43<52:15:15, 37.67s/it, loss=0.7338, lr=1.00e-07]Steps:   0%|          | 6/5000 [06:43<52:15:15, 37.67s/it, loss=0.4885, lr=1.20e-07]Steps:   0%|          | 7/5000 [06:52<39:28:48, 28.47s/it, loss=0.4885, lr=1.20e-07]Steps:   0%|          | 7/5000 [06:52<39:28:48, 28.47s/it, loss=0.5522, lr=1.40e-07]Steps:   0%|          | 8/5000 [07:02<31:06:29, 22.43s/it, loss=0.5522, lr=1.40e-07]Steps:   0%|          | 8/5000 [07:02<31:06:29, 22.43s/it, loss=1.2222, lr=1.60e-07]Steps:   0%|          | 9/5000 [07:11<25:26:03, 18.35s/it, loss=1.2222, lr=1.60e-07]Steps:   0%|          | 9/5000 [07:11<25:26:03, 18.35s/it, loss=1.3824, lr=1.80e-07]Steps:   0%|          | 10/5000 [07:21<21:34:41, 15.57s/it, loss=1.3824, lr=1.80e-07]Steps:   0%|          | 10/5000 [07:21<21:34:41, 15.57s/it, loss=0.6003, lr=2.00e-07]
[Step 10] Training Debug Info:
  Loss: 2.169741
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.8516
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0002, std: 1.3125
  Model pred mean: 0.0242, std: 1.3828
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 10] Training Debug Info:
  Loss: 1.237057
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0270, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0262, std: 1.3594
  Model pred mean: 0.0525, std: 0.8398
  Sigmas: [0.053955078125]... (timesteps: [54.0])

[Step 10] Training Debug Info:
  Loss: 1.564423
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0007, std: 0.8906
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0027, std: 1.3359
  Model pred mean: 0.0332, std: 0.9336
  Sigmas: [0.2109375]... (timesteps: [211.0])

[Step 10] Training Debug Info:
  Loss: 0.564498
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0332, std: 0.9922
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0332, std: 1.4062
  Model pred mean: -0.0182, std: 1.2422
  Sigmas: [0.71875]... (timesteps: [719.0])
Steps:   0%|          | 11/5000 [07:30<18:56:31, 13.67s/it, loss=0.6003, lr=2.00e-07]Steps:   0%|          | 11/5000 [07:30<18:56:31, 13.67s/it, loss=0.5645, lr=2.20e-07]Steps:   0%|          | 12/5000 [07:39<17:03:55, 12.32s/it, loss=0.5645, lr=2.20e-07]Steps:   0%|          | 12/5000 [07:39<17:03:55, 12.32s/it, loss=0.4466, lr=2.40e-07]Steps:   0%|          | 13/5000 [07:48<15:46:32, 11.39s/it, loss=0.4466, lr=2.40e-07]Steps:   0%|          | 13/5000 [07:48<15:46:32, 11.39s/it, loss=1.4349, lr=2.60e-07]Steps:   0%|          | 14/5000 [07:58<15:04:02, 10.88s/it, loss=1.4349, lr=2.60e-07]Steps:   0%|          | 14/5000 [07:58<15:04:02, 10.88s/it, loss=0.8415, lr=2.80e-07]Steps:   0%|          | 15/5000 [08:08<14:32:15, 10.50s/it, loss=0.8415, lr=2.80e-07]Steps:   0%|          | 15/5000 [08:08<14:32:15, 10.50s/it, loss=0.4392, lr=3.00e-07]Steps:   0%|          | 16/5000 [08:17<14:03:03, 10.15s/it, loss=0.4392, lr=3.00e-07]Steps:   0%|          | 16/5000 [08:17<14:03:03, 10.15s/it, loss=0.5407, lr=3.20e-07]Steps:   0%|          | 17/5000 [08:26<13:44:00,  9.92s/it, loss=0.5407, lr=3.20e-07]Steps:   0%|          | 17/5000 [08:26<13:44:00,  9.92s/it, loss=0.4995, lr=3.40e-07]Steps:   0%|          | 18/5000 [08:36<13:29:36,  9.75s/it, loss=0.4995, lr=3.40e-07]Steps:   0%|          | 18/5000 [08:36<13:29:36,  9.75s/it, loss=0.7159, lr=3.60e-07]Steps:   0%|          | 19/5000 [08:45<13:23:15,  9.68s/it, loss=0.7159, lr=3.60e-07]Steps:   0%|          | 19/5000 [08:45<13:23:15,  9.68s/it, loss=1.6410, lr=3.80e-07]Steps:   0%|          | 20/5000 [08:55<13:21:08,  9.65s/it, loss=1.6410, lr=3.80e-07]Steps:   0%|          | 20/5000 [08:55<13:21:08,  9.65s/it, loss=0.4415, lr=4.00e-07]
[Step 20] Training Debug Info:
  Loss: 1.986377
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0071, std: 0.8828
  Noise mean: 0.0043, std: 1.0000
  Target mean: -0.0028, std: 1.3359
  Model pred mean: 0.0245, std: 1.2109
  Sigmas: [0.2353515625]... (timesteps: [235.0])

[Step 20] Training Debug Info:
  Loss: 0.526689
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0035, std: 0.9570
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0023, std: 1.3906
  Model pred mean: 0.0040, std: 1.2656
  Sigmas: [0.703125]... (timesteps: [703.0])

[Step 20] Training Debug Info:
  Loss: 1.729226
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0112, std: 0.9062
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0090, std: 1.3516
  Model pred mean: 0.0277, std: 1.0547
  Sigmas: [0.197265625]... (timesteps: [197.0])

[Step 20] Training Debug Info:
  Loss: 0.618720
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0262, std: 0.9180
  Noise mean: -0.0036, std: 1.0078
  Target mean: 0.0227, std: 1.3594
  Model pred mean: 0.0310, std: 1.2812
  Sigmas: [0.6171875]... (timesteps: [619.0])
Steps:   0%|          | 21/5000 [09:04<13:14:32,  9.57s/it, loss=0.4415, lr=4.00e-07]Steps:   0%|          | 21/5000 [09:04<13:14:32,  9.57s/it, loss=0.6187, lr=4.20e-07]Steps:   0%|          | 22/5000 [09:14<13:16:23,  9.60s/it, loss=0.6187, lr=4.20e-07]Steps:   0%|          | 22/5000 [09:14<13:16:23,  9.60s/it, loss=1.5744, lr=4.40e-07]Steps:   0%|          | 23/5000 [09:23<13:11:58,  9.55s/it, loss=1.5744, lr=4.40e-07]Steps:   0%|          | 23/5000 [09:23<13:11:58,  9.55s/it, loss=1.6670, lr=4.60e-07]Steps:   0%|          | 24/5000 [09:33<13:05:16,  9.47s/it, loss=1.6670, lr=4.60e-07]Steps:   0%|          | 24/5000 [09:33<13:05:16,  9.47s/it, loss=0.5796, lr=4.80e-07]Steps:   0%|          | 25/5000 [09:42<12:58:59,  9.39s/it, loss=0.5796, lr=4.80e-07]Steps:   0%|          | 25/5000 [09:42<12:58:59,  9.39s/it, loss=1.3557, lr=5.00e-07]Steps:   1%|          | 26/5000 [09:51<12:57:14,  9.38s/it, loss=1.3557, lr=5.00e-07]Steps:   1%|          | 26/5000 [09:51<12:57:14,  9.38s/it, loss=0.4925, lr=5.20e-07]Steps:   1%|          | 27/5000 [10:01<12:59:14,  9.40s/it, loss=0.4925, lr=5.20e-07]Steps:   1%|          | 27/5000 [10:01<12:59:14,  9.40s/it, loss=0.5129, lr=5.40e-07]Steps:   1%|          | 28/5000 [10:10<12:57:25,  9.38s/it, loss=0.5129, lr=5.40e-07]Steps:   1%|          | 28/5000 [10:10<12:57:25,  9.38s/it, loss=0.7615, lr=5.60e-07]Steps:   1%|          | 29/5000 [10:20<13:09:24,  9.53s/it, loss=0.7615, lr=5.60e-07]Steps:   1%|          | 29/5000 [10:20<13:09:24,  9.53s/it, loss=0.5489, lr=5.80e-07]Steps:   1%|          | 30/5000 [10:29<13:06:45,  9.50s/it, loss=0.5489, lr=5.80e-07]Steps:   1%|          | 30/5000 [10:29<13:06:45,  9.50s/it, loss=0.4826, lr=6.00e-07]
[Step 30] Training Debug Info:
  Loss: 0.669912
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0019, std: 0.9336
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0036, std: 1.3672
  Model pred mean: 0.0121, std: 1.2812
  Sigmas: [0.53515625]... (timesteps: [535.0])

[Step 30] Training Debug Info:
  Loss: 0.425072
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0097, std: 0.8867
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0086, std: 1.3281
  Model pred mean: 0.0019, std: 1.1953
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 30] Training Debug Info:
  Loss: 0.422036
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0135, std: 0.9023
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0151, std: 1.3516
  Model pred mean: -0.0121, std: 1.1953
  Sigmas: [0.84375]... (timesteps: [844.0])

[Step 30] Training Debug Info:
  Loss: 0.457327
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0011, std: 0.8633
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0017, std: 1.3203
  Model pred mean: 0.0088, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [792.0])
Steps:   1%|          | 31/5000 [10:39<13:04:27,  9.47s/it, loss=0.4826, lr=6.00e-07]Steps:   1%|          | 31/5000 [10:39<13:04:27,  9.47s/it, loss=0.4573, lr=6.20e-07]Steps:   1%|          | 32/5000 [10:48<13:05:52,  9.49s/it, loss=0.4573, lr=6.20e-07]Steps:   1%|          | 32/5000 [10:48<13:05:52,  9.49s/it, loss=0.7255, lr=6.40e-07]Steps:   1%|          | 33/5000 [10:58<13:01:47,  9.44s/it, loss=0.7255, lr=6.40e-07]Steps:   1%|          | 33/5000 [10:58<13:01:47,  9.44s/it, loss=1.4679, lr=6.60e-07]Steps:   1%|          | 34/5000 [11:07<12:57:19,  9.39s/it, loss=1.4679, lr=6.60e-07]Steps:   1%|          | 34/5000 [11:07<12:57:19,  9.39s/it, loss=0.6667, lr=6.80e-07]Steps:   1%|          | 35/5000 [11:16<13:00:06,  9.43s/it, loss=0.6667, lr=6.80e-07]Steps:   1%|          | 35/5000 [11:16<13:00:06,  9.43s/it, loss=0.4240, lr=7.00e-07]Steps:   1%|          | 36/5000 [11:26<13:08:36,  9.53s/it, loss=0.4240, lr=7.00e-07]Steps:   1%|          | 36/5000 [11:26<13:08:36,  9.53s/it, loss=1.2647, lr=7.20e-07]Steps:   1%|          | 37/5000 [11:35<13:03:29,  9.47s/it, loss=1.2647, lr=7.20e-07]Steps:   1%|          | 37/5000 [11:35<13:03:29,  9.47s/it, loss=0.3981, lr=7.40e-07]Steps:   1%|          | 38/5000 [11:45<13:00:24,  9.44s/it, loss=0.3981, lr=7.40e-07]Steps:   1%|          | 38/5000 [11:45<13:00:24,  9.44s/it, loss=0.4725, lr=7.60e-07]Steps:   1%|          | 39/5000 [11:54<13:05:16,  9.50s/it, loss=0.4725, lr=7.60e-07]Steps:   1%|          | 39/5000 [11:54<13:05:16,  9.50s/it, loss=1.2211, lr=7.80e-07]Steps:   1%|          | 40/5000 [12:04<13:03:19,  9.48s/it, loss=1.2211, lr=7.80e-07]Steps:   1%|          | 40/5000 [12:04<13:03:19,  9.48s/it, loss=0.9935, lr=8.00e-07]
[Step 40] Training Debug Info:
  Loss: 0.984781
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0245, std: 0.8984
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0239, std: 1.3438
  Model pred mean: -0.0126, std: 1.2344
  Sigmas: [0.435546875]... (timesteps: [436.0])

[Step 40] Training Debug Info:
  Loss: 0.437951
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0031, std: 0.8789
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0036, std: 1.3281
  Model pred mean: -0.0015, std: 1.1406
  Sigmas: [0.94140625]... (timesteps: [941.0])

[Step 40] Training Debug Info:
  Loss: 1.208472
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0576, std: 0.9180
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0583, std: 1.3594
  Model pred mean: -0.0245, std: 1.0312
  Sigmas: [0.291015625]... (timesteps: [291.0])

[Step 40] Training Debug Info:
  Loss: 0.704198
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0138, std: 0.9062
  Noise mean: 0.0037, std: 0.9961
  Target mean: 0.0176, std: 1.3516
  Model pred mean: 0.0293, std: 1.2266
  Sigmas: [0.57421875]... (timesteps: [576.0])
Steps:   1%|          | 41/5000 [12:13<13:00:26,  9.44s/it, loss=0.9935, lr=8.00e-07]Steps:   1%|          | 41/5000 [12:13<13:00:26,  9.44s/it, loss=0.7042, lr=8.20e-07]Steps:   1%|          | 42/5000 [12:23<13:02:02,  9.46s/it, loss=0.7042, lr=8.20e-07]Steps:   1%|          | 42/5000 [12:23<13:02:02,  9.46s/it, loss=0.4350, lr=8.40e-07]Steps:   1%|          | 43/5000 [12:32<13:01:59,  9.47s/it, loss=0.4350, lr=8.40e-07]Steps:   1%|          | 43/5000 [12:32<13:01:59,  9.47s/it, loss=0.6233, lr=8.60e-07]Steps:   1%|          | 44/5000 [12:42<12:59:58,  9.44s/it, loss=0.6233, lr=8.60e-07]Steps:   1%|          | 44/5000 [12:42<12:59:58,  9.44s/it, loss=1.2942, lr=8.80e-07]Steps:   1%|          | 45/5000 [12:51<13:06:30,  9.52s/it, loss=1.2942, lr=8.80e-07]Steps:   1%|          | 45/5000 [12:51<13:06:30,  9.52s/it, loss=1.2610, lr=9.00e-07]Steps:   1%|          | 46/5000 [13:01<13:01:51,  9.47s/it, loss=1.2610, lr=9.00e-07]Steps:   1%|          | 46/5000 [13:01<13:01:51,  9.47s/it, loss=1.1681, lr=9.20e-07]Steps:   1%|          | 47/5000 [13:10<13:02:16,  9.48s/it, loss=1.1681, lr=9.20e-07]Steps:   1%|          | 47/5000 [13:10<13:02:16,  9.48s/it, loss=0.8171, lr=9.40e-07]Steps:   1%|          | 48/5000 [13:20<13:01:40,  9.47s/it, loss=0.8171, lr=9.40e-07]Steps:   1%|          | 48/5000 [13:20<13:01:40,  9.47s/it, loss=1.1462, lr=9.60e-07]Steps:   1%|          | 49/5000 [13:29<13:03:17,  9.49s/it, loss=1.1462, lr=9.60e-07]Steps:   1%|          | 49/5000 [13:29<13:03:17,  9.49s/it, loss=0.6082, lr=9.80e-07]Steps:   1%|          | 50/5000 [13:38<12:59:33,  9.45s/it, loss=0.6082, lr=9.80e-07]Steps:   1%|          | 50/5000 [13:38<12:59:33,  9.45s/it, loss=0.5230, lr=1.00e-06]01/30/2026 07:31:08 - INFO - __main__ - 
🔍 Running validation at step 50...
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 50 (parquet mode)...
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 50...
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 07:31:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.65it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.18it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.11it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.11it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.09it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.09it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.08it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.08it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.08it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.08it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 07:31:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 07:31:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.25it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 07:32:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 07:32:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:32:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 07:32:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:32:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 07:32:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:33:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 07:33:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:33:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 07:33:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.18it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:34:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 07:34:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:34:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 07:34:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:35:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 07:35:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:35:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 07:35:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.06it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 07:36:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 07:36:14 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.60it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.23it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.11it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.09it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.08it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.07it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.06it/s][A
 43%|████▎     | 12/28 [00:10<00:15,  1.06it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.06it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.06it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.06it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.06it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.06it/s][A100%|██████████| 28/28 [00:26<00:00,  1.07it/s]
01/30/2026 07:36:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050/step000050_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 07:36:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 07:36:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 07:36:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000050
01/30/2026 07:36:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 50] Training Debug Info:
  Loss: 1.166541
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0130, std: 0.9258
  Noise mean: -0.0029, std: 1.0000
  Target mean: 0.0101, std: 1.3594
  Model pred mean: 0.0247, std: 0.8633
  Sigmas: [0.0791015625]... (timesteps: [79.0])

[Step 50] Training Debug Info:
  Loss: 1.204178
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0275, std: 0.9062
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0297, std: 1.3516
  Model pred mean: 0.0354, std: 0.8203
  Sigmas: [0.306640625]... (timesteps: [306.0])

[Step 50] Training Debug Info:
  Loss: 0.720234
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0192, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0193, std: 1.3516
  Model pred mean: 0.0072, std: 1.1016
  Sigmas: [0.5234375]... (timesteps: [525.0])

[Step 50] Training Debug Info:
  Loss: 0.450554
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0359, std: 0.8945
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0347, std: 1.3359
  Model pred mean: -0.0184, std: 1.1562
  Sigmas: [0.80078125]... (timesteps: [802.0])
Steps:   1%|          | 51/5000 [19:25<151:54:19, 110.50s/it, loss=0.5230, lr=1.00e-06]Steps:   1%|          | 51/5000 [19:25<151:54:19, 110.50s/it, loss=0.4506, lr=1.02e-06]Steps:   1%|          | 52/5000 [19:34<110:16:40, 80.23s/it, loss=0.4506, lr=1.02e-06] Steps:   1%|          | 52/5000 [19:34<110:16:40, 80.23s/it, loss=1.2262, lr=1.04e-06]Steps:   1%|          | 53/5000 [19:44<81:02:20, 58.97s/it, loss=1.2262, lr=1.04e-06] Steps:   1%|          | 53/5000 [19:44<81:02:20, 58.97s/it, loss=0.4276, lr=1.06e-06]Steps:   1%|          | 54/5000 [19:53<60:35:26, 44.10s/it, loss=0.4276, lr=1.06e-06]Steps:   1%|          | 54/5000 [19:53<60:35:26, 44.10s/it, loss=0.6004, lr=1.08e-06]Steps:   1%|          | 55/5000 [20:02<46:13:47, 33.66s/it, loss=0.6004, lr=1.08e-06]Steps:   1%|          | 55/5000 [20:02<46:13:47, 33.66s/it, loss=1.2553, lr=1.10e-06]Steps:   1%|          | 56/5000 [20:12<36:13:07, 26.37s/it, loss=1.2553, lr=1.10e-06]Steps:   1%|          | 56/5000 [20:12<36:13:07, 26.37s/it, loss=1.2446, lr=1.12e-06]Steps:   1%|          | 57/5000 [20:21<29:14:57, 21.30s/it, loss=1.2446, lr=1.12e-06]Steps:   1%|          | 57/5000 [20:21<29:14:57, 21.30s/it, loss=0.7678, lr=1.14e-06]Steps:   1%|          | 58/5000 [20:31<24:17:18, 17.69s/it, loss=0.7678, lr=1.14e-06]Steps:   1%|          | 58/5000 [20:31<24:17:18, 17.69s/it, loss=1.1439, lr=1.16e-06]Steps:   1%|          | 59/5000 [20:40<20:50:08, 15.18s/it, loss=1.1439, lr=1.16e-06]Steps:   1%|          | 59/5000 [20:40<20:50:08, 15.18s/it, loss=0.3906, lr=1.18e-06]Steps:   1%|          | 60/5000 [20:49<18:27:55, 13.46s/it, loss=0.3906, lr=1.18e-06]Steps:   1%|          | 60/5000 [20:49<18:27:55, 13.46s/it, loss=0.4190, lr=1.20e-06]
[Step 60] Training Debug Info:
  Loss: 0.571533
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0153, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0154, std: 1.3672
  Model pred mean: -0.0162, std: 1.1797
  Sigmas: [0.6015625]... (timesteps: [601.0])

[Step 60] Training Debug Info:
  Loss: 0.419203
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0057, std: 0.8711
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0025, std: 1.3281
  Model pred mean: -0.0006, std: 1.1797
  Sigmas: [0.7890625]... (timesteps: [788.0])

[Step 60] Training Debug Info:
  Loss: 0.636085
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0154, std: 0.8789
  Noise mean: -0.0021, std: 1.0000
  Target mean: 0.0134, std: 1.3359
  Model pred mean: 0.0239, std: 1.1328
  Sigmas: [0.59375]... (timesteps: [592.0])

[Step 60] Training Debug Info:
  Loss: 0.399323
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0417, std: 0.9102
  Noise mean: 0.0056, std: 1.0000
  Target mean: 0.0474, std: 1.3516
  Model pred mean: 0.0337, std: 1.1797
  Sigmas: [0.8515625]... (timesteps: [852.0])
Steps:   1%|          | 61/5000 [20:59<16:49:43, 12.27s/it, loss=0.4190, lr=1.20e-06]Steps:   1%|          | 61/5000 [20:59<16:49:43, 12.27s/it, loss=0.3993, lr=1.22e-06]Steps:   1%|          | 62/5000 [21:08<15:37:39, 11.39s/it, loss=0.3993, lr=1.22e-06]Steps:   1%|          | 62/5000 [21:08<15:37:39, 11.39s/it, loss=1.1974, lr=1.24e-06]Steps:   1%|▏         | 63/5000 [21:18<14:52:16, 10.84s/it, loss=1.1974, lr=1.24e-06]Steps:   1%|▏         | 63/5000 [21:18<14:52:16, 10.84s/it, loss=0.4167, lr=1.26e-06]Steps:   1%|▏         | 64/5000 [21:27<14:14:39, 10.39s/it, loss=0.4167, lr=1.26e-06]Steps:   1%|▏         | 64/5000 [21:27<14:14:39, 10.39s/it, loss=0.4660, lr=1.28e-06]Steps:   1%|▏         | 65/5000 [21:37<13:53:09, 10.13s/it, loss=0.4660, lr=1.28e-06]Steps:   1%|▏         | 65/5000 [21:37<13:53:09, 10.13s/it, loss=0.3954, lr=1.30e-06]Steps:   1%|▏         | 66/5000 [21:46<13:33:17,  9.89s/it, loss=0.3954, lr=1.30e-06]Steps:   1%|▏         | 66/5000 [21:46<13:33:17,  9.89s/it, loss=1.0698, lr=1.32e-06]Steps:   1%|▏         | 67/5000 [21:55<13:22:33,  9.76s/it, loss=1.0698, lr=1.32e-06]Steps:   1%|▏         | 67/5000 [21:55<13:22:33,  9.76s/it, loss=0.6706, lr=1.34e-06]Steps:   1%|▏         | 68/5000 [22:05<13:13:21,  9.65s/it, loss=0.6706, lr=1.34e-06]Steps:   1%|▏         | 68/5000 [22:05<13:13:21,  9.65s/it, loss=1.2267, lr=1.36e-06]Steps:   1%|▏         | 69/5000 [22:14<13:10:43,  9.62s/it, loss=1.2267, lr=1.36e-06]Steps:   1%|▏         | 69/5000 [22:14<13:10:43,  9.62s/it, loss=0.8052, lr=1.38e-06]Steps:   1%|▏         | 70/5000 [22:24<13:02:48,  9.53s/it, loss=0.8052, lr=1.38e-06]Steps:   1%|▏         | 70/5000 [22:24<13:02:48,  9.53s/it, loss=0.3886, lr=1.40e-06]
[Step 70] Training Debug Info:
  Loss: 0.724870
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0121, std: 0.8789
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0117, std: 1.3359
  Model pred mean: 0.0139, std: 1.0078
  Sigmas: [0.54296875]... (timesteps: [544.0])

[Step 70] Training Debug Info:
  Loss: 0.449069
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0181, std: 0.8672
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0171, std: 1.3203
  Model pred mean: 0.0149, std: 1.1484
  Sigmas: [0.74609375]... (timesteps: [747.0])

[Step 70] Training Debug Info:
  Loss: 0.504894
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0131, std: 0.9844
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0124, std: 1.4062
  Model pred mean: -0.0200, std: 1.2266
  Sigmas: [0.703125]... (timesteps: [705.0])

[Step 70] Training Debug Info:
  Loss: 0.530752
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0016, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0024, std: 1.3516
  Model pred mean: -0.0089, std: 1.1641
  Sigmas: [0.66015625]... (timesteps: [659.0])
Steps:   1%|▏         | 71/5000 [22:33<13:01:26,  9.51s/it, loss=0.3886, lr=1.40e-06]Steps:   1%|▏         | 71/5000 [22:33<13:01:26,  9.51s/it, loss=0.5308, lr=1.42e-06]Steps:   1%|▏         | 72/5000 [22:42<12:56:30,  9.45s/it, loss=0.5308, lr=1.42e-06]Steps:   1%|▏         | 72/5000 [22:42<12:56:30,  9.45s/it, loss=0.6784, lr=1.44e-06]Steps:   1%|▏         | 73/5000 [22:52<12:54:55,  9.44s/it, loss=0.6784, lr=1.44e-06]Steps:   1%|▏         | 73/5000 [22:52<12:54:55,  9.44s/it, loss=0.5750, lr=1.46e-06]Steps:   1%|▏         | 74/5000 [23:02<13:03:11,  9.54s/it, loss=0.5750, lr=1.46e-06]Steps:   1%|▏         | 74/5000 [23:02<13:03:11,  9.54s/it, loss=0.6555, lr=1.48e-06]Steps:   2%|▏         | 75/5000 [23:07<11:11:54,  8.19s/it, loss=0.6555, lr=1.48e-06]Steps:   2%|▏         | 75/5000 [23:07<11:11:54,  8.19s/it, loss=0.4895, lr=1.50e-06]01/30/2026 07:40:36 - INFO - __main__ - 
==================================================
01/30/2026 07:40:36 - INFO - __main__ - Epoch 0 completed: avg_loss = 0.7928
01/30/2026 07:40:36 - INFO - __main__ - ==================================================

Steps:   2%|▏         | 76/5000 [23:17<11:56:10,  8.73s/it, loss=0.4895, lr=1.50e-06]Steps:   2%|▏         | 76/5000 [23:17<11:56:10,  8.73s/it, loss=1.1186, lr=1.52e-06]Steps:   2%|▏         | 77/5000 [23:26<12:10:45,  8.91s/it, loss=1.1186, lr=1.52e-06]Steps:   2%|▏         | 77/5000 [23:26<12:10:45,  8.91s/it, loss=0.8169, lr=1.54e-06]Steps:   2%|▏         | 78/5000 [23:35<12:23:33,  9.06s/it, loss=0.8169, lr=1.54e-06]Steps:   2%|▏         | 78/5000 [23:35<12:23:33,  9.06s/it, loss=1.1020, lr=1.56e-06]Steps:   2%|▏         | 79/5000 [23:45<12:36:09,  9.22s/it, loss=1.1020, lr=1.56e-06]Steps:   2%|▏         | 79/5000 [23:45<12:36:09,  9.22s/it, loss=1.0434, lr=1.58e-06]Steps:   2%|▏         | 80/5000 [23:54<12:40:41,  9.28s/it, loss=1.0434, lr=1.58e-06]Steps:   2%|▏         | 80/5000 [23:54<12:40:41,  9.28s/it, loss=0.5862, lr=1.60e-06]
[Step 80] Training Debug Info:
  Loss: 1.193405
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0258, std: 0.9258
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0280, std: 1.3672
  Model pred mean: 0.0237, std: 0.8164
  Sigmas: [0.1298828125]... (timesteps: [130.0])

[Step 80] Training Debug Info:
  Loss: 1.204526
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0162, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0150, std: 1.3516
  Model pred mean: 0.0112, std: 0.8086
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 80] Training Debug Info:
  Loss: 0.362029
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0063, std: 0.8867
  Noise mean: 0.0029, std: 1.0000
  Target mean: 0.0092, std: 1.3359
  Model pred mean: 0.0045, std: 1.1953
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 80] Training Debug Info:
  Loss: 0.438502
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0096, std: 0.8984
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0068, std: 1.3438
  Model pred mean: 0.0055, std: 1.1562
  Sigmas: [0.90234375]... (timesteps: [901.0])
Steps:   2%|▏         | 81/5000 [24:04<12:49:51,  9.39s/it, loss=0.5862, lr=1.60e-06]Steps:   2%|▏         | 81/5000 [24:04<12:49:51,  9.39s/it, loss=0.4385, lr=1.62e-06]Steps:   2%|▏         | 82/5000 [24:13<12:49:21,  9.39s/it, loss=0.4385, lr=1.62e-06]Steps:   2%|▏         | 82/5000 [24:13<12:49:21,  9.39s/it, loss=0.5832, lr=1.64e-06]Steps:   2%|▏         | 83/5000 [24:23<12:57:16,  9.48s/it, loss=0.5832, lr=1.64e-06]Steps:   2%|▏         | 83/5000 [24:23<12:57:16,  9.48s/it, loss=0.4410, lr=1.66e-06]Steps:   2%|▏         | 84/5000 [24:32<12:53:58,  9.45s/it, loss=0.4410, lr=1.66e-06]Steps:   2%|▏         | 84/5000 [24:32<12:53:58,  9.45s/it, loss=1.0447, lr=1.68e-06]Steps:   2%|▏         | 85/5000 [24:42<12:57:25,  9.49s/it, loss=1.0447, lr=1.68e-06]Steps:   2%|▏         | 85/5000 [24:42<12:57:25,  9.49s/it, loss=0.5727, lr=1.70e-06]Steps:   2%|▏         | 86/5000 [24:51<12:51:32,  9.42s/it, loss=0.5727, lr=1.70e-06]Steps:   2%|▏         | 86/5000 [24:51<12:51:32,  9.42s/it, loss=0.4965, lr=1.72e-06]Steps:   2%|▏         | 87/5000 [25:01<12:47:14,  9.37s/it, loss=0.4965, lr=1.72e-06]Steps:   2%|▏         | 87/5000 [25:01<12:47:14,  9.37s/it, loss=1.0082, lr=1.74e-06]Steps:   2%|▏         | 88/5000 [25:10<12:48:05,  9.38s/it, loss=1.0082, lr=1.74e-06]Steps:   2%|▏         | 88/5000 [25:10<12:48:05,  9.38s/it, loss=1.1736, lr=1.76e-06]Steps:   2%|▏         | 89/5000 [25:19<12:44:37,  9.34s/it, loss=1.1736, lr=1.76e-06]Steps:   2%|▏         | 89/5000 [25:19<12:44:37,  9.34s/it, loss=0.6519, lr=1.78e-06]Steps:   2%|▏         | 90/5000 [25:29<12:45:46,  9.36s/it, loss=0.6519, lr=1.78e-06]Steps:   2%|▏         | 90/5000 [25:29<12:45:46,  9.36s/it, loss=0.4109, lr=1.80e-06]
[Step 90] Training Debug Info:
  Loss: 0.621887
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0086, std: 0.9727
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0107, std: 1.3984
  Model pred mean: -0.0101, std: 1.1406
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 90] Training Debug Info:
  Loss: 0.684308
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0684, std: 0.9336
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0703, std: 1.3672
  Model pred mean: 0.0640, std: 1.0859
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 90] Training Debug Info:
  Loss: 1.030732
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0099, std: 0.9453
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0123, std: 1.3750
  Model pred mean: 0.0020, std: 0.9258
  Sigmas: [0.279296875]... (timesteps: [279.0])

[Step 90] Training Debug Info:
  Loss: 0.820910
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.9297
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0031, std: 1.3672
  Model pred mean: 0.0016, std: 1.0234
  Sigmas: [0.390625]... (timesteps: [390.0])
Steps:   2%|▏         | 91/5000 [25:38<12:50:07,  9.41s/it, loss=0.4109, lr=1.80e-06]Steps:   2%|▏         | 91/5000 [25:38<12:50:07,  9.41s/it, loss=0.8209, lr=1.82e-06]Steps:   2%|▏         | 92/5000 [25:48<12:49:42,  9.41s/it, loss=0.8209, lr=1.82e-06]Steps:   2%|▏         | 92/5000 [25:48<12:49:42,  9.41s/it, loss=0.8319, lr=1.84e-06]Steps:   2%|▏         | 93/5000 [25:57<12:50:37,  9.42s/it, loss=0.8319, lr=1.84e-06]Steps:   2%|▏         | 93/5000 [25:57<12:50:37,  9.42s/it, loss=0.6548, lr=1.86e-06]Steps:   2%|▏         | 94/5000 [26:07<12:56:16,  9.49s/it, loss=0.6548, lr=1.86e-06]Steps:   2%|▏         | 94/5000 [26:07<12:56:16,  9.49s/it, loss=1.1022, lr=1.88e-06]Steps:   2%|▏         | 95/5000 [26:16<12:58:06,  9.52s/it, loss=1.1022, lr=1.88e-06]Steps:   2%|▏         | 95/5000 [26:16<12:58:06,  9.52s/it, loss=0.4319, lr=1.90e-06]Steps:   2%|▏         | 96/5000 [26:26<12:55:28,  9.49s/it, loss=0.4319, lr=1.90e-06]Steps:   2%|▏         | 96/5000 [26:26<12:55:28,  9.49s/it, loss=1.0929, lr=1.92e-06]Steps:   2%|▏         | 97/5000 [26:35<12:50:37,  9.43s/it, loss=1.0929, lr=1.92e-06]Steps:   2%|▏         | 97/5000 [26:35<12:50:37,  9.43s/it, loss=0.6089, lr=1.94e-06]Steps:   2%|▏         | 98/5000 [26:44<12:47:35,  9.40s/it, loss=0.6089, lr=1.94e-06]Steps:   2%|▏         | 98/5000 [26:44<12:47:35,  9.40s/it, loss=1.1448, lr=1.96e-06]Steps:   2%|▏         | 99/5000 [26:54<12:45:02,  9.37s/it, loss=1.1448, lr=1.96e-06]Steps:   2%|▏         | 99/5000 [26:54<12:45:02,  9.37s/it, loss=0.8166, lr=1.98e-06]Steps:   2%|▏         | 100/5000 [27:03<12:45:08,  9.37s/it, loss=0.8166, lr=1.98e-06]Steps:   2%|▏         | 100/5000 [27:03<12:45:08,  9.37s/it, loss=1.1759, lr=2.00e-06]01/30/2026 07:44:32 - INFO - __main__ - 
[Step 100] ✅ Loss in normal range (1.1759)
01/30/2026 07:44:32 - INFO - __main__ -   Loss avg (last 100): 0.7963
01/30/2026 07:44:32 - INFO - __main__ -   Loss range: [0.3886, 1.6670]
01/30/2026 07:44:32 - INFO - __main__ - 
🔍 Running validation at step 100...
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 100 (parquet mode)...
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 100...
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 07:44:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.09it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.09it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 07:45:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 07:45:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.64it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.10it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.08it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 07:45:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 07:45:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.57it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.05it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.04it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:45:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 07:45:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:46:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 07:46:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:46:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 07:46:50 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:47:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 07:47:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:47:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 07:47:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 07:48:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 07:48:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.03it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:48:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 07:48:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:49:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 07:49:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.62it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 07:49:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 07:49:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 07:50:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100/step000100_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 07:50:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 07:50:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 07:50:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000100
01/30/2026 07:50:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 100] Training Debug Info:
  Loss: 0.829411
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0044, std: 0.8867
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0056, std: 1.3359
  Model pred mean: 0.0062, std: 0.9531
  Sigmas: [0.4609375]... (timesteps: [461.0])

[Step 100] Training Debug Info:
  Loss: 0.775920
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0100, std: 0.8750
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0104, std: 1.3281
  Model pred mean: -0.0133, std: 0.9883
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 100] Training Debug Info:
  Loss: 0.567441
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0089, std: 0.8828
  Noise mean: 0.0049, std: 1.0000
  Target mean: 0.0139, std: 1.3359
  Model pred mean: 0.0096, std: 1.1250
  Sigmas: [0.625]... (timesteps: [624.0])

[Step 100] Training Debug Info:
  Loss: 0.621220
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0154, std: 0.9062
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0139, std: 1.3516
  Model pred mean: -0.0058, std: 1.0859
  Sigmas: [0.953125]... (timesteps: [953.0])
Steps:   2%|▏         | 101/5000 [32:51<150:49:02, 110.83s/it, loss=1.1759, lr=2.00e-06]Steps:   2%|▏         | 101/5000 [32:51<150:49:02, 110.83s/it, loss=0.6212, lr=2.02e-06]Steps:   2%|▏         | 102/5000 [33:00<109:24:01, 80.41s/it, loss=0.6212, lr=2.02e-06] Steps:   2%|▏         | 102/5000 [33:00<109:24:01, 80.41s/it, loss=1.0548, lr=2.04e-06]Steps:   2%|▏         | 103/5000 [33:09<80:23:11, 59.10s/it, loss=1.0548, lr=2.04e-06] Steps:   2%|▏         | 103/5000 [33:09<80:23:11, 59.10s/it, loss=0.9853, lr=2.06e-06]Steps:   2%|▏         | 104/5000 [33:19<60:07:41, 44.21s/it, loss=0.9853, lr=2.06e-06]Steps:   2%|▏         | 104/5000 [33:19<60:07:41, 44.21s/it, loss=1.1229, lr=2.08e-06]Steps:   2%|▏         | 105/5000 [33:28<45:56:38, 33.79s/it, loss=1.1229, lr=2.08e-06]Steps:   2%|▏         | 105/5000 [33:28<45:56:38, 33.79s/it, loss=0.4573, lr=2.10e-06]Steps:   2%|▏         | 106/5000 [33:38<35:56:43, 26.44s/it, loss=0.4573, lr=2.10e-06]Steps:   2%|▏         | 106/5000 [33:38<35:56:43, 26.44s/it, loss=0.9439, lr=2.12e-06]Steps:   2%|▏         | 107/5000 [33:47<29:06:39, 21.42s/it, loss=0.9439, lr=2.12e-06]Steps:   2%|▏         | 107/5000 [33:47<29:06:39, 21.42s/it, loss=1.0469, lr=2.14e-06]Steps:   2%|▏         | 108/5000 [33:57<24:17:20, 17.87s/it, loss=1.0469, lr=2.14e-06]Steps:   2%|▏         | 108/5000 [33:57<24:17:20, 17.87s/it, loss=1.2095, lr=2.16e-06]Steps:   2%|▏         | 109/5000 [34:06<20:47:30, 15.30s/it, loss=1.2095, lr=2.16e-06]Steps:   2%|▏         | 109/5000 [34:06<20:47:30, 15.30s/it, loss=0.7863, lr=2.18e-06]Steps:   2%|▏         | 110/5000 [34:15<18:20:21, 13.50s/it, loss=0.7863, lr=2.18e-06]Steps:   2%|▏         | 110/5000 [34:15<18:20:21, 13.50s/it, loss=1.1663, lr=2.20e-06]
[Step 110] Training Debug Info:
  Loss: 0.687776
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0344, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0342, std: 1.3672
  Model pred mean: 0.0281, std: 1.0781
  Sigmas: [0.51171875]... (timesteps: [513.0])

[Step 110] Training Debug Info:
  Loss: 1.146817
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0280, std: 0.9219
  Noise mean: -0.0002, std: 0.9961
  Target mean: -0.0282, std: 1.3594
  Model pred mean: -0.0278, std: 0.8359
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 110] Training Debug Info:
  Loss: 1.049545
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0067, std: 0.8945
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0094, std: 1.3359
  Model pred mean: 0.0044, std: 0.8438
  Sigmas: [0.02001953125]... (timesteps: [20.0])

[Step 110] Training Debug Info:
  Loss: 0.446997
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0095, std: 0.8867
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0090, std: 1.3359
  Model pred mean: -0.0088, std: 1.1562
  Sigmas: [0.7421875]... (timesteps: [744.0])
Steps:   2%|▏         | 111/5000 [34:25<16:41:53, 12.30s/it, loss=1.1663, lr=2.20e-06]Steps:   2%|▏         | 111/5000 [34:25<16:41:53, 12.30s/it, loss=0.4470, lr=2.22e-06]Steps:   2%|▏         | 112/5000 [34:34<15:26:54, 11.38s/it, loss=0.4470, lr=2.22e-06]Steps:   2%|▏         | 112/5000 [34:34<15:26:54, 11.38s/it, loss=0.3627, lr=2.24e-06]Steps:   2%|▏         | 113/5000 [34:44<14:38:49, 10.79s/it, loss=0.3627, lr=2.24e-06]Steps:   2%|▏         | 113/5000 [34:44<14:38:49, 10.79s/it, loss=0.8857, lr=2.26e-06]Steps:   2%|▏         | 114/5000 [34:53<14:12:32, 10.47s/it, loss=0.8857, lr=2.26e-06]Steps:   2%|▏         | 114/5000 [34:53<14:12:32, 10.47s/it, loss=1.0762, lr=2.28e-06]Steps:   2%|▏         | 115/5000 [35:03<13:53:19, 10.24s/it, loss=1.0762, lr=2.28e-06]Steps:   2%|▏         | 115/5000 [35:03<13:53:19, 10.24s/it, loss=0.8739, lr=2.30e-06]Steps:   2%|▏         | 116/5000 [35:12<13:32:18,  9.98s/it, loss=0.8739, lr=2.30e-06]Steps:   2%|▏         | 116/5000 [35:12<13:32:18,  9.98s/it, loss=0.4162, lr=2.32e-06]Steps:   2%|▏         | 117/5000 [35:22<13:16:28,  9.79s/it, loss=0.4162, lr=2.32e-06]Steps:   2%|▏         | 117/5000 [35:22<13:16:28,  9.79s/it, loss=1.1270, lr=2.34e-06]Steps:   2%|▏         | 118/5000 [35:31<13:06:14,  9.66s/it, loss=1.1270, lr=2.34e-06]Steps:   2%|▏         | 118/5000 [35:31<13:06:14,  9.66s/it, loss=0.6769, lr=2.36e-06]Steps:   2%|▏         | 119/5000 [35:41<12:59:42,  9.58s/it, loss=0.6769, lr=2.36e-06]Steps:   2%|▏         | 119/5000 [35:41<12:59:42,  9.58s/it, loss=0.3901, lr=2.38e-06]Steps:   2%|▏         | 120/5000 [35:50<13:01:13,  9.61s/it, loss=0.3901, lr=2.38e-06]Steps:   2%|▏         | 120/5000 [35:50<13:01:13,  9.61s/it, loss=0.4462, lr=2.40e-06]
[Step 120] Training Debug Info:
  Loss: 0.396935
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0001, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0009, std: 1.3516
  Model pred mean: 0.0018, std: 1.2031
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.811703
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0078, std: 0.8945
  Noise mean: -0.0021, std: 0.9961
  Target mean: -0.0098, std: 1.3359
  Model pred mean: -0.0164, std: 1.0234
  Sigmas: [0.43359375]... (timesteps: [433.0])

[Step 120] Training Debug Info:
  Loss: 0.405067
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0134, std: 0.8789
  Noise mean: -0.0043, std: 1.0000
  Target mean: 0.0092, std: 1.3281
  Model pred mean: 0.0186, std: 1.1719
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.353385
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0291, std: 0.9297
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0300, std: 1.3672
  Model pred mean: -0.0210, std: 1.2109
  Sigmas: [0.82421875]... (timesteps: [826.0])
Steps:   2%|▏         | 121/5000 [36:00<13:00:34,  9.60s/it, loss=0.4462, lr=2.40e-06]Steps:   2%|▏         | 121/5000 [36:00<13:00:34,  9.60s/it, loss=0.3534, lr=2.42e-06]Steps:   2%|▏         | 122/5000 [36:09<12:55:49,  9.54s/it, loss=0.3534, lr=2.42e-06]Steps:   2%|▏         | 122/5000 [36:09<12:55:49,  9.54s/it, loss=1.0368, lr=2.44e-06]Steps:   2%|▏         | 123/5000 [36:19<12:54:12,  9.52s/it, loss=1.0368, lr=2.44e-06]Steps:   2%|▏         | 123/5000 [36:19<12:54:12,  9.52s/it, loss=0.6945, lr=2.46e-06]Steps:   2%|▏         | 124/5000 [36:28<12:49:19,  9.47s/it, loss=0.6945, lr=2.46e-06]Steps:   2%|▏         | 124/5000 [36:28<12:49:19,  9.47s/it, loss=1.0640, lr=2.48e-06]Steps:   2%|▎         | 125/5000 [36:37<12:47:01,  9.44s/it, loss=1.0640, lr=2.48e-06]Steps:   2%|▎         | 125/5000 [36:37<12:47:01,  9.44s/it, loss=0.4344, lr=2.50e-06]Steps:   3%|▎         | 126/5000 [36:47<12:44:34,  9.41s/it, loss=0.4344, lr=2.50e-06]Steps:   3%|▎         | 126/5000 [36:47<12:44:34,  9.41s/it, loss=1.1079, lr=2.52e-06]Steps:   3%|▎         | 127/5000 [36:56<12:48:58,  9.47s/it, loss=1.1079, lr=2.52e-06]Steps:   3%|▎         | 127/5000 [36:56<12:48:58,  9.47s/it, loss=0.5777, lr=2.54e-06]Steps:   3%|▎         | 128/5000 [37:06<12:55:07,  9.55s/it, loss=0.5777, lr=2.54e-06]Steps:   3%|▎         | 128/5000 [37:06<12:55:07,  9.55s/it, loss=0.4475, lr=2.56e-06]Steps:   3%|▎         | 129/5000 [37:15<12:47:19,  9.45s/it, loss=0.4475, lr=2.56e-06]Steps:   3%|▎         | 129/5000 [37:15<12:47:19,  9.45s/it, loss=0.6623, lr=2.58e-06]Steps:   3%|▎         | 130/5000 [37:25<12:48:40,  9.47s/it, loss=0.6623, lr=2.58e-06]Steps:   3%|▎         | 130/5000 [37:25<12:48:40,  9.47s/it, loss=1.2125, lr=2.60e-06]
[Step 130] Training Debug Info:
  Loss: 0.575635
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0510, std: 0.9219
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0476, std: 1.3594
  Model pred mean: -0.0505, std: 1.1172
  Sigmas: [0.546875]... (timesteps: [547.0])

[Step 130] Training Debug Info:
  Loss: 1.146576
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0194, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0195, std: 1.3516
  Model pred mean: -0.0145, std: 0.8320
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 130] Training Debug Info:
  Loss: 1.144956
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0156, std: 0.9219
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0161, std: 1.3594
  Model pred mean: -0.0092, std: 0.8438
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 130] Training Debug Info:
  Loss: 0.346445
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0349, std: 0.9258
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0356, std: 1.3594
  Model pred mean: 0.0322, std: 1.2031
  Sigmas: [0.93359375]... (timesteps: [935.0])
Steps:   3%|▎         | 131/5000 [37:34<12:42:15,  9.39s/it, loss=1.2125, lr=2.60e-06]Steps:   3%|▎         | 131/5000 [37:34<12:42:15,  9.39s/it, loss=0.3464, lr=2.62e-06]Steps:   3%|▎         | 132/5000 [37:43<12:41:57,  9.39s/it, loss=0.3464, lr=2.62e-06]Steps:   3%|▎         | 132/5000 [37:43<12:41:57,  9.39s/it, loss=0.8502, lr=2.64e-06]Steps:   3%|▎         | 133/5000 [37:53<12:46:09,  9.45s/it, loss=0.8502, lr=2.64e-06]Steps:   3%|▎         | 133/5000 [37:53<12:46:09,  9.45s/it, loss=1.0515, lr=2.66e-06]Steps:   3%|▎         | 134/5000 [38:02<12:45:14,  9.44s/it, loss=1.0515, lr=2.66e-06]Steps:   3%|▎         | 134/5000 [38:02<12:45:14,  9.44s/it, loss=0.7608, lr=2.68e-06]Steps:   3%|▎         | 135/5000 [38:12<12:42:19,  9.40s/it, loss=0.7608, lr=2.68e-06]Steps:   3%|▎         | 135/5000 [38:12<12:42:19,  9.40s/it, loss=0.6308, lr=2.70e-06]Steps:   3%|▎         | 136/5000 [38:21<12:42:51,  9.41s/it, loss=0.6308, lr=2.70e-06]Steps:   3%|▎         | 136/5000 [38:21<12:42:51,  9.41s/it, loss=0.8474, lr=2.72e-06]Steps:   3%|▎         | 137/5000 [38:31<12:43:02,  9.41s/it, loss=0.8474, lr=2.72e-06]Steps:   3%|▎         | 137/5000 [38:31<12:43:02,  9.41s/it, loss=0.4784, lr=2.74e-06]Steps:   3%|▎         | 138/5000 [38:40<12:39:35,  9.37s/it, loss=0.4784, lr=2.74e-06]Steps:   3%|▎         | 138/5000 [38:40<12:39:35,  9.37s/it, loss=1.1058, lr=2.76e-06]Steps:   3%|▎         | 139/5000 [38:49<12:38:03,  9.36s/it, loss=1.1058, lr=2.76e-06]Steps:   3%|▎         | 139/5000 [38:49<12:38:03,  9.36s/it, loss=0.7940, lr=2.78e-06]Steps:   3%|▎         | 140/5000 [38:59<12:45:43,  9.45s/it, loss=0.7940, lr=2.78e-06]Steps:   3%|▎         | 140/5000 [38:59<12:45:43,  9.45s/it, loss=1.0612, lr=2.80e-06]
[Step 140] Training Debug Info:
  Loss: 0.751051
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0211, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0228, std: 1.3438
  Model pred mean: -0.0220, std: 1.0234
  Sigmas: [0.474609375]... (timesteps: [474.0])

[Step 140] Training Debug Info:
  Loss: 0.605377
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0347, std: 0.9414
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0356, std: 1.3750
  Model pred mean: -0.0217, std: 1.1172
  Sigmas: [0.9296875]... (timesteps: [931.0])

[Step 140] Training Debug Info:
  Loss: 0.531006
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0190, std: 1.0078
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0225, std: 1.4219
  Model pred mean: -0.0025, std: 1.2109
  Sigmas: [0.8515625]... (timesteps: [851.0])

[Step 140] Training Debug Info:
  Loss: 0.388391
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0012, std: 0.9492
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0034, std: 1.3828
  Model pred mean: -0.0014, std: 1.2188
  Sigmas: [0.8125]... (timesteps: [811.0])
Steps:   3%|▎         | 141/5000 [39:08<12:41:30,  9.40s/it, loss=1.0612, lr=2.80e-06]Steps:   3%|▎         | 141/5000 [39:08<12:41:30,  9.40s/it, loss=0.3884, lr=2.82e-06]Steps:   3%|▎         | 142/5000 [39:17<12:39:00,  9.37s/it, loss=0.3884, lr=2.82e-06]Steps:   3%|▎         | 142/5000 [39:17<12:39:00,  9.37s/it, loss=0.9588, lr=2.84e-06]Steps:   3%|▎         | 143/5000 [39:27<12:41:53,  9.41s/it, loss=0.9588, lr=2.84e-06]Steps:   3%|▎         | 143/5000 [39:27<12:41:53,  9.41s/it, loss=1.1536, lr=2.86e-06]Steps:   3%|▎         | 144/5000 [39:36<12:44:16,  9.44s/it, loss=1.1536, lr=2.86e-06]Steps:   3%|▎         | 144/5000 [39:36<12:44:16,  9.44s/it, loss=1.0222, lr=2.88e-06]Steps:   3%|▎         | 145/5000 [39:46<12:41:55,  9.42s/it, loss=1.0222, lr=2.88e-06]Steps:   3%|▎         | 145/5000 [39:46<12:41:55,  9.42s/it, loss=0.5779, lr=2.90e-06]Steps:   3%|▎         | 146/5000 [39:55<12:40:50,  9.40s/it, loss=0.5779, lr=2.90e-06]Steps:   3%|▎         | 146/5000 [39:55<12:40:50,  9.40s/it, loss=0.9966, lr=2.92e-06]Steps:   3%|▎         | 147/5000 [40:04<12:38:34,  9.38s/it, loss=0.9966, lr=2.92e-06]Steps:   3%|▎         | 147/5000 [40:04<12:38:34,  9.38s/it, loss=0.9875, lr=2.94e-06]Steps:   3%|▎         | 148/5000 [40:14<12:38:25,  9.38s/it, loss=0.9875, lr=2.94e-06]Steps:   3%|▎         | 148/5000 [40:14<12:38:25,  9.38s/it, loss=0.7645, lr=2.96e-06]Steps:   3%|▎         | 149/5000 [40:23<12:37:55,  9.37s/it, loss=0.7645, lr=2.96e-06]Steps:   3%|▎         | 149/5000 [40:23<12:37:55,  9.37s/it, loss=0.6129, lr=2.98e-06]Steps:   3%|▎         | 150/5000 [40:28<10:54:09,  8.09s/it, loss=0.6129, lr=2.98e-06]Steps:   3%|▎         | 150/5000 [40:28<10:54:09,  8.09s/it, loss=0.7754, lr=3.00e-06]01/30/2026 07:57:58 - INFO - __main__ - 
🔍 Running validation at step 150...
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 150 (parquet mode)...
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 150...
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 07:58:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.65it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.18it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.14it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.11it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.09it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.09it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.08it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.08it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.08it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.08it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 07:58:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 07:58:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.08it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 07:58:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 07:58:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.57it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.05it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 07:59:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 07:59:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 07:59:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 07:59:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:00:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 08:00:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:00:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 08:00:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:01:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 08:01:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:01:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 08:01:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.02it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:02:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 08:02:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:02:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 08:02:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.62it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.06it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:03:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 08:03:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.23it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.11it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.09it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.08it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.07it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.06it/s][A
 43%|████▎     | 12/28 [00:10<00:15,  1.06it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.06it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.06it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.06it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.06it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.06it/s][A100%|██████████| 28/28 [00:26<00:00,  1.07it/s]
01/30/2026 08:03:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150/step000150_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 08:03:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 08:03:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 08:03:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000150
01/30/2026 08:03:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

01/30/2026 08:03:35 - INFO - __main__ - 
==================================================
01/30/2026 08:03:35 - INFO - __main__ - Epoch 1 completed: avg_loss = 0.8003
01/30/2026 08:03:35 - INFO - __main__ - ==================================================


[Step 150] Training Debug Info:
  Loss: 0.612351
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0145, std: 0.8984
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0173, std: 1.3438
  Model pred mean: -0.0284, std: 1.1094
  Sigmas: [0.97265625]... (timesteps: [974.0])

[Step 150] Training Debug Info:
  Loss: 0.562336
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0325, std: 1.0000
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0334, std: 1.4141
  Model pred mean: -0.0330, std: 1.1953
  Sigmas: [0.6953125]... (timesteps: [694.0])

[Step 150] Training Debug Info:
  Loss: 0.628251
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0344, std: 0.8711
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0332, std: 1.3281
  Model pred mean: 0.0322, std: 1.0625
  Sigmas: [0.59765625]... (timesteps: [598.0])

[Step 150] Training Debug Info:
  Loss: 0.608279
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0104, std: 1.3750
  Model pred mean: -0.0072, std: 1.1250
  Sigmas: [0.92578125]... (timesteps: [925.0])
Steps:   3%|▎         | 151/5000 [46:16<148:00:25, 109.88s/it, loss=0.7754, lr=3.00e-06]Steps:   3%|▎         | 151/5000 [46:16<148:00:25, 109.88s/it, loss=0.6083, lr=3.02e-06]Steps:   3%|▎         | 152/5000 [46:25<107:21:42, 79.72s/it, loss=0.6083, lr=3.02e-06] Steps:   3%|▎         | 152/5000 [46:25<107:21:42, 79.72s/it, loss=1.0421, lr=3.04e-06]Steps:   3%|▎         | 153/5000 [46:35<78:57:27, 58.64s/it, loss=1.0421, lr=3.04e-06] Steps:   3%|▎         | 153/5000 [46:35<78:57:27, 58.64s/it, loss=1.1112, lr=3.06e-06]Steps:   3%|▎         | 154/5000 [46:44<59:01:19, 43.85s/it, loss=1.1112, lr=3.06e-06]Steps:   3%|▎         | 154/5000 [46:44<59:01:19, 43.85s/it, loss=0.5367, lr=3.08e-06]Steps:   3%|▎         | 155/5000 [46:53<45:11:29, 33.58s/it, loss=0.5367, lr=3.08e-06]Steps:   3%|▎         | 155/5000 [46:53<45:11:29, 33.58s/it, loss=0.6860, lr=3.10e-06]Steps:   3%|▎         | 156/5000 [47:03<35:23:18, 26.30s/it, loss=0.6860, lr=3.10e-06]Steps:   3%|▎         | 156/5000 [47:03<35:23:18, 26.30s/it, loss=0.4089, lr=3.12e-06]Steps:   3%|▎         | 157/5000 [47:12<28:33:14, 21.23s/it, loss=0.4089, lr=3.12e-06]Steps:   3%|▎         | 157/5000 [47:12<28:33:14, 21.23s/it, loss=1.0450, lr=3.14e-06]Steps:   3%|▎         | 158/5000 [47:22<23:50:57, 17.73s/it, loss=1.0450, lr=3.14e-06]Steps:   3%|▎         | 158/5000 [47:22<23:50:57, 17.73s/it, loss=1.1536, lr=3.16e-06]Steps:   3%|▎         | 159/5000 [47:31<20:35:01, 15.31s/it, loss=1.1536, lr=3.16e-06]Steps:   3%|▎         | 159/5000 [47:31<20:35:01, 15.31s/it, loss=0.3807, lr=3.18e-06]Steps:   3%|▎         | 160/5000 [47:41<18:09:54, 13.51s/it, loss=0.3807, lr=3.18e-06]Steps:   3%|▎         | 160/5000 [47:41<18:09:54, 13.51s/it, loss=0.6176, lr=3.20e-06]
[Step 160] Training Debug Info:
  Loss: 1.124246
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0000, std: 0.8477
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0014, std: 1.3125
  Model pred mean: 0.0114, std: 0.7812
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 160] Training Debug Info:
  Loss: 1.191080
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0275, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0266, std: 1.3594
  Model pred mean: 0.0332, std: 0.8047
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 160] Training Debug Info:
  Loss: 0.598270
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.8867
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0014, std: 1.3359
  Model pred mean: -0.0019, std: 1.1172
  Sigmas: [0.98828125]... (timesteps: [990.0])

[Step 160] Training Debug Info:
  Loss: 0.496731
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0356, std: 0.9922
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0352, std: 1.4062
  Model pred mean: -0.0258, std: 1.2109
  Sigmas: [0.73828125]... (timesteps: [739.0])
Steps:   3%|▎         | 161/5000 [47:50<16:27:08, 12.24s/it, loss=0.6176, lr=3.20e-06]Steps:   3%|▎         | 161/5000 [47:50<16:27:08, 12.24s/it, loss=0.4967, lr=3.22e-06]Steps:   3%|▎         | 162/5000 [47:59<15:18:49, 11.40s/it, loss=0.4967, lr=3.22e-06]Steps:   3%|▎         | 162/5000 [47:59<15:18:49, 11.40s/it, loss=0.4591, lr=3.24e-06]Steps:   3%|▎         | 163/5000 [48:09<14:27:06, 10.76s/it, loss=0.4591, lr=3.24e-06]Steps:   3%|▎         | 163/5000 [48:09<14:27:06, 10.76s/it, loss=0.7829, lr=3.26e-06]Steps:   3%|▎         | 164/5000 [48:18<13:50:02, 10.30s/it, loss=0.7829, lr=3.26e-06]Steps:   3%|▎         | 164/5000 [48:18<13:50:02, 10.30s/it, loss=0.3902, lr=3.28e-06]Steps:   3%|▎         | 165/5000 [48:27<13:27:59, 10.03s/it, loss=0.3902, lr=3.28e-06]Steps:   3%|▎         | 165/5000 [48:27<13:27:59, 10.03s/it, loss=0.9957, lr=3.30e-06]Steps:   3%|▎         | 166/5000 [48:37<13:12:11,  9.83s/it, loss=0.9957, lr=3.30e-06]Steps:   3%|▎         | 166/5000 [48:37<13:12:11,  9.83s/it, loss=0.6579, lr=3.32e-06]Steps:   3%|▎         | 167/5000 [48:46<13:01:16,  9.70s/it, loss=0.6579, lr=3.32e-06]Steps:   3%|▎         | 167/5000 [48:46<13:01:16,  9.70s/it, loss=0.4238, lr=3.34e-06]Steps:   3%|▎         | 168/5000 [48:56<12:55:03,  9.62s/it, loss=0.4238, lr=3.34e-06]Steps:   3%|▎         | 168/5000 [48:56<12:55:03,  9.62s/it, loss=1.1047, lr=3.36e-06]Steps:   3%|▎         | 169/5000 [49:05<12:54:54,  9.62s/it, loss=1.1047, lr=3.36e-06]Steps:   3%|▎         | 169/5000 [49:05<12:54:54,  9.62s/it, loss=0.5254, lr=3.38e-06]Steps:   3%|▎         | 170/5000 [49:15<12:50:25,  9.57s/it, loss=0.5254, lr=3.38e-06]Steps:   3%|▎         | 170/5000 [49:15<12:50:25,  9.57s/it, loss=0.7108, lr=3.40e-06]
[Step 170] Training Debug Info:
  Loss: 0.409078
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0100, std: 0.8828
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0079, std: 1.3359
  Model pred mean: -0.0103, std: 1.1797
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 170] Training Debug Info:
  Loss: 0.960383
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0029, std: 0.9609
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0060, std: 1.3828
  Model pred mean: -0.0049, std: 0.9766
  Sigmas: [0.34765625]... (timesteps: [347.0])

[Step 170] Training Debug Info:
  Loss: 0.514084
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0079, std: 0.9062
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0065, std: 1.3516
  Model pred mean: -0.0084, std: 1.1484
  Sigmas: [0.66015625]... (timesteps: [661.0])

[Step 170] Training Debug Info:
  Loss: 1.086521
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0270, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0262, std: 1.3594
  Model pred mean: 0.0227, std: 0.8633
  Sigmas: [0.0439453125]... (timesteps: [44.0])
Steps:   3%|▎         | 171/5000 [49:24<12:46:06,  9.52s/it, loss=0.7108, lr=3.40e-06]Steps:   3%|▎         | 171/5000 [49:24<12:46:06,  9.52s/it, loss=1.0865, lr=3.42e-06]Steps:   3%|▎         | 172/5000 [49:33<12:40:42,  9.45s/it, loss=1.0865, lr=3.42e-06]Steps:   3%|▎         | 172/5000 [49:33<12:40:42,  9.45s/it, loss=0.4997, lr=3.44e-06]Steps:   3%|▎         | 173/5000 [49:43<12:40:43,  9.46s/it, loss=0.4997, lr=3.44e-06]Steps:   3%|▎         | 173/5000 [49:43<12:40:43,  9.46s/it, loss=1.0245, lr=3.46e-06]Steps:   3%|▎         | 174/5000 [49:52<12:37:00,  9.41s/it, loss=1.0245, lr=3.46e-06]Steps:   3%|▎         | 174/5000 [49:52<12:37:00,  9.41s/it, loss=1.1209, lr=3.48e-06]Steps:   4%|▎         | 175/5000 [50:01<12:37:45,  9.42s/it, loss=1.1209, lr=3.48e-06]Steps:   4%|▎         | 175/5000 [50:01<12:37:45,  9.42s/it, loss=0.4660, lr=3.50e-06]Steps:   4%|▎         | 176/5000 [50:11<12:36:58,  9.42s/it, loss=0.4660, lr=3.50e-06]Steps:   4%|▎         | 176/5000 [50:11<12:36:58,  9.42s/it, loss=0.5216, lr=3.52e-06]Steps:   4%|▎         | 177/5000 [50:20<12:36:58,  9.42s/it, loss=0.5216, lr=3.52e-06]Steps:   4%|▎         | 177/5000 [50:20<12:36:58,  9.42s/it, loss=1.0096, lr=3.54e-06]Steps:   4%|▎         | 178/5000 [50:30<12:35:21,  9.40s/it, loss=1.0096, lr=3.54e-06]Steps:   4%|▎         | 178/5000 [50:30<12:35:21,  9.40s/it, loss=0.7259, lr=3.56e-06]Steps:   4%|▎         | 179/5000 [50:39<12:37:53,  9.43s/it, loss=0.7259, lr=3.56e-06]Steps:   4%|▎         | 179/5000 [50:39<12:37:53,  9.43s/it, loss=0.5664, lr=3.58e-06]Steps:   4%|▎         | 180/5000 [50:49<12:43:43,  9.51s/it, loss=0.5664, lr=3.58e-06]Steps:   4%|▎         | 180/5000 [50:49<12:43:43,  9.51s/it, loss=1.1349, lr=3.60e-06]
[Step 180] Training Debug Info:
  Loss: 0.934492
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0009, std: 0.9336
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0040, std: 1.3672
  Model pred mean: 0.0039, std: 0.9375
  Sigmas: [0.318359375]... (timesteps: [319.0])

[Step 180] Training Debug Info:
  Loss: 1.160660
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0103, std: 0.8867
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0094, std: 1.3438
  Model pred mean: -0.0129, std: 0.7891
  Sigmas: [0.10400390625]... (timesteps: [104.0])

[Step 180] Training Debug Info:
  Loss: 0.476443
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0154, std: 0.9023
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0147, std: 1.3438
  Model pred mean: -0.0182, std: 1.1562
  Sigmas: [0.6875]... (timesteps: [688.0])

[Step 180] Training Debug Info:
  Loss: 1.098132
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0012, std: 0.8633
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0007, std: 1.3203
  Model pred mean: 0.0048, std: 0.7891
  Sigmas: [0.33203125]... (timesteps: [332.0])
Steps:   4%|▎         | 181/5000 [50:58<12:39:03,  9.45s/it, loss=1.1349, lr=3.60e-06]Steps:   4%|▎         | 181/5000 [50:58<12:39:03,  9.45s/it, loss=1.0981, lr=3.62e-06]Steps:   4%|▎         | 182/5000 [51:08<12:41:58,  9.49s/it, loss=1.0981, lr=3.62e-06]Steps:   4%|▎         | 182/5000 [51:08<12:41:58,  9.49s/it, loss=0.4395, lr=3.64e-06]Steps:   4%|▎         | 183/5000 [51:17<12:39:06,  9.46s/it, loss=0.4395, lr=3.64e-06]Steps:   4%|▎         | 183/5000 [51:17<12:39:06,  9.46s/it, loss=1.2023, lr=3.66e-06]Steps:   4%|▎         | 184/5000 [51:26<12:34:56,  9.41s/it, loss=1.2023, lr=3.66e-06]Steps:   4%|▎         | 184/5000 [51:26<12:34:56,  9.41s/it, loss=0.4171, lr=3.68e-06]Steps:   4%|▎         | 185/5000 [51:36<12:31:05,  9.36s/it, loss=0.4171, lr=3.68e-06]Steps:   4%|▎         | 185/5000 [51:36<12:31:05,  9.36s/it, loss=0.8461, lr=3.70e-06]Steps:   4%|▎         | 186/5000 [51:45<12:33:27,  9.39s/it, loss=0.8461, lr=3.70e-06]Steps:   4%|▎         | 186/5000 [51:45<12:33:27,  9.39s/it, loss=0.4558, lr=3.72e-06]Steps:   4%|▎         | 187/5000 [51:54<12:31:15,  9.37s/it, loss=0.4558, lr=3.72e-06]Steps:   4%|▎         | 187/5000 [51:54<12:31:15,  9.37s/it, loss=1.1285, lr=3.74e-06]Steps:   4%|▍         | 188/5000 [52:04<12:33:12,  9.39s/it, loss=1.1285, lr=3.74e-06]Steps:   4%|▍         | 188/5000 [52:04<12:33:12,  9.39s/it, loss=0.7128, lr=3.76e-06]Steps:   4%|▍         | 189/5000 [52:14<12:41:19,  9.49s/it, loss=0.7128, lr=3.76e-06]Steps:   4%|▍         | 189/5000 [52:14<12:41:19,  9.49s/it, loss=1.0857, lr=3.78e-06]Steps:   4%|▍         | 190/5000 [52:23<12:40:02,  9.48s/it, loss=1.0857, lr=3.78e-06]Steps:   4%|▍         | 190/5000 [52:23<12:40:02,  9.48s/it, loss=0.5644, lr=3.80e-06]
[Step 190] Training Debug Info:
  Loss: 0.537193
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0242, std: 0.8945
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0243, std: 1.3438
  Model pred mean: -0.0276, std: 1.1328
  Sigmas: [0.63671875]... (timesteps: [636.0])

[Step 190] Training Debug Info:
  Loss: 0.373386
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0043, std: 0.8789
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0045, std: 1.3281
  Model pred mean: -0.0002, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 190] Training Debug Info:
  Loss: 0.654748
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0588, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0601, std: 1.3594
  Model pred mean: -0.0413, std: 1.0938
  Sigmas: [0.9921875]... (timesteps: [991.0])

[Step 190] Training Debug Info:
  Loss: 1.173294
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0137, std: 0.9062
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0161, std: 1.3516
  Model pred mean: 0.0098, std: 0.8008
  Sigmas: [0.21875]... (timesteps: [219.0])
Steps:   4%|▍         | 191/5000 [52:32<12:37:48,  9.45s/it, loss=0.5644, lr=3.80e-06]Steps:   4%|▍         | 191/5000 [52:32<12:37:48,  9.45s/it, loss=1.1733, lr=3.82e-06]Steps:   4%|▍         | 192/5000 [52:42<12:34:10,  9.41s/it, loss=1.1733, lr=3.82e-06]Steps:   4%|▍         | 192/5000 [52:42<12:34:10,  9.41s/it, loss=1.0227, lr=3.84e-06]Steps:   4%|▍         | 193/5000 [52:51<12:32:59,  9.40s/it, loss=1.0227, lr=3.84e-06]Steps:   4%|▍         | 193/5000 [52:51<12:32:59,  9.40s/it, loss=0.4721, lr=3.86e-06]Steps:   4%|▍         | 194/5000 [53:01<12:37:33,  9.46s/it, loss=0.4721, lr=3.86e-06]Steps:   4%|▍         | 194/5000 [53:01<12:37:33,  9.46s/it, loss=0.8670, lr=3.88e-06]Steps:   4%|▍         | 195/5000 [53:10<12:37:49,  9.46s/it, loss=0.8670, lr=3.88e-06]Steps:   4%|▍         | 195/5000 [53:10<12:37:49,  9.46s/it, loss=0.4425, lr=3.90e-06]Steps:   4%|▍         | 196/5000 [53:20<12:37:29,  9.46s/it, loss=0.4425, lr=3.90e-06]Steps:   4%|▍         | 196/5000 [53:20<12:37:29,  9.46s/it, loss=0.6882, lr=3.92e-06]Steps:   4%|▍         | 197/5000 [53:29<12:39:40,  9.49s/it, loss=0.6882, lr=3.92e-06]Steps:   4%|▍         | 197/5000 [53:29<12:39:40,  9.49s/it, loss=1.0462, lr=3.94e-06]Steps:   4%|▍         | 198/5000 [53:39<12:37:24,  9.46s/it, loss=1.0462, lr=3.94e-06]Steps:   4%|▍         | 198/5000 [53:39<12:37:24,  9.46s/it, loss=0.4523, lr=3.96e-06]Steps:   4%|▍         | 199/5000 [53:48<12:33:05,  9.41s/it, loss=0.4523, lr=3.96e-06]Steps:   4%|▍         | 199/5000 [53:48<12:33:05,  9.41s/it, loss=0.4990, lr=3.98e-06]Steps:   4%|▍         | 200/5000 [53:57<12:35:17,  9.44s/it, loss=0.4990, lr=3.98e-06]Steps:   4%|▍         | 200/5000 [53:57<12:35:17,  9.44s/it, loss=1.1091, lr=4.00e-06]01/30/2026 08:11:27 - INFO - __main__ - 
[Step 200] ✅ Loss in normal range (1.1091)
01/30/2026 08:11:27 - INFO - __main__ -   Loss avg (last 100): 0.7787
01/30/2026 08:11:27 - INFO - __main__ -   Loss range: [0.3464, 1.2125]
01/30/2026 08:11:27 - INFO - __main__ - 
🔍 Running validation at step 200...
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 200 (parquet mode)...
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 200...
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 08:11:28 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.28it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.10it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.09it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 08:11:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 08:11:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 08:12:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 08:12:21 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:12:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 08:12:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:13:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 08:13:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:13:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 08:13:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:14:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 08:14:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:14:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 08:14:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:15:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 08:15:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:15:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 08:15:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:16:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 08:16:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:16:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 08:16:32 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.06it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:16:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200/step000200_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 08:16:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 08:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 08:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000200
01/30/2026 08:17:00 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 200] Training Debug Info:
  Loss: 0.521019
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0145, std: 0.9258
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0135, std: 1.3594
  Model pred mean: 0.0110, std: 1.1484
  Sigmas: [0.9453125]... (timesteps: [947.0])

[Step 200] Training Debug Info:
  Loss: 1.146971
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0266, std: 0.9062
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0264, std: 1.3516
  Model pred mean: 0.0261, std: 0.8203
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 200] Training Debug Info:
  Loss: 0.492135
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0189, std: 0.9102
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0177, std: 1.3516
  Model pred mean: -0.0209, std: 1.1484
  Sigmas: [0.65625]... (timesteps: [656.0])

[Step 200] Training Debug Info:
  Loss: 0.489797
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0376, std: 0.8945
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0356, std: 1.3359
  Model pred mean: -0.0287, std: 1.1250
  Sigmas: [0.8828125]... (timesteps: [881.0])
Steps:   4%|▍         | 201/5000 [59:43<147:06:49, 110.36s/it, loss=1.1091, lr=4.00e-06]Steps:   4%|▍         | 201/5000 [59:43<147:06:49, 110.36s/it, loss=0.4898, lr=4.02e-06]Steps:   4%|▍         | 202/5000 [59:53<106:43:57, 80.08s/it, loss=0.4898, lr=4.02e-06] Steps:   4%|▍         | 202/5000 [59:53<106:43:57, 80.08s/it, loss=0.3720, lr=4.04e-06]Steps:   4%|▍         | 203/5000 [1:00:02<78:27:24, 58.88s/it, loss=0.3720, lr=4.04e-06]Steps:   4%|▍         | 203/5000 [1:00:02<78:27:24, 58.88s/it, loss=0.8995, lr=4.06e-06]Steps:   4%|▍         | 204/5000 [1:00:11<58:35:00, 43.97s/it, loss=0.8995, lr=4.06e-06]Steps:   4%|▍         | 204/5000 [1:00:11<58:35:00, 43.97s/it, loss=1.1784, lr=4.08e-06]Steps:   4%|▍         | 205/5000 [1:00:21<44:42:48, 33.57s/it, loss=1.1784, lr=4.08e-06]Steps:   4%|▍         | 205/5000 [1:00:21<44:42:48, 33.57s/it, loss=1.1152, lr=4.10e-06]Steps:   4%|▍         | 206/5000 [1:00:30<35:04:46, 26.34s/it, loss=1.1152, lr=4.10e-06]Steps:   4%|▍         | 206/5000 [1:00:30<35:04:46, 26.34s/it, loss=0.7400, lr=4.12e-06]Steps:   4%|▍         | 207/5000 [1:00:40<28:19:55, 21.28s/it, loss=0.7400, lr=4.12e-06]Steps:   4%|▍         | 207/5000 [1:00:40<28:19:55, 21.28s/it, loss=0.5347, lr=4.14e-06]Steps:   4%|▍         | 208/5000 [1:00:49<23:32:25, 17.68s/it, loss=0.5347, lr=4.14e-06]Steps:   4%|▍         | 208/5000 [1:00:49<23:32:25, 17.68s/it, loss=0.3862, lr=4.16e-06]Steps:   4%|▍         | 209/5000 [1:00:58<20:15:21, 15.22s/it, loss=0.3862, lr=4.16e-06]Steps:   4%|▍         | 209/5000 [1:00:58<20:15:21, 15.22s/it, loss=0.6465, lr=4.18e-06]Steps:   4%|▍         | 210/5000 [1:01:08<17:54:19, 13.46s/it, loss=0.6465, lr=4.18e-06]Steps:   4%|▍         | 210/5000 [1:01:08<17:54:19, 13.46s/it, loss=0.7012, lr=4.20e-06]
[Step 210] Training Debug Info:
  Loss: 0.406996
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0150, std: 0.9336
  Noise mean: 0.0012, std: 0.9961
  Target mean: -0.0138, std: 1.3672
  Model pred mean: -0.0098, std: 1.1953
  Sigmas: [0.859375]... (timesteps: [858.0])

[Step 210] Training Debug Info:
  Loss: 0.500319
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0042, std: 0.8711
  Noise mean: -0.0022, std: 0.9961
  Target mean: 0.0020, std: 1.3203
  Model pred mean: 0.0019, std: 1.1328
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 210] Training Debug Info:
  Loss: 0.530903
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0175, std: 0.8789
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0188, std: 1.3359
  Model pred mean: 0.0168, std: 1.1172
  Sigmas: [0.65234375]... (timesteps: [652.0])

[Step 210] Training Debug Info:
  Loss: 0.504197
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0437, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0444, std: 1.3516
  Model pred mean: 0.0400, std: 1.1719
  Sigmas: [0.68359375]... (timesteps: [683.0])
Steps:   4%|▍         | 211/5000 [1:01:17<16:12:53, 12.19s/it, loss=0.7012, lr=4.20e-06]Steps:   4%|▍         | 211/5000 [1:01:17<16:12:53, 12.19s/it, loss=0.5042, lr=4.22e-06]Steps:   4%|▍         | 212/5000 [1:01:26<15:05:36, 11.35s/it, loss=0.5042, lr=4.22e-06]Steps:   4%|▍         | 212/5000 [1:01:26<15:05:36, 11.35s/it, loss=1.0829, lr=4.24e-06]Steps:   4%|▍         | 213/5000 [1:01:36<14:15:51, 10.73s/it, loss=1.0829, lr=4.24e-06]Steps:   4%|▍         | 213/5000 [1:01:36<14:15:51, 10.73s/it, loss=1.0299, lr=4.26e-06]Steps:   4%|▍         | 214/5000 [1:01:45<13:44:45, 10.34s/it, loss=1.0299, lr=4.26e-06]Steps:   4%|▍         | 214/5000 [1:01:45<13:44:45, 10.34s/it, loss=0.9688, lr=4.28e-06]Steps:   4%|▍         | 215/5000 [1:01:55<13:25:14, 10.10s/it, loss=0.9688, lr=4.28e-06]Steps:   4%|▍         | 215/5000 [1:01:55<13:25:14, 10.10s/it, loss=0.3909, lr=4.30e-06]Steps:   4%|▍         | 216/5000 [1:02:04<13:07:29,  9.88s/it, loss=0.3909, lr=4.30e-06]Steps:   4%|▍         | 216/5000 [1:02:04<13:07:29,  9.88s/it, loss=1.1173, lr=4.32e-06]Steps:   4%|▍         | 217/5000 [1:02:13<13:00:18,  9.79s/it, loss=1.1173, lr=4.32e-06]Steps:   4%|▍         | 217/5000 [1:02:13<13:00:18,  9.79s/it, loss=0.6661, lr=4.34e-06]Steps:   4%|▍         | 218/5000 [1:02:23<12:49:11,  9.65s/it, loss=0.6661, lr=4.34e-06]Steps:   4%|▍         | 218/5000 [1:02:23<12:49:11,  9.65s/it, loss=0.8806, lr=4.36e-06]Steps:   4%|▍         | 219/5000 [1:02:32<12:41:59,  9.56s/it, loss=0.8806, lr=4.36e-06]Steps:   4%|▍         | 219/5000 [1:02:32<12:41:59,  9.56s/it, loss=0.6399, lr=4.38e-06]Steps:   4%|▍         | 220/5000 [1:02:41<12:35:01,  9.48s/it, loss=0.6399, lr=4.38e-06]Steps:   4%|▍         | 220/5000 [1:02:41<12:35:01,  9.48s/it, loss=0.8606, lr=4.40e-06]
[Step 220] Training Debug Info:
  Loss: 0.929128
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0135, std: 0.8828
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0126, std: 1.3359
  Model pred mean: 0.0161, std: 0.9570
  Sigmas: [0.421875]... (timesteps: [421.0])

[Step 220] Training Debug Info:
  Loss: 1.227825
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0211, std: 0.8711
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0228, std: 1.3281
  Model pred mean: 0.0281, std: 0.7422
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 220] Training Debug Info:
  Loss: 1.134920
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0126, std: 0.9844
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0150, std: 1.3984
  Model pred mean: -0.0081, std: 0.9180
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 220] Training Debug Info:
  Loss: 1.074286
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0029, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0036, std: 1.3516
  Model pred mean: 0.0098, std: 0.8828
  Sigmas: [0.037109375]... (timesteps: [37.0])
Steps:   4%|▍         | 221/5000 [1:02:51<12:34:46,  9.48s/it, loss=0.8606, lr=4.40e-06]Steps:   4%|▍         | 221/5000 [1:02:51<12:34:46,  9.48s/it, loss=1.0743, lr=4.42e-06]Steps:   4%|▍         | 222/5000 [1:03:00<12:33:21,  9.46s/it, loss=1.0743, lr=4.42e-06]Steps:   4%|▍         | 222/5000 [1:03:00<12:33:21,  9.46s/it, loss=0.9353, lr=4.44e-06]Steps:   4%|▍         | 223/5000 [1:03:10<12:31:35,  9.44s/it, loss=0.9353, lr=4.44e-06]Steps:   4%|▍         | 223/5000 [1:03:10<12:31:35,  9.44s/it, loss=0.7732, lr=4.46e-06]Steps:   4%|▍         | 224/5000 [1:03:19<12:29:10,  9.41s/it, loss=0.7732, lr=4.46e-06]Steps:   4%|▍         | 224/5000 [1:03:19<12:29:10,  9.41s/it, loss=0.4468, lr=4.48e-06]Steps:   4%|▍         | 225/5000 [1:03:24<10:48:33,  8.15s/it, loss=0.4468, lr=4.48e-06]Steps:   4%|▍         | 225/5000 [1:03:24<10:48:33,  8.15s/it, loss=0.4418, lr=4.50e-06]01/30/2026 08:20:54 - INFO - __main__ - 
==================================================
01/30/2026 08:20:54 - INFO - __main__ - Epoch 2 completed: avg_loss = 0.7586
01/30/2026 08:20:54 - INFO - __main__ - ==================================================

Steps:   5%|▍         | 226/5000 [1:03:35<11:41:03,  8.81s/it, loss=0.4418, lr=4.50e-06]Steps:   5%|▍         | 226/5000 [1:03:35<11:41:03,  8.81s/it, loss=0.9571, lr=4.52e-06]Steps:   5%|▍         | 227/5000 [1:03:44<11:52:49,  8.96s/it, loss=0.9571, lr=4.52e-06]Steps:   5%|▍         | 227/5000 [1:03:44<11:52:49,  8.96s/it, loss=0.4153, lr=4.54e-06]Steps:   5%|▍         | 228/5000 [1:03:53<12:04:22,  9.11s/it, loss=0.4153, lr=4.54e-06]Steps:   5%|▍         | 228/5000 [1:03:53<12:04:22,  9.11s/it, loss=1.1129, lr=4.56e-06]Steps:   5%|▍         | 229/5000 [1:04:03<12:17:27,  9.27s/it, loss=1.1129, lr=4.56e-06]Steps:   5%|▍         | 229/5000 [1:04:03<12:17:27,  9.27s/it, loss=0.9800, lr=4.58e-06]Steps:   5%|▍         | 230/5000 [1:04:13<12:26:50,  9.39s/it, loss=0.9800, lr=4.58e-06]Steps:   5%|▍         | 230/5000 [1:04:13<12:26:50,  9.39s/it, loss=0.9604, lr=4.60e-06]
[Step 230] Training Debug Info:
  Loss: 0.384542
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0261, std: 0.9219
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0253, std: 1.3594
  Model pred mean: 0.0248, std: 1.2109
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 230] Training Debug Info:
  Loss: 0.815485
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0157, std: 0.9141
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0151, std: 1.3516
  Model pred mean: 0.0148, std: 1.0312
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 230] Training Debug Info:
  Loss: 1.027477
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0071, std: 0.8906
  Noise mean: -0.0032, std: 0.9961
  Target mean: 0.0039, std: 1.3359
  Model pred mean: 0.0079, std: 0.8828
  Sigmas: [0.01300048828125]... (timesteps: [13.0])

[Step 230] Training Debug Info:
  Loss: 0.527123
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0078, std: 0.8984
  Noise mean: 0.0035, std: 1.0000
  Target mean: 0.0113, std: 1.3438
  Model pred mean: 0.0109, std: 1.1562
  Sigmas: [0.65234375]... (timesteps: [654.0])
Steps:   5%|▍         | 231/5000 [1:04:22<12:25:58,  9.39s/it, loss=0.9604, lr=4.60e-06]Steps:   5%|▍         | 231/5000 [1:04:22<12:25:58,  9.39s/it, loss=0.5271, lr=4.62e-06]Steps:   5%|▍         | 232/5000 [1:04:32<12:29:14,  9.43s/it, loss=0.5271, lr=4.62e-06]Steps:   5%|▍         | 232/5000 [1:04:32<12:29:14,  9.43s/it, loss=0.6950, lr=4.64e-06]Steps:   5%|▍         | 233/5000 [1:04:41<12:30:57,  9.45s/it, loss=0.6950, lr=4.64e-06]Steps:   5%|▍         | 233/5000 [1:04:41<12:30:57,  9.45s/it, loss=0.4096, lr=4.66e-06]Steps:   5%|▍         | 234/5000 [1:04:50<12:28:51,  9.43s/it, loss=0.4096, lr=4.66e-06]Steps:   5%|▍         | 234/5000 [1:04:50<12:28:51,  9.43s/it, loss=0.9704, lr=4.68e-06]Steps:   5%|▍         | 235/5000 [1:05:00<12:26:29,  9.40s/it, loss=0.9704, lr=4.68e-06]Steps:   5%|▍         | 235/5000 [1:05:00<12:26:29,  9.40s/it, loss=0.5188, lr=4.70e-06]Steps:   5%|▍         | 236/5000 [1:05:09<12:23:37,  9.37s/it, loss=0.5188, lr=4.70e-06]Steps:   5%|▍         | 236/5000 [1:05:09<12:23:37,  9.37s/it, loss=0.8817, lr=4.72e-06]Steps:   5%|▍         | 237/5000 [1:05:19<12:25:55,  9.40s/it, loss=0.8817, lr=4.72e-06]Steps:   5%|▍         | 237/5000 [1:05:19<12:25:55,  9.40s/it, loss=1.1291, lr=4.74e-06]Steps:   5%|▍         | 238/5000 [1:05:28<12:25:21,  9.39s/it, loss=1.1291, lr=4.74e-06]Steps:   5%|▍         | 238/5000 [1:05:28<12:25:21,  9.39s/it, loss=1.1466, lr=4.76e-06]Steps:   5%|▍         | 239/5000 [1:05:37<12:21:47,  9.35s/it, loss=1.1466, lr=4.76e-06]Steps:   5%|▍         | 239/5000 [1:05:37<12:21:47,  9.35s/it, loss=0.4640, lr=4.78e-06]Steps:   5%|▍         | 240/5000 [1:05:47<12:27:42,  9.42s/it, loss=0.4640, lr=4.78e-06]Steps:   5%|▍         | 240/5000 [1:05:47<12:27:42,  9.42s/it, loss=0.7857, lr=4.80e-06]
[Step 240] Training Debug Info:
  Loss: 0.359746
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0090, std: 0.9727
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0084, std: 1.3906
  Model pred mean: -0.0103, std: 1.2422
  Sigmas: [0.890625]... (timesteps: [889.0])

[Step 240] Training Debug Info:
  Loss: 0.491549
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0693, std: 0.9336
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0684, std: 1.3672
  Model pred mean: 0.0718, std: 1.1797
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 240] Training Debug Info:
  Loss: 0.470964
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0073, std: 0.9453
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0093, std: 1.3750
  Model pred mean: 0.0104, std: 1.2031
  Sigmas: [0.63671875]... (timesteps: [638.0])

[Step 240] Training Debug Info:
  Loss: 1.095964
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0014, std: 1.3594
  Model pred mean: -0.0031, std: 0.8828
  Sigmas: [0.06787109375]... (timesteps: [68.0])
Steps:   5%|▍         | 241/5000 [1:05:56<12:28:48,  9.44s/it, loss=0.7857, lr=4.80e-06]Steps:   5%|▍         | 241/5000 [1:05:56<12:28:48,  9.44s/it, loss=1.0960, lr=4.82e-06]Steps:   5%|▍         | 242/5000 [1:06:06<12:28:19,  9.44s/it, loss=1.0960, lr=4.82e-06]Steps:   5%|▍         | 242/5000 [1:06:06<12:28:19,  9.44s/it, loss=0.5759, lr=4.84e-06]Steps:   5%|▍         | 243/5000 [1:06:15<12:26:14,  9.41s/it, loss=0.5759, lr=4.84e-06]Steps:   5%|▍         | 243/5000 [1:06:15<12:26:14,  9.41s/it, loss=0.5135, lr=4.86e-06]Steps:   5%|▍         | 244/5000 [1:06:25<12:26:33,  9.42s/it, loss=0.5135, lr=4.86e-06]Steps:   5%|▍         | 244/5000 [1:06:25<12:26:33,  9.42s/it, loss=1.1094, lr=4.88e-06]Steps:   5%|▍         | 245/5000 [1:06:34<12:29:53,  9.46s/it, loss=1.1094, lr=4.88e-06]Steps:   5%|▍         | 245/5000 [1:06:34<12:29:53,  9.46s/it, loss=0.4589, lr=4.90e-06]Steps:   5%|▍         | 246/5000 [1:06:43<12:28:49,  9.45s/it, loss=0.4589, lr=4.90e-06]Steps:   5%|▍         | 246/5000 [1:06:43<12:28:49,  9.45s/it, loss=0.6300, lr=4.92e-06]Steps:   5%|▍         | 247/5000 [1:06:53<12:26:32,  9.42s/it, loss=0.6300, lr=4.92e-06]Steps:   5%|▍         | 247/5000 [1:06:53<12:26:32,  9.42s/it, loss=0.6055, lr=4.94e-06]Steps:   5%|▍         | 248/5000 [1:07:02<12:24:09,  9.40s/it, loss=0.6055, lr=4.94e-06]Steps:   5%|▍         | 248/5000 [1:07:02<12:24:09,  9.40s/it, loss=0.5175, lr=4.96e-06]Steps:   5%|▍         | 249/5000 [1:07:12<12:27:47,  9.44s/it, loss=0.5175, lr=4.96e-06]Steps:   5%|▍         | 249/5000 [1:07:12<12:27:47,  9.44s/it, loss=0.7930, lr=4.98e-06]Steps:   5%|▌         | 250/5000 [1:07:21<12:27:22,  9.44s/it, loss=0.7930, lr=4.98e-06]Steps:   5%|▌         | 250/5000 [1:07:21<12:27:22,  9.44s/it, loss=0.4630, lr=5.00e-06]01/30/2026 08:24:51 - INFO - __main__ - 
🔍 Running validation at step 250...
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 250 (parquet mode)...
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 250...
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 08:24:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.28it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.10it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:10,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:17<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.09it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.09it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.09it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 08:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 08:25:18 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.64it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.14it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.10it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.08it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 08:25:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 08:25:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:26:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 08:26:13 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 08:26:41 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:27:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 08:27:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:27:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 08:27:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:28:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 08:28:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:28:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 08:28:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:29:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 08:29:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.02it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:29:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 08:29:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:29:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 08:29:56 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:30:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250/step000250_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 08:30:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 08:30:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 08:30:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000250
01/30/2026 08:30:24 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 250] Training Debug Info:
  Loss: 0.405552
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0017, std: 0.8867
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0034, std: 1.3359
  Model pred mean: 0.0004, std: 1.1797
  Sigmas: [0.76171875]... (timesteps: [760.0])

[Step 250] Training Debug Info:
  Loss: 0.946017
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0085, std: 0.8789
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0077, std: 1.3359
  Model pred mean: -0.0068, std: 0.9023
  Sigmas: [0.380859375]... (timesteps: [381.0])

[Step 250] Training Debug Info:
  Loss: 0.418861
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0093, std: 0.8828
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0089, std: 1.3359
  Model pred mean: 0.0025, std: 1.1641
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 250] Training Debug Info:
  Loss: 0.462315
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0166, std: 0.9062
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0145, std: 1.3516
  Model pred mean: -0.0156, std: 1.1719
  Sigmas: [0.73046875]... (timesteps: [732.0])
Steps:   5%|▌         | 251/5000 [1:13:07<145:31:06, 110.31s/it, loss=0.4630, lr=5.00e-06]Steps:   5%|▌         | 251/5000 [1:13:07<145:31:06, 110.31s/it, loss=0.4623, lr=5.02e-06]Steps:   5%|▌         | 252/5000 [1:13:16<105:34:12, 80.04s/it, loss=0.4623, lr=5.02e-06] Steps:   5%|▌         | 252/5000 [1:13:16<105:34:12, 80.04s/it, loss=0.5672, lr=5.04e-06]Steps:   5%|▌         | 253/5000 [1:13:26<77:39:50, 58.90s/it, loss=0.5672, lr=5.04e-06] Steps:   5%|▌         | 253/5000 [1:13:26<77:39:50, 58.90s/it, loss=0.6815, lr=5.06e-06]Steps:   5%|▌         | 254/5000 [1:13:35<58:05:50, 44.07s/it, loss=0.6815, lr=5.06e-06]Steps:   5%|▌         | 254/5000 [1:13:35<58:05:50, 44.07s/it, loss=1.0717, lr=5.08e-06]Steps:   5%|▌         | 255/5000 [1:13:45<44:24:45, 33.70s/it, loss=1.0717, lr=5.08e-06]Steps:   5%|▌         | 255/5000 [1:13:45<44:24:45, 33.70s/it, loss=0.4461, lr=5.10e-06]Steps:   5%|▌         | 256/5000 [1:13:54<34:45:58, 26.38s/it, loss=0.4461, lr=5.10e-06]Steps:   5%|▌         | 256/5000 [1:13:54<34:45:58, 26.38s/it, loss=0.6538, lr=5.12e-06]Steps:   5%|▌         | 257/5000 [1:14:04<28:07:51, 21.35s/it, loss=0.6538, lr=5.12e-06]Steps:   5%|▌         | 257/5000 [1:14:04<28:07:51, 21.35s/it, loss=0.4034, lr=5.14e-06]Steps:   5%|▌         | 258/5000 [1:14:13<23:26:04, 17.79s/it, loss=0.4034, lr=5.14e-06]Steps:   5%|▌         | 258/5000 [1:14:13<23:26:04, 17.79s/it, loss=0.5231, lr=5.16e-06]Steps:   5%|▌         | 259/5000 [1:14:22<20:04:16, 15.24s/it, loss=0.5231, lr=5.16e-06]Steps:   5%|▌         | 259/5000 [1:14:22<20:04:16, 15.24s/it, loss=0.4499, lr=5.18e-06]Steps:   5%|▌         | 260/5000 [1:14:32<17:45:27, 13.49s/it, loss=0.4499, lr=5.18e-06]Steps:   5%|▌         | 260/5000 [1:14:32<17:45:27, 13.49s/it, loss=1.1482, lr=5.20e-06]
[Step 260] Training Debug Info:
  Loss: 0.703624
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0332, std: 0.9219
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0349, std: 1.3594
  Model pred mean: 0.0310, std: 1.0625
  Sigmas: [0.4921875]... (timesteps: [492.0])

[Step 260] Training Debug Info:
  Loss: 0.875188
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0258, std: 0.9219
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0266, std: 1.3594
  Model pred mean: -0.0267, std: 0.9883
  Sigmas: [0.39453125]... (timesteps: [395.0])

[Step 260] Training Debug Info:
  Loss: 0.466768
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0070, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: 0.0048, std: 1.3438
  Model pred mean: 0.0007, std: 1.1484
  Sigmas: [0.703125]... (timesteps: [702.0])

[Step 260] Training Debug Info:
  Loss: 0.450726
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0114, std: 0.8867
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0095, std: 1.3359
  Model pred mean: -0.0124, std: 1.1562
  Sigmas: [0.734375]... (timesteps: [734.0])
Steps:   5%|▌         | 261/5000 [1:14:41<16:10:23, 12.29s/it, loss=1.1482, lr=5.20e-06]Steps:   5%|▌         | 261/5000 [1:14:41<16:10:23, 12.29s/it, loss=0.4507, lr=5.22e-06]Steps:   5%|▌         | 262/5000 [1:14:51<14:57:50, 11.37s/it, loss=0.4507, lr=5.22e-06]Steps:   5%|▌         | 262/5000 [1:14:51<14:57:50, 11.37s/it, loss=0.3731, lr=5.24e-06]Steps:   5%|▌         | 263/5000 [1:15:00<14:10:51, 10.78s/it, loss=0.3731, lr=5.24e-06]Steps:   5%|▌         | 263/5000 [1:15:00<14:10:51, 10.78s/it, loss=0.4635, lr=5.26e-06]Steps:   5%|▌         | 264/5000 [1:15:09<13:38:54, 10.37s/it, loss=0.4635, lr=5.26e-06]Steps:   5%|▌         | 264/5000 [1:15:09<13:38:54, 10.37s/it, loss=0.4208, lr=5.28e-06]Steps:   5%|▌         | 265/5000 [1:15:19<13:26:03, 10.21s/it, loss=0.4208, lr=5.28e-06]Steps:   5%|▌         | 265/5000 [1:15:19<13:26:03, 10.21s/it, loss=1.0715, lr=5.30e-06]Steps:   5%|▌         | 266/5000 [1:15:29<13:06:20,  9.97s/it, loss=1.0715, lr=5.30e-06]Steps:   5%|▌         | 266/5000 [1:15:29<13:06:20,  9.97s/it, loss=1.1580, lr=5.32e-06]Steps:   5%|▌         | 267/5000 [1:15:38<12:57:35,  9.86s/it, loss=1.1580, lr=5.32e-06]Steps:   5%|▌         | 267/5000 [1:15:38<12:57:35,  9.86s/it, loss=1.1695, lr=5.34e-06]Steps:   5%|▌         | 268/5000 [1:15:48<12:45:49,  9.71s/it, loss=1.1695, lr=5.34e-06]Steps:   5%|▌         | 268/5000 [1:15:48<12:45:49,  9.71s/it, loss=1.1591, lr=5.36e-06]Steps:   5%|▌         | 269/5000 [1:15:57<12:38:14,  9.62s/it, loss=1.1591, lr=5.36e-06]Steps:   5%|▌         | 269/5000 [1:15:57<12:38:14,  9.62s/it, loss=0.7730, lr=5.38e-06]Steps:   5%|▌         | 270/5000 [1:16:07<12:36:25,  9.60s/it, loss=0.7730, lr=5.38e-06]Steps:   5%|▌         | 270/5000 [1:16:07<12:36:25,  9.60s/it, loss=0.4706, lr=5.40e-06]
[Step 270] Training Debug Info:
  Loss: 0.384560
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0033, std: 0.9180
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0059, std: 1.3594
  Model pred mean: 0.0068, std: 1.2031
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 270] Training Debug Info:
  Loss: 0.554091
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0066, std: 0.8945
  Noise mean: -0.0022, std: 0.9961
  Target mean: -0.0089, std: 1.3438
  Model pred mean: 0.0142, std: 1.1016
  Sigmas: [0.94921875]... (timesteps: [950.0])

[Step 270] Training Debug Info:
  Loss: 0.848426
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0152, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0167, std: 1.3281
  Model pred mean: 0.0199, std: 0.9570
  Sigmas: [0.46875]... (timesteps: [468.0])

[Step 270] Training Debug Info:
  Loss: 1.066767
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0291, std: 0.9297
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0272, std: 1.3672
  Model pred mean: -0.0284, std: 0.9023
  Sigmas: [0.17578125]... (timesteps: [176.0])
Steps:   5%|▌         | 271/5000 [1:16:16<12:35:00,  9.58s/it, loss=0.4706, lr=5.40e-06]Steps:   5%|▌         | 271/5000 [1:16:16<12:35:00,  9.58s/it, loss=1.0668, lr=5.42e-06]Steps:   5%|▌         | 272/5000 [1:16:26<12:30:17,  9.52s/it, loss=1.0668, lr=5.42e-06]Steps:   5%|▌         | 272/5000 [1:16:26<12:30:17,  9.52s/it, loss=0.7071, lr=5.44e-06]Steps:   5%|▌         | 273/5000 [1:16:35<12:36:53,  9.61s/it, loss=0.7071, lr=5.44e-06]Steps:   5%|▌         | 273/5000 [1:16:35<12:36:53,  9.61s/it, loss=0.9745, lr=5.46e-06]Steps:   5%|▌         | 274/5000 [1:16:45<12:35:46,  9.60s/it, loss=0.9745, lr=5.46e-06]Steps:   5%|▌         | 274/5000 [1:16:45<12:35:46,  9.60s/it, loss=1.0964, lr=5.48e-06]Steps:   6%|▌         | 275/5000 [1:16:54<12:29:28,  9.52s/it, loss=1.0964, lr=5.48e-06]Steps:   6%|▌         | 275/5000 [1:16:54<12:29:28,  9.52s/it, loss=1.1919, lr=5.50e-06]Steps:   6%|▌         | 276/5000 [1:17:04<12:24:23,  9.45s/it, loss=1.1919, lr=5.50e-06]Steps:   6%|▌         | 276/5000 [1:17:04<12:24:23,  9.45s/it, loss=1.1564, lr=5.52e-06]Steps:   6%|▌         | 277/5000 [1:17:13<12:24:45,  9.46s/it, loss=1.1564, lr=5.52e-06]Steps:   6%|▌         | 277/5000 [1:17:13<12:24:45,  9.46s/it, loss=1.0670, lr=5.54e-06]Steps:   6%|▌         | 278/5000 [1:17:22<12:25:16,  9.47s/it, loss=1.0670, lr=5.54e-06]Steps:   6%|▌         | 278/5000 [1:17:22<12:25:16,  9.47s/it, loss=1.0876, lr=5.56e-06]Steps:   6%|▌         | 279/5000 [1:17:32<12:20:27,  9.41s/it, loss=1.0876, lr=5.56e-06]Steps:   6%|▌         | 279/5000 [1:17:32<12:20:27,  9.41s/it, loss=1.1704, lr=5.58e-06]Steps:   6%|▌         | 280/5000 [1:17:41<12:17:30,  9.38s/it, loss=1.1704, lr=5.58e-06]Steps:   6%|▌         | 280/5000 [1:17:41<12:17:30,  9.38s/it, loss=0.4843, lr=5.60e-06]
[Step 280] Training Debug Info:
  Loss: 0.655296
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0505, std: 0.9219
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0520, std: 1.3594
  Model pred mean: -0.0500, std: 1.0938
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 280] Training Debug Info:
  Loss: 0.396745
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0211, std: 0.9141
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0198, std: 1.3516
  Model pred mean: -0.0216, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [794.0])

[Step 280] Training Debug Info:
  Loss: 1.116813
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0146, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0141, std: 1.3594
  Model pred mean: -0.0057, std: 0.8516
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 280] Training Debug Info:
  Loss: 0.625338
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0352, std: 0.9258
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0327, std: 1.3672
  Model pred mean: 0.0201, std: 1.1328
  Sigmas: [0.98046875]... (timesteps: [981.0])
Steps:   6%|▌         | 281/5000 [1:17:50<12:13:33,  9.33s/it, loss=0.4843, lr=5.60e-06]Steps:   6%|▌         | 281/5000 [1:17:50<12:13:33,  9.33s/it, loss=0.6253, lr=5.62e-06]Steps:   6%|▌         | 282/5000 [1:18:00<12:22:18,  9.44s/it, loss=0.6253, lr=5.62e-06]Steps:   6%|▌         | 282/5000 [1:18:00<12:22:18,  9.44s/it, loss=0.9965, lr=5.64e-06]Steps:   6%|▌         | 283/5000 [1:18:09<12:19:07,  9.40s/it, loss=0.9965, lr=5.64e-06]Steps:   6%|▌         | 283/5000 [1:18:09<12:19:07,  9.40s/it, loss=0.8311, lr=5.66e-06]Steps:   6%|▌         | 284/5000 [1:18:19<12:17:02,  9.38s/it, loss=0.8311, lr=5.66e-06]Steps:   6%|▌         | 284/5000 [1:18:19<12:17:02,  9.38s/it, loss=1.0782, lr=5.68e-06]Steps:   6%|▌         | 285/5000 [1:18:28<12:16:44,  9.38s/it, loss=1.0782, lr=5.68e-06]Steps:   6%|▌         | 285/5000 [1:18:28<12:16:44,  9.38s/it, loss=0.5824, lr=5.70e-06]Steps:   6%|▌         | 286/5000 [1:18:38<12:23:28,  9.46s/it, loss=0.5824, lr=5.70e-06]Steps:   6%|▌         | 286/5000 [1:18:38<12:23:28,  9.46s/it, loss=0.4646, lr=5.72e-06]Steps:   6%|▌         | 287/5000 [1:18:47<12:21:27,  9.44s/it, loss=0.4646, lr=5.72e-06]Steps:   6%|▌         | 287/5000 [1:18:47<12:21:27,  9.44s/it, loss=0.8572, lr=5.74e-06]Steps:   6%|▌         | 288/5000 [1:18:56<12:17:41,  9.39s/it, loss=0.8572, lr=5.74e-06]Steps:   6%|▌         | 288/5000 [1:18:56<12:17:41,  9.39s/it, loss=0.8703, lr=5.76e-06]Steps:   6%|▌         | 289/5000 [1:19:06<12:15:28,  9.37s/it, loss=0.8703, lr=5.76e-06]Steps:   6%|▌         | 289/5000 [1:19:06<12:15:28,  9.37s/it, loss=1.1167, lr=5.78e-06]Steps:   6%|▌         | 290/5000 [1:19:15<12:20:30,  9.43s/it, loss=1.1167, lr=5.78e-06]Steps:   6%|▌         | 290/5000 [1:19:15<12:20:30,  9.43s/it, loss=1.1812, lr=5.80e-06]
[Step 290] Training Debug Info:
  Loss: 1.138953
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0232, std: 0.8984
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0199, std: 1.3438
  Model pred mean: -0.0232, std: 0.8047
  Sigmas: [0.11181640625]... (timesteps: [112.0])

[Step 290] Training Debug Info:
  Loss: 1.105139
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0337, std: 0.9414
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0342, std: 1.3750
  Model pred mean: -0.0311, std: 0.8750
  Sigmas: [0.07421875]... (timesteps: [74.0])

[Step 290] Training Debug Info:
  Loss: 0.575102
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0187, std: 1.0078
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0188, std: 1.4219
  Model pred mean: -0.0114, std: 1.1953
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 290] Training Debug Info:
  Loss: 1.096956
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0012, std: 0.9453
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0013, std: 1.3750
  Model pred mean: -0.0024, std: 0.8867
  Sigmas: [0.06298828125]... (timesteps: [63.0])
Steps:   6%|▌         | 291/5000 [1:19:25<12:18:22,  9.41s/it, loss=1.1812, lr=5.80e-06]Steps:   6%|▌         | 291/5000 [1:19:25<12:18:22,  9.41s/it, loss=1.0970, lr=5.82e-06]Steps:   6%|▌         | 292/5000 [1:19:34<12:20:05,  9.43s/it, loss=1.0970, lr=5.82e-06]Steps:   6%|▌         | 292/5000 [1:19:34<12:20:05,  9.43s/it, loss=0.5808, lr=5.84e-06]Steps:   6%|▌         | 293/5000 [1:19:43<12:17:57,  9.41s/it, loss=0.5808, lr=5.84e-06]Steps:   6%|▌         | 293/5000 [1:19:43<12:17:57,  9.41s/it, loss=0.8782, lr=5.86e-06]Steps:   6%|▌         | 294/5000 [1:19:53<12:16:28,  9.39s/it, loss=0.8782, lr=5.86e-06]Steps:   6%|▌         | 294/5000 [1:19:53<12:16:28,  9.39s/it, loss=0.9160, lr=5.88e-06]Steps:   6%|▌         | 295/5000 [1:20:02<12:15:27,  9.38s/it, loss=0.9160, lr=5.88e-06]Steps:   6%|▌         | 295/5000 [1:20:02<12:15:27,  9.38s/it, loss=0.6939, lr=5.90e-06]Steps:   6%|▌         | 296/5000 [1:20:11<12:14:21,  9.37s/it, loss=0.6939, lr=5.90e-06]Steps:   6%|▌         | 296/5000 [1:20:11<12:14:21,  9.37s/it, loss=0.4871, lr=5.92e-06]Steps:   6%|▌         | 297/5000 [1:20:21<12:18:43,  9.42s/it, loss=0.4871, lr=5.92e-06]Steps:   6%|▌         | 297/5000 [1:20:21<12:18:43,  9.42s/it, loss=1.1871, lr=5.94e-06]Steps:   6%|▌         | 298/5000 [1:20:31<12:21:28,  9.46s/it, loss=1.1871, lr=5.94e-06]Steps:   6%|▌         | 298/5000 [1:20:31<12:21:28,  9.46s/it, loss=0.3870, lr=5.96e-06]Steps:   6%|▌         | 299/5000 [1:20:40<12:19:20,  9.44s/it, loss=0.3870, lr=5.96e-06]Steps:   6%|▌         | 299/5000 [1:20:40<12:19:20,  9.44s/it, loss=0.4524, lr=5.98e-06]Steps:   6%|▌         | 300/5000 [1:20:45<10:40:29,  8.18s/it, loss=0.4524, lr=5.98e-06]Steps:   6%|▌         | 300/5000 [1:20:45<10:40:29,  8.18s/it, loss=0.5133, lr=6.00e-06]01/30/2026 08:38:14 - INFO - __main__ - 
[Step 300] ✅ Loss in normal range (0.5133)
01/30/2026 08:38:14 - INFO - __main__ -   Loss avg (last 100): 0.7731
01/30/2026 08:38:14 - INFO - __main__ -   Loss range: [0.3720, 1.1919]
01/30/2026 08:38:14 - INFO - __main__ - 
🔍 Running validation at step 300...
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 300 (parquet mode)...
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 300...
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 08:38:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.28it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 08:38:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 08:38:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 08:39:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 08:39:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:39:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 08:39:37 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:40:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 08:40:05 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:40:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 08:40:33 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:41:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 08:41:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:41:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 08:41:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:41:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 08:41:57 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.03it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:42:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 08:42:25 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:42:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 08:42:53 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:43:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 08:43:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:43:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300/step000300_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 08:43:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 08:43:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 08:43:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000300
01/30/2026 08:43:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

01/30/2026 08:43:51 - INFO - __main__ - 
==================================================
01/30/2026 08:43:51 - INFO - __main__ - Epoch 3 completed: avg_loss = 0.7791
01/30/2026 08:43:51 - INFO - __main__ - ==================================================


[Step 300] Training Debug Info:
  Loss: 0.478541
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0134, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0152, std: 1.3438
  Model pred mean: -0.0167, std: 1.1641
  Sigmas: [0.6796875]... (timesteps: [681.0])

[Step 300] Training Debug Info:
  Loss: 1.026363
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0311, std: 1.0000
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0293, std: 1.4141
  Model pred mean: -0.0271, std: 0.9883
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 300] Training Debug Info:
  Loss: 0.506851
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0383, std: 0.8711
  Noise mean: 0.0021, std: 0.9961
  Target mean: 0.0405, std: 1.3203
  Model pred mean: 0.0299, std: 1.1328
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 300] Training Debug Info:
  Loss: 0.419194
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0101, std: 0.9453
  Noise mean: 0.0044, std: 1.0000
  Target mean: -0.0057, std: 1.3750
  Model pred mean: -0.0165, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [859.0])
Steps:   6%|▌         | 301/5000 [1:26:32<143:06:40, 109.64s/it, loss=0.5133, lr=6.00e-06]Steps:   6%|▌         | 301/5000 [1:26:32<143:06:40, 109.64s/it, loss=0.4192, lr=6.02e-06]Steps:   6%|▌         | 302/5000 [1:26:41<103:48:48, 79.55s/it, loss=0.4192, lr=6.02e-06] Steps:   6%|▌         | 302/5000 [1:26:41<103:48:48, 79.55s/it, loss=1.1716, lr=6.04e-06]Steps:   6%|▌         | 303/5000 [1:26:50<76:22:28, 58.54s/it, loss=1.1716, lr=6.04e-06] Steps:   6%|▌         | 303/5000 [1:26:50<76:22:28, 58.54s/it, loss=1.1328, lr=6.06e-06]Steps:   6%|▌         | 304/5000 [1:27:00<57:13:28, 43.87s/it, loss=1.1328, lr=6.06e-06]Steps:   6%|▌         | 304/5000 [1:27:00<57:13:28, 43.87s/it, loss=0.7202, lr=6.08e-06]Steps:   6%|▌         | 305/5000 [1:27:10<43:47:26, 33.58s/it, loss=0.7202, lr=6.08e-06]Steps:   6%|▌         | 305/5000 [1:27:10<43:47:26, 33.58s/it, loss=0.9446, lr=6.10e-06]Steps:   6%|▌         | 306/5000 [1:27:19<34:17:56, 26.31s/it, loss=0.9446, lr=6.10e-06]Steps:   6%|▌         | 306/5000 [1:27:19<34:17:56, 26.31s/it, loss=0.4717, lr=6.12e-06]Steps:   6%|▌         | 307/5000 [1:27:28<27:40:08, 21.22s/it, loss=0.4717, lr=6.12e-06]Steps:   6%|▌         | 307/5000 [1:27:28<27:40:08, 21.22s/it, loss=0.3956, lr=6.14e-06]Steps:   6%|▌         | 308/5000 [1:27:38<23:03:52, 17.70s/it, loss=0.3956, lr=6.14e-06]Steps:   6%|▌         | 308/5000 [1:27:38<23:03:52, 17.70s/it, loss=1.0183, lr=6.16e-06]Steps:   6%|▌         | 309/5000 [1:27:48<19:56:51, 15.31s/it, loss=1.0183, lr=6.16e-06]Steps:   6%|▌         | 309/5000 [1:27:48<19:56:51, 15.31s/it, loss=0.8581, lr=6.18e-06]Steps:   6%|▌         | 310/5000 [1:27:57<17:37:08, 13.52s/it, loss=0.8581, lr=6.18e-06]Steps:   6%|▌         | 310/5000 [1:27:57<17:37:08, 13.52s/it, loss=0.7088, lr=6.20e-06]
[Step 310] Training Debug Info:
  Loss: 0.967058
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0002, std: 0.8477
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0012, std: 1.3125
  Model pred mean: 0.0005, std: 0.8711
  Sigmas: [0.40625]... (timesteps: [407.0])

[Step 310] Training Debug Info:
  Loss: 0.548560
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0273, std: 0.9180
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0248, std: 1.3594
  Model pred mean: 0.0281, std: 1.1406
  Sigmas: [0.6328125]... (timesteps: [633.0])

[Step 310] Training Debug Info:
  Loss: 1.188124
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0022, std: 0.8867
  Noise mean: -0.0041, std: 1.0000
  Target mean: -0.0063, std: 1.3359
  Model pred mean: 0.0001, std: 0.7891
  Sigmas: [0.16015625]... (timesteps: [160.0])

[Step 310] Training Debug Info:
  Loss: 0.800994
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0354, std: 0.9922
  Noise mean: 0.0036, std: 1.0000
  Target mean: -0.0320, std: 1.4062
  Model pred mean: -0.0300, std: 1.0859
  Sigmas: [0.4453125]... (timesteps: [446.0])
Steps:   6%|▌         | 311/5000 [1:28:06<16:00:49, 12.29s/it, loss=0.7088, lr=6.20e-06]Steps:   6%|▌         | 311/5000 [1:28:06<16:00:49, 12.29s/it, loss=0.8010, lr=6.22e-06]Steps:   6%|▌         | 312/5000 [1:28:16<14:53:37, 11.44s/it, loss=0.8010, lr=6.22e-06]Steps:   6%|▌         | 312/5000 [1:28:16<14:53:37, 11.44s/it, loss=0.8606, lr=6.24e-06]Steps:   6%|▋         | 313/5000 [1:28:25<14:03:12, 10.79s/it, loss=0.8606, lr=6.24e-06]Steps:   6%|▋         | 313/5000 [1:28:25<14:03:12, 10.79s/it, loss=0.6447, lr=6.26e-06]Steps:   6%|▋         | 314/5000 [1:28:34<13:28:08, 10.35s/it, loss=0.6447, lr=6.26e-06]Steps:   6%|▋         | 314/5000 [1:28:34<13:28:08, 10.35s/it, loss=1.1656, lr=6.28e-06]Steps:   6%|▋         | 315/5000 [1:28:44<13:05:25, 10.06s/it, loss=1.1656, lr=6.28e-06]Steps:   6%|▋         | 315/5000 [1:28:44<13:05:25, 10.06s/it, loss=1.1462, lr=6.30e-06]Steps:   6%|▋         | 316/5000 [1:28:53<12:50:41,  9.87s/it, loss=1.1462, lr=6.30e-06]Steps:   6%|▋         | 316/5000 [1:28:53<12:50:41,  9.87s/it, loss=1.1121, lr=6.32e-06]Steps:   6%|▋         | 317/5000 [1:29:03<12:40:29,  9.74s/it, loss=1.1121, lr=6.32e-06]Steps:   6%|▋         | 317/5000 [1:29:03<12:40:29,  9.74s/it, loss=0.6522, lr=6.34e-06]Steps:   6%|▋         | 318/5000 [1:29:12<12:36:00,  9.69s/it, loss=0.6522, lr=6.34e-06]Steps:   6%|▋         | 318/5000 [1:29:12<12:36:00,  9.69s/it, loss=0.9990, lr=6.36e-06]Steps:   6%|▋         | 319/5000 [1:29:22<12:30:39,  9.62s/it, loss=0.9990, lr=6.36e-06]Steps:   6%|▋         | 319/5000 [1:29:22<12:30:39,  9.62s/it, loss=1.0712, lr=6.38e-06]Steps:   6%|▋         | 320/5000 [1:29:31<12:25:31,  9.56s/it, loss=1.0712, lr=6.38e-06]Steps:   6%|▋         | 320/5000 [1:29:31<12:25:31,  9.56s/it, loss=0.4845, lr=6.40e-06]
[Step 320] Training Debug Info:
  Loss: 0.675985
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0113, std: 0.8828
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0093, std: 1.3359
  Model pred mean: -0.0060, std: 1.0547
  Sigmas: [0.546875]... (timesteps: [548.0])

[Step 320] Training Debug Info:
  Loss: 0.438509
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0027, std: 0.9609
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0009, std: 1.3828
  Model pred mean: -0.0020, std: 1.2266
  Sigmas: [0.77734375]... (timesteps: [779.0])

[Step 320] Training Debug Info:
  Loss: 0.413645
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0082, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0096, std: 1.3516
  Model pred mean: -0.0171, std: 1.1797
  Sigmas: [0.87109375]... (timesteps: [870.0])

[Step 320] Training Debug Info:
  Loss: 1.174058
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0276, std: 0.9180
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0282, std: 1.3594
  Model pred mean: 0.0339, std: 0.8125
  Sigmas: [0.1640625]... (timesteps: [164.0])
Steps:   6%|▋         | 321/5000 [1:29:40<12:22:07,  9.52s/it, loss=0.4845, lr=6.40e-06]Steps:   6%|▋         | 321/5000 [1:29:40<12:22:07,  9.52s/it, loss=1.1741, lr=6.42e-06]Steps:   6%|▋         | 322/5000 [1:29:50<12:16:39,  9.45s/it, loss=1.1741, lr=6.42e-06]Steps:   6%|▋         | 322/5000 [1:29:50<12:16:39,  9.45s/it, loss=1.1093, lr=6.44e-06]Steps:   6%|▋         | 323/5000 [1:29:59<12:19:35,  9.49s/it, loss=1.1093, lr=6.44e-06]Steps:   6%|▋         | 323/5000 [1:29:59<12:19:35,  9.49s/it, loss=0.5124, lr=6.46e-06]Steps:   6%|▋         | 324/5000 [1:30:09<12:14:48,  9.43s/it, loss=0.5124, lr=6.46e-06]Steps:   6%|▋         | 324/5000 [1:30:09<12:14:48,  9.43s/it, loss=0.5899, lr=6.48e-06]Steps:   6%|▋         | 325/5000 [1:30:18<12:14:51,  9.43s/it, loss=0.5899, lr=6.48e-06]Steps:   6%|▋         | 325/5000 [1:30:18<12:14:51,  9.43s/it, loss=0.8127, lr=6.50e-06]Steps:   7%|▋         | 326/5000 [1:30:28<12:16:11,  9.45s/it, loss=0.8127, lr=6.50e-06]Steps:   7%|▋         | 326/5000 [1:30:28<12:16:11,  9.45s/it, loss=1.1418, lr=6.52e-06]Steps:   7%|▋         | 327/5000 [1:30:37<12:19:43,  9.50s/it, loss=1.1418, lr=6.52e-06]Steps:   7%|▋         | 327/5000 [1:30:37<12:19:43,  9.50s/it, loss=0.7658, lr=6.54e-06]Steps:   7%|▋         | 328/5000 [1:30:47<12:16:13,  9.46s/it, loss=0.7658, lr=6.54e-06]Steps:   7%|▋         | 328/5000 [1:30:47<12:16:13,  9.46s/it, loss=0.5125, lr=6.56e-06]Steps:   7%|▋         | 329/5000 [1:30:56<12:17:19,  9.47s/it, loss=0.5125, lr=6.56e-06]Steps:   7%|▋         | 329/5000 [1:30:56<12:17:19,  9.47s/it, loss=0.8426, lr=6.58e-06]Steps:   7%|▋         | 330/5000 [1:31:06<12:20:13,  9.51s/it, loss=0.8426, lr=6.58e-06]Steps:   7%|▋         | 330/5000 [1:31:06<12:20:13,  9.51s/it, loss=0.7848, lr=6.60e-06]
[Step 330] Training Debug Info:
  Loss: 0.700387
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0013, std: 0.9336
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0002, std: 1.3672
  Model pred mean: 0.0050, std: 1.0781
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 330] Training Debug Info:
  Loss: 0.872805
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0085, std: 0.8867
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0085, std: 1.3359
  Model pred mean: -0.0090, std: 0.9531
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 330] Training Debug Info:
  Loss: 0.526101
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0159, std: 0.9023
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0159, std: 1.3438
  Model pred mean: -0.0049, std: 1.1328
  Sigmas: [0.921875]... (timesteps: [922.0])

[Step 330] Training Debug Info:
  Loss: 0.576069
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0021, std: 0.8672
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0006, std: 1.3203
  Model pred mean: 0.0236, std: 1.0938
  Sigmas: [0.9765625]... (timesteps: [975.0])
Steps:   7%|▋         | 331/5000 [1:31:15<12:15:43,  9.45s/it, loss=0.7848, lr=6.60e-06]Steps:   7%|▋         | 331/5000 [1:31:15<12:15:43,  9.45s/it, loss=0.5761, lr=6.62e-06]Steps:   7%|▋         | 332/5000 [1:31:24<12:14:38,  9.44s/it, loss=0.5761, lr=6.62e-06]Steps:   7%|▋         | 332/5000 [1:31:24<12:14:38,  9.44s/it, loss=1.1236, lr=6.64e-06]Steps:   7%|▋         | 333/5000 [1:31:34<12:12:55,  9.42s/it, loss=1.1236, lr=6.64e-06]Steps:   7%|▋         | 333/5000 [1:31:34<12:12:55,  9.42s/it, loss=1.1803, lr=6.66e-06]Steps:   7%|▋         | 334/5000 [1:31:43<12:14:30,  9.45s/it, loss=1.1803, lr=6.66e-06]Steps:   7%|▋         | 334/5000 [1:31:43<12:14:30,  9.45s/it, loss=0.7626, lr=6.68e-06]Steps:   7%|▋         | 335/5000 [1:31:53<12:17:05,  9.48s/it, loss=0.7626, lr=6.68e-06]Steps:   7%|▋         | 335/5000 [1:31:53<12:17:05,  9.48s/it, loss=0.4050, lr=6.70e-06]Steps:   7%|▋         | 336/5000 [1:32:02<12:17:17,  9.48s/it, loss=0.4050, lr=6.70e-06]Steps:   7%|▋         | 336/5000 [1:32:02<12:17:17,  9.48s/it, loss=0.4124, lr=6.72e-06]Steps:   7%|▋         | 337/5000 [1:32:12<12:15:20,  9.46s/it, loss=0.4124, lr=6.72e-06]Steps:   7%|▋         | 337/5000 [1:32:12<12:15:20,  9.46s/it, loss=0.5325, lr=6.74e-06]Steps:   7%|▋         | 338/5000 [1:32:21<12:13:33,  9.44s/it, loss=0.5325, lr=6.74e-06]Steps:   7%|▋         | 338/5000 [1:32:21<12:13:33,  9.44s/it, loss=0.7648, lr=6.76e-06]Steps:   7%|▋         | 339/5000 [1:32:31<12:18:23,  9.51s/it, loss=0.7648, lr=6.76e-06]Steps:   7%|▋         | 339/5000 [1:32:31<12:18:23,  9.51s/it, loss=1.1467, lr=6.78e-06]Steps:   7%|▋         | 340/5000 [1:32:40<12:16:48,  9.49s/it, loss=1.1467, lr=6.78e-06]Steps:   7%|▋         | 340/5000 [1:32:40<12:16:48,  9.49s/it, loss=0.8472, lr=6.80e-06]
[Step 340] Training Debug Info:
  Loss: 0.599631
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0240, std: 0.8945
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0244, std: 1.3438
  Model pred mean: -0.0593, std: 1.0938
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 340] Training Debug Info:
  Loss: 0.995148
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0035, std: 0.8789
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0022, std: 1.3281
  Model pred mean: -0.0039, std: 0.8945
  Sigmas: [0.369140625]... (timesteps: [369.0])

[Step 340] Training Debug Info:
  Loss: 1.050490
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0571, std: 0.9180
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0576, std: 1.3594
  Model pred mean: -0.0554, std: 0.9023
  Sigmas: [0.25390625]... (timesteps: [252.99998474121094])

[Step 340] Training Debug Info:
  Loss: 0.572465
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0143, std: 0.9062
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0119, std: 1.3516
  Model pred mean: -0.0024, std: 1.1484
  Sigmas: [0.9375]... (timesteps: [939.0])
Steps:   7%|▋         | 341/5000 [1:32:50<12:16:00,  9.48s/it, loss=0.8472, lr=6.80e-06]Steps:   7%|▋         | 341/5000 [1:32:50<12:16:00,  9.48s/it, loss=0.5725, lr=6.82e-06]Steps:   7%|▋         | 342/5000 [1:32:59<12:12:44,  9.44s/it, loss=0.5725, lr=6.82e-06]Steps:   7%|▋         | 342/5000 [1:32:59<12:12:44,  9.44s/it, loss=1.1285, lr=6.84e-06]Steps:   7%|▋         | 343/5000 [1:33:09<12:15:52,  9.48s/it, loss=1.1285, lr=6.84e-06]Steps:   7%|▋         | 343/5000 [1:33:09<12:15:52,  9.48s/it, loss=0.6043, lr=6.86e-06]Steps:   7%|▋         | 344/5000 [1:33:18<12:16:04,  9.49s/it, loss=0.6043, lr=6.86e-06]Steps:   7%|▋         | 344/5000 [1:33:18<12:16:04,  9.49s/it, loss=0.7878, lr=6.88e-06]Steps:   7%|▋         | 345/5000 [1:33:28<12:15:58,  9.49s/it, loss=0.7878, lr=6.88e-06]Steps:   7%|▋         | 345/5000 [1:33:28<12:15:58,  9.49s/it, loss=0.6316, lr=6.90e-06]Steps:   7%|▋         | 346/5000 [1:33:37<12:14:21,  9.47s/it, loss=0.6316, lr=6.90e-06]Steps:   7%|▋         | 346/5000 [1:33:37<12:14:21,  9.47s/it, loss=0.5610, lr=6.92e-06]Steps:   7%|▋         | 347/5000 [1:33:46<12:12:01,  9.44s/it, loss=0.5610, lr=6.92e-06]Steps:   7%|▋         | 347/5000 [1:33:46<12:12:01,  9.44s/it, loss=0.7027, lr=6.94e-06]Steps:   7%|▋         | 348/5000 [1:33:56<12:12:17,  9.44s/it, loss=0.7027, lr=6.94e-06]Steps:   7%|▋         | 348/5000 [1:33:56<12:12:17,  9.44s/it, loss=0.4864, lr=6.96e-06]Steps:   7%|▋         | 349/5000 [1:34:05<12:10:19,  9.42s/it, loss=0.4864, lr=6.96e-06]Steps:   7%|▋         | 349/5000 [1:34:05<12:10:19,  9.42s/it, loss=0.7397, lr=6.98e-06]Steps:   7%|▋         | 350/5000 [1:34:15<12:12:27,  9.45s/it, loss=0.7397, lr=6.98e-06]Steps:   7%|▋         | 350/5000 [1:34:15<12:12:27,  9.45s/it, loss=0.6035, lr=7.00e-06]01/30/2026 08:51:44 - INFO - __main__ - 
🔍 Running validation at step 350...
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 350 (parquet mode)...
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 350...
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 08:51:45 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.65it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:06<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:10,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:17<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.09it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.09it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.09it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 08:52:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 08:52:11 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.64it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.14it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.10it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.09it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.08it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 08:52:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 08:52:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.04it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:53:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 08:53:06 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:53:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 08:53:34 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:54:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 08:54:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:54:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 08:54:30 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:54:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 08:54:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 08:55:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 08:55:26 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 08:55:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 08:55:54 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 08:56:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 08:56:22 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.07it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:56:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 08:56:49 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.62it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.07it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:10<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 08:57:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350/step000350_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 08:57:16 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 08:57:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 08:57:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000350
01/30/2026 08:57:17 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 350] Training Debug Info:
  Loss: 0.458594
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0142, std: 0.9258
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0131, std: 1.3594
  Model pred mean: 0.0082, std: 1.1797
  Sigmas: [0.734375]... (timesteps: [734.0])

[Step 350] Training Debug Info:
  Loss: 0.749070
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0269, std: 0.9062
  Noise mean: 0.0040, std: 1.0000
  Target mean: 0.0309, std: 1.3516
  Model pred mean: 0.0277, std: 1.0312
  Sigmas: [0.4765625]... (timesteps: [477.0])

[Step 350] Training Debug Info:
  Loss: 0.407991
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9102
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0182, std: 1.3516
  Model pred mean: -0.0194, std: 1.1953
  Sigmas: [0.828125]... (timesteps: [830.0])

[Step 350] Training Debug Info:
  Loss: 0.462916
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0354, std: 0.8945
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0337, std: 1.3359
  Model pred mean: -0.0304, std: 1.1484
  Sigmas: [0.70703125]... (timesteps: [708.0])
Steps:   7%|▋         | 351/5000 [1:40:00<142:27:15, 110.31s/it, loss=0.6035, lr=7.00e-06]Steps:   7%|▋         | 351/5000 [1:40:00<142:27:15, 110.31s/it, loss=0.4629, lr=7.02e-06]Steps:   7%|▋         | 352/5000 [1:40:10<103:26:43, 80.12s/it, loss=0.4629, lr=7.02e-06] Steps:   7%|▋         | 352/5000 [1:40:10<103:26:43, 80.12s/it, loss=0.7557, lr=7.04e-06]Steps:   7%|▋         | 353/5000 [1:40:19<76:01:01, 58.89s/it, loss=0.7557, lr=7.04e-06] Steps:   7%|▋         | 353/5000 [1:40:19<76:01:01, 58.89s/it, loss=0.4159, lr=7.06e-06]Steps:   7%|▋         | 354/5000 [1:40:29<56:46:14, 43.99s/it, loss=0.4159, lr=7.06e-06]Steps:   7%|▋         | 354/5000 [1:40:29<56:46:14, 43.99s/it, loss=0.8341, lr=7.08e-06]Steps:   7%|▋         | 355/5000 [1:40:38<43:19:33, 33.58s/it, loss=0.8341, lr=7.08e-06]Steps:   7%|▋         | 355/5000 [1:40:38<43:19:33, 33.58s/it, loss=1.1806, lr=7.10e-06]Steps:   7%|▋         | 356/5000 [1:40:47<33:53:41, 26.28s/it, loss=1.1806, lr=7.10e-06]Steps:   7%|▋         | 356/5000 [1:40:47<33:53:41, 26.28s/it, loss=0.3377, lr=7.12e-06]Steps:   7%|▋         | 357/5000 [1:40:57<27:23:37, 21.24s/it, loss=0.3377, lr=7.12e-06]Steps:   7%|▋         | 357/5000 [1:40:57<27:23:37, 21.24s/it, loss=0.5273, lr=7.14e-06]Steps:   7%|▋         | 358/5000 [1:41:06<22:50:04, 17.71s/it, loss=0.5273, lr=7.14e-06]Steps:   7%|▋         | 358/5000 [1:41:06<22:50:04, 17.71s/it, loss=1.0633, lr=7.16e-06]Steps:   7%|▋         | 359/5000 [1:41:16<19:40:26, 15.26s/it, loss=1.0633, lr=7.16e-06]Steps:   7%|▋         | 359/5000 [1:41:16<19:40:26, 15.26s/it, loss=1.1550, lr=7.18e-06]Steps:   7%|▋         | 360/5000 [1:41:25<17:29:00, 13.56s/it, loss=1.1550, lr=7.18e-06]Steps:   7%|▋         | 360/5000 [1:41:25<17:29:00, 13.56s/it, loss=0.6480, lr=7.20e-06]
[Step 360] Training Debug Info:
  Loss: 0.541568
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0137, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0142, std: 1.3672
  Model pred mean: -0.0078, std: 1.1484
  Sigmas: [0.60546875]... (timesteps: [605.0])

[Step 360] Training Debug Info:
  Loss: 0.399905
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0064, std: 0.8672
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0056, std: 1.3281
  Model pred mean: -0.0004, std: 1.1719
  Sigmas: [0.91796875]... (timesteps: [918.0])

[Step 360] Training Debug Info:
  Loss: 0.603096
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0189, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0205, std: 1.3281
  Model pred mean: 0.0161, std: 1.0781
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 360] Training Debug Info:
  Loss: 0.389846
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0430, std: 0.9141
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0417, std: 1.3516
  Model pred mean: 0.0405, std: 1.2031
  Sigmas: [0.828125]... (timesteps: [829.0])
Steps:   7%|▋         | 361/5000 [1:41:34<15:48:55, 12.27s/it, loss=0.6480, lr=7.20e-06]Steps:   7%|▋         | 361/5000 [1:41:34<15:48:55, 12.27s/it, loss=0.3898, lr=7.22e-06]Steps:   7%|▋         | 362/5000 [1:41:44<14:41:16, 11.40s/it, loss=0.3898, lr=7.22e-06]Steps:   7%|▋         | 362/5000 [1:41:44<14:41:16, 11.40s/it, loss=0.4617, lr=7.24e-06]Steps:   7%|▋         | 363/5000 [1:41:53<13:51:52, 10.76s/it, loss=0.4617, lr=7.24e-06]Steps:   7%|▋         | 363/5000 [1:41:53<13:51:52, 10.76s/it, loss=1.0879, lr=7.26e-06]Steps:   7%|▋         | 364/5000 [1:42:03<13:19:19, 10.34s/it, loss=1.0879, lr=7.26e-06]Steps:   7%|▋         | 364/5000 [1:42:03<13:19:19, 10.34s/it, loss=0.9479, lr=7.28e-06]Steps:   7%|▋         | 365/5000 [1:42:12<13:02:57, 10.14s/it, loss=0.9479, lr=7.28e-06]Steps:   7%|▋         | 365/5000 [1:42:12<13:02:57, 10.14s/it, loss=1.1612, lr=7.30e-06]Steps:   7%|▋         | 366/5000 [1:42:22<12:45:31,  9.91s/it, loss=1.1612, lr=7.30e-06]Steps:   7%|▋         | 366/5000 [1:42:22<12:45:31,  9.91s/it, loss=0.4063, lr=7.32e-06]Steps:   7%|▋         | 367/5000 [1:42:31<12:32:04,  9.74s/it, loss=0.4063, lr=7.32e-06]Steps:   7%|▋         | 367/5000 [1:42:31<12:32:04,  9.74s/it, loss=1.0888, lr=7.34e-06]Steps:   7%|▋         | 368/5000 [1:42:40<12:22:42,  9.62s/it, loss=1.0888, lr=7.34e-06]Steps:   7%|▋         | 368/5000 [1:42:40<12:22:42,  9.62s/it, loss=1.2231, lr=7.36e-06]Steps:   7%|▋         | 369/5000 [1:42:50<12:18:53,  9.57s/it, loss=1.2231, lr=7.36e-06]Steps:   7%|▋         | 369/5000 [1:42:50<12:18:53,  9.57s/it, loss=0.9553, lr=7.38e-06]Steps:   7%|▋         | 370/5000 [1:42:59<12:12:40,  9.49s/it, loss=0.9553, lr=7.38e-06]Steps:   7%|▋         | 370/5000 [1:42:59<12:12:40,  9.49s/it, loss=0.9567, lr=7.40e-06]
[Step 370] Training Debug Info:
  Loss: 0.368263
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0128, std: 0.8789
  Noise mean: 0.0036, std: 0.9961
  Target mean: 0.0164, std: 1.3281
  Model pred mean: 0.0117, std: 1.1719
  Sigmas: [0.84765625]... (timesteps: [848.0])

[Step 370] Training Debug Info:
  Loss: 0.385916
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0228, std: 0.8672
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0228, std: 1.3203
  Model pred mean: 0.0215, std: 1.1641
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 370] Training Debug Info:
  Loss: 0.573014
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0119, std: 0.9844
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0123, std: 1.4062
  Model pred mean: -0.0153, std: 1.1797
  Sigmas: [0.61328125]... (timesteps: [612.0])

[Step 370] Training Debug Info:
  Loss: 0.492865
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0017, std: 0.9102
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: -0.0117, std: 1.1406
  Sigmas: [0.68359375]... (timesteps: [682.0])
Steps:   7%|▋         | 371/5000 [1:43:08<12:12:15,  9.49s/it, loss=0.9567, lr=7.40e-06]Steps:   7%|▋         | 371/5000 [1:43:08<12:12:15,  9.49s/it, loss=0.4929, lr=7.42e-06]Steps:   7%|▋         | 372/5000 [1:43:18<12:12:04,  9.49s/it, loss=0.4929, lr=7.42e-06]Steps:   7%|▋         | 372/5000 [1:43:18<12:12:04,  9.49s/it, loss=1.0606, lr=7.44e-06]Steps:   7%|▋         | 373/5000 [1:43:27<12:12:38,  9.50s/it, loss=1.0606, lr=7.44e-06]Steps:   7%|▋         | 373/5000 [1:43:27<12:12:38,  9.50s/it, loss=0.3662, lr=7.46e-06]Steps:   7%|▋         | 374/5000 [1:43:37<12:09:22,  9.46s/it, loss=0.3662, lr=7.46e-06]Steps:   7%|▋         | 374/5000 [1:43:37<12:09:22,  9.46s/it, loss=0.9190, lr=7.48e-06]Steps:   8%|▊         | 375/5000 [1:43:42<10:33:14,  8.21s/it, loss=0.9190, lr=7.48e-06]Steps:   8%|▊         | 375/5000 [1:43:42<10:33:14,  8.21s/it, loss=1.0601, lr=7.50e-06]01/30/2026 09:01:12 - INFO - __main__ - 
==================================================
01/30/2026 09:01:12 - INFO - __main__ - Epoch 4 completed: avg_loss = 0.7940
01/30/2026 09:01:12 - INFO - __main__ - ==================================================

Steps:   8%|▊         | 376/5000 [1:43:52<11:08:37,  8.68s/it, loss=1.0601, lr=7.50e-06]Steps:   8%|▊         | 376/5000 [1:43:52<11:08:37,  8.68s/it, loss=0.7464, lr=7.52e-06]Steps:   8%|▊         | 377/5000 [1:44:02<11:30:43,  8.96s/it, loss=0.7464, lr=7.52e-06]Steps:   8%|▊         | 377/5000 [1:44:02<11:30:43,  8.96s/it, loss=1.0445, lr=7.54e-06]Steps:   8%|▊         | 378/5000 [1:44:11<11:43:22,  9.13s/it, loss=1.0445, lr=7.54e-06]Steps:   8%|▊         | 378/5000 [1:44:11<11:43:22,  9.13s/it, loss=1.1685, lr=7.56e-06]Steps:   8%|▊         | 379/5000 [1:44:21<11:54:20,  9.28s/it, loss=1.1685, lr=7.56e-06]Steps:   8%|▊         | 379/5000 [1:44:21<11:54:20,  9.28s/it, loss=1.0276, lr=7.58e-06]Steps:   8%|▊         | 380/5000 [1:44:30<12:04:33,  9.41s/it, loss=1.0276, lr=7.58e-06]Steps:   8%|▊         | 380/5000 [1:44:30<12:04:33,  9.41s/it, loss=0.9190, lr=7.60e-06]
[Step 380] Training Debug Info:
  Loss: 1.169705
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0261, std: 0.9219
  Noise mean: -0.0019, std: 0.9961
  Target mean: 0.0242, std: 1.3594
  Model pred mean: 0.0275, std: 0.8281
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 380] Training Debug Info:
  Loss: 1.034093
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0154, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0153, std: 1.3516
  Model pred mean: 0.0091, std: 0.8828
  Sigmas: [0.01397705078125]... (timesteps: [14.0])

[Step 380] Training Debug Info:
  Loss: 0.941920
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0057, std: 0.8906
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0078, std: 1.3359
  Model pred mean: 0.0095, std: 0.9297
  Sigmas: [0.38671875]... (timesteps: [387.0])

[Step 380] Training Debug Info:
  Loss: 0.484824
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0073, std: 0.8984
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0063, std: 1.3438
  Model pred mean: 0.0121, std: 1.1562
  Sigmas: [0.6875]... (timesteps: [686.0])
Steps:   8%|▊         | 381/5000 [1:44:40<12:12:09,  9.51s/it, loss=0.9190, lr=7.60e-06]Steps:   8%|▊         | 381/5000 [1:44:40<12:12:09,  9.51s/it, loss=0.4848, lr=7.62e-06]Steps:   8%|▊         | 382/5000 [1:44:50<12:09:47,  9.48s/it, loss=0.4848, lr=7.62e-06]Steps:   8%|▊         | 382/5000 [1:44:50<12:09:47,  9.48s/it, loss=0.5617, lr=7.64e-06]Steps:   8%|▊         | 383/5000 [1:44:59<12:07:43,  9.46s/it, loss=0.5617, lr=7.64e-06]Steps:   8%|▊         | 383/5000 [1:44:59<12:07:43,  9.46s/it, loss=0.6656, lr=7.66e-06]Steps:   8%|▊         | 384/5000 [1:45:09<12:11:46,  9.51s/it, loss=0.6656, lr=7.66e-06]Steps:   8%|▊         | 384/5000 [1:45:09<12:11:46,  9.51s/it, loss=0.4556, lr=7.68e-06]Steps:   8%|▊         | 385/5000 [1:45:18<12:08:19,  9.47s/it, loss=0.4556, lr=7.68e-06]Steps:   8%|▊         | 385/5000 [1:45:18<12:08:19,  9.47s/it, loss=1.0423, lr=7.70e-06]Steps:   8%|▊         | 386/5000 [1:45:27<12:03:52,  9.41s/it, loss=1.0423, lr=7.70e-06]Steps:   8%|▊         | 386/5000 [1:45:27<12:03:52,  9.41s/it, loss=0.8891, lr=7.72e-06]Steps:   8%|▊         | 387/5000 [1:45:37<12:05:51,  9.44s/it, loss=0.8891, lr=7.72e-06]Steps:   8%|▊         | 387/5000 [1:45:37<12:05:51,  9.44s/it, loss=0.4099, lr=7.74e-06]Steps:   8%|▊         | 388/5000 [1:45:46<12:08:05,  9.47s/it, loss=0.4099, lr=7.74e-06]Steps:   8%|▊         | 388/5000 [1:45:46<12:08:05,  9.47s/it, loss=1.0485, lr=7.76e-06]Steps:   8%|▊         | 389/5000 [1:45:56<12:02:44,  9.40s/it, loss=1.0485, lr=7.76e-06]Steps:   8%|▊         | 389/5000 [1:45:56<12:02:44,  9.40s/it, loss=0.3926, lr=7.78e-06]Steps:   8%|▊         | 390/5000 [1:46:05<12:04:52,  9.43s/it, loss=0.3926, lr=7.78e-06]Steps:   8%|▊         | 390/5000 [1:46:05<12:04:52,  9.43s/it, loss=1.1952, lr=7.80e-06]
[Step 390] Training Debug Info:
  Loss: 1.067669
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0087, std: 0.9727
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0095, std: 1.3906
  Model pred mean: -0.0089, std: 0.9375
  Sigmas: [0.06298828125]... (timesteps: [63.0])

[Step 390] Training Debug Info:
  Loss: 0.436823
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0679, std: 0.9336
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0659, std: 1.3672
  Model pred mean: 0.0703, std: 1.1953
  Sigmas: [0.66015625]... (timesteps: [659.0])

[Step 390] Training Debug Info:
  Loss: 0.580894
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0089, std: 0.9453
  Noise mean: 0.0041, std: 1.0000
  Target mean: 0.0129, std: 1.3828
  Model pred mean: 0.0084, std: 1.1641
  Sigmas: [0.5390625]... (timesteps: [540.0])

[Step 390] Training Debug Info:
  Loss: 0.445908
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.9336
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0005, std: 1.3672
  Model pred mean: -0.0017, std: 1.1953
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   8%|▊         | 391/5000 [1:46:15<12:05:41,  9.45s/it, loss=1.1952, lr=7.80e-06]Steps:   8%|▊         | 391/5000 [1:46:15<12:05:41,  9.45s/it, loss=0.4459, lr=7.82e-06]Steps:   8%|▊         | 392/5000 [1:46:24<12:04:01,  9.43s/it, loss=0.4459, lr=7.82e-06]Steps:   8%|▊         | 392/5000 [1:46:24<12:04:01,  9.43s/it, loss=0.8418, lr=7.84e-06]Steps:   8%|▊         | 393/5000 [1:46:33<12:02:46,  9.41s/it, loss=0.8418, lr=7.84e-06]Steps:   8%|▊         | 393/5000 [1:46:33<12:02:46,  9.41s/it, loss=0.4854, lr=7.86e-06]Steps:   8%|▊         | 394/5000 [1:46:43<12:04:25,  9.44s/it, loss=0.4854, lr=7.86e-06]Steps:   8%|▊         | 394/5000 [1:46:43<12:04:25,  9.44s/it, loss=1.0017, lr=7.88e-06]Steps:   8%|▊         | 395/5000 [1:46:52<12:03:33,  9.43s/it, loss=1.0017, lr=7.88e-06]Steps:   8%|▊         | 395/5000 [1:46:52<12:03:33,  9.43s/it, loss=0.5343, lr=7.90e-06]Steps:   8%|▊         | 396/5000 [1:47:02<12:03:19,  9.43s/it, loss=0.5343, lr=7.90e-06]Steps:   8%|▊         | 396/5000 [1:47:02<12:03:19,  9.43s/it, loss=1.1602, lr=7.92e-06]Steps:   8%|▊         | 397/5000 [1:47:11<12:11:34,  9.54s/it, loss=1.1602, lr=7.92e-06]Steps:   8%|▊         | 397/5000 [1:47:11<12:11:34,  9.54s/it, loss=1.1692, lr=7.94e-06]Steps:   8%|▊         | 398/5000 [1:47:21<12:08:01,  9.49s/it, loss=1.1692, lr=7.94e-06]Steps:   8%|▊         | 398/5000 [1:47:21<12:08:01,  9.49s/it, loss=0.4288, lr=7.96e-06]Steps:   8%|▊         | 399/5000 [1:47:30<12:03:02,  9.43s/it, loss=0.4288, lr=7.96e-06]Steps:   8%|▊         | 399/5000 [1:47:30<12:03:02,  9.43s/it, loss=0.5088, lr=7.98e-06]Steps:   8%|▊         | 400/5000 [1:47:39<11:58:34,  9.37s/it, loss=0.5088, lr=7.98e-06]Steps:   8%|▊         | 400/5000 [1:47:39<11:58:34,  9.37s/it, loss=1.1050, lr=8.00e-06]01/30/2026 09:05:09 - INFO - __main__ - 
[Step 400] ✅ Loss in normal range (1.1050)
01/30/2026 09:05:09 - INFO - __main__ -   Loss avg (last 100): 0.7928
01/30/2026 09:05:09 - INFO - __main__ -   Loss range: [0.3377, 1.2231]
01/30/2026 09:05:09 - INFO - __main__ - 
🔍 Running validation at step 400...
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 400 (parquet mode)...
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 400...
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 09:05:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.65it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.18it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.09it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.09it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.09it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 09:05:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 09:05:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.64it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.09it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.08it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 09:06:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 09:06:03 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.57it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.05it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.04it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.04it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:06:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 09:06:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 09:06:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 09:06:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:07:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 09:07:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:07:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 09:07:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:08:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 09:08:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:08:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 09:08:52 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 09:09:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 09:09:20 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:09:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 09:09:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.62it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.15it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 09:10:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 09:10:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.06it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.06it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.06it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.06it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.06it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.06it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.06it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.06it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.06it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.06it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.06it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.06it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 09:10:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400/step000400_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 09:10:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 09:10:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 09:10:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000400
01/30/2026 09:10:43 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 400] Training Debug Info:
  Loss: 0.468920
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0019, std: 0.8867
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0012, std: 1.3359
  Model pred mean: -0.0088, std: 1.1562
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 400] Training Debug Info:
  Loss: 0.627530
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0095, std: 0.8750
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0103, std: 1.3281
  Model pred mean: -0.0052, std: 1.0547
  Sigmas: [0.5625]... (timesteps: [561.0])

[Step 400] Training Debug Info:
  Loss: 0.798766
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0089, std: 0.8828
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0098, std: 1.3359
  Model pred mean: 0.0114, std: 0.9844
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 400] Training Debug Info:
  Loss: 1.155958
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0157, std: 0.9062
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0160, std: 1.3516
  Model pred mean: -0.0211, std: 0.8164
  Sigmas: [0.14453125]... (timesteps: [145.0])
Steps:   8%|▊         | 401/5000 [1:53:27<141:48:47, 111.01s/it, loss=1.1050, lr=8.00e-06]Steps:   8%|▊         | 401/5000 [1:53:27<141:48:47, 111.01s/it, loss=1.1560, lr=8.02e-06]Steps:   8%|▊         | 402/5000 [1:53:37<102:51:52, 80.54s/it, loss=1.1560, lr=8.02e-06] Steps:   8%|▊         | 402/5000 [1:53:37<102:51:52, 80.54s/it, loss=1.1761, lr=8.04e-06]Steps:   8%|▊         | 403/5000 [1:53:46<75:34:13, 59.18s/it, loss=1.1761, lr=8.04e-06] Steps:   8%|▊         | 403/5000 [1:53:46<75:34:13, 59.18s/it, loss=0.3961, lr=8.06e-06]Steps:   8%|▊         | 404/5000 [1:53:56<56:38:34, 44.37s/it, loss=0.3961, lr=8.06e-06]Steps:   8%|▊         | 404/5000 [1:53:56<56:38:34, 44.37s/it, loss=0.6766, lr=8.08e-06]Steps:   8%|▊         | 405/5000 [1:54:06<43:21:31, 33.97s/it, loss=0.6766, lr=8.08e-06]Steps:   8%|▊         | 405/5000 [1:54:06<43:21:31, 33.97s/it, loss=0.5132, lr=8.10e-06]Steps:   8%|▊         | 406/5000 [1:54:15<33:56:47, 26.60s/it, loss=0.5132, lr=8.10e-06]Steps:   8%|▊         | 406/5000 [1:54:15<33:56:47, 26.60s/it, loss=0.6130, lr=8.12e-06]Steps:   8%|▊         | 407/5000 [1:54:25<27:23:55, 21.48s/it, loss=0.6130, lr=8.12e-06]Steps:   8%|▊         | 407/5000 [1:54:25<27:23:55, 21.48s/it, loss=1.1816, lr=8.14e-06]Steps:   8%|▊         | 408/5000 [1:54:34<22:45:42, 17.84s/it, loss=1.1816, lr=8.14e-06]Steps:   8%|▊         | 408/5000 [1:54:34<22:45:42, 17.84s/it, loss=0.9877, lr=8.16e-06]Steps:   8%|▊         | 409/5000 [1:54:43<19:29:20, 15.28s/it, loss=0.9877, lr=8.16e-06]Steps:   8%|▊         | 409/5000 [1:54:43<19:29:20, 15.28s/it, loss=0.8080, lr=8.18e-06]Steps:   8%|▊         | 410/5000 [1:54:53<17:11:04, 13.48s/it, loss=0.8080, lr=8.18e-06]Steps:   8%|▊         | 410/5000 [1:54:53<17:11:04, 13.48s/it, loss=1.0061, lr=8.20e-06]
[Step 410] Training Debug Info:
  Loss: 0.352035
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0349, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0347, std: 1.3594
  Model pred mean: 0.0386, std: 1.2188
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 410] Training Debug Info:
  Loss: 0.792726
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0260, std: 0.9219
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0248, std: 1.3594
  Model pred mean: -0.0286, std: 1.0469
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 410] Training Debug Info:
  Loss: 0.560453
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0060, std: 0.8906
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0054, std: 1.3359
  Model pred mean: 0.0018, std: 1.1328
  Sigmas: [0.625]... (timesteps: [625.0])

[Step 410] Training Debug Info:
  Loss: 0.437743
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0091, std: 0.8867
  Noise mean: 0.0036, std: 0.9961
  Target mean: -0.0054, std: 1.3359
  Model pred mean: -0.0079, std: 1.1641
  Sigmas: [0.74609375]... (timesteps: [748.0])
Steps:   8%|▊         | 411/5000 [1:55:02<15:40:35, 12.30s/it, loss=1.0061, lr=8.20e-06]Steps:   8%|▊         | 411/5000 [1:55:02<15:40:35, 12.30s/it, loss=0.4377, lr=8.22e-06]Steps:   8%|▊         | 412/5000 [1:55:12<14:40:19, 11.51s/it, loss=0.4377, lr=8.22e-06]Steps:   8%|▊         | 412/5000 [1:55:12<14:40:19, 11.51s/it, loss=0.5779, lr=8.24e-06]Steps:   8%|▊         | 413/5000 [1:55:21<13:51:50, 10.88s/it, loss=0.5779, lr=8.24e-06]Steps:   8%|▊         | 413/5000 [1:55:21<13:51:50, 10.88s/it, loss=0.4411, lr=8.26e-06]Steps:   8%|▊         | 414/5000 [1:55:31<13:23:45, 10.52s/it, loss=0.4411, lr=8.26e-06]Steps:   8%|▊         | 414/5000 [1:55:31<13:23:45, 10.52s/it, loss=0.3690, lr=8.28e-06]Steps:   8%|▊         | 415/5000 [1:55:40<12:59:12, 10.20s/it, loss=0.3690, lr=8.28e-06]Steps:   8%|▊         | 415/5000 [1:55:40<12:59:12, 10.20s/it, loss=0.5890, lr=8.30e-06]Steps:   8%|▊         | 416/5000 [1:55:50<12:39:58,  9.95s/it, loss=0.5890, lr=8.30e-06]Steps:   8%|▊         | 416/5000 [1:55:50<12:39:58,  9.95s/it, loss=0.8182, lr=8.32e-06]Steps:   8%|▊         | 417/5000 [1:55:59<12:26:34,  9.77s/it, loss=0.8182, lr=8.32e-06]Steps:   8%|▊         | 417/5000 [1:55:59<12:26:34,  9.77s/it, loss=0.5799, lr=8.34e-06]Steps:   8%|▊         | 418/5000 [1:56:09<12:23:35,  9.74s/it, loss=0.5799, lr=8.34e-06]Steps:   8%|▊         | 418/5000 [1:56:09<12:23:35,  9.74s/it, loss=1.1780, lr=8.36e-06]Steps:   8%|▊         | 419/5000 [1:56:18<12:17:06,  9.65s/it, loss=1.1780, lr=8.36e-06]Steps:   8%|▊         | 419/5000 [1:56:18<12:17:06,  9.65s/it, loss=0.4455, lr=8.38e-06]Steps:   8%|▊         | 420/5000 [1:56:28<12:15:44,  9.64s/it, loss=0.4455, lr=8.38e-06]Steps:   8%|▊         | 420/5000 [1:56:28<12:15:44,  9.64s/it, loss=0.6105, lr=8.40e-06]
[Step 420] Training Debug Info:
  Loss: 1.161487
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0023, std: 0.9180
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0000, std: 1.3594
  Model pred mean: 0.0062, std: 0.8242
  Sigmas: [0.134765625]... (timesteps: [135.0])

[Step 420] Training Debug Info:
  Loss: 1.129362
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0056, std: 0.8945
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0034, std: 1.3438
  Model pred mean: -0.0021, std: 0.8125
  Sigmas: [0.1162109375]... (timesteps: [116.0])

[Step 420] Training Debug Info:
  Loss: 0.933484
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0142, std: 0.8789
  Noise mean: -0.0030, std: 1.0000
  Target mean: 0.0112, std: 1.3359
  Model pred mean: 0.0151, std: 0.9375
  Sigmas: [0.423828125]... (timesteps: [423.0])

[Step 420] Training Debug Info:
  Loss: 0.965852
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0300, std: 0.9297
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0304, std: 1.3594
  Model pred mean: -0.0272, std: 0.9688
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:   8%|▊         | 421/5000 [1:56:37<12:13:51,  9.62s/it, loss=0.6105, lr=8.40e-06]Steps:   8%|▊         | 421/5000 [1:56:37<12:13:51,  9.62s/it, loss=0.9659, lr=8.42e-06]Steps:   8%|▊         | 422/5000 [1:56:47<12:08:47,  9.55s/it, loss=0.9659, lr=8.42e-06]Steps:   8%|▊         | 422/5000 [1:56:47<12:08:47,  9.55s/it, loss=0.8929, lr=8.44e-06]Steps:   8%|▊         | 423/5000 [1:56:56<12:05:11,  9.51s/it, loss=0.8929, lr=8.44e-06]Steps:   8%|▊         | 423/5000 [1:56:56<12:05:11,  9.51s/it, loss=1.0512, lr=8.46e-06]Steps:   8%|▊         | 424/5000 [1:57:06<12:04:02,  9.49s/it, loss=1.0512, lr=8.46e-06]Steps:   8%|▊         | 424/5000 [1:57:06<12:04:02,  9.49s/it, loss=0.8997, lr=8.48e-06]Steps:   8%|▊         | 425/5000 [1:57:15<12:04:36,  9.50s/it, loss=0.8997, lr=8.48e-06]Steps:   8%|▊         | 425/5000 [1:57:15<12:04:36,  9.50s/it, loss=1.1224, lr=8.50e-06]Steps:   9%|▊         | 426/5000 [1:57:25<11:59:45,  9.44s/it, loss=1.1224, lr=8.50e-06]Steps:   9%|▊         | 426/5000 [1:57:25<11:59:45,  9.44s/it, loss=1.1080, lr=8.52e-06]Steps:   9%|▊         | 427/5000 [1:57:34<12:02:00,  9.47s/it, loss=1.1080, lr=8.52e-06]Steps:   9%|▊         | 427/5000 [1:57:34<12:02:00,  9.47s/it, loss=1.1541, lr=8.54e-06]Steps:   9%|▊         | 428/5000 [1:57:43<11:59:13,  9.44s/it, loss=1.1541, lr=8.54e-06]Steps:   9%|▊         | 428/5000 [1:57:43<11:59:13,  9.44s/it, loss=0.8973, lr=8.56e-06]Steps:   9%|▊         | 429/5000 [1:57:53<11:56:49,  9.41s/it, loss=0.8973, lr=8.56e-06]Steps:   9%|▊         | 429/5000 [1:57:53<11:56:49,  9.41s/it, loss=0.5903, lr=8.58e-06]Steps:   9%|▊         | 430/5000 [1:58:02<11:53:30,  9.37s/it, loss=0.5903, lr=8.58e-06]Steps:   9%|▊         | 430/5000 [1:58:02<11:53:30,  9.37s/it, loss=1.2002, lr=8.60e-06]
[Step 430] Training Debug Info:
  Loss: 0.723327
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0532, std: 0.9219
  Noise mean: 0.0009, std: 0.9961
  Target mean: -0.0522, std: 1.3594
  Model pred mean: -0.0016, std: 1.0938
  Sigmas: [0.9609375]... (timesteps: [959.0])

[Step 430] Training Debug Info:
  Loss: 0.489886
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9141
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0195, std: 1.3516
  Model pred mean: -0.0125, std: 1.1719
  Sigmas: [0.921875]... (timesteps: [923.0])

[Step 430] Training Debug Info:
  Loss: 0.442245
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0140, std: 0.9219
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0132, std: 1.3594
  Model pred mean: -0.0143, std: 1.1953
  Sigmas: [0.7578125]... (timesteps: [757.0])

[Step 430] Training Debug Info:
  Loss: 1.136220
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0356, std: 0.9258
  Noise mean: -0.0007, std: 0.9961
  Target mean: 0.0349, std: 1.3594
  Model pred mean: 0.0403, std: 0.8438
  Sigmas: [0.1796875]... (timesteps: [180.0])
Steps:   9%|▊         | 431/5000 [1:58:11<11:52:14,  9.35s/it, loss=1.2002, lr=8.60e-06]Steps:   9%|▊         | 431/5000 [1:58:11<11:52:14,  9.35s/it, loss=1.1362, lr=8.62e-06]Steps:   9%|▊         | 432/5000 [1:58:21<11:53:48,  9.38s/it, loss=1.1362, lr=8.62e-06]Steps:   9%|▊         | 432/5000 [1:58:21<11:53:48,  9.38s/it, loss=0.4874, lr=8.64e-06]Steps:   9%|▊         | 433/5000 [1:58:30<11:55:29,  9.40s/it, loss=0.4874, lr=8.64e-06]Steps:   9%|▊         | 433/5000 [1:58:30<11:55:29,  9.40s/it, loss=0.5052, lr=8.66e-06]Steps:   9%|▊         | 434/5000 [1:58:40<11:58:36,  9.44s/it, loss=0.5052, lr=8.66e-06]Steps:   9%|▊         | 434/5000 [1:58:40<11:58:36,  9.44s/it, loss=0.4753, lr=8.68e-06]Steps:   9%|▊         | 435/5000 [1:58:49<11:56:58,  9.42s/it, loss=0.4753, lr=8.68e-06]Steps:   9%|▊         | 435/5000 [1:58:49<11:56:58,  9.42s/it, loss=1.0234, lr=8.70e-06]Steps:   9%|▊         | 436/5000 [1:58:58<11:52:35,  9.37s/it, loss=1.0234, lr=8.70e-06]Steps:   9%|▊         | 436/5000 [1:58:58<11:52:35,  9.37s/it, loss=1.1820, lr=8.72e-06]Steps:   9%|▊         | 437/5000 [1:59:08<11:56:51,  9.43s/it, loss=1.1820, lr=8.72e-06]Steps:   9%|▊         | 437/5000 [1:59:08<11:56:51,  9.43s/it, loss=0.8673, lr=8.74e-06]Steps:   9%|▉         | 438/5000 [1:59:17<11:59:15,  9.46s/it, loss=0.8673, lr=8.74e-06]Steps:   9%|▉         | 438/5000 [1:59:17<11:59:15,  9.46s/it, loss=1.0792, lr=8.76e-06]Steps:   9%|▉         | 439/5000 [1:59:27<11:56:24,  9.42s/it, loss=1.0792, lr=8.76e-06]Steps:   9%|▉         | 439/5000 [1:59:27<11:56:24,  9.42s/it, loss=0.4339, lr=8.78e-06]Steps:   9%|▉         | 440/5000 [1:59:36<12:00:04,  9.47s/it, loss=0.4339, lr=8.78e-06]Steps:   9%|▉         | 440/5000 [1:59:36<12:00:04,  9.47s/it, loss=0.4090, lr=8.80e-06]
[Step 440] Training Debug Info:
  Loss: 0.611800
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0220, std: 0.8984
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0226, std: 1.3438
  Model pred mean: -0.0053, std: 1.0781
  Sigmas: [0.99609375]... (timesteps: [996.0])

[Step 440] Training Debug Info:
  Loss: 0.553925
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0334, std: 0.9414
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0349, std: 1.3750
  Model pred mean: -0.0312, std: 1.1484
  Sigmas: [0.58984375]... (timesteps: [590.0])

[Step 440] Training Debug Info:
  Loss: 0.812881
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0195, std: 1.0078
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0201, std: 1.4219
  Model pred mean: -0.0120, std: 1.0859
  Sigmas: [0.953125]... (timesteps: [955.0])

[Step 440] Training Debug Info:
  Loss: 0.470739
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0005, std: 0.9453
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0037, std: 1.3750
  Model pred mean: -0.0034, std: 1.1953
  Sigmas: [0.66796875]... (timesteps: [668.0])
Steps:   9%|▉         | 441/5000 [1:59:46<11:56:49,  9.43s/it, loss=0.4090, lr=8.80e-06]Steps:   9%|▉         | 441/5000 [1:59:46<11:56:49,  9.43s/it, loss=0.4707, lr=8.82e-06]Steps:   9%|▉         | 442/5000 [1:59:55<12:00:19,  9.48s/it, loss=0.4707, lr=8.82e-06]Steps:   9%|▉         | 442/5000 [1:59:55<12:00:19,  9.48s/it, loss=1.0746, lr=8.84e-06]Steps:   9%|▉         | 443/5000 [2:00:05<11:57:06,  9.44s/it, loss=1.0746, lr=8.84e-06]Steps:   9%|▉         | 443/5000 [2:00:05<11:57:06,  9.44s/it, loss=0.8349, lr=8.86e-06]Steps:   9%|▉         | 444/5000 [2:00:14<11:59:13,  9.47s/it, loss=0.8349, lr=8.86e-06]Steps:   9%|▉         | 444/5000 [2:00:14<11:59:13,  9.47s/it, loss=0.4350, lr=8.88e-06]Steps:   9%|▉         | 445/5000 [2:00:24<12:02:34,  9.52s/it, loss=0.4350, lr=8.88e-06]Steps:   9%|▉         | 445/5000 [2:00:24<12:02:34,  9.52s/it, loss=0.4636, lr=8.90e-06]Steps:   9%|▉         | 446/5000 [2:00:33<11:56:46,  9.44s/it, loss=0.4636, lr=8.90e-06]Steps:   9%|▉         | 446/5000 [2:00:33<11:56:46,  9.44s/it, loss=0.6520, lr=8.92e-06]Steps:   9%|▉         | 447/5000 [2:00:43<11:59:25,  9.48s/it, loss=0.6520, lr=8.92e-06]Steps:   9%|▉         | 447/5000 [2:00:43<11:59:25,  9.48s/it, loss=0.5029, lr=8.94e-06]Steps:   9%|▉         | 448/5000 [2:00:52<11:57:11,  9.45s/it, loss=0.5029, lr=8.94e-06]Steps:   9%|▉         | 448/5000 [2:00:52<11:57:11,  9.45s/it, loss=1.0986, lr=8.96e-06]Steps:   9%|▉         | 449/5000 [2:01:01<11:55:15,  9.43s/it, loss=1.0986, lr=8.96e-06]Steps:   9%|▉         | 449/5000 [2:01:01<11:55:15,  9.43s/it, loss=0.4022, lr=8.98e-06]Steps:   9%|▉         | 450/5000 [2:01:07<10:23:09,  8.22s/it, loss=0.4022, lr=8.98e-06]Steps:   9%|▉         | 450/5000 [2:01:07<10:23:09,  8.22s/it, loss=0.5263, lr=9.00e-06]01/30/2026 09:18:36 - INFO - __main__ - 
🔍 Running validation at step 450...
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 450 (parquet mode)...
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 450...
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 09:18:38 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.66it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.28it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.19it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.15it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.13it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.12it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.10it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.10it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.09it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.09it/s][A
 75%|███████▌  | 21/28 [00:18<00:06,  1.09it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.09it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.08it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.09it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.08it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 09:19:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 09:19:04 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.26it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.08it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.08it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.08it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.08it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.08it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.08it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.08it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 09:19:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 09:19:31 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.57it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.12it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.05it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.04it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:19:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 09:19:59 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 09:20:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 09:20:27 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:20:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt04_0_The_figure_illustrates_a_model_evaluation_framewor.png
01/30/2026 09:20:55 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 6/12: The figure illustrates a linear probing framework applied to a frozen multimodal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:21:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt05_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 09:21:23 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 7/12: The figure presents a comparative architectural diagram illustrating two differe...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.10it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:21:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt06_0_The_figure_presents_a_comparative_architectural_di.png
01/30/2026 09:21:51 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 8/12: The figure illustrates the overall architecture of L-RPCANet, a multi-stage deep...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.03it/s]
01/30/2026 09:22:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt07_0_The_figure_illustrates_the_overall_architecture_of.png
01/30/2026 09:22:19 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 9/12: The figure illustrates the complete pipeline of a 3D scene reconstruction system...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:22:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt08_0_The_figure_illustrates_the_complete_pipeline_of_a.png
01/30/2026 09:22:47 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 10/12: The figure presents seven distinct architectural patterns for fusing multi-modal...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.55it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:23:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt09_0_The_figure_presents_seven_distinct_architectural_p.png
01/30/2026 09:23:15 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 11/12: The figure presents a comparative analysis between a baseline method and the pro...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.07it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 09:23:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt10_0_The_figure_presents_a_comparative_analysis_between.png
01/30/2026 09:23:42 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 12/12: The figure presents a conceptual comparison of four different point cloud comple...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.61it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.24it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.16it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.12it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.10it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.09it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.08it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.08it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:09<00:16,  1.07it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.07it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.07it/s][A
 46%|████▋     | 13/28 [00:11<00:14,  1.07it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.08it/s]
01/30/2026 09:24:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450/step000450_prompt11_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 09:24:09 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 09:24:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ✅ Validation complete! Saved 12 images to:
01/30/2026 09:24:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000450
01/30/2026 09:24:10 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

01/30/2026 09:24:13 - INFO - __main__ - 
==================================================
01/30/2026 09:24:13 - INFO - __main__ - Epoch 5 completed: avg_loss = 0.7765
01/30/2026 09:24:13 - INFO - __main__ - ==================================================


[Step 450] Training Debug Info:
  Loss: 1.139725
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0144, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0148, std: 1.3438
  Model pred mean: -0.0048, std: 0.8203
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 450] Training Debug Info:
  Loss: 0.679627
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0327, std: 1.0000
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0300, std: 1.4141
  Model pred mean: -0.0282, std: 1.1406
  Sigmas: [0.5703125]... (timesteps: [570.0])

[Step 450] Training Debug Info:
  Loss: 0.695075
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0349, std: 0.8711
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0356, std: 1.3281
  Model pred mean: 0.0374, std: 1.0078
  Sigmas: [0.5546875]... (timesteps: [553.0])

[Step 450] Training Debug Info:
  Loss: 0.496333
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0090, std: 0.9453
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0090, std: 1.3750
  Model pred mean: -0.0050, std: 1.1719
  Sigmas: [0.6328125]... (timesteps: [631.0])
Steps:   9%|▉         | 451/5000 [2:06:54<138:44:29, 109.80s/it, loss=0.5263, lr=9.00e-06]Steps:   9%|▉         | 451/5000 [2:06:54<138:44:29, 109.80s/it, loss=0.4963, lr=9.02e-06]Steps:   9%|▉         | 452/5000 [2:07:03<100:38:24, 79.66s/it, loss=0.4963, lr=9.02e-06] Steps:   9%|▉         | 452/5000 [2:07:03<100:38:24, 79.66s/it, loss=0.4252, lr=9.04e-06]Steps:   9%|▉         | 453/5000 [2:07:13<74:08:26, 58.70s/it, loss=0.4252, lr=9.04e-06] Steps:   9%|▉         | 453/5000 [2:07:13<74:08:26, 58.70s/it, loss=1.1042, lr=9.06e-06]Steps:   9%|▉         | 454/5000 [2:07:22<55:24:45, 43.88s/it, loss=1.1042, lr=9.06e-06]Steps:   9%|▉         | 454/5000 [2:07:22<55:24:45, 43.88s/it, loss=0.4827, lr=9.08e-06]Steps:   9%|▉         | 455/5000 [2:07:31<42:19:26, 33.52s/it, loss=0.4827, lr=9.08e-06]Steps:   9%|▉         | 455/5000 [2:07:31<42:19:26, 33.52s/it, loss=1.1288, lr=9.10e-06]Steps:   9%|▉         | 456/5000 [2:07:41<33:09:46, 26.27s/it, loss=1.1288, lr=9.10e-06]Steps:   9%|▉         | 456/5000 [2:07:41<33:09:46, 26.27s/it, loss=0.5489, lr=9.12e-06]Steps:   9%|▉         | 457/5000 [2:07:51<26:54:21, 21.32s/it, loss=0.5489, lr=9.12e-06]Steps:   9%|▉         | 457/5000 [2:07:51<26:54:21, 21.32s/it, loss=1.1855, lr=9.14e-06]Steps:   9%|▉         | 458/5000 [2:08:00<22:22:34, 17.74s/it, loss=1.1855, lr=9.14e-06]Steps:   9%|▉         | 458/5000 [2:08:00<22:22:34, 17.74s/it, loss=0.4046, lr=9.16e-06]Steps:   9%|▉         | 459/5000 [2:08:10<19:22:55, 15.37s/it, loss=0.4046, lr=9.16e-06]Steps:   9%|▉         | 459/5000 [2:08:10<19:22:55, 15.37s/it, loss=0.8266, lr=9.18e-06]Steps:   9%|▉         | 460/5000 [2:08:19<17:13:25, 13.66s/it, loss=0.8266, lr=9.18e-06]Steps:   9%|▉         | 460/5000 [2:08:19<17:13:25, 13.66s/it, loss=1.1772, lr=9.20e-06]
[Step 460] Training Debug Info:
  Loss: 1.217641
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0013, std: 0.8516
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0031, std: 1.3125
  Model pred mean: 0.0026, std: 0.7227
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 460] Training Debug Info:
  Loss: 0.423799
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0262, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0264, std: 1.3594
  Model pred mean: 0.0266, std: 1.1875
  Sigmas: [0.74609375]... (timesteps: [746.0])

[Step 460] Training Debug Info:
  Loss: 0.596527
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0017, std: 0.8867
  Noise mean: 0.0018, std: 0.9961
  Target mean: 0.0001, std: 1.3359
  Model pred mean: 0.0376, std: 1.1328
  Sigmas: [0.99609375]... (timesteps: [995.0])

[Step 460] Training Debug Info:
  Loss: 0.855768
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0334, std: 0.9922
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0378, std: 1.4141
  Model pred mean: -0.0330, std: 1.0703
  Sigmas: [0.408203125]... (timesteps: [408.0])
Steps:   9%|▉         | 461/5000 [2:08:29<15:35:54, 12.37s/it, loss=1.1772, lr=9.20e-06]Steps:   9%|▉         | 461/5000 [2:08:29<15:35:54, 12.37s/it, loss=0.8558, lr=9.22e-06]Steps:   9%|▉         | 462/5000 [2:08:38<14:25:51, 11.45s/it, loss=0.8558, lr=9.22e-06]Steps:   9%|▉         | 462/5000 [2:08:38<14:25:51, 11.45s/it, loss=0.4228, lr=9.24e-06]Steps:   9%|▉         | 463/5000 [2:08:48<13:41:32, 10.86s/it, loss=0.4228, lr=9.24e-06]Steps:   9%|▉         | 463/5000 [2:08:48<13:41:32, 10.86s/it, loss=1.1528, lr=9.26e-06]Steps:   9%|▉         | 464/5000 [2:08:57<13:07:03, 10.41s/it, loss=1.1528, lr=9.26e-06]Steps:   9%|▉         | 464/5000 [2:08:57<13:07:03, 10.41s/it, loss=0.6721, lr=9.28e-06]Steps:   9%|▉         | 465/5000 [2:09:06<12:43:25, 10.10s/it, loss=0.6721, lr=9.28e-06]Steps:   9%|▉         | 465/5000 [2:09:06<12:43:25, 10.10s/it, loss=0.3510, lr=9.30e-06]Steps:   9%|▉         | 466/5000 [2:09:16<12:27:52,  9.90s/it, loss=0.3510, lr=9.30e-06]Steps:   9%|▉         | 466/5000 [2:09:16<12:27:52,  9.90s/it, loss=1.1050, lr=9.32e-06]wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
Steps:   9%|▉         | 467/5000 [2:09:25<12:16:37,  9.75s/it, loss=1.1050, lr=9.32e-06]Steps:   9%|▉         | 467/5000 [2:09:25<12:16:37,  9.75s/it, loss=1.0915, lr=9.34e-06]Steps:   9%|▉         | 468/5000 [2:09:35<12:17:40,  9.77s/it, loss=1.0915, lr=9.34e-06]Steps:   9%|▉         | 468/5000 [2:09:35<12:17:40,  9.77s/it, loss=0.8517, lr=9.36e-06]Steps:   9%|▉         | 469/5000 [2:09:44<12:09:19,  9.66s/it, loss=0.8517, lr=9.36e-06]Steps:   9%|▉         | 469/5000 [2:09:44<12:09:19,  9.66s/it, loss=0.9019, lr=9.38e-06]Steps:   9%|▉         | 470/5000 [2:09:54<12:03:46,  9.59s/it, loss=0.9019, lr=9.38e-06]Steps:   9%|▉         | 470/5000 [2:09:54<12:03:46,  9.59s/it, loss=0.4228, lr=9.40e-06]
[Step 470] Training Debug Info:
  Loss: 1.176452
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0093, std: 0.8828
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0085, std: 1.3359
  Model pred mean: -0.0015, std: 0.7891
  Sigmas: [0.130859375]... (timesteps: [131.0])

[Step 470] Training Debug Info:
  Loss: 1.071163
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0003, std: 0.9609
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0012, std: 1.3828
  Model pred mean: 0.0053, std: 0.9258
  Sigmas: [0.2578125]... (timesteps: [257.0])

[Step 470] Training Debug Info:
  Loss: 1.141146
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0092, std: 0.9023
  Noise mean: -0.0006, std: 0.9961
  Target mean: -0.0097, std: 1.3438
  Model pred mean: -0.0025, std: 0.8281
  Sigmas: [0.2373046875]... (timesteps: [237.0])

[Step 470] Training Debug Info:
  Loss: 0.512237
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0266, std: 0.9180
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0283, std: 1.3594
  Model pred mean: 0.0223, std: 1.1406
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   9%|▉         | 471/5000 [2:10:03<12:04:40,  9.60s/it, loss=0.4228, lr=9.40e-06]Steps:   9%|▉         | 471/5000 [2:10:03<12:04:40,  9.60s/it, loss=0.5122, lr=9.42e-06]Steps:   9%|▉         | 472/5000 [2:10:13<11:57:36,  9.51s/it, loss=0.5122, lr=9.42e-06]Steps:   9%|▉         | 472/5000 [2:10:13<11:57:36,  9.51s/it, loss=0.4781, lr=9.44e-06]Steps:   9%|▉         | 473/5000 [2:10:22<11:53:57,  9.46s/it, loss=0.4781, lr=9.44e-06]Steps:   9%|▉         | 473/5000 [2:10:22<11:53:57,  9.46s/it, loss=0.7365, lr=9.46e-06]Steps:   9%|▉         | 474/5000 [2:10:32<11:54:09,  9.47s/it, loss=0.7365, lr=9.46e-06]Steps:   9%|▉         | 474/5000 [2:10:32<11:54:09,  9.47s/it, loss=0.6384, lr=9.48e-06]Steps:  10%|▉         | 475/5000 [2:10:41<11:51:29,  9.43s/it, loss=0.6384, lr=9.48e-06]Steps:  10%|▉         | 475/5000 [2:10:41<11:51:29,  9.43s/it, loss=0.6401, lr=9.50e-06]Steps:  10%|▉         | 476/5000 [2:10:50<11:52:23,  9.45s/it, loss=0.6401, lr=9.50e-06]Steps:  10%|▉         | 476/5000 [2:10:50<11:52:23,  9.45s/it, loss=1.1270, lr=9.52e-06]Steps:  10%|▉         | 477/5000 [2:11:00<11:55:01,  9.49s/it, loss=1.1270, lr=9.52e-06]Steps:  10%|▉         | 477/5000 [2:11:00<11:55:01,  9.49s/it, loss=0.7986, lr=9.54e-06]Steps:  10%|▉         | 478/5000 [2:11:09<11:52:25,  9.45s/it, loss=0.7986, lr=9.54e-06]Steps:  10%|▉         | 478/5000 [2:11:09<11:52:25,  9.45s/it, loss=0.7382, lr=9.56e-06]Steps:  10%|▉         | 479/5000 [2:11:19<11:53:32,  9.47s/it, loss=0.7382, lr=9.56e-06]Steps:  10%|▉         | 479/5000 [2:11:19<11:53:32,  9.47s/it, loss=0.6299, lr=9.58e-06]Steps:  10%|▉         | 480/5000 [2:11:28<11:53:05,  9.47s/it, loss=0.6299, lr=9.58e-06]Steps:  10%|▉         | 480/5000 [2:11:28<11:53:05,  9.47s/it, loss=0.3308, lr=9.60e-06]
[Step 480] Training Debug Info:
  Loss: 0.498482
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9336
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0007, std: 1.3672
  Model pred mean: 0.0053, std: 1.1875
  Sigmas: [0.59375]... (timesteps: [594.0])

[Step 480] Training Debug Info:
  Loss: 0.565672
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0071, std: 1.3359
  Model pred mean: -0.0053, std: 1.1328
  Sigmas: [0.62890625]... (timesteps: [628.0])

[Step 480] Training Debug Info:
  Loss: 1.149695
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0149, std: 0.9023
  Noise mean: -0.0004, std: 0.9961
  Target mean: -0.0154, std: 1.3438
  Model pred mean: -0.0120, std: 0.8086
  Sigmas: [0.19140625]... (timesteps: [191.0])

[Step 480] Training Debug Info:
  Loss: 0.736442
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0027, std: 0.8633
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0032, std: 1.3203
  Model pred mean: 0.0069, std: 1.0234
  Sigmas: [0.52734375]... (timesteps: [529.0])
Steps:  10%|▉         | 481/5000 [2:11:38<11:49:43,  9.42s/it, loss=0.3308, lr=9.60e-06]Steps:  10%|▉         | 481/5000 [2:11:38<11:49:43,  9.42s/it, loss=0.7364, lr=9.62e-06]Steps:  10%|▉         | 482/5000 [2:11:47<11:49:31,  9.42s/it, loss=0.7364, lr=9.62e-06]Steps:  10%|▉         | 482/5000 [2:11:47<11:49:31,  9.42s/it, loss=1.1417, lr=9.64e-06]Steps:  10%|▉         | 483/5000 [2:11:57<11:58:06,  9.54s/it, loss=1.1417, lr=9.64e-06]Steps:  10%|▉         | 483/5000 [2:11:57<11:58:06,  9.54s/it, loss=1.1361, lr=9.66e-06]Steps:  10%|▉         | 484/5000 [2:12:06<11:57:10,  9.53s/it, loss=1.1361, lr=9.66e-06]Steps:  10%|▉         | 484/5000 [2:12:06<11:57:10,  9.53s/it, loss=0.6722, lr=9.68e-06]Steps:  10%|▉         | 485/5000 [2:12:16<11:51:05,  9.45s/it, loss=0.6722, lr=9.68e-06]Steps:  10%|▉         | 485/5000 [2:12:16<11:51:05,  9.45s/it, loss=0.4029, lr=9.70e-06]Steps:  10%|▉         | 486/5000 [2:12:25<11:57:12,  9.53s/it, loss=0.4029, lr=9.70e-06]Steps:  10%|▉         | 486/5000 [2:12:25<11:57:12,  9.53s/it, loss=1.1894, lr=9.72e-06]Steps:  10%|▉         | 487/5000 [2:12:35<11:50:20,  9.44s/it, loss=1.1894, lr=9.72e-06]Steps:  10%|▉         | 487/5000 [2:12:35<11:50:20,  9.44s/it, loss=0.3413, lr=9.74e-06]Steps:  10%|▉         | 488/5000 [2:12:44<11:49:21,  9.43s/it, loss=0.3413, lr=9.74e-06]Steps:  10%|▉         | 488/5000 [2:12:44<11:49:21,  9.43s/it, loss=0.6226, lr=9.76e-06]Steps:  10%|▉         | 489/5000 [2:12:54<11:50:00,  9.44s/it, loss=0.6226, lr=9.76e-06]Steps:  10%|▉         | 489/5000 [2:12:54<11:50:00,  9.44s/it, loss=0.7524, lr=9.78e-06]Steps:  10%|▉         | 490/5000 [2:13:03<11:49:45,  9.44s/it, loss=0.7524, lr=9.78e-06]Steps:  10%|▉         | 490/5000 [2:13:03<11:49:45,  9.44s/it, loss=0.7770, lr=9.80e-06]
[Step 490] Training Debug Info:
  Loss: 0.522889
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0259, std: 0.8945
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0261, std: 1.3438
  Model pred mean: -0.0310, std: 1.1406
  Sigmas: [0.6484375]... (timesteps: [647.0])

[Step 490] Training Debug Info:
  Loss: 0.594702
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0024, std: 0.8789
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0006, std: 1.3359
  Model pred mean: -0.0076, std: 1.0781
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 490] Training Debug Info:
  Loss: 0.449371
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0574, std: 0.9180
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0566, std: 1.3594
  Model pred mean: -0.0583, std: 1.1797
  Sigmas: [0.7109375]... (timesteps: [711.0])

[Step 490] Training Debug Info:
  Loss: 0.380614
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0147, std: 0.9062
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0134, std: 1.3516
  Model pred mean: 0.0197, std: 1.2031
  Sigmas: [0.83984375]... (timesteps: [838.0])
Steps:  10%|▉         | 491/5000 [2:13:12<11:51:20,  9.47s/it, loss=0.7770, lr=9.80e-06]Steps:  10%|▉         | 491/5000 [2:13:12<11:51:20,  9.47s/it, loss=0.3806, lr=9.82e-06]Steps:  10%|▉         | 492/5000 [2:13:22<11:50:53,  9.46s/it, loss=0.3806, lr=9.82e-06]Steps:  10%|▉         | 492/5000 [2:13:22<11:50:53,  9.46s/it, loss=1.0942, lr=9.84e-06]Steps:  10%|▉         | 493/5000 [2:13:31<11:48:38,  9.43s/it, loss=1.0942, lr=9.84e-06]Steps:  10%|▉         | 493/5000 [2:13:31<11:48:38,  9.43s/it, loss=0.3744, lr=9.86e-06]Steps:  10%|▉         | 494/5000 [2:13:41<11:47:54,  9.43s/it, loss=0.3744, lr=9.86e-06]Steps:  10%|▉         | 494/5000 [2:13:41<11:47:54,  9.43s/it, loss=0.6765, lr=9.88e-06]Steps:  10%|▉         | 495/5000 [2:13:50<11:54:26,  9.52s/it, loss=0.6765, lr=9.88e-06]Steps:  10%|▉         | 495/5000 [2:13:50<11:54:26,  9.52s/it, loss=0.8554, lr=9.90e-06]Steps:  10%|▉         | 496/5000 [2:14:00<11:50:33,  9.47s/it, loss=0.8554, lr=9.90e-06]Steps:  10%|▉         | 496/5000 [2:14:00<11:50:33,  9.47s/it, loss=0.4117, lr=9.92e-06]Steps:  10%|▉         | 497/5000 [2:14:09<11:49:06,  9.45s/it, loss=0.4117, lr=9.92e-06]Steps:  10%|▉         | 497/5000 [2:14:09<11:49:06,  9.45s/it, loss=0.6642, lr=9.94e-06]Steps:  10%|▉         | 498/5000 [2:14:19<11:51:26,  9.48s/it, loss=0.6642, lr=9.94e-06]Steps:  10%|▉         | 498/5000 [2:14:19<11:51:26,  9.48s/it, loss=0.4489, lr=9.96e-06]Steps:  10%|▉         | 499/5000 [2:14:28<11:55:56,  9.54s/it, loss=0.4489, lr=9.96e-06]Steps:  10%|▉         | 499/5000 [2:14:28<11:55:56,  9.54s/it, loss=1.0216, lr=9.98e-06]Steps:  10%|█         | 500/5000 [2:14:38<11:51:45,  9.49s/it, loss=1.0216, lr=9.98e-06]Steps:  10%|█         | 500/5000 [2:14:38<11:51:45,  9.49s/it, loss=0.3887, lr=1.00e-05]01/30/2026 09:32:07 - INFO - __main__ - 
[Step 500] ✅ Loss in normal range (0.3887)
01/30/2026 09:32:07 - INFO - __main__ -   Loss avg (last 100): 0.7483
01/30/2026 09:32:07 - INFO - __main__ -   Loss range: [0.3308, 1.2002]
01/30/2026 09:32:07 - INFO - __main__ - 
🔍 Running validation at step 500...
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 500 (parquet mode)...
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 500...
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 09:32:08 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/12: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.65it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.27it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.18it/s][A
 14%|█▍        | 4/28 [00:03<00:20,  1.14it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.12it/s][A
 21%|██▏       | 6/28 [00:05<00:19,  1.11it/s][A
 25%|██▌       | 7/28 [00:06<00:18,  1.11it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.10it/s][A
 32%|███▏      | 9/28 [00:07<00:17,  1.10it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.09it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.09it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.09it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.09it/s][A
 50%|█████     | 14/28 [00:12<00:12,  1.09it/s][A
 54%|█████▎    | 15/28 [00:13<00:11,  1.09it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.09it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.09it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.09it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.08it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.08it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.08it/s][A
 79%|███████▊  | 22/28 [00:19<00:05,  1.08it/s][A
 82%|████████▏ | 23/28 [00:20<00:04,  1.08it/s][A
 86%|████████▌ | 24/28 [00:21<00:03,  1.08it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.08it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.08it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.08it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.08it/s][A100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
01/30/2026 09:32:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 09:32:35 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/12: The figure presents an overview of four distinct end-to-end Task-Oriented Dialog...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:16,  1.63it/s][A
  7%|▋         | 2/28 [00:01<00:20,  1.25it/s][A
 11%|█         | 3/28 [00:02<00:21,  1.17it/s][A
 14%|█▍        | 4/28 [00:03<00:21,  1.13it/s][A
 18%|█▊        | 5/28 [00:04<00:20,  1.11it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.10it/s][A
 25%|██▌       | 7/28 [00:06<00:19,  1.09it/s][A
 29%|██▊       | 8/28 [00:07<00:18,  1.09it/s][A
 32%|███▏      | 9/28 [00:08<00:17,  1.08it/s][A
 36%|███▌      | 10/28 [00:08<00:16,  1.08it/s][A
 39%|███▉      | 11/28 [00:09<00:15,  1.08it/s][A
 43%|████▎     | 12/28 [00:10<00:14,  1.08it/s][A
 46%|████▋     | 13/28 [00:11<00:13,  1.08it/s][A
 50%|█████     | 14/28 [00:12<00:13,  1.07it/s][A
 54%|█████▎    | 15/28 [00:13<00:12,  1.07it/s][A
 57%|█████▋    | 16/28 [00:14<00:11,  1.07it/s][A
 61%|██████    | 17/28 [00:15<00:10,  1.07it/s][A
 64%|██████▍   | 18/28 [00:16<00:09,  1.07it/s][A
 68%|██████▊   | 19/28 [00:17<00:08,  1.07it/s][A
 71%|███████▏  | 20/28 [00:18<00:07,  1.07it/s][A
 75%|███████▌  | 21/28 [00:19<00:06,  1.07it/s][A
 79%|███████▊  | 22/28 [00:20<00:05,  1.07it/s][A
 82%|████████▏ | 23/28 [00:21<00:04,  1.07it/s][A
 86%|████████▌ | 24/28 [00:22<00:03,  1.07it/s][A
 89%|████████▉ | 25/28 [00:22<00:02,  1.07it/s][A
 93%|█████████▎| 26/28 [00:23<00:01,  1.07it/s][A
 96%|█████████▋| 27/28 [00:24<00:00,  1.07it/s][A
100%|██████████| 28/28 [00:25<00:00,  1.07it/s][A100%|██████████| 28/28 [00:25<00:00,  1.09it/s]
01/30/2026 09:33:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt01_0_The_figure_presents_an_overview_of_four_distinct_e.png
01/30/2026 09:33:02 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/12: The figure illustrates a network architecture for a single-step diffusion model ...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.20it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:20,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.04it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.04it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.03it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.03it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.03it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.03it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.03it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.03it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.03it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.03it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.03it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.03it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.03it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.03it/s][A
 89%|████████▉ | 25/28 [00:23<00:02,  1.03it/s][A
 93%|█████████▎| 26/28 [00:24<00:01,  1.03it/s][A
 96%|█████████▋| 27/28 [00:25<00:00,  1.03it/s][A
100%|██████████| 28/28 [00:26<00:00,  1.03it/s][A100%|██████████| 28/28 [00:26<00:00,  1.04it/s]
01/30/2026 09:33:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt02_0_The_figure_illustrates_a_network_architecture_for.png
01/30/2026 09:33:29 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/12: The figure presents a comparative diagram of four different defect detection tas...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.56it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.08it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.06it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.05it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.04it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.03it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.03it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.03it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A
 57%|█████▋    | 16/28 [00:15<00:11,  1.02it/s][A
 61%|██████    | 17/28 [00:16<00:10,  1.02it/s][A
 64%|██████▍   | 18/28 [00:17<00:09,  1.02it/s][A
 68%|██████▊   | 19/28 [00:18<00:08,  1.02it/s][A
 71%|███████▏  | 20/28 [00:19<00:07,  1.02it/s][A
 75%|███████▌  | 21/28 [00:20<00:06,  1.02it/s][A
 79%|███████▊  | 22/28 [00:21<00:05,  1.02it/s][A
 82%|████████▏ | 23/28 [00:22<00:04,  1.02it/s][A
 86%|████████▌ | 24/28 [00:23<00:03,  1.02it/s][A
 89%|████████▉ | 25/28 [00:24<00:02,  1.02it/s][A
 93%|█████████▎| 26/28 [00:25<00:01,  1.02it/s][A
 96%|█████████▋| 27/28 [00:26<00:00,  1.02it/s][A
100%|██████████| 28/28 [00:27<00:00,  1.02it/s][A100%|██████████| 28/28 [00:27<00:00,  1.04it/s]
01/30/2026 09:33:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt03_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 09:33:58 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 5/12: The figure illustrates a model evaluation framework for a diffusion-based predic...

  0%|          | 0/28 [00:00<?, ?it/s][A
  4%|▎         | 1/28 [00:00<00:17,  1.54it/s][A
  7%|▋         | 2/28 [00:01<00:21,  1.19it/s][A
 11%|█         | 3/28 [00:02<00:22,  1.11it/s][A
 14%|█▍        | 4/28 [00:03<00:22,  1.07it/s][A
 18%|█▊        | 5/28 [00:04<00:21,  1.05it/s][A
 21%|██▏       | 6/28 [00:05<00:21,  1.04it/s][A
 25%|██▌       | 7/28 [00:06<00:20,  1.03it/s][A
 29%|██▊       | 8/28 [00:07<00:19,  1.03it/s][A
 32%|███▏      | 9/28 [00:08<00:18,  1.03it/s][A
 36%|███▌      | 10/28 [00:09<00:17,  1.02it/s][A
 39%|███▉      | 11/28 [00:10<00:16,  1.02it/s][A
 43%|████▎     | 12/28 [00:11<00:15,  1.02it/s][A
 46%|████▋     | 13/28 [00:12<00:14,  1.02it/s][A
 50%|█████     | 14/28 [00:13<00:13,  1.02it/s][A
 54%|█████▎    | 15/28 [00:14<00:12,  1.02it/s][A