nohup: ignoring input
W0127 02:44:14.222000 3578530 site-packages/torch/distributed/run.py:793] 
W0127 02:44:14.222000 3578530 site-packages/torch/distributed/run.py:793] *****************************************
W0127 02:44:14.222000 3578530 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0127 02:44:14.222000 3578530 site-packages/torch/distributed/run.py:793] *****************************************
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
01/27/2026 02:44:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:44:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:44:22 - INFO - __main__ - [INFO] Using model type: QwenImage
01/27/2026 02:44:22 - INFO - __main__ - [INFO] Skipping text encoder load (parquet dataset + DeepSpeed mode)
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - üè≠ Model Factory Initialized
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Model Type: QwenImage
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Pretrained Path: Qwen/Qwen-Image-2512
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Cache Dir: /home/v-yuxluo/data/huggingface_cache
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    VAE Class: AutoencoderKLQwenImage
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Transformer Class: QwenImageTransformer2DModel
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Text Encoder Class: Qwen2_5_VLForConditionalGeneration
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory -    Pipeline Class: QwenImagePipeline
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading tokenizer: Qwen2Tokenizer
01/27/2026 02:44:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:44:22 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoder: Qwen2_5_VLForConditionalGeneration
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - [INFO] Skipping text encoder load (parquet dataset mode)
01/27/2026 02:44:22 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading VAE: AutoencoderKLQwenImage
{'input_channels'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKLQwenImage.

All the weights of AutoencoderKLQwenImage were initialized from the model checkpoint at Qwen/Qwen-Image-2512.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKLQwenImage for predictions without further training.
01/27/2026 02:44:23 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading transformer: QwenImageTransformer2DModel
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 62394.60it/s]
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 15827.56it/s]
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 18280.26it/s]
Instantiating QwenImageTransformer2DModel model under default dtype torch.bfloat16.
{'zero_cond_t', 'use_layer3d_rope', 'use_additional_t_cond'} was not found in config. Values will be initialized to default values.
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 10020.90it/s]
Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]Loading checkpoint shards:  11%|‚ñà         | 1/9 [00:00<00:03,  2.63it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:00<00:00, 15.41it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 16.86it/s]
All model checkpoint weights were used when initializing QwenImageTransformer2DModel.

All the weights of QwenImageTransformer2DModel were initialized from the model checkpoint at Qwen/Qwen-Image-2512.
If your task is similar to the task the model of the checkpoint was trained on, you can already use QwenImageTransformer2DModel for predictions without further training.
01/27/2026 02:44:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] Fine-tuning the full model ...
01/27/2026 02:44:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] Enabling gradient checkpointing for transformer
01/27/2026 02:44:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading scheduler: FlowMatchEulerDiscreteScheduler
01/27/2026 02:44:24 - INFO - OpenSciDraw.utils.model_factory - [INFO] VAE scale factor: 8
01/27/2026 02:44:24 - INFO - __main__ - [INFO] DeepSpeed detected - keeping transformer in bf16 for ZeRO-3
01/27/2026 02:44:24 - INFO - __main__ - [INFO] Configuring model devices and offloading
01/27/2026 02:44:24 - INFO - __main__ - [INFO] Using parquet dataset - VAE and text encoder remain on CPU
01/27/2026 02:44:24 - INFO - __main__ - [INFO] DeepSpeed mode: transformer stays on CPU, ZeRO-3 will handle placement
01/27/2026 02:44:24 - INFO - __main__ - [INFO] Gradient checkpointing enabled
01/27/2026 02:44:24 - INFO - __main__ - [INFO] Number of trainable parameters: 20430.40M
01/27/2026 02:44:24 - INFO - __main__ - [INFO] Loading dataset
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 160.16it/s]‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 143.78it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 143.99it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 140.49it/s]Scanning Parquet Files:  40%|‚ñà‚ñà‚ñà‚ñà      | 34/84 [00:00<00:00, 54.52it/s] Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 55.18it/s] Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 55.73it/s] Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 54.79it/s] Scanning Parquet Files:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 43/84 [00:00<00:00, 42.79it/s]Scanning Parquet Files:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 41/84 [00:00<00:00, 45.08it/s]Scanning Parquet Files:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 40/84 [00:00<00:00, 47.44it/s]Scanning Parquet Files:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 41/84 [00:00<00:00, 45.35it/s]Scanning Parquet Files:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 46/84 [00:00<00:00, 42.85it/s]Scanning Parquet Files:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 50/84 [00:01<00:00, 39.75it/s]Scanning Parquet Files:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 47/84 [00:00<00:00, 40.29it/s]Scanning Parquet Files:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 47/84 [00:00<00:00, 40.80it/s]Scanning Parquet Files:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 52/84 [00:01<00:00, 38.97it/s]Scanning Parquet Files:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 52/84 [00:01<00:00, 39.92it/s]Scanning Parquet Files:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 55/84 [00:01<00:00, 36.06it/s]Scanning Parquet Files:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 51/84 [00:01<00:00, 35.92it/s]Scanning Parquet Files:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 60/84 [00:01<00:00, 35.46it/s]Scanning Parquet Files:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 55/84 [00:01<00:00, 34.84it/s]Scanning Parquet Files:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 57/84 [00:01<00:00, 34.18it/s]Scanning Parquet Files:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 57/84 [00:01<00:00, 34.98it/s]Scanning Parquet Files:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 64/84 [00:01<00:00, 35.05it/s]Scanning Parquet Files:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 59/84 [00:01<00:00, 32.71it/s]Scanning Parquet Files:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 61/84 [00:01<00:00, 33.07it/s]Scanning Parquet Files:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 61/84 [00:01<00:00, 32.38it/s]Scanning Parquet Files:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 68/84 [00:01<00:00, 32.87it/s]Scanning Parquet Files:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 63/84 [00:01<00:00, 32.89it/s]Scanning Parquet Files:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 65/84 [00:01<00:00, 33.45it/s]Scanning Parquet Files:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 65/84 [00:01<00:00, 32.69it/s]Scanning Parquet Files:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 72/84 [00:01<00:00, 33.24it/s]Scanning Parquet Files:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 69/84 [00:01<00:00, 33.56it/s]Scanning Parquet Files:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 69/84 [00:01<00:00, 33.05it/s]Scanning Parquet Files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 67/84 [00:01<00:00, 31.19it/s]Scanning Parquet Files:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 76/84 [00:01<00:00, 31.88it/s]Scanning Parquet Files:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 71/84 [00:01<00:00, 32.09it/s]Scanning Parquet Files:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 73/84 [00:01<00:00, 31.92it/s]Scanning Parquet Files:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 73/84 [00:01<00:00, 31.96it/s]Scanning Parquet Files:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 80/84 [00:02<00:00, 32.81it/s]Scanning Parquet Files:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 77/84 [00:01<00:00, 32.89it/s]Scanning Parquet Files:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 77/84 [00:01<00:00, 32.76it/s]Scanning Parquet Files:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 75/84 [00:01<00:00, 31.17it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 33.11it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 38.58it/s]
‚úÖ Loaded 233515 samples.
Scanning Parquet Files:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 81/84 [00:02<00:00, 31.13it/s]Scanning Parquet Files:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 81/84 [00:02<00:00, 31.23it/s]Scanning Parquet Files:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 79/84 [00:02<00:00, 31.39it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 38.71it/s]
Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 39.10it/s]
‚úÖ Loaded 233515 samples.
‚úÖ Loaded 233515 samples.
Scanning Parquet Files:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 83/84 [00:02<00:00, 32.95it/s]Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 38.17it/s]
‚úÖ Loaded 233515 samples.
Filtered dataset: 233360 samples remaining.
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
01/27/2026 02:44:27 - INFO - __main__ - [INFO] Set DeepSpeed train_micro_batch_size_per_gpu to 1
01/27/2026 02:44:27 - INFO - __main__ - [INFO] resume_from_checkpoint is None, but checking for existing checkpoints in /home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps...
01/27/2026 02:44:27 - INFO - __main__ - [INFO] No checkpoints found in /home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps, starting fresh
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank2]:     main()
[rank2]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 633, in main
[rank2]:     transformer, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 1551, in prepare
[rank2]:     result = self._prepare_deepspeed(*args)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2328, in _prepare_deepspeed
[rank2]:     optimizer = map_pytorch_optim_to_deepspeed(optimizer)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 97, in map_pytorch_optim_to_deepspeed
[rank2]:     return optimizer_class(optimizer.param_groups, **defaults)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
[rank2]:     self.ds_opt_adam = CPUAdamBuilder().load()
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 542, in load
[rank2]:     return self.jit_load(verbose)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 575, in jit_load
[rank2]:     cxx_args = self.strip_empty_entries(self.cxx_args())
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 858, in cxx_args
[rank2]:     CUDA_ENABLE = self.get_cuda_compile_flag()
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 430, in get_cuda_compile_flag
[rank2]:     assert_no_cuda_mismatch(self.name)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 109, in assert_no_cuda_mismatch
[rank2]:     raise CUDAMismatchException(
[rank2]: deepspeed.ops.op_builder.builder.CUDAMismatchException: >- DeepSpeed Op Builder: Installed CUDA version 11.8 does not match the version torch was compiled with 12.1, unable to compile cuda/cpp extensions without a matching cuda version.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank3]:     main()
[rank3]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 633, in main
[rank3]:     transformer, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 1551, in prepare
[rank3]:     result = self._prepare_deepspeed(*args)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2328, in _prepare_deepspeed
[rank3]:     optimizer = map_pytorch_optim_to_deepspeed(optimizer)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 97, in map_pytorch_optim_to_deepspeed
[rank3]:     return optimizer_class(optimizer.param_groups, **defaults)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
[rank3]:     self.ds_opt_adam = CPUAdamBuilder().load()
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 542, in load
[rank3]:     return self.jit_load(verbose)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 575, in jit_load
[rank3]:     cxx_args = self.strip_empty_entries(self.cxx_args())
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 858, in cxx_args
[rank3]:     CUDA_ENABLE = self.get_cuda_compile_flag()
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 430, in get_cuda_compile_flag
[rank3]:     assert_no_cuda_mismatch(self.name)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 109, in assert_no_cuda_mismatch
[rank3]:     raise CUDAMismatchException(
[rank3]: deepspeed.ops.op_builder.builder.CUDAMismatchException: >- DeepSpeed Op Builder: Installed CUDA version 11.8 does not match the version torch was compiled with 12.1, unable to compile cuda/cpp extensions without a matching cuda version.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank0]:     main()
[rank0]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 633, in main
[rank0]:     transformer, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 1551, in prepare
[rank0]:     result = self._prepare_deepspeed(*args)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2328, in _prepare_deepspeed
[rank0]:     optimizer = map_pytorch_optim_to_deepspeed(optimizer)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 97, in map_pytorch_optim_to_deepspeed
[rank0]:     return optimizer_class(optimizer.param_groups, **defaults)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
[rank0]:     self.ds_opt_adam = CPUAdamBuilder().load()
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 542, in load
[rank0]:     return self.jit_load(verbose)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 575, in jit_load
[rank0]:     cxx_args = self.strip_empty_entries(self.cxx_args())
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 858, in cxx_args
[rank0]:     CUDA_ENABLE = self.get_cuda_compile_flag()
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 430, in get_cuda_compile_flag
[rank0]:     assert_no_cuda_mismatch(self.name)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 109, in assert_no_cuda_mismatch
[rank0]:     raise CUDAMismatchException(
[rank0]: deepspeed.ops.op_builder.builder.CUDAMismatchException: >- DeepSpeed Op Builder: Installed CUDA version 11.8 does not match the version torch was compiled with 12.1, unable to compile cuda/cpp extensions without a matching cuda version.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank1]:     main()
[rank1]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 633, in main
[rank1]:     transformer, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 1551, in prepare
[rank1]:     result = self._prepare_deepspeed(*args)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2328, in _prepare_deepspeed
[rank1]:     optimizer = map_pytorch_optim_to_deepspeed(optimizer)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 97, in map_pytorch_optim_to_deepspeed
[rank1]:     return optimizer_class(optimizer.param_groups, **defaults)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
[rank1]:     self.ds_opt_adam = CPUAdamBuilder().load()
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 542, in load
[rank1]:     return self.jit_load(verbose)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 575, in jit_load
[rank1]:     cxx_args = self.strip_empty_entries(self.cxx_args())
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 858, in cxx_args
[rank1]:     CUDA_ENABLE = self.get_cuda_compile_flag()
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 430, in get_cuda_compile_flag
[rank1]:     assert_no_cuda_mismatch(self.name)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py", line 109, in assert_no_cuda_mismatch
[rank1]:     raise CUDAMismatchException(
[rank1]: deepspeed.ops.op_builder.builder.CUDAMismatchException: >- DeepSpeed Op Builder: Installed CUDA version 11.8 does not match the version torch was compiled with 12.1, unable to compile cuda/cpp extensions without a matching cuda version.
Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x1462578bb880>
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 102, in __del__
    self.ds_opt_adam.destroy_adam(self.opt_id)
AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'
Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x150dd6547880>
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 102, in __del__
    self.ds_opt_adam.destroy_adam(self.opt_id)
AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'
Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x14c0963db880>
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 102, in __del__
    self.ds_opt_adam.destroy_adam(self.opt_id)
AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'
Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x154527a33880>
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py", line 102, in __del__
    self.ds_opt_adam.destroy_adam(self.opt_id)
AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'
[rank0]:[W127 02:44:28.624289730 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0127 02:44:29.785000 3578530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3578899 closing signal SIGTERM
W0127 02:44:29.786000 3578530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3578900 closing signal SIGTERM
W0127 02:44:29.787000 3578530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3578902 closing signal SIGTERM
E0127 02:44:30.156000 3578530 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 2 (pid: 3578901) of binary: /home/v-yuxluo/miniconda3/envs/flux2/bin/python3.10
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/bin/accelerate", line 7, in <module>
    sys.exit(main())
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1266, in launch_command
    deepspeed_launcher(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/launch.py", line 952, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_OpenSciDraw_fulltune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-27_02:44:29
  host      : robustdnn-a100-14.internal.cloudapp.net
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3578901)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
