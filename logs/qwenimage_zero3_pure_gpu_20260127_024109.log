nohup: ignoring input
W0127 02:41:17.411000 3574823 site-packages/torch/distributed/run.py:793] 
W0127 02:41:17.411000 3574823 site-packages/torch/distributed/run.py:793] *****************************************
W0127 02:41:17.411000 3574823 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0127 02:41:17.411000 3574823 site-packages/torch/distributed/run.py:793] *****************************************
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
Config (path: configs/260127/qwenimage_fulltune_5000.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'QwenImage', 'transformer_cfg': {'type': 'QwenImageTransformer2DModel'}, 'pretrained_model_name_or_path': 'Qwen/Qwen-Image-2512', 'huggingface_token': None, 'use_lora': False, 'lora_layers': 'to_k,to_q,to_v', 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'adamw', 'use_8bit_adam': False, 'learning_rate': 5e-06, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 100, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'checkpoints_total_limit': 5, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': '/home/v-yuxluo/data/huggingface_cache', 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'logit_normal', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 1.0, 'base_filesys_path': '/home/v-yuxluo/data/', 'dataset_cfg': {'type': 'ArXiVParquetDatasetV2', 'base_dir': '/home/v-yuxluo/data/', 'parquet_base_path': 'ArXiV_parquet/qwenimage_latents', 'num_workers': 2, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': False}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 1, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'QwenImage_fulltune_train_iteration', 'validation_steps': 99999, 'max_sequence_length': 1024, 'dataloader_num_workers': 2, 'pin_memory': True, 'num_inference_steps': 50, 'model_output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'output_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps', 'log_steps': 10, 'verbose_logging': True, 'logging_dir': '/home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps/logs', 'wandb_project': 'QwenImage-20B-FullTune', 'tracker_run_name': '260127_qwenimage_5000steps', 'validation_prompts': ['A scientific diagram showing a neural network architecture with multiple layers', 'A chart comparing machine learning algorithms performance'], 'resolution_list': [[768, 768], [768, 768]], 'config_dir': 'configs/260127/qwenimage_fulltune_5000.py'}
01/27/2026 02:41:25 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:41:25 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:41:25 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:41:25 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/27/2026 02:41:25 - INFO - __main__ - [INFO] Using model type: QwenImage
01/27/2026 02:41:25 - INFO - __main__ - [INFO] Skipping text encoder load (parquet dataset + DeepSpeed mode)
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory - üè≠ Model Factory Initialized
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Model Type: QwenImage
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Pretrained Path: Qwen/Qwen-Image-2512
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Cache Dir: /home/v-yuxluo/data/huggingface_cache
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    VAE Class: AutoencoderKLQwenImage
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Transformer Class: QwenImageTransformer2DModel
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Text Encoder Class: Qwen2_5_VLForConditionalGeneration
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory -    Pipeline Class: QwenImagePipeline
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/27/2026 02:41:25 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading tokenizer: Qwen2Tokenizer
01/27/2026 02:41:26 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoder: Qwen2_5_VLForConditionalGeneration
01/27/2026 02:41:26 - INFO - OpenSciDraw.utils.model_factory - [INFO] Skipping text encoder load (parquet dataset mode)
01/27/2026 02:41:26 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading VAE: AutoencoderKLQwenImage
{'input_channels'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKLQwenImage.

All the weights of AutoencoderKLQwenImage were initialized from the model checkpoint at Qwen/Qwen-Image-2512.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKLQwenImage for predictions without further training.
01/27/2026 02:41:26 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading transformer: QwenImageTransformer2DModel
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 47783.21it/s]
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 25979.86it/s]
Instantiating QwenImageTransformer2DModel model under default dtype torch.bfloat16.
{'zero_cond_t', 'use_layer3d_rope', 'use_additional_t_cond'} was not found in config. Values will be initialized to default values.
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 57456.22it/s]
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 106936.93it/s]
Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]Loading checkpoint shards:  11%|‚ñà         | 1/9 [00:00<00:02,  3.52it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:00<00:00, 18.55it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 20.30it/s]
All model checkpoint weights were used when initializing QwenImageTransformer2DModel.

All the weights of QwenImageTransformer2DModel were initialized from the model checkpoint at Qwen/Qwen-Image-2512.
If your task is similar to the task the model of the checkpoint was trained on, you can already use QwenImageTransformer2DModel for predictions without further training.
01/27/2026 02:41:27 - INFO - OpenSciDraw.utils.model_factory - [INFO] Fine-tuning the full model ...
01/27/2026 02:41:27 - INFO - OpenSciDraw.utils.model_factory - [INFO] Enabling gradient checkpointing for transformer
01/27/2026 02:41:27 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading scheduler: FlowMatchEulerDiscreteScheduler
01/27/2026 02:41:27 - INFO - OpenSciDraw.utils.model_factory - [INFO] VAE scale factor: 8
01/27/2026 02:41:27 - INFO - __main__ - [INFO] DeepSpeed detected - keeping transformer in bf16 for ZeRO-3
01/27/2026 02:41:27 - INFO - __main__ - [INFO] Configuring model devices and offloading
01/27/2026 02:41:27 - INFO - __main__ - [INFO] Using parquet dataset - VAE and text encoder remain on CPU
01/27/2026 02:41:27 - INFO - __main__ - [INFO] DeepSpeed mode: transformer stays on CPU, ZeRO-3 will handle placement
01/27/2026 02:41:27 - INFO - __main__ - [INFO] Gradient checkpointing enabled
01/27/2026 02:41:27 - INFO - __main__ - [INFO] Number of trainable parameters: 20430.40M
01/27/2026 02:41:27 - INFO - __main__ - [INFO] Loading dataset
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/qwenimage_latents...
‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]‚è≥ Loading/parsing metadata (parquet: path only) from 84 parquet files...
Scanning Parquet Files:   0%|          | 0/84 [00:00<?, ?it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 148.50it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 145.98it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 142.61it/s]Scanning Parquet Files:  20%|‚ñà‚ñà        | 17/84 [00:00<00:00, 138.58it/s]Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 56.60it/s] Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 55.58it/s] Scanning Parquet Files:  38%|‚ñà‚ñà‚ñà‚ñä      | 32/84 [00:00<00:00, 56.02it/s] Scanning Parquet Files:  37%|‚ñà‚ñà‚ñà‚ñã      | 31/84 [00:00<00:01, 50.47it/s] Scanning Parquet Files:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 41/84 [00:00<00:00, 45.40it/s]Scanning Parquet Files:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 41/84 [00:00<00:00, 44.89it/s]Scanning Parquet Files:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 41/84 [00:00<00:00, 45.17it/s]Scanning Parquet Files:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 39/84 [00:00<00:01, 43.83it/s]Scanning Parquet Files:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 48/84 [00:01<00:00, 41.10it/s]Scanning Parquet Files:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 47/84 [00:00<00:00, 40.89it/s]Scanning Parquet Files:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 47/84 [00:00<00:00, 40.27it/s]Scanning Parquet Files:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 45/84 [00:00<00:00, 39.85it/s]Scanning Parquet Files:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 52/84 [00:01<00:00, 40.04it/s]Scanning Parquet Files:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 52/84 [00:01<00:00, 39.35it/s]Scanning Parquet Files:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 50/84 [00:01<00:00, 37.31it/s]Scanning Parquet Files:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 53/84 [00:01<00:00, 34.92it/s]Scanning Parquet Files:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 57/84 [00:01<00:00, 35.48it/s]Scanning Parquet Files:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 57/84 [00:01<00:00, 34.75it/s]Scanning Parquet Files:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 55/84 [00:01<00:00, 35.54it/s]Scanning Parquet Files:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 57/84 [00:01<00:00, 33.89it/s]Scanning Parquet Files:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 61/84 [00:01<00:00, 33.36it/s]Scanning Parquet Files:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 61/84 [00:01<00:00, 32.95it/s]Scanning Parquet Files:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 61/84 [00:01<00:00, 31.97it/s]Scanning Parquet Files:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 59/84 [00:01<00:00, 31.92it/s]Scanning Parquet Files:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 65/84 [00:01<00:00, 33.86it/s]Scanning Parquet Files:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 65/84 [00:01<00:00, 33.47it/s]Scanning Parquet Files:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 65/84 [00:01<00:00, 32.31it/s]Scanning Parquet Files:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 63/84 [00:01<00:00, 32.43it/s]Scanning Parquet Files:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 69/84 [00:01<00:00, 34.30it/s]Scanning Parquet Files:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 69/84 [00:01<00:00, 33.73it/s]Scanning Parquet Files:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 69/84 [00:01<00:00, 32.26it/s]Scanning Parquet Files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 67/84 [00:01<00:00, 30.52it/s]Scanning Parquet Files:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 73/84 [00:01<00:00, 32.52it/s]Scanning Parquet Files:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 73/84 [00:01<00:00, 32.02it/s]Scanning Parquet Files:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 73/84 [00:01<00:00, 30.78it/s]Scanning Parquet Files:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 71/84 [00:01<00:00, 31.28it/s]Scanning Parquet Files:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 78/84 [00:01<00:00, 35.31it/s]Scanning Parquet Files:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 77/84 [00:01<00:00, 32.77it/s]Scanning Parquet Files:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 77/84 [00:02<00:00, 31.42it/s]Scanning Parquet Files:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 75/84 [00:02<00:00, 30.13it/s]Scanning Parquet Files:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 82/84 [00:02<00:00, 32.43it/s]Scanning Parquet Files:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 81/84 [00:02<00:00, 30.65it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 39.32it/s]
Scanning Parquet Files:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 81/84 [00:02<00:00, 29.96it/s]Scanning Parquet Files:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 79/84 [00:02<00:00, 31.10it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 38.81it/s]
‚úÖ Loaded 233515 samples.
‚úÖ Loaded 233515 samples.
Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 37.86it/s]
‚úÖ Loaded 233515 samples.
Scanning Parquet Files:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 83/84 [00:02<00:00, 31.42it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 37.28it/s]
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
01/27/2026 02:41:30 - INFO - __main__ - [INFO] Set DeepSpeed train_micro_batch_size_per_gpu to 1
01/27/2026 02:41:30 - INFO - __main__ - [INFO] resume_from_checkpoint is None, but checking for existing checkpoints in /home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps...
01/27/2026 02:41:30 - INFO - __main__ - [INFO] No checkpoints found in /home/v-yuxluo/data/experiments/260127_qwenimage_20b_5000steps, starting fresh
‚úÖ Loaded 233515 samples.
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Filtered dataset: 233360 samples remaining.
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
Stage 3 initialize beginning
MA 38.06 GB         Max_MA 38.06 GB         CA 38.06 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 34.08 GB, percent = 3.9%
DeepSpeedZeRoOffload initialize [begin]
MA 38.06 GB         Max_MA 38.27 GB         CA 38.37 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 34.11 GB, percent = 3.9%
Parameter Offload - Persistent parameters statistics: param_count = 1087, numel = 5582400
DeepSpeedZeRoOffload initialize [end]
MA 9.51 GB         Max_MA 38.06 GB         CA 38.37 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 34.23 GB, percent = 4.0%
Before creating fp16 partitions
MA 9.51 GB         Max_MA 9.51 GB         CA 38.37 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 34.23 GB, percent = 4.0%
After creating fp16 partitions: 6
MA 9.51 GB         Max_MA 9.51 GB         CA 9.52 GB         Max_CA 38 GB 
CPU Virtual Memory:  used = 34.2 GB, percent = 3.9%
Before creating fp32 partitions
MA 9.51 GB         Max_MA 9.51 GB         CA 9.52 GB         Max_CA 10 GB 
CPU Virtual Memory:  used = 34.2 GB, percent = 3.9%
After creating fp32 partitions
MA 28.54 GB         Max_MA 32.29 GB         CA 35.71 GB         Max_CA 36 GB 
CPU Virtual Memory:  used = 34.21 GB, percent = 3.9%
Before initializing optimizer states
MA 28.54 GB         Max_MA 28.54 GB         CA 35.71 GB         Max_CA 36 GB 
CPU Virtual Memory:  used = 34.21 GB, percent = 3.9%
After initializing optimizer states
MA 28.54 GB         Max_MA 32.29 GB         CA 39.46 GB         Max_CA 39 GB 
CPU Virtual Memory:  used = 34.21 GB, percent = 3.9%
After initializing ZeRO optimizer
MA 38.99 GB         Max_MA 39.2 GB         CA 48.97 GB         Max_CA 49 GB 
CPU Virtual Memory:  used = 34.24 GB, percent = 4.0%
01/27/2026 02:41:51 - INFO - __main__ - ***** Running training *****
01/27/2026 02:41:51 - INFO - __main__ -   Num examples = 233360
01/27/2026 02:41:51 - INFO - __main__ -   Num Epochs = 2
01/27/2026 02:41:51 - INFO - __main__ -   Instantaneous batch size per device = 1
01/27/2026 02:41:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
01/27/2026 02:41:51 - INFO - __main__ -   Gradient Accumulation steps = 4
01/27/2026 02:41:51 - INFO - __main__ -   Total optimization steps = 5000
Steps:   0%|          | 0/5000 [00:00<?, ?it/s]01/27/2026 02:41:51 - INFO - __main__ - [INFO] Using training iteration function: QwenImage_fulltune_train_iteration
01/27/2026 02:41:52 - INFO - __main__ - [INFO] Using validation function: QwenImage_fulltune_validation_func_parquet
01/27/2026 02:41:52 - INFO - __main__ - [INFO] Validation every 99999 steps
wandb: Loaded settings from
wandb:   /home/v-yuxluo/.config/wandb/settings
wandb: [wandb.login()] Loaded credentials for https://microsoft-research.wandb.io from /home/v-yuxluo/.netrc.
wandb: Currently logged in as: v-yuxluo to https://microsoft-research.wandb.io. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /home/v-yuxluo/WORK_local/ArXivQwenImage/wandb/run-20260127_024153-3icgohb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 260127_qwenimage_5000steps
wandb: ‚≠êÔ∏è View project at https://microsoft-research.wandb.io/v-yuxluo/QwenImage-20B-FullTune
wandb: üöÄ View run at https://microsoft-research.wandb.io/v-yuxluo/QwenImage-20B-FullTune/runs/3icgohb6
01/27/2026 02:41:54 - INFO - __main__ - 
======================================================================
01/27/2026 02:41:54 - INFO - __main__ - Starting Training Loop
01/27/2026 02:41:54 - INFO - __main__ - ======================================================================

[Step 0] QwenImage Full Fine-tune Debug:
  Loss: 0.037769
  Latent shape: torch.Size([1, 16, 1, 72, 126])
  Bucket size: 576x1008
  Model input mean: 0.1582, std: 0.8320
  Noise mean: -0.0011, std: 1.0000
  Model pred mean: -0.1562, std: 1.2656
  Sigmas: [0.384765625]

[Step 0] QwenImage Full Fine-tune Debug:
  Loss: 0.058399
  Latent shape: torch.Size([1, 16, 1, 102, 90])
  Bucket size: 816x720
  Model input mean: 0.1426, std: 0.8242
  Noise mean: 0.0014, std: 1.0000
  Model pred mean: -0.1426, std: 1.2500
  Sigmas: [0.451171875]

[Step 0] QwenImage Full Fine-tune Debug:
  Loss: 0.030818
  Latent shape: torch.Size([1, 16, 1, 54, 162])
  Bucket size: 432x1296
  Model input mean: 0.1729, std: 0.8516
  Noise mean: 0.0018, std: 0.9961
  Model pred mean: -0.1729, std: 1.2812
  Sigmas: [0.240234375]

[Step 0] QwenImage Full Fine-tune Debug:
  Loss: 0.017383
  Latent shape: torch.Size([1, 16, 1, 54, 156])
  Bucket size: 432x1248
  Model input mean: 0.1807, std: 0.8398
  Noise mean: -0.0024, std: 1.0000
  Model pred mean: -0.1758, std: 1.2812
  Sigmas: [0.40234375]
Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
    main()
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 818, in main
    accelerator.backward(loss)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2844, in backward
    self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 281, in backward
    self.engine.step()
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2690, in step
    self._take_model_step(lr_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2585, in _take_model_step
    self.optimizer.step()
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 2217, in step
    self._optimizer_step(sub_group_id)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1078, in _optimizer_step
    step_with_gradscaler(self.optimizer)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1062, in step_with_gradscaler
    optimizer.step()
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
    adamw(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
    func(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 79.15 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 75.99 GiB memory in use. Of the allocated memory 72.64 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank0]:     main()
[rank0]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 818, in main
[rank0]:     accelerator.backward(loss)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2844, in backward
[rank0]:     self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 281, in backward
[rank0]:     self.engine.step()
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2690, in step
[rank0]:     self._take_model_step(lr_kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2585, in _take_model_step
[rank0]:     self.optimizer.step()
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 2217, in step
[rank0]:     self._optimizer_step(sub_group_id)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1078, in _optimizer_step
[rank0]:     step_with_gradscaler(self.optimizer)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1062, in step_with_gradscaler
[rank0]:     optimizer.step()
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
[rank0]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
[rank0]:     adamw(
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
[rank0]:     func(
[rank0]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
[rank0]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 79.15 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 75.99 GiB memory in use. Of the allocated memory 72.64 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank1]:     main()
[rank1]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 818, in main
[rank1]:     accelerator.backward(loss)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2844, in backward
[rank1]:     self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 281, in backward
[rank1]:     self.engine.step()
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2690, in step
[rank1]:     self._take_model_step(lr_kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2585, in _take_model_step
[rank1]:     self.optimizer.step()
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 2217, in step
[rank1]:     self._optimizer_step(sub_group_id)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1078, in _optimizer_step
[rank1]:     step_with_gradscaler(self.optimizer)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1062, in step_with_gradscaler
[rank1]:     optimizer.step()
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
[rank1]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
[rank1]:     adamw(
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
[rank1]:     func(
[rank1]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
[rank1]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 1 has a total capacity of 79.15 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 75.99 GiB memory in use. Of the allocated memory 72.64 GiB is allocated by PyTorch, and 2.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank2]:     main()
[rank2]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 818, in main
[rank2]:     accelerator.backward(loss)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2844, in backward
[rank2]:     self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 281, in backward
[rank2]:     self.engine.step()
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2690, in step
[rank2]:     self._take_model_step(lr_kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2585, in _take_model_step
[rank2]:     self.optimizer.step()
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 2217, in step
[rank2]:     self._optimizer_step(sub_group_id)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1078, in _optimizer_step
[rank2]:     step_with_gradscaler(self.optimizer)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1062, in step_with_gradscaler
[rank2]:     optimizer.step()
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
[rank2]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
[rank2]:     adamw(
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
[rank2]:     func(
[rank2]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
[rank2]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 2 has a total capacity of 79.15 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 75.99 GiB memory in use. Of the allocated memory 72.64 GiB is allocated by PyTorch, and 2.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 1007, in <module>
[rank3]:     main()
[rank3]:   File "/home/v-yuxluo/WORK_local/ArXivQwenImage/train_OpenSciDraw_fulltune.py", line 818, in main
[rank3]:     accelerator.backward(loss)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/accelerator.py", line 2844, in backward
[rank3]:     self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 281, in backward
[rank3]:     self.engine.step()
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2690, in step
[rank3]:     self._take_model_step(lr_kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2585, in _take_model_step
[rank3]:     self.optimizer.step()
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 2217, in step
[rank3]:     self._optimizer_step(sub_group_id)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1078, in _optimizer_step
[rank3]:     step_with_gradscaler(self.optimizer)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1062, in step_with_gradscaler
[rank3]:     optimizer.step()
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
[rank3]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 487, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 220, in step
[rank3]:     adamw(
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 782, in adamw
[rank3]:     func(
[rank3]:   File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
[rank3]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 3 has a total capacity of 79.15 GiB of which 3.16 GiB is free. Including non-PyTorch memory, this process has 75.99 GiB memory in use. Of the allocated memory 72.64 GiB is allocated by PyTorch, and 2.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33m260127_qwenimage_5000steps[0m at: [34mhttps://microsoft-research.wandb.io/v-yuxluo/QwenImage-20B-FullTune/runs/3icgohb6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260127_024153-3icgohb6/logs[0m
W0127 02:42:22.033000 3574823 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3575198 closing signal SIGTERM
W0127 02:42:22.034000 3574823 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3575200 closing signal SIGTERM
W0127 02:42:22.036000 3574823 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3575201 closing signal SIGTERM
E0127 02:42:23.621000 3574823 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 3575199) of binary: /home/v-yuxluo/miniconda3/envs/flux2/bin/python3.10
Traceback (most recent call last):
  File "/home/v-yuxluo/miniconda3/envs/flux2/bin/accelerate", line 7, in <module>
    sys.exit(main())
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1266, in launch_command
    deepspeed_launcher(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/accelerate/commands/launch.py", line 952, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_OpenSciDraw_fulltune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-27_02:42:22
  host      : robustdnn-a100-14.internal.cloudapp.net
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3575199)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
