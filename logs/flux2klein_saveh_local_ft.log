W0130 04:22:23.810000 2150042 site-packages/torch/distributed/run.py:793] 
W0130 04:22:23.810000 2150042 site-packages/torch/distributed/run.py:793] *****************************************
W0130 04:22:23.810000 2150042 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0130 04:22:23.810000 2150042 site-packages/torch/distributed/run.py:793] *****************************************
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 500, 'num_inference_steps': 28, 'validation_prompts': ['The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime.', 'The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies.', 'The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers.', 'The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout.'], 'resolution_list': [[1008, 576], [1008, 576], [1008, 576], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 500, 'num_inference_steps': 28, 'validation_prompts': ['The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime.', 'The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies.', 'The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers.', 'The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout.'], 'resolution_list': [[1008, 576], [1008, 576], [1008, 576], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 500, 'num_inference_steps': 28, 'validation_prompts': ['The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime.', 'The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies.', 'The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers.', 'The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout.'], 'resolution_list': [[1008, 576], [1008, 576], [1008, 576], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
Config (path: configs/260130/flux2klein_saveh_local_5k.py): {'seed': 42, 'device': 'cuda', 'dtype': 'float32', 'revision': None, 'variant': None, 'bnb_quantization_config_path': None, 'model_type': 'Flux2Klein', 'transformer_cfg': {'type': 'Flux2Transformer2DModel'}, 'pretrained_model_name_or_path': 'black-forest-labs/FLUX.2-klein-base-9B', 'huggingface_token': None, 'use_lora': False, 'lora_layers': None, 'rank': 64, 'lora_alpha': 4, 'lora_dropout': 0.0, 'layer_weighting': 5.0, 'pos_embedding': 'rope', 'decoder_arch': 'vit', 'use_parquet_dataset': True, 'train_batch_size': 1, 'num_train_epochs': 100, 'max_train_steps': 5000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': True, 'cache_latents': False, 'optimizer': 'AdamW', 'use_8bit_adam': False, 'learning_rate': 1e-05, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'prodigy_beta3': None, 'prodigy_decouple': True, 'prodigy_use_bias_correction': True, 'prodigy_safeguard_warmup': True, 'checkpointing_steps': 1000, 'resume_from_checkpoint': 'latest', 'checkpoints_total_limit': None, 'mixed_precision': 'bf16', 'allow_tf32': True, 'upcast_before_saving': False, 'offload': False, 'report_to': 'wandb', 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'cache_dir': None, 'scale_lr': False, 'lr_num_cycles': 1, 'lr_power': 1.0, 'weighting_scheme': 'none', 'logit_mean': 0.0, 'logit_std': 1.0, 'mode_scale': 1.29, 'validation_guidance_scale': 3.5, 'dataset_cfg': {'type': 'ArXiVParquetDatasetV3', 'base_dir': '/home/v-yuxluo/data', 'parquet_base_path': 'ArXiV_parquet/flux_latents_saveh', 'vae_scaling_factor': 0.3611, 'num_workers': 4, 'num_train_examples': None, 'debug_mode': False, 'is_main_process': True, 'stat_data': True}, 'sampler_cfg': {'type': 'DistributedBucketSamplerV2', 'dataset': None, 'batch_size': 2, 'num_replicas': None, 'rank': None, 'drop_last': True, 'shuffle': True}, 'train_iteration_func': 'Flux2Klein_fulltune_train_iteration', 'model_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'image_output_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k', 'logging_dir': '/home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/logs', 'log_steps': 1, 'wandb_project': 'Flux2Klein-SaveH', 'run_name': 'flux2klein_9b_saveh_2015_5k', 'validation_func': 'Flux2Klein_fulltune_validation_func_parquet', 'validation_steps': 500, 'num_inference_steps': 28, 'validation_prompts': ['The figure illustrates a process hooking mechanism using the LD_PRELOAD environment variable to inject a custom data collection library, siren.so, into target ELF binary executables during runtime.', 'The figure presents a comparative diagram of four different defect detection tasks, labeled (a) ISDD, (b) MISDD, (c) MIISDD, and (d) MISDD-MM, illustrating variations in data modality handling and fusion strategies.', 'The figure illustrates a linear probing framework applied to a frozen multimodal large language model (LLM) across different decoder layers.', 'The figure presents a conceptual comparison of four different point cloud completion learning paradigms, arranged in a 2x2 grid layout.'], 'resolution_list': [[1008, 576], [1008, 576], [1008, 576], [768, 720]], 'max_sequence_length': 2048, 'dataloader_num_workers': 4, 'debug_mode': False, 'config_dir': 'configs/260130/flux2klein_saveh_local_5k.py'}
01/30/2026 04:22:32 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 04:22:32 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 04:22:32 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 04:22:32 - INFO - __main__ - [INFO] Using model type: Flux2Klein
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory - üè≠ Model Factory Initialized
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Model Type: Flux2Klein
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Pretrained Path: black-forest-labs/FLUX.2-klein-base-9B
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Cache Dir: None
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    VAE Class: AutoencoderKLFlux2
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Transformer Class: Flux2Transformer2DModel
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Text Encoder Class: Qwen3ForCausalLM
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory -    Pipeline Class: Flux2KleinPipeline
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory - ============================================================
01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading tokenizer: Qwen2TokenizerFast
01/30/2026 04:22:32 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 4, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

01/30/2026 04:22:32 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoder: Qwen3ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.50it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.50it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.51it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:03,  1.17s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  1.43it/s]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  1.43it/s]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  1.43it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.03it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.03it/s]

Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.03it/s]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.13s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:03<00:01,  1.13s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.24it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.08it/s]
01/30/2026 04:22:37 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading VAE: AutoencoderKLFlux2
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 13774.40it/s]
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 26132.74it/s]
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 26800.66it/s]
All model checkpoint weights were used when initializing AutoencoderKLFlux2.

All the weights of AutoencoderKLFlux2 were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKLFlux2 for predictions without further training.
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading transformer: Flux2Transformer2DModel
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 33825.03it/s]
Instantiating Flux2Transformer2DModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 70.38it/s]
All model checkpoint weights were used when initializing Flux2Transformer2DModel.

All the weights of Flux2Transformer2DModel were initialized from the model checkpoint at black-forest-labs/FLUX.2-klein-base-9B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Flux2Transformer2DModel for predictions without further training.
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] Fine-tuning the full model ...
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] Enabling gradient checkpointing for transformer
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading scheduler: FlowMatchEulerDiscreteScheduler
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] Loading text encoding pipeline: Flux2KleinPipeline
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
‚è≥ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]{'is_distilled'} was not found in config. Values will be initialized to default values.
Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 2511.56it/s]
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:389: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  if hasattr(vae, attr_name):
/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/utils/model_factory.py:390: FutureWarning: Accessing config attribute `block_out_channels` directly via 'AutoencoderKLFlux2' object attribute is deprecated. Please access 'block_out_channels' over 'AutoencoderKLFlux2's config object instead, e.g. 'unet.config.block_out_channels'.
  attr_value = getattr(vae, attr_name)
01/30/2026 04:22:38 - INFO - OpenSciDraw.utils.model_factory - [INFO] VAE scale factor: 16
01/30/2026 04:22:38 - INFO - __main__ - [INFO] DeepSpeed detected - keeping transformer in bf16 for ZeRO-3
01/30/2026 04:22:38 - INFO - __main__ - [INFO] Configuring model devices and offloading
01/30/2026 04:22:38 - INFO - __main__ - [INFO] Using parquet dataset - VAE and text encoder remain on CPU
Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 75.36it/s]
01/30/2026 04:22:38 - INFO - __main__ - [INFO] DeepSpeed mode: transformer stays on CPU, ZeRO-3 will handle placement
‚úÖ Loaded 5086 samples./home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \

01/30/2026 04:22:38 - INFO - __main__ - [INFO] Gradient checkpointing enabled
01/30/2026 04:22:38 - INFO - __main__ - [INFO] Number of trainable parameters: 9078.58M
01/30/2026 04:22:38 - INFO - __main__ - [INFO] Loading dataset
Filtered dataset: 4803 samples remaining.
üìä Data Statistics:
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
‚è≥ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
‚è≥ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 69.59it/s]
‚úÖ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
üìä Data Statistics:
Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 70.26it/s]
‚úÖ Loaded 5086 samples.
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
Filtered dataset: 4803 samples remaining.
 - Resolution 960x576: 160 samples (3.33%)
üìä Data Statistics:
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import \
üîç Building metadata from all parquet files in /home/v-yuxluo/data/ArXiV_parquet/flux_latents_saveh...
‚è≥ Loading/parsing metadata from 4 parquet files...
Scanning Parquet Files:   0%|          | 0/4 [00:00<?, ?it/s]Scanning Parquet Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 68.17it/s]
‚úÖ Loaded 5086 samples.
Filtered dataset: 4803 samples remaining.
üìä Data Statistics:
    bucket_h  bucket_w  counts
0        384      1392      93
1        384      1440     100
2        384      1488      98
3        384      1536     211
4        432      1296     174
5        432      1344     308
6        480      1152     150
7        480      1200     432
8        528      1008     589
9        528      1056     168
10       528      1104     389
11       576       960     160
12       576      1008     461
13       624       864      75
14       624       912     406
15       672       864     354
16       720       816     245
17       768       768     194
18       816       720     108
19       864       672      88
 - Resolution 1392x384: 93 samples (1.94%)
 - Resolution 1440x384: 100 samples (2.08%)
 - Resolution 1488x384: 98 samples (2.04%)
 - Resolution 1536x384: 211 samples (4.39%)
 - Resolution 1296x432: 174 samples (3.62%)
 - Resolution 1344x432: 308 samples (6.41%)
 - Resolution 1152x480: 150 samples (3.12%)
 - Resolution 1200x480: 432 samples (8.99%)
 - Resolution 1008x528: 589 samples (12.26%)
 - Resolution 1056x528: 168 samples (3.50%)
 - Resolution 1104x528: 389 samples (8.10%)
 - Resolution 960x576: 160 samples (3.33%)
 - Resolution 1008x576: 461 samples (9.60%)
 - Resolution 864x624: 75 samples (1.56%)
 - Resolution 912x624: 406 samples (8.45%)
 - Resolution 864x672: 354 samples (7.37%)
 - Resolution 816x720: 245 samples (5.10%)
 - Resolution 768x768: 194 samples (4.04%)
 - Resolution 720x816: 108 samples (2.25%)
 - Resolution 672x864: 88 samples (1.83%)
/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn(
01/30/2026 04:22:39 - INFO - __main__ - [INFO] Set DeepSpeed train_micro_batch_size_per_gpu to 1
01/30/2026 04:22:39 - INFO - __main__ - [INFO] No checkpoints found in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k, starting fresh
Stage 3 initialize beginning
MA 20.72 GB         Max_MA 20.72 GB         CA 20.74 GB         Max_CA 21 GB 
CPU Virtual Memory:  used = 50.7 GB, percent = 5.9%
DeepSpeedZeRoOffload initialize [begin]
MA 20.72 GB         Max_MA 21.29 GB         CA 21.74 GB         Max_CA 22 GB 
CPU Virtual Memory:  used = 50.72 GB, percent = 5.9%
Parameter Offload - Persistent parameters statistics: param_count = 80, numel = 10240
DeepSpeedZeRoOffload initialize [end]
MA 8.04 GB         Max_MA 20.75 GB         CA 21.74 GB         Max_CA 22 GB 
CPU Virtual Memory:  used = 50.73 GB, percent = 5.9%
Before creating fp16 partitions
MA 8.04 GB         Max_MA 8.04 GB         CA 21.74 GB         Max_CA 22 GB 
CPU Virtual Memory:  used = 50.73 GB, percent = 5.9%
After creating fp16 partitions: 3
MA 8.04 GB         Max_MA 8.04 GB         CA 8.06 GB         Max_CA 22 GB 
CPU Virtual Memory:  used = 63.41 GB, percent = 7.3%
Before creating fp32 partitions
MA 8.04 GB         Max_MA 8.04 GB         CA 8.06 GB         Max_CA 8 GB 
CPU Virtual Memory:  used = 50.71 GB, percent = 5.9%
After creating fp32 partitions
MA 16.5 GB         Max_MA 20.3 GB         CA 23.16 GB         Max_CA 23 GB 
CPU Virtual Memory:  used = 50.7 GB, percent = 5.9%
Before initializing optimizer states
MA 16.5 GB         Max_MA 16.5 GB         CA 23.16 GB         Max_CA 23 GB 
CPU Virtual Memory:  used = 50.72 GB, percent = 5.9%
After initializing optimizer states
MA 16.5 GB         Max_MA 20.3 GB         CA 23.16 GB         Max_CA 23 GB 
CPU Virtual Memory:  used = 50.71 GB, percent = 5.9%
After initializing ZeRO optimizer
MA 21.66 GB         Max_MA 22.22 GB         CA 27.39 GB         Max_CA 27 GB 
CPU Virtual Memory:  used = 50.72 GB, percent = 5.9%
01/30/2026 04:22:49 - INFO - __main__ - ***** Running training *****
01/30/2026 04:22:49 - INFO - __main__ -   Num examples = 4803
01/30/2026 04:22:49 - INFO - __main__ -   Num Epochs = 67
01/30/2026 04:22:49 - INFO - __main__ -   Instantaneous batch size per device = 1
01/30/2026 04:22:49 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
01/30/2026 04:22:49 - INFO - __main__ -   Gradient Accumulation steps = 4
01/30/2026 04:22:49 - INFO - __main__ -   Total optimization steps = 5000
Steps:   0%|          | 0/5000 [00:00<?, ?it/s]01/30/2026 04:22:49 - INFO - __main__ - [INFO] Using training iteration function: Flux2Klein_fulltune_train_iteration
01/30/2026 04:22:50 - INFO - __main__ - [INFO] Using validation function: Flux2Klein_fulltune_validation_func_parquet
01/30/2026 04:22:50 - INFO - __main__ - [INFO] Validation every 500 steps
wandb: Loaded settings from
wandb:   /home/v-yuxluo/.config/wandb/settings
wandb: [wandb.login()] Loaded credentials for https://microsoft-research.wandb.io from WANDB_API_KEY.
wandb: Currently logged in as: v-yuxluo to https://microsoft-research.wandb.io. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /home/v-yuxluo/WORK_local/ArXivQwenImage/wandb/run-20260130_042250-c32ga4ra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flux2klein_9b_saveh_2015_5k
wandb: ‚≠êÔ∏è View project at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-SaveH
wandb: üöÄ View run at https://microsoft-research.wandb.io/v-yuxluo/Flux2Klein-SaveH/runs/c32ga4ra
01/30/2026 04:22:51 - INFO - __main__ - 
======================================================================
01/30/2026 04:22:51 - INFO - __main__ - Starting Training Loop
01/30/2026 04:22:51 - INFO - __main__ - ======================================================================

[Step 0] Training Debug Info:
  Loss: 0.611523
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0128, std: 0.8984
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0122, std: 1.3438
  Model pred mean: -0.0041, std: 1.2500
  Sigmas: [0.6171875]... (timesteps: [618.0])

[Step 0] Training Debug Info:
  Loss: 1.127975
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0330, std: 1.0000
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0330, std: 1.4141
  Model pred mean: -0.0138, std: 0.9336
  Sigmas: [0.041015625]... (timesteps: [41.0])

[Step 0] Training Debug Info:
  Loss: 0.690811
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0366, std: 0.8711
  Noise mean: 0.0034, std: 0.9961
  Target mean: 0.0400, std: 1.3281
  Model pred mean: 0.0464, std: 1.2266
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 0] Training Debug Info:
  Loss: 1.149871
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0140, std: 1.3750
  Model pred mean: 0.0030, std: 1.3281
  Sigmas: [0.400390625]... (timesteps: [400.0])
Steps:   0%|          | 1/5000 [00:11<16:32:09, 11.91s/it]Steps:   0%|          | 1/5000 [00:11<16:32:09, 11.91s/it, loss=1.1499, lr=2.00e-08]01/30/2026 04:23:00 - INFO - __main__ - 
üîç Running validation at step 1...
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1 (parquet mode)...
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1...
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/4: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/4: The figure presents a comparative diagram of four different defect detection tas...
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt01_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/4: The figure illustrates a linear probing framework applied to a frozen multimodal...
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt02_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/4: The figure presents a conceptual comparison of four different point cloud comple...
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 04:23:01 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001/step000001_prompt03_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ‚úÖ Validation complete! Saved 4 images to:
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000001
01/30/2026 04:23:01 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================

Steps:   0%|          | 2/5000 [00:21<14:25:22, 10.39s/it, loss=1.1499, lr=2.00e-08]Steps:   0%|          | 2/5000 [00:21<14:25:22, 10.39s/it, loss=0.4527, lr=4.00e-08]Steps:   0%|          | 3/5000 [00:29<12:56:45,  9.33s/it, loss=0.4527, lr=4.00e-08]Steps:   0%|          | 3/5000 [00:29<12:56:45,  9.33s/it, loss=1.1276, lr=6.00e-08]Steps:   0%|          | 4/5000 [00:37<12:26:24,  8.96s/it, loss=1.1276, lr=6.00e-08]Steps:   0%|          | 4/5000 [00:37<12:26:24,  8.96s/it, loss=1.0302, lr=8.00e-08]Steps:   0%|          | 5/5000 [00:45<11:58:30,  8.63s/it, loss=1.0302, lr=8.00e-08]Steps:   0%|          | 5/5000 [00:45<11:58:30,  8.63s/it, loss=0.7339, lr=1.00e-07]Steps:   0%|          | 6/5000 [00:53<11:40:31,  8.42s/it, loss=0.7339, lr=1.00e-07]Steps:   0%|          | 6/5000 [00:53<11:40:31,  8.42s/it, loss=0.4887, lr=1.20e-07]Steps:   0%|          | 7/5000 [01:01<11:34:44,  8.35s/it, loss=0.4887, lr=1.20e-07]Steps:   0%|          | 7/5000 [01:01<11:34:44,  8.35s/it, loss=0.5523, lr=1.40e-07]Steps:   0%|          | 8/5000 [01:09<11:25:49,  8.24s/it, loss=0.5523, lr=1.40e-07]Steps:   0%|          | 8/5000 [01:09<11:25:49,  8.24s/it, loss=1.2216, lr=1.60e-07]Steps:   0%|          | 9/5000 [01:18<11:30:34,  8.30s/it, loss=1.2216, lr=1.60e-07]Steps:   0%|          | 9/5000 [01:18<11:30:34,  8.30s/it, loss=1.3816, lr=1.80e-07]Steps:   0%|          | 10/5000 [01:26<11:21:46,  8.20s/it, loss=1.3816, lr=1.80e-07]Steps:   0%|          | 10/5000 [01:26<11:21:46,  8.20s/it, loss=0.6003, lr=2.00e-07]
[Step 10] Training Debug Info:
  Loss: 2.170733
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0010, std: 0.8516
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0002, std: 1.3125
  Model pred mean: 0.0240, std: 1.3828
  Sigmas: [0.2890625]... (timesteps: [290.0])

[Step 10] Training Debug Info:
  Loss: 1.237354
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0270, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0262, std: 1.3594
  Model pred mean: 0.0525, std: 0.8398
  Sigmas: [0.053955078125]... (timesteps: [54.0])

[Step 10] Training Debug Info:
  Loss: 1.561369
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0007, std: 0.8906
  Noise mean: 0.0034, std: 1.0000
  Target mean: 0.0027, std: 1.3359
  Model pred mean: 0.0334, std: 0.9297
  Sigmas: [0.2109375]... (timesteps: [211.0])

[Step 10] Training Debug Info:
  Loss: 0.564320
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0332, std: 0.9922
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0332, std: 1.4062
  Model pred mean: -0.0183, std: 1.2422
  Sigmas: [0.71875]... (timesteps: [719.0])
Steps:   0%|          | 11/5000 [01:34<11:15:18,  8.12s/it, loss=0.6003, lr=2.00e-07]Steps:   0%|          | 11/5000 [01:34<11:15:18,  8.12s/it, loss=0.5643, lr=2.20e-07]Steps:   0%|          | 12/5000 [01:42<11:16:09,  8.13s/it, loss=0.5643, lr=2.20e-07]Steps:   0%|          | 12/5000 [01:42<11:16:09,  8.13s/it, loss=0.4465, lr=2.40e-07]Steps:   0%|          | 13/5000 [01:50<11:13:39,  8.11s/it, loss=0.4465, lr=2.40e-07]Steps:   0%|          | 13/5000 [01:50<11:13:39,  8.11s/it, loss=1.4375, lr=2.60e-07]Steps:   0%|          | 14/5000 [01:58<11:08:53,  8.05s/it, loss=1.4375, lr=2.60e-07]Steps:   0%|          | 14/5000 [01:58<11:08:53,  8.05s/it, loss=0.8413, lr=2.80e-07]Steps:   0%|          | 15/5000 [02:06<11:14:52,  8.12s/it, loss=0.8413, lr=2.80e-07]Steps:   0%|          | 15/5000 [02:06<11:14:52,  8.12s/it, loss=0.4411, lr=3.00e-07]Steps:   0%|          | 16/5000 [02:14<11:10:29,  8.07s/it, loss=0.4411, lr=3.00e-07]Steps:   0%|          | 16/5000 [02:14<11:10:29,  8.07s/it, loss=0.5409, lr=3.20e-07]Steps:   0%|          | 17/5000 [02:22<11:09:16,  8.06s/it, loss=0.5409, lr=3.20e-07]Steps:   0%|          | 17/5000 [02:22<11:09:16,  8.06s/it, loss=0.4996, lr=3.40e-07]Steps:   0%|          | 18/5000 [02:30<11:13:02,  8.11s/it, loss=0.4996, lr=3.40e-07]Steps:   0%|          | 18/5000 [02:30<11:13:02,  8.11s/it, loss=0.7162, lr=3.60e-07]Steps:   0%|          | 19/5000 [02:38<11:11:09,  8.08s/it, loss=0.7162, lr=3.60e-07]Steps:   0%|          | 19/5000 [02:38<11:11:09,  8.08s/it, loss=1.6414, lr=3.80e-07]Steps:   0%|          | 20/5000 [02:47<11:18:51,  8.18s/it, loss=1.6414, lr=3.80e-07]Steps:   0%|          | 20/5000 [02:47<11:18:51,  8.18s/it, loss=0.4418, lr=4.00e-07]
[Step 20] Training Debug Info:
  Loss: 1.987510
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0071, std: 0.8828
  Noise mean: 0.0043, std: 1.0000
  Target mean: -0.0028, std: 1.3359
  Model pred mean: 0.0244, std: 1.2109
  Sigmas: [0.2353515625]... (timesteps: [235.0])

[Step 20] Training Debug Info:
  Loss: 0.526682
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0035, std: 0.9570
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0023, std: 1.3906
  Model pred mean: 0.0039, std: 1.2656
  Sigmas: [0.703125]... (timesteps: [703.0])

[Step 20] Training Debug Info:
  Loss: 1.729333
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0112, std: 0.9062
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0090, std: 1.3516
  Model pred mean: 0.0280, std: 1.0547
  Sigmas: [0.197265625]... (timesteps: [197.0])

[Step 20] Training Debug Info:
  Loss: 0.618598
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0262, std: 0.9180
  Noise mean: -0.0036, std: 1.0078
  Target mean: 0.0227, std: 1.3594
  Model pred mean: 0.0310, std: 1.2812
  Sigmas: [0.6171875]... (timesteps: [619.0])
Steps:   0%|          | 21/5000 [02:55<11:15:10,  8.14s/it, loss=0.4418, lr=4.00e-07]Steps:   0%|          | 21/5000 [02:55<11:15:10,  8.14s/it, loss=0.6186, lr=4.20e-07]Steps:   0%|          | 22/5000 [03:03<11:10:33,  8.08s/it, loss=0.6186, lr=4.20e-07]Steps:   0%|          | 22/5000 [03:03<11:10:33,  8.08s/it, loss=1.5741, lr=4.40e-07]Steps:   0%|          | 23/5000 [03:11<11:12:40,  8.11s/it, loss=1.5741, lr=4.40e-07]Steps:   0%|          | 23/5000 [03:11<11:12:40,  8.11s/it, loss=1.6678, lr=4.60e-07]Steps:   0%|          | 24/5000 [03:19<11:09:38,  8.07s/it, loss=1.6678, lr=4.60e-07]Steps:   0%|          | 24/5000 [03:19<11:09:38,  8.07s/it, loss=0.5800, lr=4.80e-07]Steps:   0%|          | 25/5000 [03:27<11:10:07,  8.08s/it, loss=0.5800, lr=4.80e-07]Steps:   0%|          | 25/5000 [03:27<11:10:07,  8.08s/it, loss=1.3539, lr=5.00e-07]Steps:   1%|          | 26/5000 [03:35<11:06:55,  8.04s/it, loss=1.3539, lr=5.00e-07]Steps:   1%|          | 26/5000 [03:35<11:06:55,  8.04s/it, loss=0.4918, lr=5.20e-07]Steps:   1%|          | 27/5000 [03:43<11:06:00,  8.04s/it, loss=0.4918, lr=5.20e-07]Steps:   1%|          | 27/5000 [03:43<11:06:00,  8.04s/it, loss=0.5140, lr=5.40e-07]Steps:   1%|          | 28/5000 [03:51<11:10:36,  8.09s/it, loss=0.5140, lr=5.40e-07]Steps:   1%|          | 28/5000 [03:51<11:10:36,  8.09s/it, loss=0.7621, lr=5.60e-07]Steps:   1%|          | 29/5000 [03:59<11:09:52,  8.09s/it, loss=0.7621, lr=5.60e-07]Steps:   1%|          | 29/5000 [03:59<11:09:52,  8.09s/it, loss=0.5507, lr=5.80e-07]Steps:   1%|          | 30/5000 [04:07<11:08:05,  8.07s/it, loss=0.5507, lr=5.80e-07]Steps:   1%|          | 30/5000 [04:07<11:08:05,  8.07s/it, loss=0.4826, lr=6.00e-07]
[Step 30] Training Debug Info:
  Loss: 0.670030
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0019, std: 0.9336
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0036, std: 1.3672
  Model pred mean: 0.0120, std: 1.2812
  Sigmas: [0.53515625]... (timesteps: [535.0])

[Step 30] Training Debug Info:
  Loss: 0.424652
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0097, std: 0.8867
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0086, std: 1.3281
  Model pred mean: 0.0020, std: 1.1953
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 30] Training Debug Info:
  Loss: 0.422154
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0135, std: 0.9023
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0151, std: 1.3516
  Model pred mean: -0.0123, std: 1.1953
  Sigmas: [0.84375]... (timesteps: [844.0])

[Step 30] Training Debug Info:
  Loss: 0.457323
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0011, std: 0.8633
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0017, std: 1.3203
  Model pred mean: 0.0090, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [792.0])
Steps:   1%|          | 31/5000 [04:16<11:10:02,  8.09s/it, loss=0.4826, lr=6.00e-07]Steps:   1%|          | 31/5000 [04:16<11:10:02,  8.09s/it, loss=0.4573, lr=6.20e-07]Steps:   1%|          | 32/5000 [04:24<11:08:06,  8.07s/it, loss=0.4573, lr=6.20e-07]Steps:   1%|          | 32/5000 [04:24<11:08:06,  8.07s/it, loss=0.7247, lr=6.40e-07]Steps:   1%|          | 33/5000 [04:32<11:05:10,  8.04s/it, loss=0.7247, lr=6.40e-07]Steps:   1%|          | 33/5000 [04:32<11:05:10,  8.04s/it, loss=1.4686, lr=6.60e-07]Steps:   1%|          | 34/5000 [04:40<11:06:27,  8.05s/it, loss=1.4686, lr=6.60e-07]Steps:   1%|          | 34/5000 [04:40<11:06:27,  8.05s/it, loss=0.6668, lr=6.80e-07]Steps:   1%|          | 35/5000 [04:48<11:03:38,  8.02s/it, loss=0.6668, lr=6.80e-07]Steps:   1%|          | 35/5000 [04:48<11:03:38,  8.02s/it, loss=0.4230, lr=7.00e-07]Steps:   1%|          | 36/5000 [04:56<11:09:22,  8.09s/it, loss=0.4230, lr=7.00e-07]Steps:   1%|          | 36/5000 [04:56<11:09:22,  8.09s/it, loss=1.2654, lr=7.20e-07]Steps:   1%|          | 37/5000 [05:04<11:04:37,  8.03s/it, loss=1.2654, lr=7.20e-07]Steps:   1%|          | 37/5000 [05:04<11:04:37,  8.03s/it, loss=0.3974, lr=7.40e-07]Steps:   1%|          | 38/5000 [05:12<11:03:21,  8.02s/it, loss=0.3974, lr=7.40e-07]Steps:   1%|          | 38/5000 [05:12<11:03:21,  8.02s/it, loss=0.4733, lr=7.60e-07]Steps:   1%|          | 39/5000 [05:20<11:08:21,  8.08s/it, loss=0.4733, lr=7.60e-07]Steps:   1%|          | 39/5000 [05:20<11:08:21,  8.08s/it, loss=1.2172, lr=7.80e-07]Steps:   1%|          | 40/5000 [05:28<11:07:01,  8.07s/it, loss=1.2172, lr=7.80e-07]Steps:   1%|          | 40/5000 [05:28<11:07:01,  8.07s/it, loss=0.9938, lr=8.00e-07]
[Step 40] Training Debug Info:
  Loss: 0.984965
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0245, std: 0.8984
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0239, std: 1.3438
  Model pred mean: -0.0127, std: 1.2344
  Sigmas: [0.435546875]... (timesteps: [436.0])

[Step 40] Training Debug Info:
  Loss: 0.436809
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0031, std: 0.8789
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0036, std: 1.3281
  Model pred mean: -0.0017, std: 1.1406
  Sigmas: [0.94140625]... (timesteps: [941.0])

[Step 40] Training Debug Info:
  Loss: 1.208858
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0576, std: 0.9180
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0583, std: 1.3594
  Model pred mean: -0.0243, std: 1.0312
  Sigmas: [0.291015625]... (timesteps: [291.0])

[Step 40] Training Debug Info:
  Loss: 0.704069
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0138, std: 0.9062
  Noise mean: 0.0037, std: 0.9961
  Target mean: 0.0176, std: 1.3516
  Model pred mean: 0.0293, std: 1.2266
  Sigmas: [0.57421875]... (timesteps: [576.0])
Steps:   1%|          | 41/5000 [05:36<11:11:07,  8.12s/it, loss=0.9938, lr=8.00e-07]Steps:   1%|          | 41/5000 [05:36<11:11:07,  8.12s/it, loss=0.7041, lr=8.20e-07]Steps:   1%|          | 42/5000 [05:44<11:07:26,  8.08s/it, loss=0.7041, lr=8.20e-07]Steps:   1%|          | 42/5000 [05:44<11:07:26,  8.08s/it, loss=0.4351, lr=8.40e-07]Steps:   1%|          | 43/5000 [05:52<11:07:19,  8.08s/it, loss=0.4351, lr=8.40e-07]Steps:   1%|          | 43/5000 [05:52<11:07:19,  8.08s/it, loss=0.6232, lr=8.60e-07]Steps:   1%|          | 44/5000 [06:00<11:06:09,  8.06s/it, loss=0.6232, lr=8.60e-07]Steps:   1%|          | 44/5000 [06:00<11:06:09,  8.06s/it, loss=1.2941, lr=8.80e-07]Steps:   1%|          | 45/5000 [06:09<11:12:05,  8.14s/it, loss=1.2941, lr=8.80e-07]Steps:   1%|          | 45/5000 [06:09<11:12:05,  8.14s/it, loss=1.2616, lr=9.00e-07]Steps:   1%|          | 46/5000 [06:17<11:08:26,  8.10s/it, loss=1.2616, lr=9.00e-07]Steps:   1%|          | 46/5000 [06:17<11:08:26,  8.10s/it, loss=1.1679, lr=9.20e-07]Steps:   1%|          | 47/5000 [06:25<11:11:31,  8.13s/it, loss=1.1679, lr=9.20e-07]Steps:   1%|          | 47/5000 [06:25<11:11:31,  8.13s/it, loss=0.8164, lr=9.40e-07]Steps:   1%|          | 48/5000 [06:33<11:08:18,  8.10s/it, loss=0.8164, lr=9.40e-07]Steps:   1%|          | 48/5000 [06:33<11:08:18,  8.10s/it, loss=1.1462, lr=9.60e-07]Steps:   1%|          | 49/5000 [06:41<11:04:42,  8.06s/it, loss=1.1462, lr=9.60e-07]Steps:   1%|          | 49/5000 [06:41<11:04:42,  8.06s/it, loss=0.6092, lr=9.80e-07]Steps:   1%|          | 50/5000 [06:49<11:08:16,  8.10s/it, loss=0.6092, lr=9.80e-07]Steps:   1%|          | 50/5000 [06:49<11:08:16,  8.10s/it, loss=0.5233, lr=1.00e-06]
[Step 50] Training Debug Info:
  Loss: 1.166771
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0130, std: 0.9258
  Noise mean: -0.0029, std: 1.0000
  Target mean: 0.0101, std: 1.3594
  Model pred mean: 0.0247, std: 0.8633
  Sigmas: [0.0791015625]... (timesteps: [79.0])

[Step 50] Training Debug Info:
  Loss: 1.207230
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0275, std: 0.9062
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0297, std: 1.3516
  Model pred mean: 0.0354, std: 0.8203
  Sigmas: [0.306640625]... (timesteps: [306.0])

[Step 50] Training Debug Info:
  Loss: 0.721318
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0192, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0193, std: 1.3516
  Model pred mean: 0.0074, std: 1.1016
  Sigmas: [0.5234375]... (timesteps: [525.0])

[Step 50] Training Debug Info:
  Loss: 0.450900
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0359, std: 0.8945
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0347, std: 1.3359
  Model pred mean: -0.0184, std: 1.1562
  Sigmas: [0.80078125]... (timesteps: [802.0])
Steps:   1%|          | 51/5000 [06:57<11:05:56,  8.07s/it, loss=0.5233, lr=1.00e-06]Steps:   1%|          | 51/5000 [06:57<11:05:56,  8.07s/it, loss=0.4509, lr=1.02e-06]Steps:   1%|          | 52/5000 [07:05<11:10:33,  8.13s/it, loss=0.4509, lr=1.02e-06]Steps:   1%|          | 52/5000 [07:05<11:10:33,  8.13s/it, loss=1.2308, lr=1.04e-06]Steps:   1%|          | 53/5000 [07:13<11:06:59,  8.09s/it, loss=1.2308, lr=1.04e-06]Steps:   1%|          | 53/5000 [07:13<11:06:59,  8.09s/it, loss=0.4273, lr=1.06e-06]Steps:   1%|          | 54/5000 [07:21<11:01:09,  8.02s/it, loss=0.4273, lr=1.06e-06]Steps:   1%|          | 54/5000 [07:21<11:01:09,  8.02s/it, loss=0.6004, lr=1.08e-06]Steps:   1%|          | 55/5000 [07:29<11:05:19,  8.07s/it, loss=0.6004, lr=1.08e-06]Steps:   1%|          | 55/5000 [07:29<11:05:19,  8.07s/it, loss=1.2557, lr=1.10e-06]Steps:   1%|          | 56/5000 [07:37<11:00:35,  8.02s/it, loss=1.2557, lr=1.10e-06]Steps:   1%|          | 56/5000 [07:37<11:00:35,  8.02s/it, loss=1.2447, lr=1.12e-06]Steps:   1%|          | 57/5000 [07:45<11:04:34,  8.07s/it, loss=1.2447, lr=1.12e-06]Steps:   1%|          | 57/5000 [07:45<11:04:34,  8.07s/it, loss=0.7680, lr=1.14e-06]Steps:   1%|          | 58/5000 [07:53<11:03:18,  8.05s/it, loss=0.7680, lr=1.14e-06]Steps:   1%|          | 58/5000 [07:53<11:03:18,  8.05s/it, loss=1.1441, lr=1.16e-06]Steps:   1%|          | 59/5000 [08:01<11:00:38,  8.02s/it, loss=1.1441, lr=1.16e-06]Steps:   1%|          | 59/5000 [08:01<11:00:38,  8.02s/it, loss=0.3910, lr=1.18e-06]Steps:   1%|          | 60/5000 [08:09<10:59:49,  8.01s/it, loss=0.3910, lr=1.18e-06]Steps:   1%|          | 60/5000 [08:09<10:59:49,  8.01s/it, loss=0.4192, lr=1.20e-06]
[Step 60] Training Debug Info:
  Loss: 0.571702
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0153, std: 0.9336
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0154, std: 1.3672
  Model pred mean: -0.0166, std: 1.1797
  Sigmas: [0.6015625]... (timesteps: [601.0])

[Step 60] Training Debug Info:
  Loss: 0.419090
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0057, std: 0.8711
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0025, std: 1.3281
  Model pred mean: -0.0005, std: 1.1797
  Sigmas: [0.7890625]... (timesteps: [788.0])

[Step 60] Training Debug Info:
  Loss: 0.636299
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0154, std: 0.8789
  Noise mean: -0.0021, std: 1.0000
  Target mean: 0.0134, std: 1.3359
  Model pred mean: 0.0242, std: 1.1328
  Sigmas: [0.59375]... (timesteps: [592.0])

[Step 60] Training Debug Info:
  Loss: 0.399391
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0417, std: 0.9102
  Noise mean: 0.0056, std: 1.0000
  Target mean: 0.0474, std: 1.3516
  Model pred mean: 0.0339, std: 1.1797
  Sigmas: [0.8515625]... (timesteps: [852.0])
Steps:   1%|          | 61/5000 [08:18<11:03:11,  8.06s/it, loss=0.4192, lr=1.20e-06]Steps:   1%|          | 61/5000 [08:18<11:03:11,  8.06s/it, loss=0.3994, lr=1.22e-06]Steps:   1%|          | 62/5000 [08:26<11:01:09,  8.03s/it, loss=0.3994, lr=1.22e-06]Steps:   1%|          | 62/5000 [08:26<11:01:09,  8.03s/it, loss=1.1978, lr=1.24e-06]Steps:   1%|‚ñè         | 63/5000 [08:34<11:03:54,  8.07s/it, loss=1.1978, lr=1.24e-06]Steps:   1%|‚ñè         | 63/5000 [08:34<11:03:54,  8.07s/it, loss=0.4167, lr=1.26e-06]Steps:   1%|‚ñè         | 64/5000 [08:42<11:01:18,  8.04s/it, loss=0.4167, lr=1.26e-06]Steps:   1%|‚ñè         | 64/5000 [08:42<11:01:18,  8.04s/it, loss=0.4653, lr=1.28e-06]Steps:   1%|‚ñè         | 65/5000 [08:50<11:01:32,  8.04s/it, loss=0.4653, lr=1.28e-06]Steps:   1%|‚ñè         | 65/5000 [08:50<11:01:32,  8.04s/it, loss=0.3947, lr=1.30e-06]Steps:   1%|‚ñè         | 66/5000 [08:58<11:03:37,  8.07s/it, loss=0.3947, lr=1.30e-06]Steps:   1%|‚ñè         | 66/5000 [08:58<11:03:37,  8.07s/it, loss=1.0697, lr=1.32e-06]Steps:   1%|‚ñè         | 67/5000 [09:06<11:00:55,  8.04s/it, loss=1.0697, lr=1.32e-06]Steps:   1%|‚ñè         | 67/5000 [09:06<11:00:55,  8.04s/it, loss=0.6697, lr=1.34e-06]Steps:   1%|‚ñè         | 68/5000 [09:14<11:04:17,  8.08s/it, loss=0.6697, lr=1.34e-06]Steps:   1%|‚ñè         | 68/5000 [09:14<11:04:17,  8.08s/it, loss=1.2270, lr=1.36e-06]Steps:   1%|‚ñè         | 69/5000 [09:22<11:02:06,  8.06s/it, loss=1.2270, lr=1.36e-06]Steps:   1%|‚ñè         | 69/5000 [09:22<11:02:06,  8.06s/it, loss=0.8053, lr=1.38e-06]Steps:   1%|‚ñè         | 70/5000 [09:30<10:59:33,  8.03s/it, loss=0.8053, lr=1.38e-06]Steps:   1%|‚ñè         | 70/5000 [09:30<10:59:33,  8.03s/it, loss=0.3880, lr=1.40e-06]
[Step 70] Training Debug Info:
  Loss: 0.724994
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0121, std: 0.8789
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0117, std: 1.3359
  Model pred mean: 0.0139, std: 1.0078
  Sigmas: [0.54296875]... (timesteps: [544.0])

[Step 70] Training Debug Info:
  Loss: 0.448949
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0181, std: 0.8672
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0171, std: 1.3203
  Model pred mean: 0.0146, std: 1.1484
  Sigmas: [0.74609375]... (timesteps: [747.0])

[Step 70] Training Debug Info:
  Loss: 0.504619
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0131, std: 0.9844
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0124, std: 1.4062
  Model pred mean: -0.0197, std: 1.2266
  Sigmas: [0.703125]... (timesteps: [705.0])

[Step 70] Training Debug Info:
  Loss: 0.530847
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0016, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0024, std: 1.3516
  Model pred mean: -0.0089, std: 1.1641
  Sigmas: [0.66015625]... (timesteps: [659.0])
Steps:   1%|‚ñè         | 71/5000 [09:38<10:57:08,  8.00s/it, loss=0.3880, lr=1.40e-06]Steps:   1%|‚ñè         | 71/5000 [09:38<10:57:08,  8.00s/it, loss=0.5308, lr=1.42e-06]Steps:   1%|‚ñè         | 72/5000 [09:46<11:00:55,  8.05s/it, loss=0.5308, lr=1.42e-06]Steps:   1%|‚ñè         | 72/5000 [09:46<11:00:55,  8.05s/it, loss=0.6785, lr=1.44e-06]Steps:   1%|‚ñè         | 73/5000 [09:54<11:05:41,  8.11s/it, loss=0.6785, lr=1.44e-06]Steps:   1%|‚ñè         | 73/5000 [09:54<11:05:41,  8.11s/it, loss=0.5752, lr=1.46e-06]Steps:   1%|‚ñè         | 74/5000 [10:02<11:02:30,  8.07s/it, loss=0.5752, lr=1.46e-06]Steps:   1%|‚ñè         | 74/5000 [10:02<11:02:30,  8.07s/it, loss=0.6558, lr=1.48e-06]Steps:   2%|‚ñè         | 75/5000 [10:06<9:25:22,  6.89s/it, loss=0.6558, lr=1.48e-06] Steps:   2%|‚ñè         | 75/5000 [10:06<9:25:22,  6.89s/it, loss=0.4892, lr=1.50e-06]01/30/2026 04:32:55 - INFO - __main__ - 
==================================================
01/30/2026 04:32:55 - INFO - __main__ - Epoch 0 completed: avg_loss = 0.7929
01/30/2026 04:32:55 - INFO - __main__ - ==================================================

Steps:   2%|‚ñè         | 76/5000 [10:15<9:58:59,  7.30s/it, loss=0.4892, lr=1.50e-06]Steps:   2%|‚ñè         | 76/5000 [10:15<9:58:59,  7.30s/it, loss=1.1186, lr=1.52e-06]Steps:   2%|‚ñè         | 77/5000 [10:23<10:23:13,  7.60s/it, loss=1.1186, lr=1.52e-06]Steps:   2%|‚ñè         | 77/5000 [10:23<10:23:13,  7.60s/it, loss=0.8168, lr=1.54e-06]Steps:   2%|‚ñè         | 78/5000 [10:31<10:33:46,  7.73s/it, loss=0.8168, lr=1.54e-06]Steps:   2%|‚ñè         | 78/5000 [10:31<10:33:46,  7.73s/it, loss=1.1022, lr=1.56e-06]Steps:   2%|‚ñè         | 79/5000 [10:39<10:46:42,  7.88s/it, loss=1.1022, lr=1.56e-06]Steps:   2%|‚ñè         | 79/5000 [10:39<10:46:42,  7.88s/it, loss=1.0433, lr=1.58e-06]Steps:   2%|‚ñè         | 80/5000 [10:47<10:49:18,  7.92s/it, loss=1.0433, lr=1.58e-06]Steps:   2%|‚ñè         | 80/5000 [10:47<10:49:18,  7.92s/it, loss=0.5862, lr=1.60e-06]
[Step 80] Training Debug Info:
  Loss: 1.193316
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0258, std: 0.9258
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0280, std: 1.3672
  Model pred mean: 0.0233, std: 0.8164
  Sigmas: [0.1298828125]... (timesteps: [130.0])

[Step 80] Training Debug Info:
  Loss: 1.204436
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0162, std: 0.9102
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0150, std: 1.3516
  Model pred mean: 0.0113, std: 0.8086
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 80] Training Debug Info:
  Loss: 0.362050
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0063, std: 0.8867
  Noise mean: 0.0029, std: 1.0000
  Target mean: 0.0092, std: 1.3359
  Model pred mean: 0.0045, std: 1.1953
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 80] Training Debug Info:
  Loss: 0.439451
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0096, std: 0.8984
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0068, std: 1.3438
  Model pred mean: 0.0053, std: 1.1562
  Sigmas: [0.90234375]... (timesteps: [901.0])
Steps:   2%|‚ñè         | 81/5000 [10:55<10:51:40,  7.95s/it, loss=0.5862, lr=1.60e-06]Steps:   2%|‚ñè         | 81/5000 [10:55<10:51:40,  7.95s/it, loss=0.4395, lr=1.62e-06]Steps:   2%|‚ñè         | 82/5000 [11:03<10:52:32,  7.96s/it, loss=0.4395, lr=1.62e-06]Steps:   2%|‚ñè         | 82/5000 [11:03<10:52:32,  7.96s/it, loss=0.5829, lr=1.64e-06]Steps:   2%|‚ñè         | 83/5000 [11:11<10:58:57,  8.04s/it, loss=0.5829, lr=1.64e-06]Steps:   2%|‚ñè         | 83/5000 [11:11<10:58:57,  8.04s/it, loss=0.4403, lr=1.66e-06]Steps:   2%|‚ñè         | 84/5000 [11:20<11:03:27,  8.10s/it, loss=0.4403, lr=1.66e-06]Steps:   2%|‚ñè         | 84/5000 [11:20<11:03:27,  8.10s/it, loss=1.0446, lr=1.68e-06]Steps:   2%|‚ñè         | 85/5000 [11:28<11:00:15,  8.06s/it, loss=1.0446, lr=1.68e-06]Steps:   2%|‚ñè         | 85/5000 [11:28<11:00:15,  8.06s/it, loss=0.5728, lr=1.70e-06]Steps:   2%|‚ñè         | 86/5000 [11:36<10:57:16,  8.03s/it, loss=0.5728, lr=1.70e-06]Steps:   2%|‚ñè         | 86/5000 [11:36<10:57:16,  8.03s/it, loss=0.4956, lr=1.72e-06]Steps:   2%|‚ñè         | 87/5000 [11:44<10:55:56,  8.01s/it, loss=0.4956, lr=1.72e-06]Steps:   2%|‚ñè         | 87/5000 [11:44<10:55:56,  8.01s/it, loss=1.0082, lr=1.74e-06]Steps:   2%|‚ñè         | 88/5000 [11:52<11:01:47,  8.08s/it, loss=1.0082, lr=1.74e-06]Steps:   2%|‚ñè         | 88/5000 [11:52<11:01:47,  8.08s/it, loss=1.1737, lr=1.76e-06]Steps:   2%|‚ñè         | 89/5000 [12:00<11:02:49,  8.10s/it, loss=1.1737, lr=1.76e-06]Steps:   2%|‚ñè         | 89/5000 [12:00<11:02:49,  8.10s/it, loss=0.6519, lr=1.78e-06]Steps:   2%|‚ñè         | 90/5000 [12:08<11:00:06,  8.07s/it, loss=0.6519, lr=1.78e-06]Steps:   2%|‚ñè         | 90/5000 [12:08<11:00:06,  8.07s/it, loss=0.4110, lr=1.80e-06]
[Step 90] Training Debug Info:
  Loss: 0.616734
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0086, std: 0.9727
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0107, std: 1.3984
  Model pred mean: -0.0106, std: 1.1406
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 90] Training Debug Info:
  Loss: 0.684201
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0684, std: 0.9336
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0703, std: 1.3672
  Model pred mean: 0.0640, std: 1.0859
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 90] Training Debug Info:
  Loss: 1.030837
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0099, std: 0.9453
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0123, std: 1.3750
  Model pred mean: 0.0025, std: 0.9258
  Sigmas: [0.279296875]... (timesteps: [279.0])

[Step 90] Training Debug Info:
  Loss: 0.820822
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.9297
  Noise mean: -0.0034, std: 1.0000
  Target mean: -0.0031, std: 1.3672
  Model pred mean: 0.0019, std: 1.0156
  Sigmas: [0.390625]... (timesteps: [390.0])
Steps:   2%|‚ñè         | 91/5000 [12:16<10:58:13,  8.05s/it, loss=0.4110, lr=1.80e-06]Steps:   2%|‚ñè         | 91/5000 [12:16<10:58:13,  8.05s/it, loss=0.8208, lr=1.82e-06]Steps:   2%|‚ñè         | 92/5000 [12:24<10:58:02,  8.04s/it, loss=0.8208, lr=1.82e-06]Steps:   2%|‚ñè         | 92/5000 [12:24<10:58:02,  8.04s/it, loss=0.8320, lr=1.84e-06]Steps:   2%|‚ñè         | 93/5000 [12:32<11:01:52,  8.09s/it, loss=0.8320, lr=1.84e-06]Steps:   2%|‚ñè         | 93/5000 [12:32<11:01:52,  8.09s/it, loss=0.6549, lr=1.86e-06]Steps:   2%|‚ñè         | 94/5000 [12:40<10:59:06,  8.06s/it, loss=0.6549, lr=1.86e-06]Steps:   2%|‚ñè         | 94/5000 [12:40<10:59:06,  8.06s/it, loss=1.1022, lr=1.88e-06]Steps:   2%|‚ñè         | 95/5000 [12:48<11:03:16,  8.11s/it, loss=1.1022, lr=1.88e-06]Steps:   2%|‚ñè         | 95/5000 [12:48<11:03:16,  8.11s/it, loss=0.4314, lr=1.90e-06]Steps:   2%|‚ñè         | 96/5000 [12:56<11:01:22,  8.09s/it, loss=0.4314, lr=1.90e-06]Steps:   2%|‚ñè         | 96/5000 [12:56<11:01:22,  8.09s/it, loss=1.0927, lr=1.92e-06]Steps:   2%|‚ñè         | 97/5000 [13:04<10:58:46,  8.06s/it, loss=1.0927, lr=1.92e-06]Steps:   2%|‚ñè         | 97/5000 [13:04<10:58:46,  8.06s/it, loss=0.6090, lr=1.94e-06]Steps:   2%|‚ñè         | 98/5000 [13:12<10:56:49,  8.04s/it, loss=0.6090, lr=1.94e-06]Steps:   2%|‚ñè         | 98/5000 [13:12<10:56:49,  8.04s/it, loss=1.1447, lr=1.96e-06]Steps:   2%|‚ñè         | 99/5000 [13:21<11:01:23,  8.10s/it, loss=1.1447, lr=1.96e-06]Steps:   2%|‚ñè         | 99/5000 [13:21<11:01:23,  8.10s/it, loss=0.8165, lr=1.98e-06]Steps:   2%|‚ñè         | 100/5000 [13:29<11:02:57,  8.12s/it, loss=0.8165, lr=1.98e-06]Steps:   2%|‚ñè         | 100/5000 [13:29<11:02:57,  8.12s/it, loss=1.1759, lr=2.00e-06]01/30/2026 04:36:18 - INFO - __main__ - 
[Step 100] ‚úÖ Loss in normal range (1.1759)
01/30/2026 04:36:18 - INFO - __main__ -   Loss avg (last 100): 0.7964
01/30/2026 04:36:18 - INFO - __main__ -   Loss range: [0.3880, 1.6678]

[Step 100] Training Debug Info:
  Loss: 0.829471
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0044, std: 0.8867
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0056, std: 1.3359
  Model pred mean: 0.0063, std: 0.9531
  Sigmas: [0.4609375]... (timesteps: [461.0])

[Step 100] Training Debug Info:
  Loss: 0.775655
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0100, std: 0.8750
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0104, std: 1.3281
  Model pred mean: -0.0133, std: 0.9883
  Sigmas: [0.478515625]... (timesteps: [478.0])

[Step 100] Training Debug Info:
  Loss: 0.567246
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0089, std: 0.8828
  Noise mean: 0.0049, std: 1.0000
  Target mean: 0.0139, std: 1.3359
  Model pred mean: 0.0095, std: 1.1250
  Sigmas: [0.625]... (timesteps: [624.0])

[Step 100] Training Debug Info:
  Loss: 0.619671
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0154, std: 0.9062
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0139, std: 1.3516
  Model pred mean: -0.0068, std: 1.0859
  Sigmas: [0.953125]... (timesteps: [953.0])
Steps:   2%|‚ñè         | 101/5000 [13:37<10:59:39,  8.08s/it, loss=1.1759, lr=2.00e-06]Steps:   2%|‚ñè         | 101/5000 [13:37<10:59:39,  8.08s/it, loss=0.6197, lr=2.02e-06]Steps:   2%|‚ñè         | 102/5000 [13:45<10:57:57,  8.06s/it, loss=0.6197, lr=2.02e-06]Steps:   2%|‚ñè         | 102/5000 [13:45<10:57:57,  8.06s/it, loss=1.0547, lr=2.04e-06]Steps:   2%|‚ñè         | 103/5000 [13:53<10:57:19,  8.05s/it, loss=1.0547, lr=2.04e-06]Steps:   2%|‚ñè         | 103/5000 [13:53<10:57:19,  8.05s/it, loss=0.9853, lr=2.06e-06]Steps:   2%|‚ñè         | 104/5000 [14:01<11:03:04,  8.13s/it, loss=0.9853, lr=2.06e-06]Steps:   2%|‚ñè         | 104/5000 [14:01<11:03:04,  8.13s/it, loss=1.1229, lr=2.08e-06]Steps:   2%|‚ñè         | 105/5000 [14:09<11:06:03,  8.16s/it, loss=1.1229, lr=2.08e-06]Steps:   2%|‚ñè         | 105/5000 [14:09<11:06:03,  8.16s/it, loss=0.4573, lr=2.10e-06]Steps:   2%|‚ñè         | 106/5000 [14:17<11:01:01,  8.10s/it, loss=0.4573, lr=2.10e-06]Steps:   2%|‚ñè         | 106/5000 [14:17<11:01:01,  8.10s/it, loss=0.9440, lr=2.12e-06]Steps:   2%|‚ñè         | 107/5000 [14:25<10:58:51,  8.08s/it, loss=0.9440, lr=2.12e-06]Steps:   2%|‚ñè         | 107/5000 [14:25<10:58:51,  8.08s/it, loss=1.0469, lr=2.14e-06]Steps:   2%|‚ñè         | 108/5000 [14:33<10:55:59,  8.05s/it, loss=1.0469, lr=2.14e-06]Steps:   2%|‚ñè         | 108/5000 [14:33<10:55:59,  8.05s/it, loss=1.2096, lr=2.16e-06]Steps:   2%|‚ñè         | 109/5000 [14:41<10:57:19,  8.06s/it, loss=1.2096, lr=2.16e-06]Steps:   2%|‚ñè         | 109/5000 [14:41<10:57:19,  8.06s/it, loss=0.7863, lr=2.18e-06]Steps:   2%|‚ñè         | 110/5000 [14:49<10:54:30,  8.03s/it, loss=0.7863, lr=2.18e-06]Steps:   2%|‚ñè         | 110/5000 [14:49<10:54:30,  8.03s/it, loss=1.1664, lr=2.20e-06]
[Step 110] Training Debug Info:
  Loss: 0.687849
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0344, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0342, std: 1.3672
  Model pred mean: 0.0288, std: 1.0781
  Sigmas: [0.51171875]... (timesteps: [513.0])

[Step 110] Training Debug Info:
  Loss: 1.146873
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0280, std: 0.9219
  Noise mean: -0.0002, std: 0.9961
  Target mean: -0.0282, std: 1.3594
  Model pred mean: -0.0277, std: 0.8359
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 110] Training Debug Info:
  Loss: 1.049433
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0067, std: 0.8945
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0094, std: 1.3359
  Model pred mean: 0.0048, std: 0.8477
  Sigmas: [0.02001953125]... (timesteps: [20.0])

[Step 110] Training Debug Info:
  Loss: 0.446905
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0095, std: 0.8867
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0090, std: 1.3359
  Model pred mean: -0.0082, std: 1.1562
  Sigmas: [0.7421875]... (timesteps: [744.0])
Steps:   2%|‚ñè         | 111/5000 [14:58<11:00:35,  8.11s/it, loss=1.1664, lr=2.20e-06]Steps:   2%|‚ñè         | 111/5000 [14:58<11:00:35,  8.11s/it, loss=0.4469, lr=2.22e-06]Steps:   2%|‚ñè         | 112/5000 [15:06<10:56:07,  8.05s/it, loss=0.4469, lr=2.22e-06]Steps:   2%|‚ñè         | 112/5000 [15:06<10:56:07,  8.05s/it, loss=0.3650, lr=2.24e-06]Steps:   2%|‚ñè         | 113/5000 [15:14<10:54:17,  8.03s/it, loss=0.3650, lr=2.24e-06]Steps:   2%|‚ñè         | 113/5000 [15:14<10:54:17,  8.03s/it, loss=0.8858, lr=2.26e-06]Steps:   2%|‚ñè         | 114/5000 [15:22<10:53:59,  8.03s/it, loss=0.8858, lr=2.26e-06]Steps:   2%|‚ñè         | 114/5000 [15:22<10:53:59,  8.03s/it, loss=1.0761, lr=2.28e-06]Steps:   2%|‚ñè         | 115/5000 [15:30<10:59:30,  8.10s/it, loss=1.0761, lr=2.28e-06]Steps:   2%|‚ñè         | 115/5000 [15:30<10:59:30,  8.10s/it, loss=0.8737, lr=2.30e-06]Steps:   2%|‚ñè         | 116/5000 [15:38<11:01:42,  8.13s/it, loss=0.8737, lr=2.30e-06]Steps:   2%|‚ñè         | 116/5000 [15:38<11:01:42,  8.13s/it, loss=0.4161, lr=2.32e-06]Steps:   2%|‚ñè         | 117/5000 [15:46<10:58:07,  8.09s/it, loss=0.4161, lr=2.32e-06]Steps:   2%|‚ñè         | 117/5000 [15:46<10:58:07,  8.09s/it, loss=1.1269, lr=2.34e-06]Steps:   2%|‚ñè         | 118/5000 [15:54<10:56:46,  8.07s/it, loss=1.1269, lr=2.34e-06]Steps:   2%|‚ñè         | 118/5000 [15:54<10:56:46,  8.07s/it, loss=0.6764, lr=2.36e-06]Steps:   2%|‚ñè         | 119/5000 [16:02<10:55:36,  8.06s/it, loss=0.6764, lr=2.36e-06]Steps:   2%|‚ñè         | 119/5000 [16:02<10:55:36,  8.06s/it, loss=0.3899, lr=2.38e-06]Steps:   2%|‚ñè         | 120/5000 [16:10<11:01:01,  8.13s/it, loss=0.3899, lr=2.38e-06]Steps:   2%|‚ñè         | 120/5000 [16:10<11:01:01,  8.13s/it, loss=0.4464, lr=2.40e-06]
[Step 120] Training Debug Info:
  Loss: 0.397535
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0001, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0009, std: 1.3516
  Model pred mean: 0.0020, std: 1.2031
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.811905
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0078, std: 0.8945
  Noise mean: -0.0021, std: 0.9961
  Target mean: -0.0098, std: 1.3359
  Model pred mean: -0.0159, std: 1.0234
  Sigmas: [0.43359375]... (timesteps: [433.0])

[Step 120] Training Debug Info:
  Loss: 0.405127
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0134, std: 0.8789
  Noise mean: -0.0043, std: 1.0000
  Target mean: 0.0092, std: 1.3281
  Model pred mean: 0.0184, std: 1.1719
  Sigmas: [0.796875]... (timesteps: [795.0])

[Step 120] Training Debug Info:
  Loss: 0.352732
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0291, std: 0.9297
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0300, std: 1.3672
  Model pred mean: -0.0209, std: 1.2188
  Sigmas: [0.82421875]... (timesteps: [826.0])
Steps:   2%|‚ñè         | 121/5000 [16:19<11:02:37,  8.15s/it, loss=0.4464, lr=2.40e-06]Steps:   2%|‚ñè         | 121/5000 [16:19<11:02:37,  8.15s/it, loss=0.3527, lr=2.42e-06]Steps:   2%|‚ñè         | 122/5000 [16:27<10:59:00,  8.11s/it, loss=0.3527, lr=2.42e-06]Steps:   2%|‚ñè         | 122/5000 [16:27<10:59:00,  8.11s/it, loss=1.0368, lr=2.44e-06]Steps:   2%|‚ñè         | 123/5000 [16:35<10:56:38,  8.08s/it, loss=1.0368, lr=2.44e-06]Steps:   2%|‚ñè         | 123/5000 [16:35<10:56:38,  8.08s/it, loss=0.6943, lr=2.46e-06]Steps:   2%|‚ñè         | 124/5000 [16:43<10:53:33,  8.04s/it, loss=0.6943, lr=2.46e-06]Steps:   2%|‚ñè         | 124/5000 [16:43<10:53:33,  8.04s/it, loss=1.0640, lr=2.48e-06]Steps:   2%|‚ñé         | 125/5000 [16:51<10:57:32,  8.09s/it, loss=1.0640, lr=2.48e-06]Steps:   2%|‚ñé         | 125/5000 [16:51<10:57:32,  8.09s/it, loss=0.4339, lr=2.50e-06]Steps:   3%|‚ñé         | 126/5000 [16:59<10:55:01,  8.06s/it, loss=0.4339, lr=2.50e-06]Steps:   3%|‚ñé         | 126/5000 [16:59<10:55:01,  8.06s/it, loss=1.1077, lr=2.52e-06]Steps:   3%|‚ñé         | 127/5000 [17:07<11:00:55,  8.14s/it, loss=1.1077, lr=2.52e-06]Steps:   3%|‚ñé         | 127/5000 [17:07<11:00:55,  8.14s/it, loss=0.5774, lr=2.54e-06]Steps:   3%|‚ñé         | 128/5000 [17:15<10:57:11,  8.09s/it, loss=0.5774, lr=2.54e-06]Steps:   3%|‚ñé         | 128/5000 [17:15<10:57:11,  8.09s/it, loss=0.4442, lr=2.56e-06]Steps:   3%|‚ñé         | 129/5000 [17:23<10:51:53,  8.03s/it, loss=0.4442, lr=2.56e-06]Steps:   3%|‚ñé         | 129/5000 [17:23<10:51:53,  8.03s/it, loss=0.6636, lr=2.58e-06]Steps:   3%|‚ñé         | 130/5000 [17:31<10:49:25,  8.00s/it, loss=0.6636, lr=2.58e-06]Steps:   3%|‚ñé         | 130/5000 [17:31<10:49:25,  8.00s/it, loss=1.2125, lr=2.60e-06]
[Step 130] Training Debug Info:
  Loss: 0.575655
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0510, std: 0.9219
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0476, std: 1.3594
  Model pred mean: -0.0510, std: 1.1172
  Sigmas: [0.546875]... (timesteps: [547.0])

[Step 130] Training Debug Info:
  Loss: 1.146750
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0194, std: 0.9141
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0195, std: 1.3516
  Model pred mean: -0.0144, std: 0.8320
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 130] Training Debug Info:
  Loss: 1.145384
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0156, std: 0.9219
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0161, std: 1.3594
  Model pred mean: -0.0093, std: 0.8438
  Sigmas: [0.138671875]... (timesteps: [139.0])

[Step 130] Training Debug Info:
  Loss: 0.347959
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0349, std: 0.9258
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0356, std: 1.3594
  Model pred mean: 0.0325, std: 1.2031
  Sigmas: [0.93359375]... (timesteps: [935.0])
Steps:   3%|‚ñé         | 131/5000 [17:39<10:52:30,  8.04s/it, loss=1.2125, lr=2.60e-06]Steps:   3%|‚ñé         | 131/5000 [17:39<10:52:30,  8.04s/it, loss=0.3480, lr=2.62e-06]Steps:   3%|‚ñé         | 132/5000 [17:47<10:55:12,  8.08s/it, loss=0.3480, lr=2.62e-06]Steps:   3%|‚ñé         | 132/5000 [17:47<10:55:12,  8.08s/it, loss=0.8502, lr=2.64e-06]Steps:   3%|‚ñé         | 133/5000 [17:55<10:54:09,  8.06s/it, loss=0.8502, lr=2.64e-06]Steps:   3%|‚ñé         | 133/5000 [17:55<10:54:09,  8.06s/it, loss=1.0515, lr=2.66e-06]Steps:   3%|‚ñé         | 134/5000 [18:03<10:52:29,  8.05s/it, loss=1.0515, lr=2.66e-06]Steps:   3%|‚ñé         | 134/5000 [18:03<10:52:29,  8.05s/it, loss=0.7605, lr=2.68e-06]Steps:   3%|‚ñé         | 135/5000 [18:11<10:51:54,  8.04s/it, loss=0.7605, lr=2.68e-06]Steps:   3%|‚ñé         | 135/5000 [18:11<10:51:54,  8.04s/it, loss=0.6307, lr=2.70e-06]Steps:   3%|‚ñé         | 136/5000 [18:19<10:47:56,  7.99s/it, loss=0.6307, lr=2.70e-06]Steps:   3%|‚ñé         | 136/5000 [18:19<10:47:56,  7.99s/it, loss=0.8474, lr=2.72e-06]Steps:   3%|‚ñé         | 137/5000 [18:28<10:59:02,  8.13s/it, loss=0.8474, lr=2.72e-06]Steps:   3%|‚ñé         | 137/5000 [18:28<10:59:02,  8.13s/it, loss=0.4783, lr=2.74e-06]Steps:   3%|‚ñé         | 138/5000 [18:36<10:54:18,  8.07s/it, loss=0.4783, lr=2.74e-06]Steps:   3%|‚ñé         | 138/5000 [18:36<10:54:18,  8.07s/it, loss=1.1057, lr=2.76e-06]Steps:   3%|‚ñé         | 139/5000 [18:44<10:51:47,  8.05s/it, loss=1.1057, lr=2.76e-06]Steps:   3%|‚ñé         | 139/5000 [18:44<10:51:47,  8.05s/it, loss=0.7939, lr=2.78e-06]Steps:   3%|‚ñé         | 140/5000 [18:52<10:51:45,  8.05s/it, loss=0.7939, lr=2.78e-06]Steps:   3%|‚ñé         | 140/5000 [18:52<10:51:45,  8.05s/it, loss=1.0611, lr=2.80e-06]
[Step 140] Training Debug Info:
  Loss: 0.751140
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0211, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0228, std: 1.3438
  Model pred mean: -0.0216, std: 1.0312
  Sigmas: [0.474609375]... (timesteps: [474.0])

[Step 140] Training Debug Info:
  Loss: 0.603453
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0347, std: 0.9414
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0356, std: 1.3750
  Model pred mean: -0.0234, std: 1.1172
  Sigmas: [0.9296875]... (timesteps: [931.0])

[Step 140] Training Debug Info:
  Loss: 0.530428
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0190, std: 1.0078
  Noise mean: -0.0035, std: 1.0000
  Target mean: -0.0225, std: 1.4219
  Model pred mean: -0.0019, std: 1.2109
  Sigmas: [0.8515625]... (timesteps: [851.0])

[Step 140] Training Debug Info:
  Loss: 0.389785
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0012, std: 0.9492
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0034, std: 1.3828
  Model pred mean: -0.0015, std: 1.2188
  Sigmas: [0.8125]... (timesteps: [811.0])
Steps:   3%|‚ñé         | 141/5000 [19:00<10:50:12,  8.03s/it, loss=1.0611, lr=2.80e-06]Steps:   3%|‚ñé         | 141/5000 [19:00<10:50:12,  8.03s/it, loss=0.3898, lr=2.82e-06]Steps:   3%|‚ñé         | 142/5000 [19:08<10:52:46,  8.06s/it, loss=0.3898, lr=2.82e-06]Steps:   3%|‚ñé         | 142/5000 [19:08<10:52:46,  8.06s/it, loss=0.9491, lr=2.84e-06]Steps:   3%|‚ñé         | 143/5000 [19:16<10:56:19,  8.11s/it, loss=0.9491, lr=2.84e-06]Steps:   3%|‚ñé         | 143/5000 [19:16<10:56:19,  8.11s/it, loss=1.1539, lr=2.86e-06]Steps:   3%|‚ñé         | 144/5000 [19:24<10:53:34,  8.08s/it, loss=1.1539, lr=2.86e-06]Steps:   3%|‚ñé         | 144/5000 [19:24<10:53:34,  8.08s/it, loss=1.0222, lr=2.88e-06]Steps:   3%|‚ñé         | 145/5000 [19:32<10:51:30,  8.05s/it, loss=1.0222, lr=2.88e-06]Steps:   3%|‚ñé         | 145/5000 [19:32<10:51:30,  8.05s/it, loss=0.5799, lr=2.90e-06]Steps:   3%|‚ñé         | 146/5000 [19:40<10:48:31,  8.02s/it, loss=0.5799, lr=2.90e-06]Steps:   3%|‚ñé         | 146/5000 [19:40<10:48:31,  8.02s/it, loss=0.9967, lr=2.92e-06]Steps:   3%|‚ñé         | 147/5000 [19:48<10:53:37,  8.08s/it, loss=0.9967, lr=2.92e-06]Steps:   3%|‚ñé         | 147/5000 [19:48<10:53:37,  8.08s/it, loss=0.9875, lr=2.94e-06]Steps:   3%|‚ñé         | 148/5000 [19:56<10:57:47,  8.13s/it, loss=0.9875, lr=2.94e-06]Steps:   3%|‚ñé         | 148/5000 [19:56<10:57:47,  8.13s/it, loss=0.7645, lr=2.96e-06]Steps:   3%|‚ñé         | 149/5000 [20:04<10:53:56,  8.09s/it, loss=0.7645, lr=2.96e-06]Steps:   3%|‚ñé         | 149/5000 [20:04<10:53:56,  8.09s/it, loss=0.6154, lr=2.98e-06]Steps:   3%|‚ñé         | 150/5000 [20:08<9:18:01,  6.90s/it, loss=0.6154, lr=2.98e-06] Steps:   3%|‚ñé         | 150/5000 [20:08<9:18:01,  6.90s/it, loss=0.7752, lr=3.00e-06]01/30/2026 04:42:58 - INFO - __main__ - 
==================================================
01/30/2026 04:42:58 - INFO - __main__ - Epoch 1 completed: avg_loss = 0.8002
01/30/2026 04:42:58 - INFO - __main__ - ==================================================


[Step 150] Training Debug Info:
  Loss: 0.612535
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0145, std: 0.8984
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0173, std: 1.3438
  Model pred mean: -0.0243, std: 1.1094
  Sigmas: [0.97265625]... (timesteps: [974.0])

[Step 150] Training Debug Info:
  Loss: 0.562875
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0325, std: 1.0000
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0334, std: 1.4141
  Model pred mean: -0.0325, std: 1.1953
  Sigmas: [0.6953125]... (timesteps: [694.0])

[Step 150] Training Debug Info:
  Loss: 0.628273
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0344, std: 0.8711
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0332, std: 1.3281
  Model pred mean: 0.0334, std: 1.0625
  Sigmas: [0.59765625]... (timesteps: [598.0])

[Step 150] Training Debug Info:
  Loss: 0.608958
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0108, std: 0.9492
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0104, std: 1.3750
  Model pred mean: -0.0052, std: 1.1328
  Sigmas: [0.92578125]... (timesteps: [925.0])
Steps:   3%|‚ñé         | 151/5000 [20:17<9:50:56,  7.31s/it, loss=0.7752, lr=3.00e-06]Steps:   3%|‚ñé         | 151/5000 [20:17<9:50:56,  7.31s/it, loss=0.6090, lr=3.02e-06]Steps:   3%|‚ñé         | 152/5000 [20:25<10:07:34,  7.52s/it, loss=0.6090, lr=3.02e-06]Steps:   3%|‚ñé         | 152/5000 [20:25<10:07:34,  7.52s/it, loss=1.0420, lr=3.04e-06]Steps:   3%|‚ñé         | 153/5000 [20:33<10:27:42,  7.77s/it, loss=1.0420, lr=3.04e-06]Steps:   3%|‚ñé         | 153/5000 [20:33<10:27:42,  7.77s/it, loss=1.1112, lr=3.06e-06]Steps:   3%|‚ñé         | 154/5000 [20:41<10:40:21,  7.93s/it, loss=1.1112, lr=3.06e-06]Steps:   3%|‚ñé         | 154/5000 [20:41<10:40:21,  7.93s/it, loss=0.5365, lr=3.08e-06]Steps:   3%|‚ñé         | 155/5000 [20:49<10:42:01,  7.95s/it, loss=0.5365, lr=3.08e-06]Steps:   3%|‚ñé         | 155/5000 [20:49<10:42:01,  7.95s/it, loss=0.6862, lr=3.10e-06]Steps:   3%|‚ñé         | 156/5000 [20:57<10:42:39,  7.96s/it, loss=0.6862, lr=3.10e-06]Steps:   3%|‚ñé         | 156/5000 [20:57<10:42:39,  7.96s/it, loss=0.4106, lr=3.12e-06]Steps:   3%|‚ñé         | 157/5000 [21:05<10:44:03,  7.98s/it, loss=0.4106, lr=3.12e-06]Steps:   3%|‚ñé         | 157/5000 [21:05<10:44:03,  7.98s/it, loss=1.0450, lr=3.14e-06]Steps:   3%|‚ñé         | 158/5000 [21:14<10:48:44,  8.04s/it, loss=1.0450, lr=3.14e-06]Steps:   3%|‚ñé         | 158/5000 [21:14<10:48:44,  8.04s/it, loss=1.1536, lr=3.16e-06]Steps:   3%|‚ñé         | 159/5000 [21:22<10:52:31,  8.09s/it, loss=1.1536, lr=3.16e-06]Steps:   3%|‚ñé         | 159/5000 [21:22<10:52:31,  8.09s/it, loss=0.3806, lr=3.18e-06]Steps:   3%|‚ñé         | 160/5000 [21:30<10:49:36,  8.05s/it, loss=0.3806, lr=3.18e-06]Steps:   3%|‚ñé         | 160/5000 [21:30<10:49:36,  8.05s/it, loss=0.5963, lr=3.20e-06]
[Step 160] Training Debug Info:
  Loss: 1.124395
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0000, std: 0.8477
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0014, std: 1.3125
  Model pred mean: 0.0120, std: 0.7812
  Sigmas: [0.06396484375]... (timesteps: [64.0])

[Step 160] Training Debug Info:
  Loss: 1.191060
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0275, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0266, std: 1.3594
  Model pred mean: 0.0332, std: 0.8086
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 160] Training Debug Info:
  Loss: 0.595440
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.8867
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0014, std: 1.3359
  Model pred mean: -0.0022, std: 1.1172
  Sigmas: [0.98828125]... (timesteps: [990.0])

[Step 160] Training Debug Info:
  Loss: 0.497061
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0356, std: 0.9922
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0352, std: 1.4062
  Model pred mean: -0.0262, std: 1.2109
  Sigmas: [0.73828125]... (timesteps: [739.0])
Steps:   3%|‚ñé         | 161/5000 [21:38<10:46:54,  8.02s/it, loss=0.5963, lr=3.20e-06]Steps:   3%|‚ñé         | 161/5000 [21:38<10:46:54,  8.02s/it, loss=0.4971, lr=3.22e-06]Steps:   3%|‚ñé         | 162/5000 [21:46<10:45:21,  8.00s/it, loss=0.4971, lr=3.22e-06]Steps:   3%|‚ñé         | 162/5000 [21:46<10:45:21,  8.00s/it, loss=0.4596, lr=3.24e-06]Steps:   3%|‚ñé         | 163/5000 [21:54<10:44:22,  7.99s/it, loss=0.4596, lr=3.24e-06]Steps:   3%|‚ñé         | 163/5000 [21:54<10:44:22,  7.99s/it, loss=0.7828, lr=3.26e-06]Steps:   3%|‚ñé         | 164/5000 [22:02<10:52:49,  8.10s/it, loss=0.7828, lr=3.26e-06]Steps:   3%|‚ñé         | 164/5000 [22:02<10:52:49,  8.10s/it, loss=0.3902, lr=3.28e-06]Steps:   3%|‚ñé         | 165/5000 [22:10<10:50:02,  8.07s/it, loss=0.3902, lr=3.28e-06]Steps:   3%|‚ñé         | 165/5000 [22:10<10:50:02,  8.07s/it, loss=0.9955, lr=3.30e-06]Steps:   3%|‚ñé         | 166/5000 [22:18<10:47:21,  8.04s/it, loss=0.9955, lr=3.30e-06]Steps:   3%|‚ñé         | 166/5000 [22:18<10:47:21,  8.04s/it, loss=0.6576, lr=3.32e-06]Steps:   3%|‚ñé         | 167/5000 [22:26<10:47:21,  8.04s/it, loss=0.6576, lr=3.32e-06]Steps:   3%|‚ñé         | 167/5000 [22:26<10:47:21,  8.04s/it, loss=0.4211, lr=3.34e-06]Steps:   3%|‚ñé         | 168/5000 [22:34<10:47:15,  8.04s/it, loss=0.4211, lr=3.34e-06]Steps:   3%|‚ñé         | 168/5000 [22:34<10:47:15,  8.04s/it, loss=1.1046, lr=3.36e-06]Steps:   3%|‚ñé         | 169/5000 [22:42<10:55:37,  8.14s/it, loss=1.1046, lr=3.36e-06]Steps:   3%|‚ñé         | 169/5000 [22:42<10:55:37,  8.14s/it, loss=0.5253, lr=3.38e-06]Steps:   3%|‚ñé         | 170/5000 [22:50<10:51:32,  8.09s/it, loss=0.5253, lr=3.38e-06]Steps:   3%|‚ñé         | 170/5000 [22:50<10:51:32,  8.09s/it, loss=0.7111, lr=3.40e-06]
[Step 170] Training Debug Info:
  Loss: 0.408324
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0100, std: 0.8828
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0079, std: 1.3359
  Model pred mean: -0.0104, std: 1.1797
  Sigmas: [0.79296875]... (timesteps: [792.0])

[Step 170] Training Debug Info:
  Loss: 0.960955
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0029, std: 0.9609
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0060, std: 1.3828
  Model pred mean: -0.0044, std: 0.9688
  Sigmas: [0.34765625]... (timesteps: [347.0])

[Step 170] Training Debug Info:
  Loss: 0.514022
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0079, std: 0.9062
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0065, std: 1.3516
  Model pred mean: -0.0098, std: 1.1562
  Sigmas: [0.66015625]... (timesteps: [661.0])

[Step 170] Training Debug Info:
  Loss: 1.086429
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0270, std: 0.9180
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0262, std: 1.3594
  Model pred mean: 0.0232, std: 0.8633
  Sigmas: [0.0439453125]... (timesteps: [44.0])
Steps:   3%|‚ñé         | 171/5000 [22:58<10:49:42,  8.07s/it, loss=0.7111, lr=3.40e-06]Steps:   3%|‚ñé         | 171/5000 [22:58<10:49:42,  8.07s/it, loss=1.0864, lr=3.42e-06]Steps:   3%|‚ñé         | 172/5000 [23:06<10:47:03,  8.04s/it, loss=1.0864, lr=3.42e-06]Steps:   3%|‚ñé         | 172/5000 [23:06<10:47:03,  8.04s/it, loss=0.4995, lr=3.44e-06]Steps:   3%|‚ñé         | 173/5000 [23:14<10:46:14,  8.03s/it, loss=0.4995, lr=3.44e-06]Steps:   3%|‚ñé         | 173/5000 [23:14<10:46:14,  8.03s/it, loss=1.0245, lr=3.46e-06]Steps:   3%|‚ñé         | 174/5000 [23:22<10:44:34,  8.01s/it, loss=1.0245, lr=3.46e-06]Steps:   3%|‚ñé         | 174/5000 [23:22<10:44:34,  8.01s/it, loss=1.1211, lr=3.48e-06]Steps:   4%|‚ñé         | 175/5000 [23:31<10:51:45,  8.10s/it, loss=1.1211, lr=3.48e-06]Steps:   4%|‚ñé         | 175/5000 [23:31<10:51:45,  8.10s/it, loss=0.4634, lr=3.50e-06]Steps:   4%|‚ñé         | 176/5000 [23:39<10:48:09,  8.06s/it, loss=0.4634, lr=3.50e-06]Steps:   4%|‚ñé         | 176/5000 [23:39<10:48:09,  8.06s/it, loss=0.5124, lr=3.52e-06]Steps:   4%|‚ñé         | 177/5000 [23:47<10:46:44,  8.05s/it, loss=0.5124, lr=3.52e-06]Steps:   4%|‚ñé         | 177/5000 [23:47<10:46:44,  8.05s/it, loss=1.0104, lr=3.54e-06]Steps:   4%|‚ñé         | 178/5000 [23:55<10:44:35,  8.02s/it, loss=1.0104, lr=3.54e-06]Steps:   4%|‚ñé         | 178/5000 [23:55<10:44:35,  8.02s/it, loss=0.7237, lr=3.56e-06]Steps:   4%|‚ñé         | 179/5000 [24:03<10:47:25,  8.06s/it, loss=0.7237, lr=3.56e-06]Steps:   4%|‚ñé         | 179/5000 [24:03<10:47:25,  8.06s/it, loss=0.5680, lr=3.58e-06]Steps:   4%|‚ñé         | 180/5000 [24:11<10:52:18,  8.12s/it, loss=0.5680, lr=3.58e-06]Steps:   4%|‚ñé         | 180/5000 [24:11<10:52:18,  8.12s/it, loss=1.1349, lr=3.60e-06]
[Step 180] Training Debug Info:
  Loss: 0.934565
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0009, std: 0.9336
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0040, std: 1.3672
  Model pred mean: 0.0039, std: 0.9336
  Sigmas: [0.318359375]... (timesteps: [319.0])

[Step 180] Training Debug Info:
  Loss: 1.160885
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0103, std: 0.8867
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0094, std: 1.3438
  Model pred mean: -0.0151, std: 0.7891
  Sigmas: [0.10400390625]... (timesteps: [104.0])

[Step 180] Training Debug Info:
  Loss: 0.476332
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0154, std: 0.9023
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0147, std: 1.3438
  Model pred mean: -0.0182, std: 1.1562
  Sigmas: [0.6875]... (timesteps: [688.0])

[Step 180] Training Debug Info:
  Loss: 1.098752
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0012, std: 0.8633
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0007, std: 1.3203
  Model pred mean: 0.0053, std: 0.7852
  Sigmas: [0.33203125]... (timesteps: [332.0])
Steps:   4%|‚ñé         | 181/5000 [24:19<10:48:18,  8.07s/it, loss=1.1349, lr=3.60e-06]Steps:   4%|‚ñé         | 181/5000 [24:19<10:48:18,  8.07s/it, loss=1.0988, lr=3.62e-06]Steps:   4%|‚ñé         | 182/5000 [24:27<10:46:42,  8.05s/it, loss=1.0988, lr=3.62e-06]Steps:   4%|‚ñé         | 182/5000 [24:27<10:46:42,  8.05s/it, loss=0.4394, lr=3.64e-06]Steps:   4%|‚ñé         | 183/5000 [24:35<10:44:39,  8.03s/it, loss=0.4394, lr=3.64e-06]Steps:   4%|‚ñé         | 183/5000 [24:35<10:44:39,  8.03s/it, loss=1.2020, lr=3.66e-06]Steps:   4%|‚ñé         | 184/5000 [24:43<10:42:22,  8.00s/it, loss=1.2020, lr=3.66e-06]Steps:   4%|‚ñé         | 184/5000 [24:43<10:42:22,  8.00s/it, loss=0.4182, lr=3.68e-06]Steps:   4%|‚ñé         | 185/5000 [24:51<10:44:42,  8.03s/it, loss=0.4182, lr=3.68e-06]Steps:   4%|‚ñé         | 185/5000 [24:51<10:44:42,  8.03s/it, loss=0.8458, lr=3.70e-06]Steps:   4%|‚ñé         | 186/5000 [24:59<10:44:59,  8.04s/it, loss=0.8458, lr=3.70e-06]Steps:   4%|‚ñé         | 186/5000 [24:59<10:44:59,  8.04s/it, loss=0.4562, lr=3.72e-06]Steps:   4%|‚ñé         | 187/5000 [25:07<10:41:51,  8.00s/it, loss=0.4562, lr=3.72e-06]Steps:   4%|‚ñé         | 187/5000 [25:07<10:41:51,  8.00s/it, loss=1.1286, lr=3.74e-06]Steps:   4%|‚ñç         | 188/5000 [25:15<10:41:29,  8.00s/it, loss=1.1286, lr=3.74e-06]Steps:   4%|‚ñç         | 188/5000 [25:15<10:41:29,  8.00s/it, loss=0.7125, lr=3.76e-06]Steps:   4%|‚ñç         | 189/5000 [25:23<10:42:14,  8.01s/it, loss=0.7125, lr=3.76e-06]Steps:   4%|‚ñç         | 189/5000 [25:23<10:42:14,  8.01s/it, loss=1.0857, lr=3.78e-06]Steps:   4%|‚ñç         | 190/5000 [25:31<10:42:42,  8.02s/it, loss=1.0857, lr=3.78e-06]Steps:   4%|‚ñç         | 190/5000 [25:31<10:42:42,  8.02s/it, loss=0.5648, lr=3.80e-06]
[Step 190] Training Debug Info:
  Loss: 0.538126
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0242, std: 0.8945
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0243, std: 1.3438
  Model pred mean: -0.0266, std: 1.1328
  Sigmas: [0.63671875]... (timesteps: [636.0])

[Step 190] Training Debug Info:
  Loss: 0.373000
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0043, std: 0.8789
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0045, std: 1.3281
  Model pred mean: -0.0003, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [826.0])

[Step 190] Training Debug Info:
  Loss: 0.654816
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0588, std: 0.9180
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0601, std: 1.3594
  Model pred mean: -0.0366, std: 1.0938
  Sigmas: [0.9921875]... (timesteps: [991.0])

[Step 190] Training Debug Info:
  Loss: 1.173421
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0137, std: 0.9062
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0161, std: 1.3516
  Model pred mean: 0.0097, std: 0.8047
  Sigmas: [0.21875]... (timesteps: [219.0])
Steps:   4%|‚ñç         | 191/5000 [25:39<10:48:09,  8.09s/it, loss=0.5648, lr=3.80e-06]Steps:   4%|‚ñç         | 191/5000 [25:39<10:48:09,  8.09s/it, loss=1.1734, lr=3.82e-06]Steps:   4%|‚ñç         | 192/5000 [25:47<10:45:28,  8.06s/it, loss=1.1734, lr=3.82e-06]Steps:   4%|‚ñç         | 192/5000 [25:47<10:45:28,  8.06s/it, loss=1.0228, lr=3.84e-06]Steps:   4%|‚ñç         | 193/5000 [25:55<10:43:40,  8.03s/it, loss=1.0228, lr=3.84e-06]Steps:   4%|‚ñç         | 193/5000 [25:55<10:43:40,  8.03s/it, loss=0.4719, lr=3.86e-06]Steps:   4%|‚ñç         | 194/5000 [26:03<10:44:07,  8.04s/it, loss=0.4719, lr=3.86e-06]Steps:   4%|‚ñç         | 194/5000 [26:03<10:44:07,  8.04s/it, loss=0.8669, lr=3.88e-06]Steps:   4%|‚ñç         | 195/5000 [26:11<10:44:28,  8.05s/it, loss=0.8669, lr=3.88e-06]Steps:   4%|‚ñç         | 195/5000 [26:11<10:44:28,  8.05s/it, loss=0.4434, lr=3.90e-06]Steps:   4%|‚ñç         | 196/5000 [26:20<10:53:22,  8.16s/it, loss=0.4434, lr=3.90e-06]Steps:   4%|‚ñç         | 196/5000 [26:20<10:53:22,  8.16s/it, loss=0.6826, lr=3.92e-06]Steps:   4%|‚ñç         | 197/5000 [26:28<10:49:22,  8.11s/it, loss=0.6826, lr=3.92e-06]Steps:   4%|‚ñç         | 197/5000 [26:28<10:49:22,  8.11s/it, loss=1.0461, lr=3.94e-06]Steps:   4%|‚ñç         | 198/5000 [26:36<10:46:56,  8.08s/it, loss=1.0461, lr=3.94e-06]Steps:   4%|‚ñç         | 198/5000 [26:36<10:46:56,  8.08s/it, loss=0.4484, lr=3.96e-06]Steps:   4%|‚ñç         | 199/5000 [26:44<10:44:20,  8.05s/it, loss=0.4484, lr=3.96e-06]Steps:   4%|‚ñç         | 199/5000 [26:44<10:44:20,  8.05s/it, loss=0.4992, lr=3.98e-06]Steps:   4%|‚ñç         | 200/5000 [26:52<10:43:18,  8.04s/it, loss=0.4992, lr=3.98e-06]Steps:   4%|‚ñç         | 200/5000 [26:52<10:43:18,  8.04s/it, loss=1.1091, lr=4.00e-06]01/30/2026 04:49:41 - INFO - __main__ - 
[Step 200] ‚úÖ Loss in normal range (1.1091)
01/30/2026 04:49:41 - INFO - __main__ -   Loss avg (last 100): 0.7782
01/30/2026 04:49:41 - INFO - __main__ -   Loss range: [0.3480, 1.2125]

[Step 200] Training Debug Info:
  Loss: 0.523819
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0145, std: 0.9258
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0135, std: 1.3594
  Model pred mean: 0.0101, std: 1.1562
  Sigmas: [0.9453125]... (timesteps: [947.0])

[Step 200] Training Debug Info:
  Loss: 1.146836
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0266, std: 0.9062
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0264, std: 1.3516
  Model pred mean: 0.0260, std: 0.8164
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 200] Training Debug Info:
  Loss: 0.491687
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0189, std: 0.9102
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0177, std: 1.3516
  Model pred mean: -0.0205, std: 1.1562
  Sigmas: [0.65625]... (timesteps: [656.0])

[Step 200] Training Debug Info:
  Loss: 0.489766
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0376, std: 0.8945
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0356, std: 1.3359
  Model pred mean: -0.0292, std: 1.1328
  Sigmas: [0.8828125]... (timesteps: [881.0])
Steps:   4%|‚ñç         | 201/5000 [27:00<10:52:44,  8.16s/it, loss=1.1091, lr=4.00e-06]Steps:   4%|‚ñç         | 201/5000 [27:00<10:52:44,  8.16s/it, loss=0.4898, lr=4.02e-06]Steps:   4%|‚ñç         | 202/5000 [27:08<10:50:28,  8.13s/it, loss=0.4898, lr=4.02e-06]Steps:   4%|‚ñç         | 202/5000 [27:08<10:50:28,  8.13s/it, loss=0.3711, lr=4.04e-06]Steps:   4%|‚ñç         | 203/5000 [27:16<10:46:40,  8.09s/it, loss=0.3711, lr=4.04e-06]Steps:   4%|‚ñç         | 203/5000 [27:16<10:46:40,  8.09s/it, loss=0.8997, lr=4.06e-06]Steps:   4%|‚ñç         | 204/5000 [27:24<10:41:52,  8.03s/it, loss=0.8997, lr=4.06e-06]Steps:   4%|‚ñç         | 204/5000 [27:24<10:41:52,  8.03s/it, loss=1.1785, lr=4.08e-06]Steps:   4%|‚ñç         | 205/5000 [27:32<10:39:56,  8.01s/it, loss=1.1785, lr=4.08e-06]Steps:   4%|‚ñç         | 205/5000 [27:32<10:39:56,  8.01s/it, loss=1.1152, lr=4.10e-06]Steps:   4%|‚ñç         | 206/5000 [27:40<10:37:30,  7.98s/it, loss=1.1152, lr=4.10e-06]Steps:   4%|‚ñç         | 206/5000 [27:40<10:37:30,  7.98s/it, loss=0.7400, lr=4.12e-06]Steps:   4%|‚ñç         | 207/5000 [27:48<10:43:23,  8.05s/it, loss=0.7400, lr=4.12e-06]Steps:   4%|‚ñç         | 207/5000 [27:48<10:43:23,  8.05s/it, loss=0.5338, lr=4.14e-06]Steps:   4%|‚ñç         | 208/5000 [27:56<10:41:26,  8.03s/it, loss=0.5338, lr=4.14e-06]Steps:   4%|‚ñç         | 208/5000 [27:56<10:41:26,  8.03s/it, loss=0.3867, lr=4.16e-06]Steps:   4%|‚ñç         | 209/5000 [28:04<10:41:47,  8.04s/it, loss=0.3867, lr=4.16e-06]Steps:   4%|‚ñç         | 209/5000 [28:04<10:41:47,  8.04s/it, loss=0.6464, lr=4.18e-06]Steps:   4%|‚ñç         | 210/5000 [28:12<10:40:47,  8.03s/it, loss=0.6464, lr=4.18e-06]Steps:   4%|‚ñç         | 210/5000 [28:12<10:40:47,  8.03s/it, loss=0.7030, lr=4.20e-06]
[Step 210] Training Debug Info:
  Loss: 0.403935
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0150, std: 0.9336
  Noise mean: 0.0012, std: 0.9961
  Target mean: -0.0138, std: 1.3672
  Model pred mean: -0.0121, std: 1.2031
  Sigmas: [0.859375]... (timesteps: [858.0])

[Step 210] Training Debug Info:
  Loss: 0.484641
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0042, std: 0.8711
  Noise mean: -0.0022, std: 0.9961
  Target mean: 0.0020, std: 1.3203
  Model pred mean: 0.0015, std: 1.1250
  Sigmas: [0.953125]... (timesteps: [954.0])

[Step 210] Training Debug Info:
  Loss: 0.530655
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0175, std: 0.8789
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0188, std: 1.3359
  Model pred mean: 0.0177, std: 1.1172
  Sigmas: [0.65234375]... (timesteps: [652.0])

[Step 210] Training Debug Info:
  Loss: 0.504024
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0437, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0444, std: 1.3516
  Model pred mean: 0.0398, std: 1.1719
  Sigmas: [0.68359375]... (timesteps: [683.0])
Steps:   4%|‚ñç         | 211/5000 [28:20<10:38:37,  8.00s/it, loss=0.7030, lr=4.20e-06]Steps:   4%|‚ñç         | 211/5000 [28:20<10:38:37,  8.00s/it, loss=0.5040, lr=4.22e-06]Steps:   4%|‚ñç         | 212/5000 [28:29<10:48:51,  8.13s/it, loss=0.5040, lr=4.22e-06]Steps:   4%|‚ñç         | 212/5000 [28:29<10:48:51,  8.13s/it, loss=1.0827, lr=4.24e-06]Steps:   4%|‚ñç         | 213/5000 [28:37<10:43:25,  8.06s/it, loss=1.0827, lr=4.24e-06]Steps:   4%|‚ñç         | 213/5000 [28:37<10:43:25,  8.06s/it, loss=1.0297, lr=4.26e-06]Steps:   4%|‚ñç         | 214/5000 [28:45<10:41:01,  8.04s/it, loss=1.0297, lr=4.26e-06]Steps:   4%|‚ñç         | 214/5000 [28:45<10:41:01,  8.04s/it, loss=0.9686, lr=4.28e-06]Steps:   4%|‚ñç         | 215/5000 [28:53<10:41:42,  8.05s/it, loss=0.9686, lr=4.28e-06]Steps:   4%|‚ñç         | 215/5000 [28:53<10:41:42,  8.05s/it, loss=0.3870, lr=4.30e-06]Steps:   4%|‚ñç         | 216/5000 [29:01<10:40:01,  8.03s/it, loss=0.3870, lr=4.30e-06]Steps:   4%|‚ñç         | 216/5000 [29:01<10:40:01,  8.03s/it, loss=1.1173, lr=4.32e-06]Steps:   4%|‚ñç         | 217/5000 [29:09<10:49:26,  8.15s/it, loss=1.1173, lr=4.32e-06]Steps:   4%|‚ñç         | 217/5000 [29:09<10:49:26,  8.15s/it, loss=0.6715, lr=4.34e-06]Steps:   4%|‚ñç         | 218/5000 [29:17<10:45:44,  8.10s/it, loss=0.6715, lr=4.34e-06]Steps:   4%|‚ñç         | 218/5000 [29:17<10:45:44,  8.10s/it, loss=0.8805, lr=4.36e-06]Steps:   4%|‚ñç         | 219/5000 [29:25<10:42:29,  8.06s/it, loss=0.8805, lr=4.36e-06]Steps:   4%|‚ñç         | 219/5000 [29:25<10:42:29,  8.06s/it, loss=0.6397, lr=4.38e-06]Steps:   4%|‚ñç         | 220/5000 [29:33<10:40:12,  8.04s/it, loss=0.6397, lr=4.38e-06]Steps:   4%|‚ñç         | 220/5000 [29:33<10:40:12,  8.04s/it, loss=0.8606, lr=4.40e-06]
[Step 220] Training Debug Info:
  Loss: 0.928212
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0135, std: 0.8828
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0126, std: 1.3359
  Model pred mean: 0.0159, std: 0.9531
  Sigmas: [0.421875]... (timesteps: [421.0])

[Step 220] Training Debug Info:
  Loss: 1.227597
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0211, std: 0.8711
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0228, std: 1.3281
  Model pred mean: 0.0281, std: 0.7422
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 220] Training Debug Info:
  Loss: 1.134423
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0126, std: 0.9844
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0150, std: 1.3984
  Model pred mean: -0.0085, std: 0.9180
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 220] Training Debug Info:
  Loss: 1.074189
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0029, std: 0.9102
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0036, std: 1.3516
  Model pred mean: 0.0095, std: 0.8828
  Sigmas: [0.037109375]... (timesteps: [37.0])
Steps:   4%|‚ñç         | 221/5000 [29:41<10:38:24,  8.02s/it, loss=0.8606, lr=4.40e-06]Steps:   4%|‚ñç         | 221/5000 [29:41<10:38:24,  8.02s/it, loss=1.0742, lr=4.42e-06]Steps:   4%|‚ñç         | 222/5000 [29:49<10:37:06,  8.00s/it, loss=1.0742, lr=4.42e-06]Steps:   4%|‚ñç         | 222/5000 [29:49<10:37:06,  8.00s/it, loss=0.9349, lr=4.44e-06]Steps:   4%|‚ñç         | 223/5000 [29:57<10:48:07,  8.14s/it, loss=0.9349, lr=4.44e-06]Steps:   4%|‚ñç         | 223/5000 [29:57<10:48:07,  8.14s/it, loss=0.7732, lr=4.46e-06]Steps:   4%|‚ñç         | 224/5000 [30:05<10:45:45,  8.11s/it, loss=0.7732, lr=4.46e-06]Steps:   4%|‚ñç         | 224/5000 [30:05<10:45:45,  8.11s/it, loss=0.4480, lr=4.48e-06]Steps:   4%|‚ñç         | 225/5000 [30:10<9:10:18,  6.91s/it, loss=0.4480, lr=4.48e-06] Steps:   4%|‚ñç         | 225/5000 [30:10<9:10:18,  6.91s/it, loss=0.4420, lr=4.50e-06]01/30/2026 04:52:59 - INFO - __main__ - 
==================================================
01/30/2026 04:52:59 - INFO - __main__ - Epoch 2 completed: avg_loss = 0.7581
01/30/2026 04:52:59 - INFO - __main__ - ==================================================

Steps:   5%|‚ñç         | 226/5000 [30:18<9:42:45,  7.32s/it, loss=0.4420, lr=4.50e-06]Steps:   5%|‚ñç         | 226/5000 [30:18<9:42:45,  7.32s/it, loss=0.9564, lr=4.52e-06]Steps:   5%|‚ñç         | 227/5000 [30:26<9:58:17,  7.52s/it, loss=0.9564, lr=4.52e-06]Steps:   5%|‚ñç         | 227/5000 [30:26<9:58:17,  7.52s/it, loss=0.4164, lr=4.54e-06]Steps:   5%|‚ñç         | 228/5000 [30:34<10:18:26,  7.78s/it, loss=0.4164, lr=4.54e-06]Steps:   5%|‚ñç         | 228/5000 [30:34<10:18:26,  7.78s/it, loss=1.1127, lr=4.56e-06]Steps:   5%|‚ñç         | 229/5000 [30:43<10:31:45,  7.95s/it, loss=1.1127, lr=4.56e-06]Steps:   5%|‚ñç         | 229/5000 [30:43<10:31:45,  7.95s/it, loss=0.9798, lr=4.58e-06]Steps:   5%|‚ñç         | 230/5000 [30:51<10:32:49,  7.96s/it, loss=0.9798, lr=4.58e-06]Steps:   5%|‚ñç         | 230/5000 [30:51<10:32:49,  7.96s/it, loss=0.9598, lr=4.60e-06]
[Step 230] Training Debug Info:
  Loss: 0.384530
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0261, std: 0.9219
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0253, std: 1.3594
  Model pred mean: 0.0258, std: 1.2109
  Sigmas: [0.8046875]... (timesteps: [803.0])

[Step 230] Training Debug Info:
  Loss: 0.815066
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0157, std: 0.9141
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0151, std: 1.3516
  Model pred mean: 0.0154, std: 1.0234
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 230] Training Debug Info:
  Loss: 1.027391
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0071, std: 0.8906
  Noise mean: -0.0032, std: 0.9961
  Target mean: 0.0039, std: 1.3359
  Model pred mean: 0.0075, std: 0.8789
  Sigmas: [0.01300048828125]... (timesteps: [13.0])

[Step 230] Training Debug Info:
  Loss: 0.527105
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0078, std: 0.8984
  Noise mean: 0.0035, std: 1.0000
  Target mean: 0.0113, std: 1.3438
  Model pred mean: 0.0115, std: 1.1484
  Sigmas: [0.65234375]... (timesteps: [654.0])
Steps:   5%|‚ñç         | 231/5000 [30:59<10:34:20,  7.98s/it, loss=0.9598, lr=4.60e-06]Steps:   5%|‚ñç         | 231/5000 [30:59<10:34:20,  7.98s/it, loss=0.5271, lr=4.62e-06]Steps:   5%|‚ñç         | 232/5000 [31:07<10:33:59,  7.98s/it, loss=0.5271, lr=4.62e-06]Steps:   5%|‚ñç         | 232/5000 [31:07<10:33:59,  7.98s/it, loss=0.6952, lr=4.64e-06]Steps:   5%|‚ñç         | 233/5000 [31:15<10:34:30,  7.99s/it, loss=0.6952, lr=4.64e-06]Steps:   5%|‚ñç         | 233/5000 [31:15<10:34:30,  7.99s/it, loss=0.4098, lr=4.66e-06]Steps:   5%|‚ñç         | 234/5000 [31:23<10:45:02,  8.12s/it, loss=0.4098, lr=4.66e-06]Steps:   5%|‚ñç         | 234/5000 [31:23<10:45:02,  8.12s/it, loss=0.9707, lr=4.68e-06]Steps:   5%|‚ñç         | 235/5000 [31:31<10:40:47,  8.07s/it, loss=0.9707, lr=4.68e-06]Steps:   5%|‚ñç         | 235/5000 [31:31<10:40:47,  8.07s/it, loss=0.5183, lr=4.70e-06]Steps:   5%|‚ñç         | 236/5000 [31:39<10:37:18,  8.03s/it, loss=0.5183, lr=4.70e-06]Steps:   5%|‚ñç         | 236/5000 [31:39<10:37:18,  8.03s/it, loss=0.8820, lr=4.72e-06]Steps:   5%|‚ñç         | 237/5000 [31:47<10:35:24,  8.00s/it, loss=0.8820, lr=4.72e-06]Steps:   5%|‚ñç         | 237/5000 [31:47<10:35:24,  8.00s/it, loss=1.1293, lr=4.74e-06]Steps:   5%|‚ñç         | 238/5000 [31:55<10:33:09,  7.98s/it, loss=1.1293, lr=4.74e-06]Steps:   5%|‚ñç         | 238/5000 [31:55<10:33:09,  7.98s/it, loss=1.1466, lr=4.76e-06]Steps:   5%|‚ñç         | 239/5000 [32:03<10:36:57,  8.03s/it, loss=1.1466, lr=4.76e-06]Steps:   5%|‚ñç         | 239/5000 [32:03<10:36:57,  8.03s/it, loss=0.4648, lr=4.78e-06]Steps:   5%|‚ñç         | 240/5000 [32:11<10:41:37,  8.09s/it, loss=0.4648, lr=4.78e-06]Steps:   5%|‚ñç         | 240/5000 [32:11<10:41:37,  8.09s/it, loss=0.7858, lr=4.80e-06]
[Step 240] Training Debug Info:
  Loss: 0.363318
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0090, std: 0.9727
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0084, std: 1.3906
  Model pred mean: -0.0143, std: 1.2422
  Sigmas: [0.890625]... (timesteps: [889.0])

[Step 240] Training Debug Info:
  Loss: 0.491096
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0693, std: 0.9336
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0684, std: 1.3672
  Model pred mean: 0.0708, std: 1.1719
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 240] Training Debug Info:
  Loss: 0.471167
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0073, std: 0.9453
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0093, std: 1.3750
  Model pred mean: 0.0082, std: 1.2031
  Sigmas: [0.63671875]... (timesteps: [638.0])

[Step 240] Training Debug Info:
  Loss: 1.095885
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0001, std: 0.9297
  Noise mean: 0.0012, std: 1.0000
  Target mean: 0.0014, std: 1.3594
  Model pred mean: -0.0032, std: 0.8789
  Sigmas: [0.06787109375]... (timesteps: [68.0])
Steps:   5%|‚ñç         | 241/5000 [32:19<10:38:53,  8.06s/it, loss=0.7858, lr=4.80e-06]Steps:   5%|‚ñç         | 241/5000 [32:19<10:38:53,  8.06s/it, loss=1.0959, lr=4.82e-06]Steps:   5%|‚ñç         | 242/5000 [32:27<10:37:55,  8.04s/it, loss=1.0959, lr=4.82e-06]Steps:   5%|‚ñç         | 242/5000 [32:27<10:37:55,  8.04s/it, loss=0.5761, lr=4.84e-06]Steps:   5%|‚ñç         | 243/5000 [32:35<10:36:36,  8.03s/it, loss=0.5761, lr=4.84e-06]Steps:   5%|‚ñç         | 243/5000 [32:35<10:36:36,  8.03s/it, loss=0.5143, lr=4.86e-06]Steps:   5%|‚ñç         | 244/5000 [32:43<10:41:11,  8.09s/it, loss=0.5143, lr=4.86e-06]Steps:   5%|‚ñç         | 244/5000 [32:43<10:41:11,  8.09s/it, loss=1.1096, lr=4.88e-06]Steps:   5%|‚ñç         | 245/5000 [32:52<10:43:53,  8.12s/it, loss=1.1096, lr=4.88e-06]Steps:   5%|‚ñç         | 245/5000 [32:52<10:43:53,  8.12s/it, loss=0.4577, lr=4.90e-06]Steps:   5%|‚ñç         | 246/5000 [33:00<10:41:30,  8.10s/it, loss=0.4577, lr=4.90e-06]Steps:   5%|‚ñç         | 246/5000 [33:00<10:41:30,  8.10s/it, loss=0.6303, lr=4.92e-06]Steps:   5%|‚ñç         | 247/5000 [33:08<10:38:30,  8.06s/it, loss=0.6303, lr=4.92e-06]Steps:   5%|‚ñç         | 247/5000 [33:08<10:38:30,  8.06s/it, loss=0.6055, lr=4.94e-06]Steps:   5%|‚ñç         | 248/5000 [33:16<10:36:37,  8.04s/it, loss=0.6055, lr=4.94e-06]Steps:   5%|‚ñç         | 248/5000 [33:16<10:36:37,  8.04s/it, loss=0.5131, lr=4.96e-06]Steps:   5%|‚ñç         | 249/5000 [33:24<10:39:04,  8.07s/it, loss=0.5131, lr=4.96e-06]Steps:   5%|‚ñç         | 249/5000 [33:24<10:39:04,  8.07s/it, loss=0.7929, lr=4.98e-06]Steps:   5%|‚ñå         | 250/5000 [33:32<10:40:44,  8.09s/it, loss=0.7929, lr=4.98e-06]Steps:   5%|‚ñå         | 250/5000 [33:32<10:40:44,  8.09s/it, loss=0.4647, lr=5.00e-06]
[Step 250] Training Debug Info:
  Loss: 0.405596
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0017, std: 0.8867
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0034, std: 1.3359
  Model pred mean: 0.0003, std: 1.1797
  Sigmas: [0.76171875]... (timesteps: [760.0])

[Step 250] Training Debug Info:
  Loss: 0.945649
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0085, std: 0.8789
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0077, std: 1.3359
  Model pred mean: -0.0057, std: 0.9062
  Sigmas: [0.380859375]... (timesteps: [381.0])

[Step 250] Training Debug Info:
  Loss: 0.419179
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0093, std: 0.8828
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0089, std: 1.3359
  Model pred mean: 0.0016, std: 1.1641
  Sigmas: [0.76171875]... (timesteps: [761.0])

[Step 250] Training Debug Info:
  Loss: 0.462501
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0166, std: 0.9062
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0145, std: 1.3516
  Model pred mean: -0.0165, std: 1.1719
  Sigmas: [0.73046875]... (timesteps: [732.0])
Steps:   5%|‚ñå         | 251/5000 [33:40<10:37:36,  8.06s/it, loss=0.4647, lr=5.00e-06]Steps:   5%|‚ñå         | 251/5000 [33:40<10:37:36,  8.06s/it, loss=0.4625, lr=5.02e-06]Steps:   5%|‚ñå         | 252/5000 [33:48<10:36:42,  8.05s/it, loss=0.4625, lr=5.02e-06]Steps:   5%|‚ñå         | 252/5000 [33:48<10:36:42,  8.05s/it, loss=0.5667, lr=5.04e-06]Steps:   5%|‚ñå         | 253/5000 [33:56<10:35:02,  8.03s/it, loss=0.5667, lr=5.04e-06]Steps:   5%|‚ñå         | 253/5000 [33:56<10:35:02,  8.03s/it, loss=0.6813, lr=5.06e-06]Steps:   5%|‚ñå         | 254/5000 [34:04<10:37:33,  8.06s/it, loss=0.6813, lr=5.06e-06]Steps:   5%|‚ñå         | 254/5000 [34:04<10:37:33,  8.06s/it, loss=1.0718, lr=5.08e-06]Steps:   5%|‚ñå         | 255/5000 [34:12<10:42:11,  8.12s/it, loss=1.0718, lr=5.08e-06]Steps:   5%|‚ñå         | 255/5000 [34:12<10:42:11,  8.12s/it, loss=0.4459, lr=5.10e-06]Steps:   5%|‚ñå         | 256/5000 [34:20<10:42:41,  8.13s/it, loss=0.4459, lr=5.10e-06]Steps:   5%|‚ñå         | 256/5000 [34:20<10:42:41,  8.13s/it, loss=0.6536, lr=5.12e-06]Steps:   5%|‚ñå         | 257/5000 [34:28<10:40:04,  8.10s/it, loss=0.6536, lr=5.12e-06]Steps:   5%|‚ñå         | 257/5000 [34:28<10:40:04,  8.10s/it, loss=0.4025, lr=5.14e-06]Steps:   5%|‚ñå         | 258/5000 [34:36<10:37:09,  8.06s/it, loss=0.4025, lr=5.14e-06]Steps:   5%|‚ñå         | 258/5000 [34:36<10:37:09,  8.06s/it, loss=0.5340, lr=5.16e-06]Steps:   5%|‚ñå         | 259/5000 [34:44<10:33:45,  8.02s/it, loss=0.5340, lr=5.16e-06]Steps:   5%|‚ñå         | 259/5000 [34:44<10:33:45,  8.02s/it, loss=0.4480, lr=5.18e-06]Steps:   5%|‚ñå         | 260/5000 [34:52<10:37:13,  8.07s/it, loss=0.4480, lr=5.18e-06]Steps:   5%|‚ñå         | 260/5000 [34:52<10:37:13,  8.07s/it, loss=1.1484, lr=5.20e-06]
[Step 260] Training Debug Info:
  Loss: 0.703927
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0332, std: 0.9219
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0349, std: 1.3594
  Model pred mean: 0.0315, std: 1.0625
  Sigmas: [0.4921875]... (timesteps: [492.0])

[Step 260] Training Debug Info:
  Loss: 0.875643
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0258, std: 0.9219
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0266, std: 1.3594
  Model pred mean: -0.0256, std: 0.9844
  Sigmas: [0.39453125]... (timesteps: [395.0])

[Step 260] Training Debug Info:
  Loss: 0.466859
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0070, std: 0.8945
  Noise mean: -0.0021, std: 1.0000
  Target mean: 0.0048, std: 1.3438
  Model pred mean: 0.0009, std: 1.1562
  Sigmas: [0.703125]... (timesteps: [702.0])

[Step 260] Training Debug Info:
  Loss: 0.450846
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0114, std: 0.8867
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0095, std: 1.3359
  Model pred mean: -0.0104, std: 1.1562
  Sigmas: [0.734375]... (timesteps: [734.0])
Steps:   5%|‚ñå         | 261/5000 [35:01<10:42:32,  8.14s/it, loss=1.1484, lr=5.20e-06]Steps:   5%|‚ñå         | 261/5000 [35:01<10:42:32,  8.14s/it, loss=0.4508, lr=5.22e-06]Steps:   5%|‚ñå         | 262/5000 [35:09<10:37:30,  8.07s/it, loss=0.4508, lr=5.22e-06]Steps:   5%|‚ñå         | 262/5000 [35:09<10:37:30,  8.07s/it, loss=0.3755, lr=5.24e-06]Steps:   5%|‚ñå         | 263/5000 [35:17<10:35:42,  8.05s/it, loss=0.3755, lr=5.24e-06]Steps:   5%|‚ñå         | 263/5000 [35:17<10:35:42,  8.05s/it, loss=0.4638, lr=5.26e-06]Steps:   5%|‚ñå         | 264/5000 [35:25<10:34:34,  8.04s/it, loss=0.4638, lr=5.26e-06]Steps:   5%|‚ñå         | 264/5000 [35:25<10:34:34,  8.04s/it, loss=0.4209, lr=5.28e-06]Steps:   5%|‚ñå         | 265/5000 [35:33<10:39:09,  8.10s/it, loss=0.4209, lr=5.28e-06]Steps:   5%|‚ñå         | 265/5000 [35:33<10:39:09,  8.10s/it, loss=1.0711, lr=5.30e-06]Steps:   5%|‚ñå         | 266/5000 [35:41<10:42:16,  8.14s/it, loss=1.0711, lr=5.30e-06]Steps:   5%|‚ñå         | 266/5000 [35:41<10:42:16,  8.14s/it, loss=1.1580, lr=5.32e-06]Steps:   5%|‚ñå         | 267/5000 [35:49<10:37:57,  8.09s/it, loss=1.1580, lr=5.32e-06]Steps:   5%|‚ñå         | 267/5000 [35:49<10:37:57,  8.09s/it, loss=1.1695, lr=5.34e-06]Steps:   5%|‚ñå         | 268/5000 [35:57<10:34:46,  8.05s/it, loss=1.1695, lr=5.34e-06]Steps:   5%|‚ñå         | 268/5000 [35:57<10:34:46,  8.05s/it, loss=1.1590, lr=5.36e-06]Steps:   5%|‚ñå         | 269/5000 [36:05<10:35:28,  8.06s/it, loss=1.1590, lr=5.36e-06]Steps:   5%|‚ñå         | 269/5000 [36:05<10:35:28,  8.06s/it, loss=0.7728, lr=5.38e-06]Steps:   5%|‚ñå         | 270/5000 [36:13<10:35:41,  8.06s/it, loss=0.7728, lr=5.38e-06]Steps:   5%|‚ñå         | 270/5000 [36:13<10:35:41,  8.06s/it, loss=0.4704, lr=5.40e-06]
[Step 270] Training Debug Info:
  Loss: 0.391319
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0033, std: 0.9180
  Noise mean: 0.0026, std: 1.0000
  Target mean: 0.0059, std: 1.3594
  Model pred mean: 0.0056, std: 1.2031
  Sigmas: [0.8203125]... (timesteps: [820.0])

[Step 270] Training Debug Info:
  Loss: 0.558918
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0066, std: 0.8945
  Noise mean: -0.0022, std: 0.9961
  Target mean: -0.0089, std: 1.3438
  Model pred mean: 0.0138, std: 1.1016
  Sigmas: [0.94921875]... (timesteps: [950.0])

[Step 270] Training Debug Info:
  Loss: 0.848775
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0152, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0167, std: 1.3281
  Model pred mean: 0.0188, std: 0.9492
  Sigmas: [0.46875]... (timesteps: [468.0])

[Step 270] Training Debug Info:
  Loss: 1.066487
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0291, std: 0.9297
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0272, std: 1.3672
  Model pred mean: -0.0284, std: 0.8984
  Sigmas: [0.17578125]... (timesteps: [176.0])
Steps:   5%|‚ñå         | 271/5000 [36:21<10:38:34,  8.10s/it, loss=0.4704, lr=5.40e-06]Steps:   5%|‚ñå         | 271/5000 [36:21<10:38:34,  8.10s/it, loss=1.0665, lr=5.42e-06]Steps:   5%|‚ñå         | 272/5000 [36:30<10:41:10,  8.14s/it, loss=1.0665, lr=5.42e-06]Steps:   5%|‚ñå         | 272/5000 [36:30<10:41:10,  8.14s/it, loss=0.7193, lr=5.44e-06]Steps:   5%|‚ñå         | 273/5000 [36:38<10:38:01,  8.10s/it, loss=0.7193, lr=5.44e-06]Steps:   5%|‚ñå         | 273/5000 [36:38<10:38:01,  8.10s/it, loss=0.9748, lr=5.46e-06]Steps:   5%|‚ñå         | 274/5000 [36:46<10:34:39,  8.06s/it, loss=0.9748, lr=5.46e-06]Steps:   5%|‚ñå         | 274/5000 [36:46<10:34:39,  8.06s/it, loss=1.0963, lr=5.48e-06]Steps:   6%|‚ñå         | 275/5000 [36:54<10:33:41,  8.05s/it, loss=1.0963, lr=5.48e-06]Steps:   6%|‚ñå         | 275/5000 [36:54<10:33:41,  8.05s/it, loss=1.1922, lr=5.50e-06]Steps:   6%|‚ñå         | 276/5000 [37:02<10:35:47,  8.08s/it, loss=1.1922, lr=5.50e-06]Steps:   6%|‚ñå         | 276/5000 [37:02<10:35:47,  8.08s/it, loss=1.1567, lr=5.52e-06]Steps:   6%|‚ñå         | 277/5000 [37:10<10:39:47,  8.13s/it, loss=1.1567, lr=5.52e-06]Steps:   6%|‚ñå         | 277/5000 [37:10<10:39:47,  8.13s/it, loss=1.0668, lr=5.54e-06]Steps:   6%|‚ñå         | 278/5000 [37:18<10:36:41,  8.09s/it, loss=1.0668, lr=5.54e-06]Steps:   6%|‚ñå         | 278/5000 [37:18<10:36:41,  8.09s/it, loss=1.0874, lr=5.56e-06]Steps:   6%|‚ñå         | 279/5000 [37:26<10:31:43,  8.03s/it, loss=1.0874, lr=5.56e-06]Steps:   6%|‚ñå         | 279/5000 [37:26<10:31:43,  8.03s/it, loss=1.1702, lr=5.58e-06]Steps:   6%|‚ñå         | 280/5000 [37:34<10:29:23,  8.00s/it, loss=1.1702, lr=5.58e-06]Steps:   6%|‚ñå         | 280/5000 [37:34<10:29:23,  8.00s/it, loss=0.4910, lr=5.60e-06]
[Step 280] Training Debug Info:
  Loss: 0.655247
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0505, std: 0.9219
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0520, std: 1.3594
  Model pred mean: -0.0503, std: 1.0938
  Sigmas: [0.482421875]... (timesteps: [482.0])

[Step 280] Training Debug Info:
  Loss: 0.393914
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0211, std: 0.9141
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0198, std: 1.3516
  Model pred mean: -0.0206, std: 1.2031
  Sigmas: [0.79296875]... (timesteps: [794.0])

[Step 280] Training Debug Info:
  Loss: 1.116437
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0146, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0141, std: 1.3594
  Model pred mean: -0.0071, std: 0.8516
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 280] Training Debug Info:
  Loss: 0.630767
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0352, std: 0.9258
  Noise mean: -0.0025, std: 1.0000
  Target mean: 0.0327, std: 1.3672
  Model pred mean: 0.0201, std: 1.1094
  Sigmas: [0.98046875]... (timesteps: [981.0])
Steps:   6%|‚ñå         | 281/5000 [37:42<10:32:02,  8.04s/it, loss=0.4910, lr=5.60e-06]Steps:   6%|‚ñå         | 281/5000 [37:42<10:32:02,  8.04s/it, loss=0.6308, lr=5.62e-06]Steps:   6%|‚ñå         | 282/5000 [37:50<10:30:08,  8.01s/it, loss=0.6308, lr=5.62e-06]Steps:   6%|‚ñå         | 282/5000 [37:50<10:30:08,  8.01s/it, loss=0.9966, lr=5.64e-06]Steps:   6%|‚ñå         | 283/5000 [37:58<10:36:10,  8.09s/it, loss=0.9966, lr=5.64e-06]Steps:   6%|‚ñå         | 283/5000 [37:58<10:36:10,  8.09s/it, loss=0.8252, lr=5.66e-06]Steps:   6%|‚ñå         | 284/5000 [38:06<10:32:50,  8.05s/it, loss=0.8252, lr=5.66e-06]Steps:   6%|‚ñå         | 284/5000 [38:06<10:32:50,  8.05s/it, loss=1.0782, lr=5.68e-06]Steps:   6%|‚ñå         | 285/5000 [38:14<10:31:43,  8.04s/it, loss=1.0782, lr=5.68e-06]Steps:   6%|‚ñå         | 285/5000 [38:14<10:31:43,  8.04s/it, loss=0.5822, lr=5.70e-06]Steps:   6%|‚ñå         | 286/5000 [38:22<10:28:21,  8.00s/it, loss=0.5822, lr=5.70e-06]Steps:   6%|‚ñå         | 286/5000 [38:22<10:28:21,  8.00s/it, loss=0.4612, lr=5.72e-06]Steps:   6%|‚ñå         | 287/5000 [38:30<10:33:04,  8.06s/it, loss=0.4612, lr=5.72e-06]Steps:   6%|‚ñå         | 287/5000 [38:30<10:33:04,  8.06s/it, loss=0.8570, lr=5.74e-06]Steps:   6%|‚ñå         | 288/5000 [38:38<10:35:42,  8.09s/it, loss=0.8570, lr=5.74e-06]Steps:   6%|‚ñå         | 288/5000 [38:38<10:35:42,  8.09s/it, loss=0.8702, lr=5.76e-06]Steps:   6%|‚ñå         | 289/5000 [38:46<10:32:40,  8.06s/it, loss=0.8702, lr=5.76e-06]Steps:   6%|‚ñå         | 289/5000 [38:46<10:32:40,  8.06s/it, loss=1.1163, lr=5.78e-06]Steps:   6%|‚ñå         | 290/5000 [38:54<10:31:53,  8.05s/it, loss=1.1163, lr=5.78e-06]Steps:   6%|‚ñå         | 290/5000 [38:54<10:31:53,  8.05s/it, loss=1.1809, lr=5.80e-06]
[Step 290] Training Debug Info:
  Loss: 1.138922
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0232, std: 0.8984
  Noise mean: 0.0033, std: 1.0000
  Target mean: -0.0199, std: 1.3438
  Model pred mean: -0.0231, std: 0.8086
  Sigmas: [0.11181640625]... (timesteps: [112.0])

[Step 290] Training Debug Info:
  Loss: 1.105281
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0337, std: 0.9414
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0342, std: 1.3750
  Model pred mean: -0.0298, std: 0.8789
  Sigmas: [0.07421875]... (timesteps: [74.0])

[Step 290] Training Debug Info:
  Loss: 0.576957
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0187, std: 1.0078
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0188, std: 1.4219
  Model pred mean: -0.0139, std: 1.1953
  Sigmas: [0.890625]... (timesteps: [890.0])

[Step 290] Training Debug Info:
  Loss: 1.096936
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0012, std: 0.9453
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0013, std: 1.3750
  Model pred mean: -0.0016, std: 0.8906
  Sigmas: [0.06298828125]... (timesteps: [63.0])
Steps:   6%|‚ñå         | 291/5000 [39:02<10:30:32,  8.03s/it, loss=1.1809, lr=5.80e-06]Steps:   6%|‚ñå         | 291/5000 [39:02<10:30:32,  8.03s/it, loss=1.0969, lr=5.82e-06]Steps:   6%|‚ñå         | 292/5000 [39:11<10:33:17,  8.07s/it, loss=1.0969, lr=5.82e-06]Steps:   6%|‚ñå         | 292/5000 [39:11<10:33:17,  8.07s/it, loss=0.5808, lr=5.84e-06]Steps:   6%|‚ñå         | 293/5000 [39:19<10:35:35,  8.10s/it, loss=0.5808, lr=5.84e-06]Steps:   6%|‚ñå         | 293/5000 [39:19<10:35:35,  8.10s/it, loss=0.8779, lr=5.86e-06]Steps:   6%|‚ñå         | 294/5000 [39:27<10:32:40,  8.07s/it, loss=0.8779, lr=5.86e-06]Steps:   6%|‚ñå         | 294/5000 [39:27<10:32:40,  8.07s/it, loss=0.9161, lr=5.88e-06]Steps:   6%|‚ñå         | 295/5000 [39:35<10:30:25,  8.04s/it, loss=0.9161, lr=5.88e-06]Steps:   6%|‚ñå         | 295/5000 [39:35<10:30:25,  8.04s/it, loss=0.6929, lr=5.90e-06]Steps:   6%|‚ñå         | 296/5000 [39:43<10:27:50,  8.01s/it, loss=0.6929, lr=5.90e-06]Steps:   6%|‚ñå         | 296/5000 [39:43<10:27:50,  8.01s/it, loss=0.4866, lr=5.92e-06]Steps:   6%|‚ñå         | 297/5000 [39:51<10:32:05,  8.06s/it, loss=0.4866, lr=5.92e-06]Steps:   6%|‚ñå         | 297/5000 [39:51<10:32:05,  8.06s/it, loss=1.1871, lr=5.94e-06]Steps:   6%|‚ñå         | 298/5000 [39:59<10:31:42,  8.06s/it, loss=1.1871, lr=5.94e-06]Steps:   6%|‚ñå         | 298/5000 [39:59<10:31:42,  8.06s/it, loss=0.3886, lr=5.96e-06]Steps:   6%|‚ñå         | 299/5000 [40:07<10:35:50,  8.12s/it, loss=0.3886, lr=5.96e-06]Steps:   6%|‚ñå         | 299/5000 [40:07<10:35:50,  8.12s/it, loss=0.4522, lr=5.98e-06]Steps:   6%|‚ñå         | 300/5000 [40:11<9:02:06,  6.92s/it, loss=0.4522, lr=5.98e-06] Steps:   6%|‚ñå         | 300/5000 [40:11<9:02:06,  6.92s/it, loss=0.5135, lr=6.00e-06]01/30/2026 05:03:00 - INFO - __main__ - 
[Step 300] ‚úÖ Loss in normal range (0.5135)
01/30/2026 05:03:00 - INFO - __main__ -   Loss avg (last 100): 0.7733
01/30/2026 05:03:00 - INFO - __main__ -   Loss range: [0.3711, 1.1922]
01/30/2026 05:03:00 - INFO - __main__ - 
==================================================
01/30/2026 05:03:00 - INFO - __main__ - Epoch 3 completed: avg_loss = 0.7794
01/30/2026 05:03:00 - INFO - __main__ - ==================================================


[Step 300] Training Debug Info:
  Loss: 0.479509
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0134, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: -0.0152, std: 1.3438
  Model pred mean: -0.0171, std: 1.1641
  Sigmas: [0.6796875]... (timesteps: [681.0])

[Step 300] Training Debug Info:
  Loss: 1.026162
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0311, std: 1.0000
  Noise mean: 0.0018, std: 1.0000
  Target mean: -0.0293, std: 1.4141
  Model pred mean: -0.0270, std: 0.9766
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 300] Training Debug Info:
  Loss: 0.506678
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0383, std: 0.8711
  Noise mean: 0.0021, std: 0.9961
  Target mean: 0.0405, std: 1.3203
  Model pred mean: 0.0303, std: 1.1328
  Sigmas: [0.6875]... (timesteps: [686.0])

[Step 300] Training Debug Info:
  Loss: 0.418534
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0101, std: 0.9453
  Noise mean: 0.0044, std: 1.0000
  Target mean: -0.0057, std: 1.3750
  Model pred mean: -0.0164, std: 1.2109
  Sigmas: [0.859375]... (timesteps: [859.0])
Steps:   6%|‚ñå         | 301/5000 [40:20<9:34:34,  7.34s/it, loss=0.5135, lr=6.00e-06]Steps:   6%|‚ñå         | 301/5000 [40:20<9:34:34,  7.34s/it, loss=0.4185, lr=6.02e-06]Steps:   6%|‚ñå         | 302/5000 [40:28<9:48:24,  7.51s/it, loss=0.4185, lr=6.02e-06]Steps:   6%|‚ñå         | 302/5000 [40:28<9:48:24,  7.51s/it, loss=1.1717, lr=6.04e-06]Steps:   6%|‚ñå         | 303/5000 [40:36<10:07:39,  7.76s/it, loss=1.1717, lr=6.04e-06]Steps:   6%|‚ñå         | 303/5000 [40:36<10:07:39,  7.76s/it, loss=1.1326, lr=6.06e-06]Steps:   6%|‚ñå         | 304/5000 [40:44<10:19:56,  7.92s/it, loss=1.1326, lr=6.06e-06]Steps:   6%|‚ñå         | 304/5000 [40:44<10:19:56,  7.92s/it, loss=0.7209, lr=6.08e-06]Steps:   6%|‚ñå         | 305/5000 [40:52<10:21:29,  7.94s/it, loss=0.7209, lr=6.08e-06]Steps:   6%|‚ñå         | 305/5000 [40:52<10:21:29,  7.94s/it, loss=0.9443, lr=6.10e-06]Steps:   6%|‚ñå         | 306/5000 [41:00<10:22:38,  7.96s/it, loss=0.9443, lr=6.10e-06]Steps:   6%|‚ñå         | 306/5000 [41:00<10:22:38,  7.96s/it, loss=0.4813, lr=6.12e-06]Steps:   6%|‚ñå         | 307/5000 [41:08<10:23:29,  7.97s/it, loss=0.4813, lr=6.12e-06]Steps:   6%|‚ñå         | 307/5000 [41:08<10:23:29,  7.97s/it, loss=0.3954, lr=6.14e-06]Steps:   6%|‚ñå         | 308/5000 [41:16<10:29:24,  8.05s/it, loss=0.3954, lr=6.14e-06]Steps:   6%|‚ñå         | 308/5000 [41:16<10:29:24,  8.05s/it, loss=1.0181, lr=6.16e-06]Steps:   6%|‚ñå         | 309/5000 [41:24<10:28:13,  8.04s/it, loss=1.0181, lr=6.16e-06]Steps:   6%|‚ñå         | 309/5000 [41:24<10:28:13,  8.04s/it, loss=0.8581, lr=6.18e-06]Steps:   6%|‚ñå         | 310/5000 [41:33<10:31:47,  8.08s/it, loss=0.8581, lr=6.18e-06]Steps:   6%|‚ñå         | 310/5000 [41:33<10:31:47,  8.08s/it, loss=0.7091, lr=6.20e-06]
[Step 310] Training Debug Info:
  Loss: 0.967319
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0002, std: 0.8477
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0012, std: 1.3125
  Model pred mean: -0.0003, std: 0.8594
  Sigmas: [0.40625]... (timesteps: [407.0])

[Step 310] Training Debug Info:
  Loss: 0.548353
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0273, std: 0.9180
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0248, std: 1.3594
  Model pred mean: 0.0287, std: 1.1328
  Sigmas: [0.6328125]... (timesteps: [633.0])

[Step 310] Training Debug Info:
  Loss: 1.188091
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0022, std: 0.8867
  Noise mean: -0.0041, std: 1.0000
  Target mean: -0.0063, std: 1.3359
  Model pred mean: -0.0013, std: 0.7891
  Sigmas: [0.16015625]... (timesteps: [160.0])

[Step 310] Training Debug Info:
  Loss: 0.800109
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0354, std: 0.9922
  Noise mean: 0.0036, std: 1.0000
  Target mean: -0.0320, std: 1.4062
  Model pred mean: -0.0305, std: 1.0859
  Sigmas: [0.4453125]... (timesteps: [446.0])
Steps:   6%|‚ñå         | 311/5000 [41:41<10:28:01,  8.04s/it, loss=0.7091, lr=6.20e-06]Steps:   6%|‚ñå         | 311/5000 [41:41<10:28:01,  8.04s/it, loss=0.8001, lr=6.22e-06]Steps:   6%|‚ñå         | 312/5000 [41:48<10:26:02,  8.01s/it, loss=0.8001, lr=6.22e-06]Steps:   6%|‚ñå         | 312/5000 [41:48<10:26:02,  8.01s/it, loss=0.8606, lr=6.24e-06]Steps:   6%|‚ñã         | 313/5000 [41:56<10:24:16,  7.99s/it, loss=0.8606, lr=6.24e-06]Steps:   6%|‚ñã         | 313/5000 [41:56<10:24:16,  7.99s/it, loss=0.6449, lr=6.26e-06]Steps:   6%|‚ñã         | 314/5000 [42:05<10:30:04,  8.07s/it, loss=0.6449, lr=6.26e-06]Steps:   6%|‚ñã         | 314/5000 [42:05<10:30:04,  8.07s/it, loss=1.1658, lr=6.28e-06]Steps:   6%|‚ñã         | 315/5000 [42:13<10:33:43,  8.12s/it, loss=1.1658, lr=6.28e-06]Steps:   6%|‚ñã         | 315/5000 [42:13<10:33:43,  8.12s/it, loss=1.1464, lr=6.30e-06]Steps:   6%|‚ñã         | 316/5000 [42:21<10:29:48,  8.07s/it, loss=1.1464, lr=6.30e-06]Steps:   6%|‚ñã         | 316/5000 [42:21<10:29:48,  8.07s/it, loss=1.1122, lr=6.32e-06]Steps:   6%|‚ñã         | 317/5000 [42:29<10:28:37,  8.05s/it, loss=1.1122, lr=6.32e-06]Steps:   6%|‚ñã         | 317/5000 [42:29<10:28:37,  8.05s/it, loss=0.6617, lr=6.34e-06]Steps:   6%|‚ñã         | 318/5000 [42:37<10:26:54,  8.03s/it, loss=0.6617, lr=6.34e-06]Steps:   6%|‚ñã         | 318/5000 [42:37<10:26:54,  8.03s/it, loss=0.9999, lr=6.36e-06]Steps:   6%|‚ñã         | 319/5000 [42:45<10:30:07,  8.08s/it, loss=0.9999, lr=6.36e-06]Steps:   6%|‚ñã         | 319/5000 [42:45<10:30:07,  8.08s/it, loss=1.0710, lr=6.38e-06]Steps:   6%|‚ñã         | 320/5000 [42:53<10:34:02,  8.13s/it, loss=1.0710, lr=6.38e-06]Steps:   6%|‚ñã         | 320/5000 [42:53<10:34:02,  8.13s/it, loss=0.4848, lr=6.40e-06]
[Step 320] Training Debug Info:
  Loss: 0.676212
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0113, std: 0.8828
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0093, std: 1.3359
  Model pred mean: -0.0056, std: 1.0625
  Sigmas: [0.546875]... (timesteps: [548.0])

[Step 320] Training Debug Info:
  Loss: 0.442636
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0027, std: 0.9609
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0009, std: 1.3828
  Model pred mean: -0.0031, std: 1.2266
  Sigmas: [0.77734375]... (timesteps: [779.0])

[Step 320] Training Debug Info:
  Loss: 0.420419
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0082, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0096, std: 1.3516
  Model pred mean: -0.0203, std: 1.1797
  Sigmas: [0.87109375]... (timesteps: [870.0])

[Step 320] Training Debug Info:
  Loss: 1.174561
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0276, std: 0.9180
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0282, std: 1.3594
  Model pred mean: 0.0352, std: 0.8125
  Sigmas: [0.1640625]... (timesteps: [164.0])
Steps:   6%|‚ñã         | 321/5000 [43:01<10:31:51,  8.10s/it, loss=0.4848, lr=6.40e-06]Steps:   6%|‚ñã         | 321/5000 [43:01<10:31:51,  8.10s/it, loss=1.1746, lr=6.42e-06]Steps:   6%|‚ñã         | 322/5000 [43:09<10:28:16,  8.06s/it, loss=1.1746, lr=6.42e-06]Steps:   6%|‚ñã         | 322/5000 [43:09<10:28:16,  8.06s/it, loss=1.1100, lr=6.44e-06]Steps:   6%|‚ñã         | 323/5000 [43:17<10:26:52,  8.04s/it, loss=1.1100, lr=6.44e-06]Steps:   6%|‚ñã         | 323/5000 [43:17<10:26:52,  8.04s/it, loss=0.5141, lr=6.46e-06]Steps:   6%|‚ñã         | 324/5000 [43:25<10:30:39,  8.09s/it, loss=0.5141, lr=6.46e-06]Steps:   6%|‚ñã         | 324/5000 [43:25<10:30:39,  8.09s/it, loss=0.5988, lr=6.48e-06]Steps:   6%|‚ñã         | 325/5000 [43:33<10:26:38,  8.04s/it, loss=0.5988, lr=6.48e-06]Steps:   6%|‚ñã         | 325/5000 [43:33<10:26:38,  8.04s/it, loss=0.8141, lr=6.50e-06]Steps:   7%|‚ñã         | 326/5000 [43:42<10:29:34,  8.08s/it, loss=0.8141, lr=6.50e-06]Steps:   7%|‚ñã         | 326/5000 [43:42<10:29:34,  8.08s/it, loss=1.1421, lr=6.52e-06]Steps:   7%|‚ñã         | 327/5000 [43:50<10:28:01,  8.06s/it, loss=1.1421, lr=6.52e-06]Steps:   7%|‚ñã         | 327/5000 [43:50<10:28:01,  8.06s/it, loss=0.7657, lr=6.54e-06]Steps:   7%|‚ñã         | 328/5000 [43:58<10:25:57,  8.04s/it, loss=0.7657, lr=6.54e-06]Steps:   7%|‚ñã         | 328/5000 [43:58<10:25:57,  8.04s/it, loss=0.5124, lr=6.56e-06]Steps:   7%|‚ñã         | 329/5000 [44:06<10:32:02,  8.12s/it, loss=0.5124, lr=6.56e-06]Steps:   7%|‚ñã         | 329/5000 [44:06<10:32:02,  8.12s/it, loss=0.8428, lr=6.58e-06]Steps:   7%|‚ñã         | 330/5000 [44:14<10:30:19,  8.10s/it, loss=0.8428, lr=6.58e-06]Steps:   7%|‚ñã         | 330/5000 [44:14<10:30:19,  8.10s/it, loss=0.7849, lr=6.60e-06]
[Step 330] Training Debug Info:
  Loss: 0.700528
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0013, std: 0.9336
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0002, std: 1.3672
  Model pred mean: 0.0049, std: 1.0781
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 330] Training Debug Info:
  Loss: 0.872956
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0085, std: 0.8867
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0085, std: 1.3359
  Model pred mean: -0.0089, std: 0.9453
  Sigmas: [0.431640625]... (timesteps: [431.0])

[Step 330] Training Debug Info:
  Loss: 0.536928
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0159, std: 0.9023
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0159, std: 1.3438
  Model pred mean: -0.0040, std: 1.1172
  Sigmas: [0.921875]... (timesteps: [922.0])

[Step 330] Training Debug Info:
  Loss: 0.584771
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0021, std: 0.8672
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0006, std: 1.3203
  Model pred mean: 0.0291, std: 1.1016
  Sigmas: [0.9765625]... (timesteps: [975.0])
Steps:   7%|‚ñã         | 331/5000 [44:22<10:32:45,  8.13s/it, loss=0.7849, lr=6.60e-06]Steps:   7%|‚ñã         | 331/5000 [44:22<10:32:45,  8.13s/it, loss=0.5848, lr=6.62e-06]Steps:   7%|‚ñã         | 332/5000 [44:30<10:29:59,  8.10s/it, loss=0.5848, lr=6.62e-06]Steps:   7%|‚ñã         | 332/5000 [44:30<10:29:59,  8.10s/it, loss=1.1239, lr=6.64e-06]Steps:   7%|‚ñã         | 333/5000 [44:38<10:26:55,  8.06s/it, loss=1.1239, lr=6.64e-06]Steps:   7%|‚ñã         | 333/5000 [44:38<10:26:55,  8.06s/it, loss=1.1804, lr=6.66e-06]Steps:   7%|‚ñã         | 334/5000 [44:46<10:23:34,  8.02s/it, loss=1.1804, lr=6.66e-06]Steps:   7%|‚ñã         | 334/5000 [44:46<10:23:34,  8.02s/it, loss=0.7626, lr=6.68e-06]Steps:   7%|‚ñã         | 335/5000 [44:54<10:25:58,  8.05s/it, loss=0.7626, lr=6.68e-06]Steps:   7%|‚ñã         | 335/5000 [44:54<10:25:58,  8.05s/it, loss=0.4073, lr=6.70e-06]Steps:   7%|‚ñã         | 336/5000 [45:02<10:25:48,  8.05s/it, loss=0.4073, lr=6.70e-06]Steps:   7%|‚ñã         | 336/5000 [45:02<10:25:48,  8.05s/it, loss=0.4152, lr=6.72e-06]Steps:   7%|‚ñã         | 337/5000 [45:10<10:28:10,  8.08s/it, loss=0.4152, lr=6.72e-06]Steps:   7%|‚ñã         | 337/5000 [45:10<10:28:10,  8.08s/it, loss=0.5335, lr=6.74e-06]Steps:   7%|‚ñã         | 338/5000 [45:18<10:25:45,  8.05s/it, loss=0.5335, lr=6.74e-06]Steps:   7%|‚ñã         | 338/5000 [45:18<10:25:45,  8.05s/it, loss=0.7649, lr=6.76e-06]Steps:   7%|‚ñã         | 339/5000 [45:26<10:25:04,  8.05s/it, loss=0.7649, lr=6.76e-06]Steps:   7%|‚ñã         | 339/5000 [45:26<10:25:04,  8.05s/it, loss=1.1470, lr=6.78e-06]Steps:   7%|‚ñã         | 340/5000 [45:35<10:30:35,  8.12s/it, loss=1.1470, lr=6.78e-06]Steps:   7%|‚ñã         | 340/5000 [45:35<10:30:35,  8.12s/it, loss=0.8470, lr=6.80e-06]
[Step 340] Training Debug Info:
  Loss: 0.598941
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0240, std: 0.8945
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0244, std: 1.3438
  Model pred mean: -0.0630, std: 1.0938
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 340] Training Debug Info:
  Loss: 0.995090
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0035, std: 0.8789
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0022, std: 1.3281
  Model pred mean: -0.0034, std: 0.8945
  Sigmas: [0.369140625]... (timesteps: [369.0])

[Step 340] Training Debug Info:
  Loss: 1.050608
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0571, std: 0.9180
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0576, std: 1.3594
  Model pred mean: -0.0535, std: 0.8984
  Sigmas: [0.25390625]... (timesteps: [252.99998474121094])

[Step 340] Training Debug Info:
  Loss: 0.580655
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0143, std: 0.9062
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0119, std: 1.3516
  Model pred mean: -0.0045, std: 1.1484
  Sigmas: [0.9375]... (timesteps: [939.0])
Steps:   7%|‚ñã         | 341/5000 [45:43<10:29:02,  8.10s/it, loss=0.8470, lr=6.80e-06]Steps:   7%|‚ñã         | 341/5000 [45:43<10:29:02,  8.10s/it, loss=0.5807, lr=6.82e-06]Steps:   7%|‚ñã         | 342/5000 [45:51<10:31:23,  8.13s/it, loss=0.5807, lr=6.82e-06]Steps:   7%|‚ñã         | 342/5000 [45:51<10:31:23,  8.13s/it, loss=1.1286, lr=6.84e-06]Steps:   7%|‚ñã         | 343/5000 [45:59<10:28:18,  8.09s/it, loss=1.1286, lr=6.84e-06]Steps:   7%|‚ñã         | 343/5000 [45:59<10:28:18,  8.09s/it, loss=0.6128, lr=6.86e-06]Steps:   7%|‚ñã         | 344/5000 [46:07<10:27:46,  8.09s/it, loss=0.6128, lr=6.86e-06]Steps:   7%|‚ñã         | 344/5000 [46:07<10:27:46,  8.09s/it, loss=0.7878, lr=6.88e-06]Steps:   7%|‚ñã         | 345/5000 [46:15<10:31:26,  8.14s/it, loss=0.7878, lr=6.88e-06]Steps:   7%|‚ñã         | 345/5000 [46:15<10:31:26,  8.14s/it, loss=0.6337, lr=6.90e-06]Steps:   7%|‚ñã         | 346/5000 [46:23<10:28:12,  8.10s/it, loss=0.6337, lr=6.90e-06]Steps:   7%|‚ñã         | 346/5000 [46:23<10:28:12,  8.10s/it, loss=0.5607, lr=6.92e-06]Steps:   7%|‚ñã         | 347/5000 [46:31<10:25:57,  8.07s/it, loss=0.5607, lr=6.92e-06]Steps:   7%|‚ñã         | 347/5000 [46:31<10:25:57,  8.07s/it, loss=0.6701, lr=6.94e-06]Steps:   7%|‚ñã         | 348/5000 [46:40<10:30:15,  8.13s/it, loss=0.6701, lr=6.94e-06]Steps:   7%|‚ñã         | 348/5000 [46:40<10:30:15,  8.13s/it, loss=0.4870, lr=6.96e-06]Steps:   7%|‚ñã         | 349/5000 [46:48<10:26:10,  8.08s/it, loss=0.4870, lr=6.96e-06]Steps:   7%|‚ñã         | 349/5000 [46:48<10:26:10,  8.08s/it, loss=0.7401, lr=6.98e-06]Steps:   7%|‚ñã         | 350/5000 [46:56<10:24:15,  8.05s/it, loss=0.7401, lr=6.98e-06]Steps:   7%|‚ñã         | 350/5000 [46:56<10:24:15,  8.05s/it, loss=0.6060, lr=7.00e-06]
[Step 350] Training Debug Info:
  Loss: 0.457292
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0142, std: 0.9258
  Noise mean: -0.0011, std: 1.0000
  Target mean: 0.0131, std: 1.3594
  Model pred mean: 0.0090, std: 1.1797
  Sigmas: [0.734375]... (timesteps: [734.0])

[Step 350] Training Debug Info:
  Loss: 0.749280
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0269, std: 0.9062
  Noise mean: 0.0040, std: 1.0000
  Target mean: 0.0309, std: 1.3516
  Model pred mean: 0.0273, std: 1.0312
  Sigmas: [0.4765625]... (timesteps: [477.0])

[Step 350] Training Debug Info:
  Loss: 0.408493
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9102
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0182, std: 1.3516
  Model pred mean: -0.0168, std: 1.1953
  Sigmas: [0.828125]... (timesteps: [830.0])

[Step 350] Training Debug Info:
  Loss: 0.464023
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0354, std: 0.8945
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0337, std: 1.3359
  Model pred mean: -0.0289, std: 1.1562
  Sigmas: [0.70703125]... (timesteps: [708.0])
Steps:   7%|‚ñã         | 351/5000 [47:04<10:28:17,  8.11s/it, loss=0.6060, lr=7.00e-06]Steps:   7%|‚ñã         | 351/5000 [47:04<10:28:17,  8.11s/it, loss=0.4640, lr=7.02e-06]Steps:   7%|‚ñã         | 352/5000 [47:12<10:28:17,  8.11s/it, loss=0.4640, lr=7.02e-06]Steps:   7%|‚ñã         | 352/5000 [47:12<10:28:17,  8.11s/it, loss=0.7558, lr=7.04e-06]Steps:   7%|‚ñã         | 353/5000 [47:20<10:30:16,  8.14s/it, loss=0.7558, lr=7.04e-06]Steps:   7%|‚ñã         | 353/5000 [47:20<10:30:16,  8.14s/it, loss=0.4142, lr=7.06e-06]Steps:   7%|‚ñã         | 354/5000 [47:28<10:23:50,  8.06s/it, loss=0.4142, lr=7.06e-06]Steps:   7%|‚ñã         | 354/5000 [47:28<10:23:50,  8.06s/it, loss=0.8334, lr=7.08e-06]Steps:   7%|‚ñã         | 355/5000 [47:36<10:20:59,  8.02s/it, loss=0.8334, lr=7.08e-06]Steps:   7%|‚ñã         | 355/5000 [47:36<10:20:59,  8.02s/it, loss=1.1804, lr=7.10e-06]Steps:   7%|‚ñã         | 356/5000 [47:44<10:22:11,  8.04s/it, loss=1.1804, lr=7.10e-06]Steps:   7%|‚ñã         | 356/5000 [47:44<10:22:11,  8.04s/it, loss=0.3348, lr=7.12e-06]Steps:   7%|‚ñã         | 357/5000 [47:52<10:20:38,  8.02s/it, loss=0.3348, lr=7.12e-06]Steps:   7%|‚ñã         | 357/5000 [47:52<10:20:38,  8.02s/it, loss=0.5265, lr=7.14e-06]Steps:   7%|‚ñã         | 358/5000 [48:00<10:23:59,  8.07s/it, loss=0.5265, lr=7.14e-06]Steps:   7%|‚ñã         | 358/5000 [48:00<10:23:59,  8.07s/it, loss=1.0642, lr=7.16e-06]Steps:   7%|‚ñã         | 359/5000 [48:08<10:22:21,  8.05s/it, loss=1.0642, lr=7.16e-06]Steps:   7%|‚ñã         | 359/5000 [48:08<10:22:21,  8.05s/it, loss=1.1549, lr=7.18e-06]Steps:   7%|‚ñã         | 360/5000 [48:16<10:21:07,  8.03s/it, loss=1.1549, lr=7.18e-06]Steps:   7%|‚ñã         | 360/5000 [48:16<10:21:07,  8.03s/it, loss=0.6480, lr=7.20e-06]
[Step 360] Training Debug Info:
  Loss: 0.541800
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0137, std: 0.9375
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0142, std: 1.3672
  Model pred mean: -0.0086, std: 1.1484
  Sigmas: [0.60546875]... (timesteps: [605.0])

[Step 360] Training Debug Info:
  Loss: 0.390650
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0064, std: 0.8672
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0056, std: 1.3281
  Model pred mean: -0.0036, std: 1.1641
  Sigmas: [0.91796875]... (timesteps: [918.0])

[Step 360] Training Debug Info:
  Loss: 0.613107
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0189, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0205, std: 1.3281
  Model pred mean: 0.0226, std: 1.0781
  Sigmas: [0.9765625]... (timesteps: [977.0])

[Step 360] Training Debug Info:
  Loss: 0.387067
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0430, std: 0.9141
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0417, std: 1.3516
  Model pred mean: 0.0381, std: 1.2031
  Sigmas: [0.828125]... (timesteps: [829.0])
Steps:   7%|‚ñã         | 361/5000 [48:24<10:22:49,  8.06s/it, loss=0.6480, lr=7.20e-06]Steps:   7%|‚ñã         | 361/5000 [48:24<10:22:49,  8.06s/it, loss=0.3871, lr=7.22e-06]Steps:   7%|‚ñã         | 362/5000 [48:32<10:21:11,  8.04s/it, loss=0.3871, lr=7.22e-06]Steps:   7%|‚ñã         | 362/5000 [48:32<10:21:11,  8.04s/it, loss=0.4619, lr=7.24e-06]Steps:   7%|‚ñã         | 363/5000 [48:40<10:18:55,  8.01s/it, loss=0.4619, lr=7.24e-06]Steps:   7%|‚ñã         | 363/5000 [48:40<10:18:55,  8.01s/it, loss=1.0900, lr=7.26e-06]Steps:   7%|‚ñã         | 364/5000 [48:48<10:23:26,  8.07s/it, loss=1.0900, lr=7.26e-06]Steps:   7%|‚ñã         | 364/5000 [48:48<10:23:26,  8.07s/it, loss=0.9482, lr=7.28e-06]Steps:   7%|‚ñã         | 365/5000 [48:56<10:22:29,  8.06s/it, loss=0.9482, lr=7.28e-06]Steps:   7%|‚ñã         | 365/5000 [48:56<10:22:29,  8.06s/it, loss=1.1611, lr=7.30e-06]Steps:   7%|‚ñã         | 366/5000 [49:04<10:20:36,  8.04s/it, loss=1.1611, lr=7.30e-06]Steps:   7%|‚ñã         | 366/5000 [49:04<10:20:36,  8.04s/it, loss=0.4081, lr=7.32e-06]Steps:   7%|‚ñã         | 367/5000 [49:13<10:22:59,  8.07s/it, loss=0.4081, lr=7.32e-06]Steps:   7%|‚ñã         | 367/5000 [49:13<10:22:59,  8.07s/it, loss=1.0883, lr=7.34e-06]Steps:   7%|‚ñã         | 368/5000 [49:21<10:20:42,  8.04s/it, loss=1.0883, lr=7.34e-06]Steps:   7%|‚ñã         | 368/5000 [49:21<10:20:42,  8.04s/it, loss=1.2234, lr=7.36e-06]Steps:   7%|‚ñã         | 369/5000 [49:29<10:24:02,  8.09s/it, loss=1.2234, lr=7.36e-06]Steps:   7%|‚ñã         | 369/5000 [49:29<10:24:02,  8.09s/it, loss=0.9551, lr=7.38e-06]Steps:   7%|‚ñã         | 370/5000 [49:37<10:21:27,  8.05s/it, loss=0.9551, lr=7.38e-06]Steps:   7%|‚ñã         | 370/5000 [49:37<10:21:27,  8.05s/it, loss=0.9561, lr=7.40e-06]
[Step 370] Training Debug Info:
  Loss: 0.369788
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0128, std: 0.8789
  Noise mean: 0.0036, std: 0.9961
  Target mean: 0.0164, std: 1.3281
  Model pred mean: 0.0120, std: 1.1797
  Sigmas: [0.84765625]... (timesteps: [848.0])

[Step 370] Training Debug Info:
  Loss: 0.384714
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0228, std: 0.8672
  Noise mean: -0.0000, std: 1.0000
  Target mean: 0.0228, std: 1.3203
  Model pred mean: 0.0217, std: 1.1641
  Sigmas: [0.81640625]... (timesteps: [817.0])

[Step 370] Training Debug Info:
  Loss: 0.572448
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0119, std: 0.9844
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0123, std: 1.4062
  Model pred mean: -0.0137, std: 1.1797
  Sigmas: [0.61328125]... (timesteps: [612.0])

[Step 370] Training Debug Info:
  Loss: 0.492512
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0017, std: 0.9102
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: -0.0106, std: 1.1484
  Sigmas: [0.68359375]... (timesteps: [682.0])
Steps:   7%|‚ñã         | 371/5000 [49:45<10:18:44,  8.02s/it, loss=0.9561, lr=7.40e-06]Steps:   7%|‚ñã         | 371/5000 [49:45<10:18:44,  8.02s/it, loss=0.4925, lr=7.42e-06]Steps:   7%|‚ñã         | 372/5000 [49:53<10:21:48,  8.06s/it, loss=0.4925, lr=7.42e-06]Steps:   7%|‚ñã         | 372/5000 [49:53<10:21:48,  8.06s/it, loss=1.0605, lr=7.44e-06]Steps:   7%|‚ñã         | 373/5000 [50:01<10:20:13,  8.04s/it, loss=1.0605, lr=7.44e-06]Steps:   7%|‚ñã         | 373/5000 [50:01<10:20:13,  8.04s/it, loss=0.3684, lr=7.46e-06]Steps:   7%|‚ñã         | 374/5000 [50:09<10:24:50,  8.10s/it, loss=0.3684, lr=7.46e-06]Steps:   7%|‚ñã         | 374/5000 [50:09<10:24:50,  8.10s/it, loss=0.9195, lr=7.48e-06]Steps:   8%|‚ñä         | 375/5000 [50:13<8:52:54,  6.91s/it, loss=0.9195, lr=7.48e-06] Steps:   8%|‚ñä         | 375/5000 [50:13<8:52:54,  6.91s/it, loss=1.0600, lr=7.50e-06]01/30/2026 05:13:02 - INFO - __main__ - 
==================================================
01/30/2026 05:13:02 - INFO - __main__ - Epoch 4 completed: avg_loss = 0.7945
01/30/2026 05:13:02 - INFO - __main__ - ==================================================

Steps:   8%|‚ñä         | 376/5000 [50:21<9:23:24,  7.31s/it, loss=1.0600, lr=7.50e-06]Steps:   8%|‚ñä         | 376/5000 [50:21<9:23:24,  7.31s/it, loss=0.7290, lr=7.52e-06]Steps:   8%|‚ñä         | 377/5000 [50:29<9:38:56,  7.51s/it, loss=0.7290, lr=7.52e-06]Steps:   8%|‚ñä         | 377/5000 [50:29<9:38:56,  7.51s/it, loss=1.0445, lr=7.54e-06]Steps:   8%|‚ñä         | 378/5000 [50:38<10:00:53,  7.80s/it, loss=1.0445, lr=7.54e-06]Steps:   8%|‚ñä         | 378/5000 [50:38<10:00:53,  7.80s/it, loss=1.1685, lr=7.56e-06]Steps:   8%|‚ñä         | 379/5000 [50:46<10:03:35,  7.84s/it, loss=1.1685, lr=7.56e-06]Steps:   8%|‚ñä         | 379/5000 [50:46<10:03:35,  7.84s/it, loss=1.0278, lr=7.58e-06]Steps:   8%|‚ñä         | 380/5000 [50:54<10:13:43,  7.97s/it, loss=1.0278, lr=7.58e-06]Steps:   8%|‚ñä         | 380/5000 [50:54<10:13:43,  7.97s/it, loss=0.9190, lr=7.60e-06]
[Step 380] Training Debug Info:
  Loss: 1.169354
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0261, std: 0.9219
  Noise mean: -0.0019, std: 0.9961
  Target mean: 0.0242, std: 1.3594
  Model pred mean: 0.0259, std: 0.8281
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 380] Training Debug Info:
  Loss: 1.033944
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0154, std: 0.9102
  Noise mean: -0.0001, std: 1.0000
  Target mean: 0.0153, std: 1.3516
  Model pred mean: 0.0098, std: 0.8789
  Sigmas: [0.01397705078125]... (timesteps: [14.0])

[Step 380] Training Debug Info:
  Loss: 0.941675
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0057, std: 0.8906
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0078, std: 1.3359
  Model pred mean: 0.0083, std: 0.9219
  Sigmas: [0.38671875]... (timesteps: [387.0])

[Step 380] Training Debug Info:
  Loss: 0.483412
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0073, std: 0.8984
  Noise mean: -0.0010, std: 1.0000
  Target mean: 0.0063, std: 1.3438
  Model pred mean: 0.0125, std: 1.1562
  Sigmas: [0.6875]... (timesteps: [686.0])
Steps:   8%|‚ñä         | 381/5000 [51:02<10:13:47,  7.97s/it, loss=0.9190, lr=7.60e-06]Steps:   8%|‚ñä         | 381/5000 [51:02<10:13:47,  7.97s/it, loss=0.4834, lr=7.62e-06]Steps:   8%|‚ñä         | 382/5000 [51:10<10:14:21,  7.98s/it, loss=0.4834, lr=7.62e-06]Steps:   8%|‚ñä         | 382/5000 [51:10<10:14:21,  7.98s/it, loss=0.5601, lr=7.64e-06]Steps:   8%|‚ñä         | 383/5000 [51:18<10:18:52,  8.04s/it, loss=0.5601, lr=7.64e-06]Steps:   8%|‚ñä         | 383/5000 [51:18<10:18:52,  8.04s/it, loss=0.6654, lr=7.66e-06]Steps:   8%|‚ñä         | 384/5000 [51:26<10:17:10,  8.02s/it, loss=0.6654, lr=7.66e-06]Steps:   8%|‚ñä         | 384/5000 [51:26<10:17:10,  8.02s/it, loss=0.4554, lr=7.68e-06]Steps:   8%|‚ñä         | 385/5000 [51:34<10:16:15,  8.01s/it, loss=0.4554, lr=7.68e-06]Steps:   8%|‚ñä         | 385/5000 [51:34<10:16:15,  8.01s/it, loss=1.0431, lr=7.70e-06]Steps:   8%|‚ñä         | 386/5000 [51:42<10:19:56,  8.06s/it, loss=1.0431, lr=7.70e-06]Steps:   8%|‚ñä         | 386/5000 [51:42<10:19:56,  8.06s/it, loss=0.8890, lr=7.72e-06]Steps:   8%|‚ñä         | 387/5000 [51:50<10:16:51,  8.02s/it, loss=0.8890, lr=7.72e-06]Steps:   8%|‚ñä         | 387/5000 [51:50<10:16:51,  8.02s/it, loss=0.4094, lr=7.74e-06]Steps:   8%|‚ñä         | 388/5000 [51:58<10:19:57,  8.07s/it, loss=0.4094, lr=7.74e-06]Steps:   8%|‚ñä         | 388/5000 [51:58<10:19:57,  8.07s/it, loss=1.0483, lr=7.76e-06]Steps:   8%|‚ñä         | 389/5000 [52:06<10:18:02,  8.04s/it, loss=1.0483, lr=7.76e-06]Steps:   8%|‚ñä         | 389/5000 [52:06<10:18:02,  8.04s/it, loss=0.3871, lr=7.78e-06]Steps:   8%|‚ñä         | 390/5000 [52:14<10:16:18,  8.02s/it, loss=0.3871, lr=7.78e-06]Steps:   8%|‚ñä         | 390/5000 [52:14<10:16:18,  8.02s/it, loss=1.1951, lr=7.80e-06]
[Step 390] Training Debug Info:
  Loss: 1.067577
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0087, std: 0.9727
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0095, std: 1.3906
  Model pred mean: -0.0100, std: 0.9414
  Sigmas: [0.06298828125]... (timesteps: [63.0])

[Step 390] Training Debug Info:
  Loss: 0.437416
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0679, std: 0.9336
  Noise mean: -0.0020, std: 1.0000
  Target mean: 0.0659, std: 1.3672
  Model pred mean: 0.0723, std: 1.2031
  Sigmas: [0.66015625]... (timesteps: [659.0])

[Step 390] Training Debug Info:
  Loss: 0.581135
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0089, std: 0.9453
  Noise mean: 0.0041, std: 1.0000
  Target mean: 0.0129, std: 1.3828
  Model pred mean: 0.0104, std: 1.1641
  Sigmas: [0.5390625]... (timesteps: [540.0])

[Step 390] Training Debug Info:
  Loss: 0.446562
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0003, std: 0.9336
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0005, std: 1.3672
  Model pred mean: -0.0014, std: 1.1953
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   8%|‚ñä         | 391/5000 [52:23<10:21:34,  8.09s/it, loss=1.1951, lr=7.80e-06]Steps:   8%|‚ñä         | 391/5000 [52:23<10:21:34,  8.09s/it, loss=0.4466, lr=7.82e-06]Steps:   8%|‚ñä         | 392/5000 [52:31<10:19:50,  8.07s/it, loss=0.4466, lr=7.82e-06]Steps:   8%|‚ñä         | 392/5000 [52:31<10:19:50,  8.07s/it, loss=0.8422, lr=7.84e-06]Steps:   8%|‚ñä         | 393/5000 [52:39<10:18:51,  8.06s/it, loss=0.8422, lr=7.84e-06]Steps:   8%|‚ñä         | 393/5000 [52:39<10:18:51,  8.06s/it, loss=0.4847, lr=7.86e-06]Steps:   8%|‚ñä         | 394/5000 [52:47<10:22:22,  8.11s/it, loss=0.4847, lr=7.86e-06]Steps:   8%|‚ñä         | 394/5000 [52:47<10:22:22,  8.11s/it, loss=1.0021, lr=7.88e-06]Steps:   8%|‚ñä         | 395/5000 [52:55<10:19:37,  8.07s/it, loss=1.0021, lr=7.88e-06]Steps:   8%|‚ñä         | 395/5000 [52:55<10:19:37,  8.07s/it, loss=0.5355, lr=7.90e-06]Steps:   8%|‚ñä         | 396/5000 [53:03<10:24:07,  8.13s/it, loss=0.5355, lr=7.90e-06]Steps:   8%|‚ñä         | 396/5000 [53:03<10:24:07,  8.13s/it, loss=1.1598, lr=7.92e-06]Steps:   8%|‚ñä         | 397/5000 [53:11<10:20:10,  8.08s/it, loss=1.1598, lr=7.92e-06]Steps:   8%|‚ñä         | 397/5000 [53:11<10:20:10,  8.08s/it, loss=1.1690, lr=7.94e-06]Steps:   8%|‚ñä         | 398/5000 [53:19<10:18:05,  8.06s/it, loss=1.1690, lr=7.94e-06]Steps:   8%|‚ñä         | 398/5000 [53:19<10:18:05,  8.06s/it, loss=0.4282, lr=7.96e-06]Steps:   8%|‚ñä         | 399/5000 [53:27<10:20:40,  8.09s/it, loss=0.4282, lr=7.96e-06]Steps:   8%|‚ñä         | 399/5000 [53:27<10:20:40,  8.09s/it, loss=0.5068, lr=7.98e-06]Steps:   8%|‚ñä         | 400/5000 [53:35<10:16:35,  8.04s/it, loss=0.5068, lr=7.98e-06]Steps:   8%|‚ñä         | 400/5000 [53:35<10:16:35,  8.04s/it, loss=1.1054, lr=8.00e-06]01/30/2026 05:16:24 - INFO - __main__ - 
[Step 400] ‚úÖ Loss in normal range (1.1054)
01/30/2026 05:16:24 - INFO - __main__ -   Loss avg (last 100): 0.7929
01/30/2026 05:16:24 - INFO - __main__ -   Loss range: [0.3348, 1.2234]

[Step 400] Training Debug Info:
  Loss: 0.481704
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0019, std: 0.8867
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0012, std: 1.3359
  Model pred mean: -0.0085, std: 1.1641
  Sigmas: [0.94921875]... (timesteps: [951.0])

[Step 400] Training Debug Info:
  Loss: 0.627173
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0095, std: 0.8750
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0103, std: 1.3281
  Model pred mean: -0.0066, std: 1.0547
  Sigmas: [0.5625]... (timesteps: [561.0])

[Step 400] Training Debug Info:
  Loss: 0.799375
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0089, std: 0.8828
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0098, std: 1.3359
  Model pred mean: 0.0117, std: 0.9805
  Sigmas: [0.470703125]... (timesteps: [471.0])

[Step 400] Training Debug Info:
  Loss: 1.156325
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0157, std: 0.9062
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0160, std: 1.3516
  Model pred mean: -0.0214, std: 0.8164
  Sigmas: [0.14453125]... (timesteps: [145.0])
Steps:   8%|‚ñä         | 401/5000 [53:43<10:15:50,  8.03s/it, loss=1.1054, lr=8.00e-06]Steps:   8%|‚ñä         | 401/5000 [53:43<10:15:50,  8.03s/it, loss=1.1563, lr=8.02e-06]Steps:   8%|‚ñä         | 402/5000 [53:52<10:20:53,  8.10s/it, loss=1.1563, lr=8.02e-06]Steps:   8%|‚ñä         | 402/5000 [53:52<10:20:53,  8.10s/it, loss=1.1763, lr=8.04e-06]Steps:   8%|‚ñä         | 403/5000 [54:00<10:17:23,  8.06s/it, loss=1.1763, lr=8.04e-06]Steps:   8%|‚ñä         | 403/5000 [54:00<10:17:23,  8.06s/it, loss=0.4049, lr=8.06e-06]Steps:   8%|‚ñä         | 404/5000 [54:08<10:23:29,  8.14s/it, loss=0.4049, lr=8.06e-06]Steps:   8%|‚ñä         | 404/5000 [54:08<10:23:29,  8.14s/it, loss=0.6765, lr=8.08e-06]Steps:   8%|‚ñä         | 405/5000 [54:16<10:20:31,  8.10s/it, loss=0.6765, lr=8.08e-06]Steps:   8%|‚ñä         | 405/5000 [54:16<10:20:31,  8.10s/it, loss=0.5131, lr=8.10e-06]Steps:   8%|‚ñä         | 406/5000 [54:24<10:15:53,  8.04s/it, loss=0.5131, lr=8.10e-06]Steps:   8%|‚ñä         | 406/5000 [54:24<10:15:53,  8.04s/it, loss=0.6128, lr=8.12e-06]Steps:   8%|‚ñä         | 407/5000 [54:32<10:21:07,  8.11s/it, loss=0.6128, lr=8.12e-06]Steps:   8%|‚ñä         | 407/5000 [54:32<10:21:07,  8.11s/it, loss=1.1829, lr=8.14e-06]Steps:   8%|‚ñä         | 408/5000 [54:40<10:17:17,  8.07s/it, loss=1.1829, lr=8.14e-06]Steps:   8%|‚ñä         | 408/5000 [54:40<10:17:17,  8.07s/it, loss=0.9873, lr=8.16e-06]Steps:   8%|‚ñä         | 409/5000 [54:48<10:18:28,  8.08s/it, loss=0.9873, lr=8.16e-06]Steps:   8%|‚ñä         | 409/5000 [54:48<10:18:28,  8.08s/it, loss=0.8101, lr=8.18e-06]Steps:   8%|‚ñä         | 410/5000 [54:56<10:15:03,  8.04s/it, loss=0.8101, lr=8.18e-06]Steps:   8%|‚ñä         | 410/5000 [54:56<10:15:03,  8.04s/it, loss=1.0140, lr=8.20e-06]
[Step 410] Training Debug Info:
  Loss: 0.354173
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0349, std: 0.9219
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0347, std: 1.3594
  Model pred mean: 0.0371, std: 1.2188
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 410] Training Debug Info:
  Loss: 0.793345
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0260, std: 0.9219
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0248, std: 1.3594
  Model pred mean: -0.0284, std: 1.0547
  Sigmas: [0.447265625]... (timesteps: [448.0])

[Step 410] Training Debug Info:
  Loss: 0.560141
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0060, std: 0.8906
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0054, std: 1.3359
  Model pred mean: 0.0000, std: 1.1328
  Sigmas: [0.625]... (timesteps: [625.0])

[Step 410] Training Debug Info:
  Loss: 0.437407
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0091, std: 0.8867
  Noise mean: 0.0036, std: 0.9961
  Target mean: -0.0054, std: 1.3359
  Model pred mean: -0.0093, std: 1.1641
  Sigmas: [0.74609375]... (timesteps: [748.0])
Steps:   8%|‚ñä         | 411/5000 [55:04<10:15:13,  8.04s/it, loss=1.0140, lr=8.20e-06]Steps:   8%|‚ñä         | 411/5000 [55:04<10:15:13,  8.04s/it, loss=0.4374, lr=8.22e-06]Steps:   8%|‚ñä         | 412/5000 [55:12<10:16:40,  8.06s/it, loss=0.4374, lr=8.22e-06]Steps:   8%|‚ñä         | 412/5000 [55:12<10:16:40,  8.06s/it, loss=0.5777, lr=8.24e-06]Steps:   8%|‚ñä         | 413/5000 [55:20<10:14:03,  8.03s/it, loss=0.5777, lr=8.24e-06]Steps:   8%|‚ñä         | 413/5000 [55:20<10:14:03,  8.03s/it, loss=0.4424, lr=8.26e-06]Steps:   8%|‚ñä         | 414/5000 [55:28<10:13:05,  8.02s/it, loss=0.4424, lr=8.26e-06]Steps:   8%|‚ñä         | 414/5000 [55:28<10:13:05,  8.02s/it, loss=0.3687, lr=8.28e-06]Steps:   8%|‚ñä         | 415/5000 [55:36<10:18:23,  8.09s/it, loss=0.3687, lr=8.28e-06]Steps:   8%|‚ñä         | 415/5000 [55:36<10:18:23,  8.09s/it, loss=0.5891, lr=8.30e-06]Steps:   8%|‚ñä         | 416/5000 [55:44<10:16:00,  8.06s/it, loss=0.5891, lr=8.30e-06]Steps:   8%|‚ñä         | 416/5000 [55:44<10:16:00,  8.06s/it, loss=0.8180, lr=8.32e-06]Steps:   8%|‚ñä         | 417/5000 [55:52<10:14:28,  8.04s/it, loss=0.8180, lr=8.32e-06]Steps:   8%|‚ñä         | 417/5000 [55:52<10:14:28,  8.04s/it, loss=0.5803, lr=8.34e-06]Steps:   8%|‚ñä         | 418/5000 [56:01<10:18:07,  8.09s/it, loss=0.5803, lr=8.34e-06]Steps:   8%|‚ñä         | 418/5000 [56:01<10:18:07,  8.09s/it, loss=1.1820, lr=8.36e-06]Steps:   8%|‚ñä         | 419/5000 [56:09<10:16:43,  8.08s/it, loss=1.1820, lr=8.36e-06]Steps:   8%|‚ñä         | 419/5000 [56:09<10:16:43,  8.08s/it, loss=0.4580, lr=8.38e-06]Steps:   8%|‚ñä         | 420/5000 [56:17<10:21:37,  8.14s/it, loss=0.4580, lr=8.38e-06]Steps:   8%|‚ñä         | 420/5000 [56:17<10:21:37,  8.14s/it, loss=0.6113, lr=8.40e-06]
[Step 420] Training Debug Info:
  Loss: 1.162476
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0023, std: 0.9180
  Noise mean: -0.0023, std: 1.0000
  Target mean: 0.0000, std: 1.3594
  Model pred mean: 0.0056, std: 0.8242
  Sigmas: [0.134765625]... (timesteps: [135.0])

[Step 420] Training Debug Info:
  Loss: 1.130296
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0056, std: 0.8945
  Noise mean: 0.0021, std: 1.0000
  Target mean: -0.0034, std: 1.3438
  Model pred mean: -0.0039, std: 0.8164
  Sigmas: [0.1162109375]... (timesteps: [116.0])

[Step 420] Training Debug Info:
  Loss: 0.933003
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0142, std: 0.8789
  Noise mean: -0.0030, std: 1.0000
  Target mean: 0.0112, std: 1.3359
  Model pred mean: 0.0155, std: 0.9336
  Sigmas: [0.423828125]... (timesteps: [423.0])

[Step 420] Training Debug Info:
  Loss: 0.966299
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0300, std: 0.9297
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0304, std: 1.3594
  Model pred mean: -0.0282, std: 0.9688
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:   8%|‚ñä         | 421/5000 [56:25<10:17:36,  8.09s/it, loss=0.6113, lr=8.40e-06]Steps:   8%|‚ñä         | 421/5000 [56:25<10:17:36,  8.09s/it, loss=0.9663, lr=8.42e-06]Steps:   8%|‚ñä         | 422/5000 [56:33<10:15:34,  8.07s/it, loss=0.9663, lr=8.42e-06]Steps:   8%|‚ñä         | 422/5000 [56:33<10:15:34,  8.07s/it, loss=0.8942, lr=8.44e-06]Steps:   8%|‚ñä         | 423/5000 [56:41<10:19:23,  8.12s/it, loss=0.8942, lr=8.44e-06]Steps:   8%|‚ñä         | 423/5000 [56:41<10:19:23,  8.12s/it, loss=1.0494, lr=8.46e-06]Steps:   8%|‚ñä         | 424/5000 [56:49<10:15:24,  8.07s/it, loss=1.0494, lr=8.46e-06]Steps:   8%|‚ñä         | 424/5000 [56:49<10:15:24,  8.07s/it, loss=0.9014, lr=8.48e-06]Steps:   8%|‚ñä         | 425/5000 [56:57<10:18:08,  8.11s/it, loss=0.9014, lr=8.48e-06]Steps:   8%|‚ñä         | 425/5000 [56:57<10:18:08,  8.11s/it, loss=1.1241, lr=8.50e-06]Steps:   9%|‚ñä         | 426/5000 [57:05<10:14:26,  8.06s/it, loss=1.1241, lr=8.50e-06]Steps:   9%|‚ñä         | 426/5000 [57:05<10:14:26,  8.06s/it, loss=1.1090, lr=8.52e-06]Steps:   9%|‚ñä         | 427/5000 [57:13<10:15:04,  8.07s/it, loss=1.1090, lr=8.52e-06]Steps:   9%|‚ñä         | 427/5000 [57:13<10:15:04,  8.07s/it, loss=1.1541, lr=8.54e-06]Steps:   9%|‚ñä         | 428/5000 [57:22<10:18:29,  8.12s/it, loss=1.1541, lr=8.54e-06]Steps:   9%|‚ñä         | 428/5000 [57:22<10:18:29,  8.12s/it, loss=0.9020, lr=8.56e-06]Steps:   9%|‚ñä         | 429/5000 [57:30<10:12:46,  8.04s/it, loss=0.9020, lr=8.56e-06]Steps:   9%|‚ñä         | 429/5000 [57:30<10:12:46,  8.04s/it, loss=0.5895, lr=8.58e-06]Steps:   9%|‚ñä         | 430/5000 [57:37<10:10:07,  8.01s/it, loss=0.5895, lr=8.58e-06]Steps:   9%|‚ñä         | 430/5000 [57:37<10:10:07,  8.01s/it, loss=1.2001, lr=8.60e-06]
[Step 430] Training Debug Info:
  Loss: 0.702505
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0532, std: 0.9219
  Noise mean: 0.0009, std: 0.9961
  Target mean: -0.0522, std: 1.3594
  Model pred mean: -0.0100, std: 1.1016
  Sigmas: [0.9609375]... (timesteps: [959.0])

[Step 430] Training Debug Info:
  Loss: 0.467406
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0186, std: 0.9141
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0195, std: 1.3516
  Model pred mean: -0.0104, std: 1.1641
  Sigmas: [0.921875]... (timesteps: [923.0])

[Step 430] Training Debug Info:
  Loss: 0.442681
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0140, std: 0.9219
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0132, std: 1.3594
  Model pred mean: -0.0140, std: 1.1953
  Sigmas: [0.7578125]... (timesteps: [757.0])

[Step 430] Training Debug Info:
  Loss: 1.136329
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0356, std: 0.9258
  Noise mean: -0.0007, std: 0.9961
  Target mean: 0.0349, std: 1.3594
  Model pred mean: 0.0386, std: 0.8438
  Sigmas: [0.1796875]... (timesteps: [180.0])
Steps:   9%|‚ñä         | 431/5000 [57:46<10:12:57,  8.05s/it, loss=1.2001, lr=8.60e-06]Steps:   9%|‚ñä         | 431/5000 [57:46<10:12:57,  8.05s/it, loss=1.1363, lr=8.62e-06]Steps:   9%|‚ñä         | 432/5000 [57:54<10:11:46,  8.04s/it, loss=1.1363, lr=8.62e-06]Steps:   9%|‚ñä         | 432/5000 [57:54<10:11:46,  8.04s/it, loss=0.4888, lr=8.64e-06]Steps:   9%|‚ñä         | 433/5000 [58:02<10:10:31,  8.02s/it, loss=0.4888, lr=8.64e-06]Steps:   9%|‚ñä         | 433/5000 [58:02<10:10:31,  8.02s/it, loss=0.5063, lr=8.66e-06]Steps:   9%|‚ñä         | 434/5000 [58:10<10:15:10,  8.08s/it, loss=0.5063, lr=8.66e-06]Steps:   9%|‚ñä         | 434/5000 [58:10<10:15:10,  8.08s/it, loss=0.4759, lr=8.68e-06]Steps:   9%|‚ñä         | 435/5000 [58:18<10:12:54,  8.06s/it, loss=0.4759, lr=8.68e-06]Steps:   9%|‚ñä         | 435/5000 [58:18<10:12:54,  8.06s/it, loss=1.0235, lr=8.70e-06]Steps:   9%|‚ñä         | 436/5000 [58:26<10:13:22,  8.06s/it, loss=1.0235, lr=8.70e-06]Steps:   9%|‚ñä         | 436/5000 [58:26<10:13:22,  8.06s/it, loss=1.1819, lr=8.72e-06]Steps:   9%|‚ñä         | 437/5000 [58:34<10:11:34,  8.04s/it, loss=1.1819, lr=8.72e-06]Steps:   9%|‚ñä         | 437/5000 [58:34<10:11:34,  8.04s/it, loss=0.8683, lr=8.74e-06]Steps:   9%|‚ñâ         | 438/5000 [58:42<10:08:57,  8.01s/it, loss=0.8683, lr=8.74e-06]Steps:   9%|‚ñâ         | 438/5000 [58:42<10:08:57,  8.01s/it, loss=1.0794, lr=8.76e-06]Steps:   9%|‚ñâ         | 439/5000 [58:50<10:12:44,  8.06s/it, loss=1.0794, lr=8.76e-06]Steps:   9%|‚ñâ         | 439/5000 [58:50<10:12:44,  8.06s/it, loss=0.4380, lr=8.78e-06]Steps:   9%|‚ñâ         | 440/5000 [58:58<10:12:25,  8.06s/it, loss=0.4380, lr=8.78e-06]Steps:   9%|‚ñâ         | 440/5000 [58:58<10:12:25,  8.06s/it, loss=0.4104, lr=8.80e-06]
[Step 440] Training Debug Info:
  Loss: 0.614885
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0220, std: 0.8984
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0226, std: 1.3438
  Model pred mean: 0.0016, std: 1.0859
  Sigmas: [0.99609375]... (timesteps: [996.0])

[Step 440] Training Debug Info:
  Loss: 0.552976
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0334, std: 0.9414
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0349, std: 1.3750
  Model pred mean: -0.0320, std: 1.1562
  Sigmas: [0.58984375]... (timesteps: [590.0])

[Step 440] Training Debug Info:
  Loss: 0.803309
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0195, std: 1.0078
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0201, std: 1.4219
  Model pred mean: -0.0029, std: 1.0938
  Sigmas: [0.953125]... (timesteps: [955.0])

[Step 440] Training Debug Info:
  Loss: 0.471362
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0005, std: 0.9453
  Noise mean: -0.0033, std: 1.0000
  Target mean: -0.0037, std: 1.3750
  Model pred mean: -0.0031, std: 1.1953
  Sigmas: [0.66796875]... (timesteps: [668.0])
Steps:   9%|‚ñâ         | 441/5000 [59:06<10:15:25,  8.10s/it, loss=0.4104, lr=8.80e-06]Steps:   9%|‚ñâ         | 441/5000 [59:06<10:15:25,  8.10s/it, loss=0.4714, lr=8.82e-06]Steps:   9%|‚ñâ         | 442/5000 [59:14<10:11:48,  8.05s/it, loss=0.4714, lr=8.82e-06]Steps:   9%|‚ñâ         | 442/5000 [59:14<10:11:48,  8.05s/it, loss=1.0742, lr=8.84e-06]Steps:   9%|‚ñâ         | 443/5000 [59:22<10:09:49,  8.03s/it, loss=1.0742, lr=8.84e-06]Steps:   9%|‚ñâ         | 443/5000 [59:22<10:09:49,  8.03s/it, loss=0.8351, lr=8.86e-06]Steps:   9%|‚ñâ         | 444/5000 [59:30<10:14:42,  8.10s/it, loss=0.8351, lr=8.86e-06]Steps:   9%|‚ñâ         | 444/5000 [59:30<10:14:42,  8.10s/it, loss=0.4351, lr=8.88e-06]Steps:   9%|‚ñâ         | 445/5000 [59:38<10:11:40,  8.06s/it, loss=0.4351, lr=8.88e-06]Steps:   9%|‚ñâ         | 445/5000 [59:38<10:11:40,  8.06s/it, loss=0.4631, lr=8.90e-06]Steps:   9%|‚ñâ         | 446/5000 [59:46<10:08:53,  8.02s/it, loss=0.4631, lr=8.90e-06]Steps:   9%|‚ñâ         | 446/5000 [59:46<10:08:53,  8.02s/it, loss=0.6515, lr=8.92e-06]Steps:   9%|‚ñâ         | 447/5000 [59:55<10:12:48,  8.08s/it, loss=0.6515, lr=8.92e-06]Steps:   9%|‚ñâ         | 447/5000 [59:55<10:12:48,  8.08s/it, loss=0.5049, lr=8.94e-06]Steps:   9%|‚ñâ         | 448/5000 [1:00:02<10:10:35,  8.05s/it, loss=0.5049, lr=8.94e-06]Steps:   9%|‚ñâ         | 448/5000 [1:00:02<10:10:35,  8.05s/it, loss=1.0976, lr=8.96e-06]Steps:   9%|‚ñâ         | 449/5000 [1:00:11<10:10:29,  8.05s/it, loss=1.0976, lr=8.96e-06]Steps:   9%|‚ñâ         | 449/5000 [1:00:11<10:10:29,  8.05s/it, loss=0.4056, lr=8.98e-06]Steps:   9%|‚ñâ         | 450/5000 [1:00:15<8:41:03,  6.87s/it, loss=0.4056, lr=8.98e-06] Steps:   9%|‚ñâ         | 450/5000 [1:00:15<8:41:03,  6.87s/it, loss=0.5242, lr=9.00e-06]01/30/2026 05:23:04 - INFO - __main__ - 
==================================================
01/30/2026 05:23:04 - INFO - __main__ - Epoch 5 completed: avg_loss = 0.7769
01/30/2026 05:23:04 - INFO - __main__ - ==================================================


[Step 450] Training Debug Info:
  Loss: 1.138672
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0144, std: 0.8984
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0148, std: 1.3438
  Model pred mean: -0.0068, std: 0.8242
  Sigmas: [0.2080078125]... (timesteps: [208.0])

[Step 450] Training Debug Info:
  Loss: 0.680098
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0327, std: 1.0000
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0300, std: 1.4141
  Model pred mean: -0.0288, std: 1.1484
  Sigmas: [0.5703125]... (timesteps: [570.0])

[Step 450] Training Debug Info:
  Loss: 0.693250
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0349, std: 0.8711
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0356, std: 1.3281
  Model pred mean: 0.0371, std: 1.0312
  Sigmas: [0.5546875]... (timesteps: [553.0])

[Step 450] Training Debug Info:
  Loss: 0.494971
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0090, std: 0.9453
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0090, std: 1.3750
  Model pred mean: -0.0079, std: 1.1875
  Sigmas: [0.6328125]... (timesteps: [631.0])
Steps:   9%|‚ñâ         | 451/5000 [1:00:23<9:22:40,  7.42s/it, loss=0.5242, lr=9.00e-06]Steps:   9%|‚ñâ         | 451/5000 [1:00:23<9:22:40,  7.42s/it, loss=0.4950, lr=9.02e-06]Steps:   9%|‚ñâ         | 452/5000 [1:00:32<9:44:25,  7.71s/it, loss=0.4950, lr=9.02e-06]Steps:   9%|‚ñâ         | 452/5000 [1:00:32<9:44:25,  7.71s/it, loss=0.4228, lr=9.04e-06]Steps:   9%|‚ñâ         | 453/5000 [1:00:40<9:50:53,  7.80s/it, loss=0.4228, lr=9.04e-06]Steps:   9%|‚ñâ         | 453/5000 [1:00:40<9:50:53,  7.80s/it, loss=1.1042, lr=9.06e-06]Steps:   9%|‚ñâ         | 454/5000 [1:00:48<9:54:11,  7.84s/it, loss=1.1042, lr=9.06e-06]Steps:   9%|‚ñâ         | 454/5000 [1:00:48<9:54:11,  7.84s/it, loss=0.4812, lr=9.08e-06]Steps:   9%|‚ñâ         | 455/5000 [1:00:56<9:57:31,  7.89s/it, loss=0.4812, lr=9.08e-06]Steps:   9%|‚ñâ         | 455/5000 [1:00:56<9:57:31,  7.89s/it, loss=1.1287, lr=9.10e-06]Steps:   9%|‚ñâ         | 456/5000 [1:01:04<10:03:57,  7.97s/it, loss=1.1287, lr=9.10e-06]Steps:   9%|‚ñâ         | 456/5000 [1:01:04<10:03:57,  7.97s/it, loss=0.5481, lr=9.12e-06]Steps:   9%|‚ñâ         | 457/5000 [1:01:12<10:04:38,  7.99s/it, loss=0.5481, lr=9.12e-06]Steps:   9%|‚ñâ         | 457/5000 [1:01:12<10:04:38,  7.99s/it, loss=1.1851, lr=9.14e-06]Steps:   9%|‚ñâ         | 458/5000 [1:01:20<10:08:52,  8.04s/it, loss=1.1851, lr=9.14e-06]Steps:   9%|‚ñâ         | 458/5000 [1:01:20<10:08:52,  8.04s/it, loss=0.4076, lr=9.16e-06]Steps:   9%|‚ñâ         | 459/5000 [1:01:28<10:07:21,  8.03s/it, loss=0.4076, lr=9.16e-06]Steps:   9%|‚ñâ         | 459/5000 [1:01:28<10:07:21,  8.03s/it, loss=0.8250, lr=9.18e-06]Steps:   9%|‚ñâ         | 460/5000 [1:01:36<10:06:31,  8.02s/it, loss=0.8250, lr=9.18e-06]Steps:   9%|‚ñâ         | 460/5000 [1:01:36<10:06:31,  8.02s/it, loss=1.1770, lr=9.20e-06]
[Step 460] Training Debug Info:
  Loss: 1.217027
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0013, std: 0.8516
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0031, std: 1.3125
  Model pred mean: -0.0003, std: 0.7148
  Sigmas: [0.2177734375]... (timesteps: [218.0])

[Step 460] Training Debug Info:
  Loss: 0.423279
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0262, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0264, std: 1.3594
  Model pred mean: 0.0293, std: 1.2031
  Sigmas: [0.74609375]... (timesteps: [746.0])

[Step 460] Training Debug Info:
  Loss: 0.595083
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0017, std: 0.8867
  Noise mean: 0.0018, std: 0.9961
  Target mean: 0.0001, std: 1.3359
  Model pred mean: 0.0201, std: 1.1328
  Sigmas: [0.99609375]... (timesteps: [995.0])

[Step 460] Training Debug Info:
  Loss: 0.855647
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0334, std: 0.9922
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0378, std: 1.4141
  Model pred mean: -0.0330, std: 1.0625
  Sigmas: [0.408203125]... (timesteps: [408.0])
Steps:   9%|‚ñâ         | 461/5000 [1:01:44<10:09:56,  8.06s/it, loss=1.1770, lr=9.20e-06]Steps:   9%|‚ñâ         | 461/5000 [1:01:44<10:09:56,  8.06s/it, loss=0.8556, lr=9.22e-06]Steps:   9%|‚ñâ         | 462/5000 [1:01:52<10:07:04,  8.03s/it, loss=0.8556, lr=9.22e-06]Steps:   9%|‚ñâ         | 462/5000 [1:01:52<10:07:04,  8.03s/it, loss=0.4367, lr=9.24e-06]Steps:   9%|‚ñâ         | 463/5000 [1:02:00<10:09:31,  8.06s/it, loss=0.4367, lr=9.24e-06]Steps:   9%|‚ñâ         | 463/5000 [1:02:00<10:09:31,  8.06s/it, loss=1.1527, lr=9.26e-06]Steps:   9%|‚ñâ         | 464/5000 [1:02:08<10:06:11,  8.02s/it, loss=1.1527, lr=9.26e-06]Steps:   9%|‚ñâ         | 464/5000 [1:02:08<10:06:11,  8.02s/it, loss=0.6986, lr=9.28e-06]Steps:   9%|‚ñâ         | 465/5000 [1:02:16<10:05:54,  8.02s/it, loss=0.6986, lr=9.28e-06]Steps:   9%|‚ñâ         | 465/5000 [1:02:16<10:05:54,  8.02s/it, loss=0.3524, lr=9.30e-06]Steps:   9%|‚ñâ         | 466/5000 [1:02:24<10:08:20,  8.05s/it, loss=0.3524, lr=9.30e-06]Steps:   9%|‚ñâ         | 466/5000 [1:02:24<10:08:20,  8.05s/it, loss=1.1043, lr=9.32e-06]Steps:   9%|‚ñâ         | 467/5000 [1:02:32<10:07:35,  8.04s/it, loss=1.1043, lr=9.32e-06]Steps:   9%|‚ñâ         | 467/5000 [1:02:32<10:07:35,  8.04s/it, loss=1.0911, lr=9.34e-06]Steps:   9%|‚ñâ         | 468/5000 [1:02:41<10:12:12,  8.11s/it, loss=1.0911, lr=9.34e-06]Steps:   9%|‚ñâ         | 468/5000 [1:02:41<10:12:12,  8.11s/it, loss=0.8519, lr=9.36e-06]Steps:   9%|‚ñâ         | 469/5000 [1:02:49<10:10:02,  8.08s/it, loss=0.8519, lr=9.36e-06]Steps:   9%|‚ñâ         | 469/5000 [1:02:49<10:10:02,  8.08s/it, loss=0.9018, lr=9.38e-06]Steps:   9%|‚ñâ         | 470/5000 [1:02:57<10:08:10,  8.06s/it, loss=0.9018, lr=9.38e-06]Steps:   9%|‚ñâ         | 470/5000 [1:02:57<10:08:10,  8.06s/it, loss=0.4260, lr=9.40e-06]
[Step 470] Training Debug Info:
  Loss: 1.175534
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0093, std: 0.8828
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0085, std: 1.3359
  Model pred mean: -0.0082, std: 0.7773
  Sigmas: [0.130859375]... (timesteps: [131.0])

[Step 470] Training Debug Info:
  Loss: 1.070867
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0003, std: 0.9609
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0012, std: 1.3828
  Model pred mean: 0.0024, std: 0.9258
  Sigmas: [0.2578125]... (timesteps: [257.0])

[Step 470] Training Debug Info:
  Loss: 1.140288
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0092, std: 0.9023
  Noise mean: -0.0006, std: 0.9961
  Target mean: -0.0097, std: 1.3438
  Model pred mean: -0.0061, std: 0.8281
  Sigmas: [0.2373046875]... (timesteps: [237.0])

[Step 470] Training Debug Info:
  Loss: 0.511782
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0266, std: 0.9180
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0283, std: 1.3594
  Model pred mean: 0.0245, std: 1.1562
  Sigmas: [0.6484375]... (timesteps: [649.0])
Steps:   9%|‚ñâ         | 471/5000 [1:03:05<10:07:53,  8.05s/it, loss=0.4260, lr=9.40e-06]Steps:   9%|‚ñâ         | 471/5000 [1:03:05<10:07:53,  8.05s/it, loss=0.5118, lr=9.42e-06]Steps:   9%|‚ñâ         | 472/5000 [1:03:13<10:11:04,  8.10s/it, loss=0.5118, lr=9.42e-06]Steps:   9%|‚ñâ         | 472/5000 [1:03:13<10:11:04,  8.10s/it, loss=0.4777, lr=9.44e-06]Steps:   9%|‚ñâ         | 473/5000 [1:03:21<10:08:11,  8.06s/it, loss=0.4777, lr=9.44e-06]Steps:   9%|‚ñâ         | 473/5000 [1:03:21<10:08:11,  8.06s/it, loss=0.7363, lr=9.46e-06]Steps:   9%|‚ñâ         | 474/5000 [1:03:29<10:10:51,  8.10s/it, loss=0.7363, lr=9.46e-06]Steps:   9%|‚ñâ         | 474/5000 [1:03:29<10:10:51,  8.10s/it, loss=0.6382, lr=9.48e-06]Steps:  10%|‚ñâ         | 475/5000 [1:03:37<10:06:19,  8.04s/it, loss=0.6382, lr=9.48e-06]Steps:  10%|‚ñâ         | 475/5000 [1:03:37<10:06:19,  8.04s/it, loss=0.6166, lr=9.50e-06]Steps:  10%|‚ñâ         | 476/5000 [1:03:45<10:04:23,  8.02s/it, loss=0.6166, lr=9.50e-06]Steps:  10%|‚ñâ         | 476/5000 [1:03:45<10:04:23,  8.02s/it, loss=1.1266, lr=9.52e-06]Steps:  10%|‚ñâ         | 477/5000 [1:03:53<10:09:19,  8.08s/it, loss=1.1266, lr=9.52e-06]Steps:  10%|‚ñâ         | 477/5000 [1:03:53<10:09:19,  8.08s/it, loss=0.7983, lr=9.54e-06]Steps:  10%|‚ñâ         | 478/5000 [1:04:01<10:06:46,  8.05s/it, loss=0.7983, lr=9.54e-06]Steps:  10%|‚ñâ         | 478/5000 [1:04:01<10:06:46,  8.05s/it, loss=0.7341, lr=9.56e-06]Steps:  10%|‚ñâ         | 479/5000 [1:04:09<10:11:30,  8.12s/it, loss=0.7341, lr=9.56e-06]Steps:  10%|‚ñâ         | 479/5000 [1:04:09<10:11:30,  8.12s/it, loss=0.6298, lr=9.58e-06]Steps:  10%|‚ñâ         | 480/5000 [1:04:17<10:10:25,  8.10s/it, loss=0.6298, lr=9.58e-06]Steps:  10%|‚ñâ         | 480/5000 [1:04:17<10:10:25,  8.10s/it, loss=0.3287, lr=9.60e-06]
[Step 480] Training Debug Info:
  Loss: 0.498266
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0002, std: 0.9336
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0007, std: 1.3672
  Model pred mean: 0.0038, std: 1.1797
  Sigmas: [0.59375]... (timesteps: [594.0])

[Step 480] Training Debug Info:
  Loss: 0.564198
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0087, std: 0.8867
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0071, std: 1.3359
  Model pred mean: -0.0070, std: 1.1172
  Sigmas: [0.62890625]... (timesteps: [628.0])

[Step 480] Training Debug Info:
  Loss: 1.149546
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0149, std: 0.9023
  Noise mean: -0.0004, std: 0.9961
  Target mean: -0.0154, std: 1.3438
  Model pred mean: -0.0124, std: 0.8125
  Sigmas: [0.19140625]... (timesteps: [191.0])

[Step 480] Training Debug Info:
  Loss: 0.736312
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0027, std: 0.8633
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0032, std: 1.3203
  Model pred mean: 0.0038, std: 1.0156
  Sigmas: [0.52734375]... (timesteps: [529.0])
Steps:  10%|‚ñâ         | 481/5000 [1:04:25<10:07:25,  8.06s/it, loss=0.3287, lr=9.60e-06]Steps:  10%|‚ñâ         | 481/5000 [1:04:25<10:07:25,  8.06s/it, loss=0.7363, lr=9.62e-06]Steps:  10%|‚ñâ         | 482/5000 [1:04:33<10:06:04,  8.05s/it, loss=0.7363, lr=9.62e-06]Steps:  10%|‚ñâ         | 482/5000 [1:04:33<10:06:04,  8.05s/it, loss=1.1411, lr=9.64e-06]Steps:  10%|‚ñâ         | 483/5000 [1:04:42<10:08:55,  8.09s/it, loss=1.1411, lr=9.64e-06]Steps:  10%|‚ñâ         | 483/5000 [1:04:42<10:08:55,  8.09s/it, loss=1.1359, lr=9.66e-06]Steps:  10%|‚ñâ         | 484/5000 [1:04:50<10:10:19,  8.11s/it, loss=1.1359, lr=9.66e-06]Steps:  10%|‚ñâ         | 484/5000 [1:04:50<10:10:19,  8.11s/it, loss=0.6657, lr=9.68e-06]Steps:  10%|‚ñâ         | 485/5000 [1:04:58<10:06:36,  8.06s/it, loss=0.6657, lr=9.68e-06]Steps:  10%|‚ñâ         | 485/5000 [1:04:58<10:06:36,  8.06s/it, loss=0.4000, lr=9.70e-06]Steps:  10%|‚ñâ         | 486/5000 [1:05:06<10:06:08,  8.06s/it, loss=0.4000, lr=9.70e-06]Steps:  10%|‚ñâ         | 486/5000 [1:05:06<10:06:08,  8.06s/it, loss=1.1889, lr=9.72e-06]Steps:  10%|‚ñâ         | 487/5000 [1:05:14<10:03:10,  8.02s/it, loss=1.1889, lr=9.72e-06]Steps:  10%|‚ñâ         | 487/5000 [1:05:14<10:03:10,  8.02s/it, loss=0.3419, lr=9.74e-06]Steps:  10%|‚ñâ         | 488/5000 [1:05:22<10:06:00,  8.06s/it, loss=0.3419, lr=9.74e-06]Steps:  10%|‚ñâ         | 488/5000 [1:05:22<10:06:00,  8.06s/it, loss=0.6230, lr=9.76e-06]Steps:  10%|‚ñâ         | 489/5000 [1:05:30<10:08:42,  8.10s/it, loss=0.6230, lr=9.76e-06]Steps:  10%|‚ñâ         | 489/5000 [1:05:30<10:08:42,  8.10s/it, loss=0.7521, lr=9.78e-06]Steps:  10%|‚ñâ         | 490/5000 [1:05:38<10:07:26,  8.08s/it, loss=0.7521, lr=9.78e-06]Steps:  10%|‚ñâ         | 490/5000 [1:05:38<10:07:26,  8.08s/it, loss=0.7767, lr=9.80e-06]
[Step 490] Training Debug Info:
  Loss: 0.522397
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0259, std: 0.8945
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0261, std: 1.3438
  Model pred mean: -0.0308, std: 1.1328
  Sigmas: [0.6484375]... (timesteps: [647.0])

[Step 490] Training Debug Info:
  Loss: 0.594197
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0024, std: 0.8789
  Noise mean: 0.0017, std: 1.0000
  Target mean: -0.0006, std: 1.3359
  Model pred mean: -0.0061, std: 1.0859
  Sigmas: [0.59765625]... (timesteps: [596.0])

[Step 490] Training Debug Info:
  Loss: 0.449526
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0574, std: 0.9180
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0566, std: 1.3594
  Model pred mean: -0.0574, std: 1.1797
  Sigmas: [0.7109375]... (timesteps: [711.0])

[Step 490] Training Debug Info:
  Loss: 0.379495
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0147, std: 0.9062
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0134, std: 1.3516
  Model pred mean: 0.0192, std: 1.2031
  Sigmas: [0.83984375]... (timesteps: [838.0])
Steps:  10%|‚ñâ         | 491/5000 [1:05:46<10:06:50,  8.07s/it, loss=0.7767, lr=9.80e-06]Steps:  10%|‚ñâ         | 491/5000 [1:05:46<10:06:50,  8.07s/it, loss=0.3795, lr=9.82e-06]Steps:  10%|‚ñâ         | 492/5000 [1:05:54<10:04:15,  8.04s/it, loss=0.3795, lr=9.82e-06]Steps:  10%|‚ñâ         | 492/5000 [1:05:54<10:04:15,  8.04s/it, loss=1.0943, lr=9.84e-06]Steps:  10%|‚ñâ         | 493/5000 [1:06:02<10:02:48,  8.02s/it, loss=1.0943, lr=9.84e-06]Steps:  10%|‚ñâ         | 493/5000 [1:06:02<10:02:48,  8.02s/it, loss=0.3745, lr=9.86e-06]Steps:  10%|‚ñâ         | 494/5000 [1:06:10<10:07:27,  8.09s/it, loss=0.3745, lr=9.86e-06]Steps:  10%|‚ñâ         | 494/5000 [1:06:10<10:07:27,  8.09s/it, loss=0.6765, lr=9.88e-06]Steps:  10%|‚ñâ         | 495/5000 [1:06:19<10:13:36,  8.17s/it, loss=0.6765, lr=9.88e-06]Steps:  10%|‚ñâ         | 495/5000 [1:06:19<10:13:36,  8.17s/it, loss=0.8548, lr=9.90e-06]Steps:  10%|‚ñâ         | 496/5000 [1:06:27<10:09:33,  8.12s/it, loss=0.8548, lr=9.90e-06]Steps:  10%|‚ñâ         | 496/5000 [1:06:27<10:09:33,  8.12s/it, loss=0.4128, lr=9.92e-06]Steps:  10%|‚ñâ         | 497/5000 [1:06:35<10:06:56,  8.09s/it, loss=0.4128, lr=9.92e-06]Steps:  10%|‚ñâ         | 497/5000 [1:06:35<10:06:56,  8.09s/it, loss=0.6643, lr=9.94e-06]Steps:  10%|‚ñâ         | 498/5000 [1:06:43<10:05:18,  8.07s/it, loss=0.6643, lr=9.94e-06]Steps:  10%|‚ñâ         | 498/5000 [1:06:43<10:05:18,  8.07s/it, loss=0.4477, lr=9.96e-06]Steps:  10%|‚ñâ         | 499/5000 [1:06:51<10:07:31,  8.10s/it, loss=0.4477, lr=9.96e-06]Steps:  10%|‚ñâ         | 499/5000 [1:06:51<10:07:31,  8.10s/it, loss=1.0216, lr=9.98e-06]Steps:  10%|‚ñà         | 500/5000 [1:06:59<10:10:35,  8.14s/it, loss=1.0216, lr=9.98e-06]Steps:  10%|‚ñà         | 500/5000 [1:06:59<10:10:35,  8.14s/it, loss=0.3923, lr=1.00e-05]01/30/2026 05:29:48 - INFO - __main__ - 
[Step 500] ‚úÖ Loss in normal range (0.3923)
01/30/2026 05:29:48 - INFO - __main__ -   Loss avg (last 100): 0.7488
01/30/2026 05:29:48 - INFO - __main__ -   Loss range: [0.3287, 1.2001]
01/30/2026 05:29:48 - INFO - __main__ - 
üîç Running validation at step 500...
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 500 (parquet mode)...
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 500...
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/4: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/4: The figure presents a comparative diagram of four different defect detection tas...
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt01_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/4: The figure illustrates a linear probing framework applied to a frozen multimodal...
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt02_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/4: The figure presents a conceptual comparison of four different point cloud comple...
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 05:29:48 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500/step000500_prompt03_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ‚úÖ Validation complete! Saved 4 images to:
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_000500
01/30/2026 05:29:48 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 500] Training Debug Info:
  Loss: 1.079215
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0124, std: 0.9258
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0135, std: 1.3594
  Model pred mean: 0.0148, std: 0.8906
  Sigmas: [0.2734375]... (timesteps: [274.0])

[Step 500] Training Debug Info:
  Loss: 0.437447
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0264, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0249, std: 1.3516
  Model pred mean: 0.0322, std: 1.1797
  Sigmas: [0.7109375]... (timesteps: [709.0])

[Step 500] Training Debug Info:
  Loss: 0.659165
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0199, std: 0.9102
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0195, std: 1.3516
  Model pred mean: -0.0184, std: 1.0859
  Sigmas: [0.52734375]... (timesteps: [526.0])

[Step 500] Training Debug Info:
  Loss: 0.448917
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0364, std: 0.8945
  Noise mean: -0.0007, std: 1.0000
  Target mean: -0.0371, std: 1.3438
  Model pred mean: -0.0273, std: 1.1641
  Sigmas: [0.8515625]... (timesteps: [852.0])
Steps:  10%|‚ñà         | 501/5000 [1:07:08<10:24:35,  8.33s/it, loss=0.3923, lr=1.00e-05]Steps:  10%|‚ñà         | 501/5000 [1:07:08<10:24:35,  8.33s/it, loss=0.4489, lr=1.00e-05]Steps:  10%|‚ñà         | 502/5000 [1:07:16<10:19:13,  8.26s/it, loss=0.4489, lr=1.00e-05]Steps:  10%|‚ñà         | 502/5000 [1:07:16<10:19:13,  8.26s/it, loss=0.4602, lr=1.00e-05]Steps:  10%|‚ñà         | 503/5000 [1:07:24<10:13:07,  8.18s/it, loss=0.4602, lr=1.00e-05]Steps:  10%|‚ñà         | 503/5000 [1:07:24<10:13:07,  8.18s/it, loss=0.4417, lr=1.00e-05]Steps:  10%|‚ñà         | 504/5000 [1:07:32<10:06:22,  8.09s/it, loss=0.4417, lr=1.00e-05]Steps:  10%|‚ñà         | 504/5000 [1:07:32<10:06:22,  8.09s/it, loss=0.4473, lr=1.00e-05]Steps:  10%|‚ñà         | 505/5000 [1:07:40<10:07:41,  8.11s/it, loss=0.4473, lr=1.00e-05]Steps:  10%|‚ñà         | 505/5000 [1:07:40<10:07:41,  8.11s/it, loss=0.7019, lr=1.00e-05]Steps:  10%|‚ñà         | 506/5000 [1:07:48<10:08:00,  8.12s/it, loss=0.7019, lr=1.00e-05]Steps:  10%|‚ñà         | 506/5000 [1:07:48<10:08:00,  8.12s/it, loss=0.6855, lr=1.00e-05]Steps:  10%|‚ñà         | 507/5000 [1:07:56<10:04:36,  8.07s/it, loss=0.6855, lr=1.00e-05]Steps:  10%|‚ñà         | 507/5000 [1:07:56<10:04:36,  8.07s/it, loss=0.8687, lr=1.00e-05]Steps:  10%|‚ñà         | 508/5000 [1:08:04<10:02:17,  8.04s/it, loss=0.8687, lr=1.00e-05]Steps:  10%|‚ñà         | 508/5000 [1:08:04<10:02:17,  8.04s/it, loss=0.4289, lr=1.00e-05]Steps:  10%|‚ñà         | 509/5000 [1:08:12<10:01:31,  8.04s/it, loss=0.4289, lr=1.00e-05]Steps:  10%|‚ñà         | 509/5000 [1:08:12<10:01:31,  8.04s/it, loss=0.4214, lr=1.00e-05]Steps:  10%|‚ñà         | 510/5000 [1:08:20<10:00:11,  8.02s/it, loss=0.4214, lr=1.00e-05]Steps:  10%|‚ñà         | 510/5000 [1:08:20<10:00:11,  8.02s/it, loss=0.4072, lr=1.00e-05]
[Step 510] Training Debug Info:
  Loss: 0.410017
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0148, std: 0.9336
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0161, std: 1.3672
  Model pred mean: -0.0166, std: 1.2188
  Sigmas: [0.87890625]... (timesteps: [879.0])

[Step 510] Training Debug Info:
  Loss: 0.494602
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0058, std: 0.8711
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0046, std: 1.3281
  Model pred mean: 0.0098, std: 1.1250
  Sigmas: [0.6953125]... (timesteps: [695.0])

[Step 510] Training Debug Info:
  Loss: 1.028377
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0181, std: 0.8789
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0159, std: 1.3281
  Model pred mean: 0.0204, std: 0.8633
  Sigmas: [0.35546875]... (timesteps: [355.0])

[Step 510] Training Debug Info:
  Loss: 0.776223
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0422, std: 0.9102
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0417, std: 1.3516
  Model pred mean: 0.0432, std: 1.0312
  Sigmas: [0.48828125]... (timesteps: [488.0])
Steps:  10%|‚ñà         | 511/5000 [1:08:28<10:07:17,  8.12s/it, loss=0.4072, lr=1.00e-05]Steps:  10%|‚ñà         | 511/5000 [1:08:28<10:07:17,  8.12s/it, loss=0.7762, lr=1.00e-05]Steps:  10%|‚ñà         | 512/5000 [1:08:36<10:04:18,  8.08s/it, loss=0.7762, lr=1.00e-05]Steps:  10%|‚ñà         | 512/5000 [1:08:36<10:04:18,  8.08s/it, loss=0.8739, lr=1.00e-05]Steps:  10%|‚ñà         | 513/5000 [1:08:44<10:01:24,  8.04s/it, loss=0.8739, lr=1.00e-05]Steps:  10%|‚ñà         | 513/5000 [1:08:44<10:01:24,  8.04s/it, loss=0.6398, lr=1.00e-05]Steps:  10%|‚ñà         | 514/5000 [1:08:52<9:59:39,  8.02s/it, loss=0.6398, lr=1.00e-05] Steps:  10%|‚ñà         | 514/5000 [1:08:52<9:59:39,  8.02s/it, loss=1.0271, lr=1.00e-05]Steps:  10%|‚ñà         | 515/5000 [1:09:00<10:00:33,  8.03s/it, loss=1.0271, lr=1.00e-05]Steps:  10%|‚ñà         | 515/5000 [1:09:00<10:00:33,  8.03s/it, loss=0.6839, lr=1.00e-05]Steps:  10%|‚ñà         | 516/5000 [1:09:09<10:08:09,  8.14s/it, loss=0.6839, lr=1.00e-05]Steps:  10%|‚ñà         | 516/5000 [1:09:09<10:08:09,  8.14s/it, loss=0.7343, lr=1.00e-05]Steps:  10%|‚ñà         | 517/5000 [1:09:17<10:04:03,  8.08s/it, loss=0.7343, lr=1.00e-05]Steps:  10%|‚ñà         | 517/5000 [1:09:17<10:04:03,  8.08s/it, loss=0.7827, lr=1.00e-05]Steps:  10%|‚ñà         | 518/5000 [1:09:25<10:01:33,  8.05s/it, loss=0.7827, lr=1.00e-05]Steps:  10%|‚ñà         | 518/5000 [1:09:25<10:01:33,  8.05s/it, loss=1.1682, lr=1.00e-05]Steps:  10%|‚ñà         | 519/5000 [1:09:33<10:00:19,  8.04s/it, loss=1.1682, lr=1.00e-05]Steps:  10%|‚ñà         | 519/5000 [1:09:33<10:00:19,  8.04s/it, loss=0.6515, lr=1.00e-05]Steps:  10%|‚ñà         | 520/5000 [1:09:41<9:59:05,  8.02s/it, loss=0.6515, lr=1.00e-05] Steps:  10%|‚ñà         | 520/5000 [1:09:41<9:59:05,  8.02s/it, loss=1.0218, lr=1.00e-05]
[Step 520] Training Debug Info:
  Loss: 0.647419
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0144, std: 0.8789
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0161, std: 1.3281
  Model pred mean: 0.0170, std: 1.0625
  Sigmas: [0.57421875]... (timesteps: [575.0])

[Step 520] Training Debug Info:
  Loss: 0.596165
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0204, std: 0.8672
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0177, std: 1.3281
  Model pred mean: 0.0199, std: 1.0781
  Sigmas: [0.6171875]... (timesteps: [617.0])

[Step 520] Training Debug Info:
  Loss: 0.873180
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0126, std: 0.9883
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0129, std: 1.4062
  Model pred mean: -0.0126, std: 1.0547
  Sigmas: [0.400390625]... (timesteps: [400.0])

[Step 520] Training Debug Info:
  Loss: 1.153930
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0023, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0015, std: 1.3516
  Model pred mean: 0.0014, std: 0.8164
  Sigmas: [0.10888671875]... (timesteps: [109.0])
Steps:  10%|‚ñà         | 521/5000 [1:09:49<10:01:58,  8.06s/it, loss=1.0218, lr=1.00e-05]Steps:  10%|‚ñà         | 521/5000 [1:09:49<10:01:58,  8.06s/it, loss=1.1539, lr=1.00e-05]Steps:  10%|‚ñà         | 522/5000 [1:09:57<10:04:49,  8.10s/it, loss=1.1539, lr=1.00e-05]Steps:  10%|‚ñà         | 522/5000 [1:09:57<10:04:49,  8.10s/it, loss=0.5041, lr=1.00e-05]Steps:  10%|‚ñà         | 523/5000 [1:10:05<10:02:19,  8.07s/it, loss=0.5041, lr=1.00e-05]Steps:  10%|‚ñà         | 523/5000 [1:10:05<10:02:19,  8.07s/it, loss=1.1540, lr=1.00e-05]Steps:  10%|‚ñà         | 524/5000 [1:10:13<10:02:15,  8.07s/it, loss=1.1540, lr=1.00e-05]Steps:  10%|‚ñà         | 524/5000 [1:10:13<10:02:15,  8.07s/it, loss=0.7339, lr=1.00e-05]Steps:  10%|‚ñà         | 525/5000 [1:10:17<8:33:57,  6.89s/it, loss=0.7339, lr=1.00e-05] Steps:  10%|‚ñà         | 525/5000 [1:10:17<8:33:57,  6.89s/it, loss=0.6907, lr=1.00e-05]01/30/2026 05:33:06 - INFO - __main__ - 
==================================================
01/30/2026 05:33:06 - INFO - __main__ - Epoch 6 completed: avg_loss = 0.7231
01/30/2026 05:33:06 - INFO - __main__ - ==================================================

Steps:  11%|‚ñà         | 526/5000 [1:10:26<9:04:08,  7.30s/it, loss=0.6907, lr=1.00e-05]Steps:  11%|‚ñà         | 526/5000 [1:10:26<9:04:08,  7.30s/it, loss=1.0445, lr=1.00e-05]Steps:  11%|‚ñà         | 527/5000 [1:10:34<9:29:07,  7.63s/it, loss=1.0445, lr=1.00e-05]Steps:  11%|‚ñà         | 527/5000 [1:10:34<9:29:07,  7.63s/it, loss=0.6178, lr=1.00e-05]Steps:  11%|‚ñà         | 528/5000 [1:10:42<9:46:35,  7.87s/it, loss=0.6178, lr=1.00e-05]Steps:  11%|‚ñà         | 528/5000 [1:10:42<9:46:35,  7.87s/it, loss=1.0139, lr=1.00e-05]Steps:  11%|‚ñà         | 529/5000 [1:10:50<9:48:21,  7.90s/it, loss=1.0139, lr=1.00e-05]Steps:  11%|‚ñà         | 529/5000 [1:10:50<9:48:21,  7.90s/it, loss=1.1001, lr=1.00e-05]Steps:  11%|‚ñà         | 530/5000 [1:10:58<9:50:13,  7.92s/it, loss=1.1001, lr=1.00e-05]Steps:  11%|‚ñà         | 530/5000 [1:10:58<9:50:13,  7.92s/it, loss=0.8062, lr=1.00e-05]
[Step 530] Training Debug Info:
  Loss: 1.123271
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0262, std: 0.9258
  Noise mean: 0.0025, std: 1.0000
  Target mean: 0.0288, std: 1.3672
  Model pred mean: 0.0233, std: 0.8516
  Sigmas: [0.0751953125]... (timesteps: [75.0])

[Step 530] Training Debug Info:
  Loss: 1.076531
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0136, std: 0.9141
  Noise mean: 0.0052, std: 1.0000
  Target mean: 0.0188, std: 1.3516
  Model pred mean: 0.0125, std: 0.8672
  Sigmas: [0.0390625]... (timesteps: [39.0])

[Step 530] Training Debug Info:
  Loss: 1.048164
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0070, std: 0.8906
  Noise mean: -0.0048, std: 1.0000
  Target mean: 0.0022, std: 1.3359
  Model pred mean: 0.0062, std: 0.8672
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 530] Training Debug Info:
  Loss: 0.704899
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0071, std: 0.8984
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0082, std: 1.3438
  Model pred mean: 0.0081, std: 1.0625
  Sigmas: [0.5234375]... (timesteps: [525.0])
Steps:  11%|‚ñà         | 531/5000 [1:11:06<9:51:09,  7.94s/it, loss=0.8062, lr=1.00e-05]Steps:  11%|‚ñà         | 531/5000 [1:11:06<9:51:09,  7.94s/it, loss=0.7049, lr=1.00e-05]Steps:  11%|‚ñà         | 532/5000 [1:11:14<9:52:26,  7.96s/it, loss=0.7049, lr=1.00e-05]Steps:  11%|‚ñà         | 532/5000 [1:11:14<9:52:26,  7.96s/it, loss=1.1823, lr=1.00e-05]Steps:  11%|‚ñà         | 533/5000 [1:11:23<10:02:01,  8.09s/it, loss=1.1823, lr=1.00e-05]Steps:  11%|‚ñà         | 533/5000 [1:11:23<10:02:01,  8.09s/it, loss=1.1640, lr=1.00e-05]Steps:  11%|‚ñà         | 534/5000 [1:11:31<10:00:02,  8.06s/it, loss=1.1640, lr=1.00e-05]Steps:  11%|‚ñà         | 534/5000 [1:11:31<10:00:02,  8.06s/it, loss=0.7832, lr=1.00e-05]Steps:  11%|‚ñà         | 535/5000 [1:11:39<9:58:06,  8.04s/it, loss=0.7832, lr=1.00e-05] Steps:  11%|‚ñà         | 535/5000 [1:11:39<9:58:06,  8.04s/it, loss=0.3964, lr=1.00e-05]Steps:  11%|‚ñà         | 536/5000 [1:11:47<9:56:21,  8.02s/it, loss=0.3964, lr=1.00e-05]Steps:  11%|‚ñà         | 536/5000 [1:11:47<9:56:21,  8.02s/it, loss=1.0441, lr=1.00e-05]Steps:  11%|‚ñà         | 537/5000 [1:11:55<9:54:53,  8.00s/it, loss=1.0441, lr=1.00e-05]Steps:  11%|‚ñà         | 537/5000 [1:11:55<9:54:53,  8.00s/it, loss=0.8526, lr=1.00e-05]Steps:  11%|‚ñà         | 538/5000 [1:12:03<9:58:33,  8.05s/it, loss=0.8526, lr=1.00e-05]Steps:  11%|‚ñà         | 538/5000 [1:12:03<9:58:33,  8.05s/it, loss=0.4304, lr=1.00e-05]Steps:  11%|‚ñà         | 539/5000 [1:12:11<10:02:21,  8.10s/it, loss=0.4304, lr=1.00e-05]Steps:  11%|‚ñà         | 539/5000 [1:12:11<10:02:21,  8.10s/it, loss=1.1518, lr=1.00e-05]Steps:  11%|‚ñà         | 540/5000 [1:12:19<10:03:08,  8.11s/it, loss=1.1518, lr=1.00e-05]Steps:  11%|‚ñà         | 540/5000 [1:12:19<10:03:08,  8.11s/it, loss=0.4861, lr=1.00e-05]
[Step 540] Training Debug Info:
  Loss: 1.066878
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0089, std: 0.9727
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0082, std: 1.3984
  Model pred mean: -0.0109, std: 0.9375
  Sigmas: [0.11083984375]... (timesteps: [111.0])

[Step 540] Training Debug Info:
  Loss: 0.918229
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0698, std: 0.9375
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0703, std: 1.3672
  Model pred mean: 0.0669, std: 0.9805
  Sigmas: [0.330078125]... (timesteps: [331.0])

[Step 540] Training Debug Info:
  Loss: 1.102579
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0094, std: 0.9453
  Noise mean: -0.0028, std: 1.0000
  Target mean: 0.0066, std: 1.3828
  Model pred mean: 0.0096, std: 0.8867
  Sigmas: [0.10009765625]... (timesteps: [100.0])

[Step 540] Training Debug Info:
  Loss: 0.587265
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0006, std: 0.9297
  Noise mean: 0.0015, std: 1.0000
  Target mean: 0.0021, std: 1.3672
  Model pred mean: -0.0035, std: 1.1484
  Sigmas: [0.5234375]... (timesteps: [524.0])
Steps:  11%|‚ñà         | 541/5000 [1:12:27<10:01:13,  8.09s/it, loss=0.4861, lr=1.00e-05]Steps:  11%|‚ñà         | 541/5000 [1:12:27<10:01:13,  8.09s/it, loss=0.5873, lr=1.00e-05]Steps:  11%|‚ñà         | 542/5000 [1:12:35<10:00:30,  8.08s/it, loss=0.5873, lr=1.00e-05]Steps:  11%|‚ñà         | 542/5000 [1:12:35<10:00:30,  8.08s/it, loss=1.2133, lr=1.00e-05]Steps:  11%|‚ñà         | 543/5000 [1:12:44<10:04:34,  8.14s/it, loss=1.2133, lr=1.00e-05]Steps:  11%|‚ñà         | 543/5000 [1:12:44<10:04:34,  8.14s/it, loss=0.4767, lr=1.00e-05]Steps:  11%|‚ñà         | 544/5000 [1:12:52<10:09:36,  8.21s/it, loss=0.4767, lr=1.00e-05]Steps:  11%|‚ñà         | 544/5000 [1:12:52<10:09:36,  8.21s/it, loss=0.8770, lr=1.00e-05]Steps:  11%|‚ñà         | 545/5000 [1:13:00<10:06:00,  8.16s/it, loss=0.8770, lr=1.00e-05]Steps:  11%|‚ñà         | 545/5000 [1:13:00<10:06:00,  8.16s/it, loss=0.5852, lr=1.00e-05]Steps:  11%|‚ñà         | 546/5000 [1:13:08<10:05:35,  8.16s/it, loss=0.5852, lr=1.00e-05]Steps:  11%|‚ñà         | 546/5000 [1:13:08<10:05:35,  8.16s/it, loss=0.9747, lr=1.00e-05]Steps:  11%|‚ñà         | 547/5000 [1:13:16<10:03:48,  8.14s/it, loss=0.9747, lr=1.00e-05]Steps:  11%|‚ñà         | 547/5000 [1:13:16<10:03:48,  8.14s/it, loss=0.6380, lr=1.00e-05]Steps:  11%|‚ñà         | 548/5000 [1:13:24<10:03:52,  8.14s/it, loss=0.6380, lr=1.00e-05]Steps:  11%|‚ñà         | 548/5000 [1:13:24<10:03:52,  8.14s/it, loss=0.5802, lr=1.00e-05]Steps:  11%|‚ñà         | 549/5000 [1:13:33<10:06:47,  8.18s/it, loss=0.5802, lr=1.00e-05]Steps:  11%|‚ñà         | 549/5000 [1:13:33<10:06:47,  8.18s/it, loss=0.7238, lr=1.00e-05]Steps:  11%|‚ñà         | 550/5000 [1:13:41<10:09:53,  8.22s/it, loss=0.7238, lr=1.00e-05]Steps:  11%|‚ñà         | 550/5000 [1:13:41<10:09:53,  8.22s/it, loss=0.4409, lr=1.00e-05]
[Step 550] Training Debug Info:
  Loss: 0.387389
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0024, std: 0.8867
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0016, std: 1.3359
  Model pred mean: -0.0011, std: 1.1875
  Sigmas: [0.91015625]... (timesteps: [910.0])

[Step 550] Training Debug Info:
  Loss: 0.543278
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0081, std: 0.8789
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0089, std: 1.3281
  Model pred mean: 0.0001, std: 1.1016
  Sigmas: [0.62109375]... (timesteps: [622.0])

[Step 550] Training Debug Info:
  Loss: 0.423368
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0099, std: 0.8828
  Noise mean: -0.0001, std: 0.9961
  Target mean: 0.0098, std: 1.3359
  Model pred mean: 0.0109, std: 1.1641
  Sigmas: [0.75]... (timesteps: [751.0])

[Step 550] Training Debug Info:
  Loss: 1.012305
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0165, std: 0.9062
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0182, std: 1.3516
  Model pred mean: -0.0175, std: 0.9023
  Sigmas: [0.326171875]... (timesteps: [326.0])
Steps:  11%|‚ñà         | 551/5000 [1:13:49<10:05:11,  8.16s/it, loss=0.4409, lr=1.00e-05]Steps:  11%|‚ñà         | 551/5000 [1:13:49<10:05:11,  8.16s/it, loss=1.0123, lr=1.00e-05]Steps:  11%|‚ñà         | 552/5000 [1:13:57<10:05:16,  8.16s/it, loss=1.0123, lr=1.00e-05]Steps:  11%|‚ñà         | 552/5000 [1:13:57<10:05:16,  8.16s/it, loss=0.6188, lr=1.00e-05]Steps:  11%|‚ñà         | 553/5000 [1:14:05<10:01:14,  8.11s/it, loss=0.6188, lr=1.00e-05]Steps:  11%|‚ñà         | 553/5000 [1:14:05<10:01:14,  8.11s/it, loss=1.1171, lr=1.00e-05]Steps:  11%|‚ñà         | 554/5000 [1:14:13<10:05:52,  8.18s/it, loss=1.1171, lr=1.00e-05]Steps:  11%|‚ñà         | 554/5000 [1:14:13<10:05:52,  8.18s/it, loss=0.4135, lr=1.00e-05]Steps:  11%|‚ñà         | 555/5000 [1:14:22<10:10:57,  8.25s/it, loss=0.4135, lr=1.00e-05]Steps:  11%|‚ñà         | 555/5000 [1:14:22<10:10:57,  8.25s/it, loss=0.9120, lr=1.00e-05]Steps:  11%|‚ñà         | 556/5000 [1:14:30<10:04:20,  8.16s/it, loss=0.9120, lr=1.00e-05]Steps:  11%|‚ñà         | 556/5000 [1:14:30<10:04:20,  8.16s/it, loss=0.6998, lr=1.00e-05]Steps:  11%|‚ñà         | 557/5000 [1:14:38<10:01:19,  8.12s/it, loss=0.6998, lr=1.00e-05]Steps:  11%|‚ñà         | 557/5000 [1:14:38<10:01:19,  8.12s/it, loss=0.3640, lr=1.00e-05]Steps:  11%|‚ñà         | 558/5000 [1:14:46<9:57:43,  8.07s/it, loss=0.3640, lr=1.00e-05] Steps:  11%|‚ñà         | 558/5000 [1:14:46<9:57:43,  8.07s/it, loss=0.4431, lr=1.00e-05]Steps:  11%|‚ñà         | 559/5000 [1:14:54<9:58:40,  8.09s/it, loss=0.4431, lr=1.00e-05]Steps:  11%|‚ñà         | 559/5000 [1:14:54<9:58:40,  8.09s/it, loss=1.1612, lr=1.00e-05]Steps:  11%|‚ñà         | 560/5000 [1:15:02<10:00:01,  8.11s/it, loss=1.1612, lr=1.00e-05]Steps:  11%|‚ñà         | 560/5000 [1:15:02<10:00:01,  8.11s/it, loss=0.5018, lr=1.00e-05]
[Step 560] Training Debug Info:
  Loss: 0.947274
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0356, std: 0.9219
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0361, std: 1.3594
  Model pred mean: 0.0330, std: 0.9375
  Sigmas: [0.353515625]... (timesteps: [354.0])

[Step 560] Training Debug Info:
  Loss: 0.456697
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0266, std: 0.9219
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0261, std: 1.3594
  Model pred mean: -0.0278, std: 1.1719
  Sigmas: [0.83984375]... (timesteps: [839.0])

[Step 560] Training Debug Info:
  Loss: 1.109618
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0068, std: 0.8945
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0086, std: 1.3438
  Model pred mean: 0.0032, std: 0.8242
  Sigmas: [0.296875]... (timesteps: [296.0])

[Step 560] Training Debug Info:
  Loss: 0.557990
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0099, std: 0.8867
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0096, std: 1.3359
  Model pred mean: -0.0010, std: 1.1250
  Sigmas: [0.93359375]... (timesteps: [932.0])
Steps:  11%|‚ñà         | 561/5000 [1:15:10<9:59:02,  8.10s/it, loss=0.5018, lr=1.00e-05] Steps:  11%|‚ñà         | 561/5000 [1:15:10<9:59:02,  8.10s/it, loss=0.5580, lr=1.00e-05]Steps:  11%|‚ñà         | 562/5000 [1:15:18<9:54:43,  8.04s/it, loss=0.5580, lr=1.00e-05]Steps:  11%|‚ñà         | 562/5000 [1:15:18<9:54:43,  8.04s/it, loss=0.6223, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 563/5000 [1:15:26<9:54:29,  8.04s/it, loss=0.6223, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 563/5000 [1:15:26<9:54:29,  8.04s/it, loss=0.6699, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 564/5000 [1:15:34<9:54:12,  8.04s/it, loss=0.6699, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 564/5000 [1:15:34<9:54:12,  8.04s/it, loss=0.4283, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 565/5000 [1:15:42<9:59:02,  8.10s/it, loss=0.4283, lr=1.00e-05]Steps:  11%|‚ñà‚ñè        | 565/5000 [1:15:42<9:59:02,  8.10s/it, loss=0.6682, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 566/5000 [1:15:51<10:02:30,  8.15s/it, loss=0.6682, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 566/5000 [1:15:51<10:02:30,  8.15s/it, loss=0.4630, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 567/5000 [1:15:59<9:59:22,  8.11s/it, loss=0.4630, lr=9.99e-06] Steps:  11%|‚ñà‚ñè        | 567/5000 [1:15:59<9:59:22,  8.11s/it, loss=1.0434, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 568/5000 [1:16:07<9:55:53,  8.07s/it, loss=1.0434, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 568/5000 [1:16:07<9:55:53,  8.07s/it, loss=1.1869, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 569/5000 [1:16:15<9:54:32,  8.05s/it, loss=1.1869, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 569/5000 [1:16:15<9:54:32,  8.05s/it, loss=0.3692, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 570/5000 [1:16:23<9:59:52,  8.12s/it, loss=0.3692, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 570/5000 [1:16:23<9:59:52,  8.12s/it, loss=0.4026, lr=9.99e-06]
[Step 570] Training Debug Info:
  Loss: 0.563266
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0010, std: 0.9180
  Noise mean: 0.0007, std: 1.0000
  Target mean: 0.0017, std: 1.3594
  Model pred mean: 0.0037, std: 1.1016
  Sigmas: [0.9609375]... (timesteps: [961.0])

[Step 570] Training Debug Info:
  Loss: 0.682981
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0070, std: 0.8984
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0088, std: 1.3438
  Model pred mean: -0.0036, std: 1.0547
  Sigmas: [0.5]... (timesteps: [500.0])

[Step 570] Training Debug Info:
  Loss: 0.926881
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0144, std: 0.8828
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0139, std: 1.3281
  Model pred mean: 0.0205, std: 0.9062
  Sigmas: [0.427734375]... (timesteps: [428.0])

[Step 570] Training Debug Info:
  Loss: 0.354280
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0306, std: 0.9297
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0317, std: 1.3594
  Model pred mean: -0.0245, std: 1.2344
  Sigmas: [0.79296875]... (timesteps: [793.0])
Steps:  11%|‚ñà‚ñè        | 571/5000 [1:16:31<10:02:44,  8.17s/it, loss=0.4026, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 571/5000 [1:16:31<10:02:44,  8.17s/it, loss=0.3543, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 572/5000 [1:16:39<9:58:34,  8.11s/it, loss=0.3543, lr=9.99e-06] Steps:  11%|‚ñà‚ñè        | 572/5000 [1:16:39<9:58:34,  8.11s/it, loss=1.1141, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 573/5000 [1:16:47<9:57:07,  8.09s/it, loss=1.1141, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 573/5000 [1:16:47<9:57:07,  8.09s/it, loss=0.4061, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 574/5000 [1:16:55<9:55:39,  8.07s/it, loss=0.4061, lr=9.99e-06]Steps:  11%|‚ñà‚ñè        | 574/5000 [1:16:55<9:55:39,  8.07s/it, loss=0.3873, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 575/5000 [1:17:04<9:58:39,  8.12s/it, loss=0.3873, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 575/5000 [1:17:04<9:58:39,  8.12s/it, loss=0.7663, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 576/5000 [1:17:12<10:00:52,  8.15s/it, loss=0.7663, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 576/5000 [1:17:12<10:00:52,  8.15s/it, loss=0.5316, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 577/5000 [1:17:20<9:58:34,  8.12s/it, loss=0.5316, lr=9.99e-06] Steps:  12%|‚ñà‚ñè        | 577/5000 [1:17:20<9:58:34,  8.12s/it, loss=1.1061, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 578/5000 [1:17:28<9:55:54,  8.09s/it, loss=1.1061, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 578/5000 [1:17:28<9:55:54,  8.09s/it, loss=0.9035, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 579/5000 [1:17:36<9:51:33,  8.03s/it, loss=0.9035, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 579/5000 [1:17:36<9:51:33,  8.03s/it, loss=0.3927, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 580/5000 [1:17:44<9:54:54,  8.08s/it, loss=0.3927, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 580/5000 [1:17:44<9:54:54,  8.08s/it, loss=0.5134, lr=9.99e-06]
[Step 580] Training Debug Info:
  Loss: 1.029658
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0508, std: 0.9219
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0493, std: 1.3594
  Model pred mean: -0.0518, std: 0.9102
  Sigmas: [0.010009765625]... (timesteps: [10.0])

[Step 580] Training Debug Info:
  Loss: 1.127431
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0201, std: 0.9141
  Noise mean: 0.0016, std: 1.0000
  Target mean: -0.0186, std: 1.3516
  Model pred mean: -0.0266, std: 0.8477
  Sigmas: [0.09423828125]... (timesteps: [94.0])

[Step 580] Training Debug Info:
  Loss: 1.105866
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0148, std: 0.9180
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0141, std: 1.3594
  Model pred mean: -0.0223, std: 0.8633
  Sigmas: [0.2099609375]... (timesteps: [210.0])

[Step 580] Training Debug Info:
  Loss: 0.738513
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0376, std: 0.9258
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0391, std: 1.3672
  Model pred mean: 0.0342, std: 1.0625
  Sigmas: [0.47265625]... (timesteps: [472.0])
Steps:  12%|‚ñà‚ñè        | 581/5000 [1:17:52<9:52:21,  8.04s/it, loss=0.5134, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 581/5000 [1:17:52<9:52:21,  8.04s/it, loss=0.7385, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 582/5000 [1:18:00<9:56:37,  8.10s/it, loss=0.7385, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 582/5000 [1:18:00<9:56:37,  8.10s/it, loss=0.5117, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 583/5000 [1:18:08<9:55:36,  8.09s/it, loss=0.5117, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 583/5000 [1:18:08<9:55:36,  8.09s/it, loss=1.0280, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 584/5000 [1:18:16<9:52:36,  8.05s/it, loss=1.0280, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 584/5000 [1:18:16<9:52:36,  8.05s/it, loss=0.6170, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 585/5000 [1:18:24<9:51:39,  8.04s/it, loss=0.6170, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 585/5000 [1:18:24<9:51:39,  8.04s/it, loss=0.7798, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 586/5000 [1:18:32<9:53:00,  8.06s/it, loss=0.7798, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 586/5000 [1:18:32<9:53:00,  8.06s/it, loss=1.0236, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 587/5000 [1:18:40<9:57:23,  8.12s/it, loss=1.0236, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 587/5000 [1:18:40<9:57:23,  8.12s/it, loss=0.4664, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 588/5000 [1:18:48<9:53:45,  8.07s/it, loss=0.4664, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 588/5000 [1:18:48<9:53:45,  8.07s/it, loss=1.1439, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 589/5000 [1:18:57<9:54:13,  8.08s/it, loss=1.1439, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 589/5000 [1:18:57<9:54:13,  8.08s/it, loss=0.9958, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 590/5000 [1:19:05<9:53:34,  8.08s/it, loss=0.9958, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 590/5000 [1:19:05<9:53:34,  8.08s/it, loss=0.4372, lr=9.99e-06]
[Step 590] Training Debug Info:
  Loss: 0.730375
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0212, std: 0.8984
  Noise mean: -0.0023, std: 1.0000
  Target mean: -0.0234, std: 1.3438
  Model pred mean: -0.0291, std: 1.0312
  Sigmas: [0.48046875]... (timesteps: [481.0])

[Step 590] Training Debug Info:
  Loss: 0.526852
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0337, std: 0.9414
  Noise mean: -0.0025, std: 1.0000
  Target mean: -0.0364, std: 1.3750
  Model pred mean: -0.0383, std: 1.1641
  Sigmas: [0.609375]... (timesteps: [610.0])

[Step 590] Training Debug Info:
  Loss: 1.092793
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0190, std: 1.0078
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0190, std: 1.4219
  Model pred mean: -0.0073, std: 0.9453
  Sigmas: [0.049072265625]... (timesteps: [49.0])

[Step 590] Training Debug Info:
  Loss: 1.078643
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0010, std: 0.9453
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0026, std: 1.3750
  Model pred mean: 0.0104, std: 0.8945
  Sigmas: [0.049072265625]... (timesteps: [49.0])
Steps:  12%|‚ñà‚ñè        | 591/5000 [1:19:13<9:56:38,  8.12s/it, loss=0.4372, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 591/5000 [1:19:13<9:56:38,  8.12s/it, loss=1.0786, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 592/5000 [1:19:21<9:58:53,  8.15s/it, loss=1.0786, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 592/5000 [1:19:21<9:58:53,  8.15s/it, loss=1.0905, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 593/5000 [1:19:29<9:55:09,  8.10s/it, loss=1.0905, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 593/5000 [1:19:29<9:55:09,  8.10s/it, loss=0.5490, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 594/5000 [1:19:37<9:52:50,  8.07s/it, loss=0.5490, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 594/5000 [1:19:37<9:52:50,  8.07s/it, loss=0.7316, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 595/5000 [1:19:45<9:50:47,  8.05s/it, loss=0.7316, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 595/5000 [1:19:45<9:50:47,  8.05s/it, loss=0.4423, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 596/5000 [1:19:53<9:49:30,  8.03s/it, loss=0.4423, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 596/5000 [1:19:53<9:49:30,  8.03s/it, loss=1.1775, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 597/5000 [1:20:01<9:53:07,  8.08s/it, loss=1.1775, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 597/5000 [1:20:01<9:53:07,  8.08s/it, loss=0.4722, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 598/5000 [1:20:09<9:55:49,  8.12s/it, loss=0.4722, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 598/5000 [1:20:09<9:55:49,  8.12s/it, loss=0.4422, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 599/5000 [1:20:17<9:53:06,  8.09s/it, loss=0.4422, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 599/5000 [1:20:17<9:53:06,  8.09s/it, loss=1.1032, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 600/5000 [1:20:22<8:25:53,  6.90s/it, loss=1.1032, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 600/5000 [1:20:22<8:25:53,  6.90s/it, loss=0.3971, lr=9.99e-06]01/30/2026 05:43:11 - INFO - __main__ - 
[Step 600] ‚úÖ Loss in normal range (0.3971)
01/30/2026 05:43:11 - INFO - __main__ -   Loss avg (last 100): 0.7314
01/30/2026 05:43:11 - INFO - __main__ -   Loss range: [0.3543, 1.2133]
01/30/2026 05:43:11 - INFO - __main__ - 
==================================================
01/30/2026 05:43:11 - INFO - __main__ - Epoch 7 completed: avg_loss = 0.7364
01/30/2026 05:43:11 - INFO - __main__ - ==================================================


[Step 600] Training Debug Info:
  Loss: 0.460166
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0134, std: 0.8984
  Noise mean: 0.0056, std: 1.0000
  Target mean: -0.0078, std: 1.3438
  Model pred mean: -0.0118, std: 1.1562
  Sigmas: [0.70703125]... (timesteps: [706.0])

[Step 600] Training Debug Info:
  Loss: 1.130602
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0330, std: 1.0000
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0339, std: 1.4141
  Model pred mean: -0.0298, std: 0.9336
  Sigmas: [0.2001953125]... (timesteps: [200.0])

[Step 600] Training Debug Info:
  Loss: 1.081037
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0354, std: 0.8672
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0381, std: 1.3281
  Model pred mean: 0.0410, std: 0.8242
  Sigmas: [0.337890625]... (timesteps: [337.0])

[Step 600] Training Debug Info:
  Loss: 0.439787
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0101, std: 0.9492
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0090, std: 1.3750
  Model pred mean: -0.0045, std: 1.2109
  Sigmas: [0.69140625]... (timesteps: [693.0])
Steps:  12%|‚ñà‚ñè        | 601/5000 [1:20:30<8:55:58,  7.31s/it, loss=0.3971, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 601/5000 [1:20:30<8:55:58,  7.31s/it, loss=0.4398, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 602/5000 [1:20:39<9:27:49,  7.75s/it, loss=0.4398, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 602/5000 [1:20:39<9:27:49,  7.75s/it, loss=0.9184, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 603/5000 [1:20:47<9:34:15,  7.84s/it, loss=0.9184, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 603/5000 [1:20:47<9:34:15,  7.84s/it, loss=0.4376, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 604/5000 [1:20:55<9:44:20,  7.98s/it, loss=0.4376, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 604/5000 [1:20:55<9:44:20,  7.98s/it, loss=1.0790, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 605/5000 [1:21:03<9:44:35,  7.98s/it, loss=1.0790, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 605/5000 [1:21:03<9:44:35,  7.98s/it, loss=0.3878, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 606/5000 [1:21:11<9:44:01,  7.97s/it, loss=0.3878, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 606/5000 [1:21:11<9:44:01,  7.97s/it, loss=1.1298, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 607/5000 [1:21:19<9:53:16,  8.10s/it, loss=1.1298, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 607/5000 [1:21:19<9:53:16,  8.10s/it, loss=0.5814, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 608/5000 [1:21:27<9:50:32,  8.07s/it, loss=0.5814, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 608/5000 [1:21:27<9:50:32,  8.07s/it, loss=1.1712, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 609/5000 [1:21:36<9:56:41,  8.15s/it, loss=1.1712, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 609/5000 [1:21:36<9:56:41,  8.15s/it, loss=0.8247, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 610/5000 [1:21:44<9:52:48,  8.10s/it, loss=0.8247, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 610/5000 [1:21:44<9:52:48,  8.10s/it, loss=0.8948, lr=9.99e-06]
[Step 610] Training Debug Info:
  Loss: 1.100568
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0019, std: 0.8516
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0008, std: 1.3125
  Model pred mean: -0.0054, std: 0.7891
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 610] Training Debug Info:
  Loss: 0.671146
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0282, std: 0.9180
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0270, std: 1.3594
  Model pred mean: 0.0062, std: 1.0781
  Sigmas: [0.98828125]... (timesteps: [987.0])

[Step 610] Training Debug Info:
  Loss: 1.071244
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0004, std: 0.8867
  Noise mean: -0.0000, std: 1.0000
  Target mean: -0.0005, std: 1.3359
  Model pred mean: -0.0013, std: 0.8516
  Sigmas: [0.322265625]... (timesteps: [323.0])

[Step 610] Training Debug Info:
  Loss: 0.489461
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0332, std: 0.9922
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0337, std: 1.4141
  Model pred mean: -0.0295, std: 1.2266
  Sigmas: [0.796875]... (timesteps: [795.0])
Steps:  12%|‚ñà‚ñè        | 611/5000 [1:21:52<9:50:01,  8.07s/it, loss=0.8948, lr=9.99e-06]Steps:  12%|‚ñà‚ñè        | 611/5000 [1:21:52<9:50:01,  8.07s/it, loss=0.4895, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 612/5000 [1:22:00<9:48:20,  8.04s/it, loss=0.4895, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 612/5000 [1:22:00<9:48:20,  8.04s/it, loss=0.7375, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 613/5000 [1:22:08<9:54:42,  8.13s/it, loss=0.7375, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 613/5000 [1:22:08<9:54:42,  8.13s/it, loss=0.8664, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 614/5000 [1:22:16<9:50:27,  8.08s/it, loss=0.8664, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 614/5000 [1:22:16<9:50:27,  8.08s/it, loss=1.1493, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 615/5000 [1:22:24<9:55:25,  8.15s/it, loss=1.1493, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 615/5000 [1:22:24<9:55:25,  8.15s/it, loss=0.6935, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 616/5000 [1:22:32<9:51:33,  8.10s/it, loss=0.6935, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 616/5000 [1:22:32<9:51:33,  8.10s/it, loss=0.3974, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 617/5000 [1:22:40<9:50:05,  8.08s/it, loss=0.3974, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 617/5000 [1:22:40<9:50:05,  8.08s/it, loss=0.6599, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 618/5000 [1:22:49<9:58:39,  8.20s/it, loss=0.6599, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 618/5000 [1:22:49<9:58:39,  8.20s/it, loss=1.0493, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 619/5000 [1:22:57<9:54:42,  8.14s/it, loss=1.0493, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 619/5000 [1:22:57<9:54:42,  8.14s/it, loss=1.0599, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 620/5000 [1:23:05<9:56:24,  8.17s/it, loss=1.0599, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 620/5000 [1:23:05<9:56:24,  8.17s/it, loss=0.4541, lr=9.98e-06]
[Step 620] Training Debug Info:
  Loss: 1.180470
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0096, std: 0.8828
  Noise mean: 0.0041, std: 1.0000
  Target mean: -0.0055, std: 1.3359
  Model pred mean: -0.0093, std: 0.7656
  Sigmas: [0.1923828125]... (timesteps: [192.0])

[Step 620] Training Debug Info:
  Loss: 0.515025
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0032, std: 0.9609
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0018, std: 1.3906
  Model pred mean: 0.0039, std: 1.1875
  Sigmas: [0.6640625]... (timesteps: [664.0])

[Step 620] Training Debug Info:
  Loss: 0.526407
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0099, std: 0.9062
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0095, std: 1.3516
  Model pred mean: -0.0023, std: 1.1328
  Sigmas: [0.64453125]... (timesteps: [645.0])

[Step 620] Training Debug Info:
  Loss: 0.373760
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0272, std: 0.9180
  Noise mean: 0.0031, std: 1.0000
  Target mean: 0.0303, std: 1.3594
  Model pred mean: 0.0332, std: 1.2031
  Sigmas: [0.85546875]... (timesteps: [855.0])
Steps:  12%|‚ñà‚ñè        | 621/5000 [1:23:13<9:55:28,  8.16s/it, loss=0.4541, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 621/5000 [1:23:13<9:55:28,  8.16s/it, loss=0.3738, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 622/5000 [1:23:21<9:51:33,  8.11s/it, loss=0.3738, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 622/5000 [1:23:21<9:51:33,  8.11s/it, loss=0.8919, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 623/5000 [1:23:29<9:54:10,  8.15s/it, loss=0.8919, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 623/5000 [1:23:29<9:54:10,  8.15s/it, loss=0.4784, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 624/5000 [1:23:37<9:55:00,  8.16s/it, loss=0.4784, lr=9.98e-06]Steps:  12%|‚ñà‚ñè        | 624/5000 [1:23:37<9:55:00,  8.16s/it, loss=1.0013, lr=9.98e-06]Steps:  12%|‚ñà‚ñé        | 625/5000 [1:23:46<9:54:12,  8.15s/it, loss=1.0013, lr=9.98e-06]Steps:  12%|‚ñà‚ñé        | 625/5000 [1:23:46<9:54:12,  8.15s/it, loss=0.4812, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 626/5000 [1:23:54<9:50:22,  8.10s/it, loss=0.4812, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 626/5000 [1:23:54<9:50:22,  8.10s/it, loss=0.4402, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 627/5000 [1:24:02<9:49:01,  8.08s/it, loss=0.4402, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 627/5000 [1:24:02<9:49:01,  8.08s/it, loss=0.5709, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 628/5000 [1:24:10<9:48:07,  8.07s/it, loss=0.5709, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 628/5000 [1:24:10<9:48:07,  8.07s/it, loss=1.0509, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 629/5000 [1:24:18<9:52:55,  8.14s/it, loss=1.0509, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 629/5000 [1:24:18<9:52:55,  8.14s/it, loss=1.2001, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 630/5000 [1:24:26<9:50:40,  8.11s/it, loss=1.2001, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 630/5000 [1:24:26<9:50:40,  8.11s/it, loss=0.3698, lr=9.98e-06]
[Step 630] Training Debug Info:
  Loss: 0.365168
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0025, std: 0.9336
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0023, std: 1.3672
  Model pred mean: -0.0006, std: 1.2266
  Sigmas: [0.82421875]... (timesteps: [825.0])

[Step 630] Training Debug Info:
  Loss: 1.132568
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0096, std: 0.8867
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0104, std: 1.3359
  Model pred mean: -0.0055, std: 0.8086
  Sigmas: [0.0888671875]... (timesteps: [89.0])

[Step 630] Training Debug Info:
  Loss: 0.644867
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0160, std: 0.9023
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0157, std: 1.3438
  Model pred mean: -0.0187, std: 1.0781
  Sigmas: [0.546875]... (timesteps: [548.0])

[Step 630] Training Debug Info:
  Loss: 1.015234
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0014, std: 0.8633
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0008, std: 1.3203
  Model pred mean: 0.0026, std: 0.8516
  Sigmas: [0.006988525390625]... (timesteps: [7.0])
Steps:  13%|‚ñà‚ñé        | 631/5000 [1:24:34<9:51:54,  8.13s/it, loss=0.3698, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 631/5000 [1:24:34<9:51:54,  8.13s/it, loss=1.0152, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 632/5000 [1:24:42<9:49:26,  8.10s/it, loss=1.0152, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 632/5000 [1:24:42<9:49:26,  8.10s/it, loss=1.1142, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 633/5000 [1:24:50<9:47:28,  8.07s/it, loss=1.1142, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 633/5000 [1:24:50<9:47:28,  8.07s/it, loss=0.4545, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 634/5000 [1:24:58<9:49:16,  8.10s/it, loss=0.4545, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 634/5000 [1:24:58<9:49:16,  8.10s/it, loss=1.1721, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 635/5000 [1:25:06<9:45:31,  8.05s/it, loss=1.1721, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 635/5000 [1:25:06<9:45:31,  8.05s/it, loss=1.1487, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 636/5000 [1:25:15<9:51:17,  8.13s/it, loss=1.1487, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 636/5000 [1:25:15<9:51:17,  8.13s/it, loss=0.6019, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 637/5000 [1:25:23<9:46:26,  8.06s/it, loss=0.6019, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 637/5000 [1:25:23<9:46:26,  8.06s/it, loss=1.0808, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 638/5000 [1:25:31<9:46:31,  8.07s/it, loss=1.0808, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 638/5000 [1:25:31<9:46:31,  8.07s/it, loss=0.4979, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 639/5000 [1:25:39<9:50:04,  8.12s/it, loss=0.4979, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 639/5000 [1:25:39<9:50:04,  8.12s/it, loss=1.0278, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 640/5000 [1:25:47<9:48:59,  8.11s/it, loss=1.0278, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 640/5000 [1:25:47<9:48:59,  8.11s/it, loss=1.0991, lr=9.98e-06]
[Step 640] Training Debug Info:
  Loss: 1.125283
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0247, std: 0.8945
  Noise mean: -0.0016, std: 1.0000
  Target mean: -0.0261, std: 1.3438
  Model pred mean: -0.0214, std: 0.8242
  Sigmas: [0.1689453125]... (timesteps: [169.0])

[Step 640] Training Debug Info:
  Loss: 0.895031
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0043, std: 0.8789
  Noise mean: 0.0002, std: 1.0000
  Target mean: -0.0041, std: 1.3359
  Model pred mean: 0.0007, std: 0.9531
  Sigmas: [0.419921875]... (timesteps: [420.0])

[Step 640] Training Debug Info:
  Loss: 0.450862
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0579, std: 0.9180
  Noise mean: 0.0040, std: 1.0000
  Target mean: -0.0540, std: 1.3594
  Model pred mean: -0.0557, std: 1.1875
  Sigmas: [0.73046875]... (timesteps: [730.0])

[Step 640] Training Debug Info:
  Loss: 0.924406
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0137, std: 0.9062
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0134, std: 1.3516
  Model pred mean: 0.0200, std: 0.9492
  Sigmas: [0.39453125]... (timesteps: [394.0])
Steps:  13%|‚ñà‚ñé        | 641/5000 [1:25:55<9:52:11,  8.15s/it, loss=1.0991, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 641/5000 [1:25:55<9:52:11,  8.15s/it, loss=0.9244, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 642/5000 [1:26:03<9:48:18,  8.10s/it, loss=0.9244, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 642/5000 [1:26:03<9:48:18,  8.10s/it, loss=0.8410, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 643/5000 [1:26:11<9:46:19,  8.07s/it, loss=0.8410, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 643/5000 [1:26:11<9:46:19,  8.07s/it, loss=1.1237, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 644/5000 [1:26:19<9:46:46,  8.08s/it, loss=1.1237, lr=9.98e-06]Steps:  13%|‚ñà‚ñé        | 644/5000 [1:26:19<9:46:46,  8.08s/it, loss=0.4270, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 645/5000 [1:26:28<9:51:37,  8.15s/it, loss=0.4270, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 645/5000 [1:26:28<9:51:37,  8.15s/it, loss=0.6235, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 646/5000 [1:26:36<9:48:30,  8.11s/it, loss=0.6235, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 646/5000 [1:26:36<9:48:30,  8.11s/it, loss=0.4751, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 647/5000 [1:26:44<9:51:21,  8.15s/it, loss=0.4751, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 647/5000 [1:26:44<9:51:21,  8.15s/it, loss=0.4074, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 648/5000 [1:26:52<9:48:26,  8.11s/it, loss=0.4074, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 648/5000 [1:26:52<9:48:26,  8.11s/it, loss=0.8692, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 649/5000 [1:27:00<9:44:44,  8.06s/it, loss=0.8692, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 649/5000 [1:27:00<9:44:44,  8.06s/it, loss=1.0330, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 650/5000 [1:27:08<9:48:52,  8.12s/it, loss=1.0330, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 650/5000 [1:27:08<9:48:52,  8.12s/it, loss=0.4387, lr=9.97e-06]
[Step 650] Training Debug Info:
  Loss: 0.999551
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0123, std: 0.9219
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0115, std: 1.3594
  Model pred mean: 0.0120, std: 0.9258
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 650] Training Debug Info:
  Loss: 1.147938
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0249, std: 0.9062
  Noise mean: 0.0042, std: 1.0000
  Target mean: 0.0292, std: 1.3516
  Model pred mean: 0.0228, std: 0.8203
  Sigmas: [0.150390625]... (timesteps: [150.0])

[Step 650] Training Debug Info:
  Loss: 0.453175
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0192, std: 0.9102
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0200, std: 1.3516
  Model pred mean: -0.0210, std: 1.1719
  Sigmas: [0.6953125]... (timesteps: [696.0])

[Step 650] Training Debug Info:
  Loss: 1.122954
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0359, std: 0.8945
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0366, std: 1.3438
  Model pred mean: -0.0366, std: 0.8203
  Sigmas: [0.0869140625]... (timesteps: [87.0])
Steps:  13%|‚ñà‚ñé        | 651/5000 [1:27:16<9:46:22,  8.09s/it, loss=0.4387, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 651/5000 [1:27:16<9:46:22,  8.09s/it, loss=1.1230, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 652/5000 [1:27:24<9:49:56,  8.14s/it, loss=1.1230, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 652/5000 [1:27:24<9:49:56,  8.14s/it, loss=0.5739, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 653/5000 [1:27:32<9:47:19,  8.11s/it, loss=0.5739, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 653/5000 [1:27:32<9:47:19,  8.11s/it, loss=0.4823, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 654/5000 [1:27:40<9:42:24,  8.04s/it, loss=0.4823, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 654/5000 [1:27:40<9:42:24,  8.04s/it, loss=1.1488, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 655/5000 [1:27:48<9:44:49,  8.08s/it, loss=1.1488, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 655/5000 [1:27:48<9:44:49,  8.08s/it, loss=0.4105, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 656/5000 [1:27:56<9:40:55,  8.02s/it, loss=0.4105, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 656/5000 [1:27:56<9:40:55,  8.02s/it, loss=1.0698, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 657/5000 [1:28:05<9:44:36,  8.08s/it, loss=1.0698, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 657/5000 [1:28:05<9:44:36,  8.08s/it, loss=0.5189, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 658/5000 [1:28:13<9:42:17,  8.05s/it, loss=0.5189, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 658/5000 [1:28:13<9:42:17,  8.05s/it, loss=1.0432, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 659/5000 [1:28:21<9:41:01,  8.03s/it, loss=1.0432, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 659/5000 [1:28:21<9:41:01,  8.03s/it, loss=0.7992, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 660/5000 [1:28:29<9:45:14,  8.09s/it, loss=0.7992, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 660/5000 [1:28:29<9:45:14,  8.09s/it, loss=0.6362, lr=9.97e-06]
[Step 660] Training Debug Info:
  Loss: 1.126271
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0134, std: 0.9375
  Noise mean: -0.0001, std: 1.0000
  Target mean: -0.0134, std: 1.3672
  Model pred mean: -0.0108, std: 0.8672
  Sigmas: [0.1572265625]... (timesteps: [157.0])

[Step 660] Training Debug Info:
  Loss: 1.124796
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0061, std: 0.8711
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0071, std: 1.3281
  Model pred mean: 0.0094, std: 0.8008
  Sigmas: [0.3046875]... (timesteps: [305.0])

[Step 660] Training Debug Info:
  Loss: 0.365464
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0161, std: 0.8789
  Noise mean: -0.0037, std: 1.0000
  Target mean: 0.0125, std: 1.3281
  Model pred mean: 0.0135, std: 1.1875
  Sigmas: [0.82421875]... (timesteps: [824.0])

[Step 660] Training Debug Info:
  Loss: 0.979477
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0437, std: 0.9141
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0437, std: 1.3516
  Model pred mean: 0.0437, std: 0.9336
  Sigmas: [0.37109375]... (timesteps: [371.0])
Steps:  13%|‚ñà‚ñé        | 661/5000 [1:28:37<9:41:08,  8.04s/it, loss=0.6362, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 661/5000 [1:28:37<9:41:08,  8.04s/it, loss=0.9795, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 662/5000 [1:28:45<9:39:36,  8.02s/it, loss=0.9795, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 662/5000 [1:28:45<9:39:36,  8.02s/it, loss=0.5098, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 663/5000 [1:28:53<9:42:55,  8.06s/it, loss=0.5098, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 663/5000 [1:28:53<9:42:55,  8.06s/it, loss=0.3580, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 664/5000 [1:29:01<9:40:55,  8.04s/it, loss=0.3580, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 664/5000 [1:29:01<9:40:55,  8.04s/it, loss=0.4600, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 665/5000 [1:29:09<9:42:07,  8.06s/it, loss=0.4600, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 665/5000 [1:29:09<9:42:07,  8.06s/it, loss=0.5372, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 666/5000 [1:29:17<9:44:44,  8.10s/it, loss=0.5372, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 666/5000 [1:29:17<9:44:44,  8.10s/it, loss=0.5443, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 667/5000 [1:29:25<9:41:58,  8.06s/it, loss=0.5443, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 667/5000 [1:29:25<9:41:58,  8.06s/it, loss=0.5082, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 668/5000 [1:29:33<9:45:49,  8.11s/it, loss=0.5082, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 668/5000 [1:29:33<9:45:49,  8.11s/it, loss=0.4302, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 669/5000 [1:29:41<9:43:26,  8.08s/it, loss=0.4302, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 669/5000 [1:29:41<9:43:26,  8.08s/it, loss=0.4492, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 670/5000 [1:29:49<9:41:17,  8.05s/it, loss=0.4492, lr=9.97e-06]Steps:  13%|‚ñà‚ñé        | 670/5000 [1:29:49<9:41:17,  8.05s/it, loss=0.4113, lr=9.96e-06]
[Step 670] Training Debug Info:
  Loss: 0.656871
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0139, std: 0.8789
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0162, std: 1.3281
  Model pred mean: 0.0125, std: 1.0469
  Sigmas: [0.5703125]... (timesteps: [569.0])

[Step 670] Training Debug Info:
  Loss: 0.963989
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0194, std: 0.8672
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0204, std: 1.3281
  Model pred mean: 0.0164, std: 0.8828
  Sigmas: [0.40625]... (timesteps: [407.0])

[Step 670] Training Debug Info:
  Loss: 0.485549
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0114, std: 0.9883
  Noise mean: 0.0006, std: 1.0000
  Target mean: -0.0107, std: 1.4062
  Model pred mean: -0.0143, std: 1.2266
  Sigmas: [0.72265625]... (timesteps: [723.0])

[Step 670] Training Debug Info:
  Loss: 1.070094
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0011, std: 0.9102
  Noise mean: 0.0043, std: 0.9961
  Target mean: 0.0032, std: 1.3516
  Model pred mean: 0.0021, std: 0.8711
  Sigmas: [0.041015625]... (timesteps: [41.0])
Steps:  13%|‚ñà‚ñé        | 671/5000 [1:29:57<9:43:16,  8.08s/it, loss=0.4113, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 671/5000 [1:29:57<9:43:16,  8.08s/it, loss=1.0701, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 672/5000 [1:30:05<9:40:59,  8.05s/it, loss=1.0701, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 672/5000 [1:30:05<9:40:59,  8.05s/it, loss=0.9994, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 673/5000 [1:30:13<9:39:58,  8.04s/it, loss=0.9994, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 673/5000 [1:30:13<9:39:58,  8.04s/it, loss=0.4097, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 674/5000 [1:30:22<9:44:25,  8.11s/it, loss=0.4097, lr=9.96e-06]Steps:  13%|‚ñà‚ñé        | 674/5000 [1:30:22<9:44:25,  8.11s/it, loss=0.4088, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 675/5000 [1:30:26<8:19:05,  6.92s/it, loss=0.4088, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 675/5000 [1:30:26<8:19:05,  6.92s/it, loss=0.4673, lr=9.96e-06]01/30/2026 05:53:15 - INFO - __main__ - 
==================================================
01/30/2026 05:53:15 - INFO - __main__ - Epoch 8 completed: avg_loss = 0.7334
01/30/2026 05:53:15 - INFO - __main__ - ==================================================

Steps:  14%|‚ñà‚ñé        | 676/5000 [1:30:34<8:47:48,  7.32s/it, loss=0.4673, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 676/5000 [1:30:34<8:47:48,  7.32s/it, loss=0.6972, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 677/5000 [1:30:43<9:11:58,  7.66s/it, loss=0.6972, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 677/5000 [1:30:43<9:11:58,  7.66s/it, loss=0.4038, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 678/5000 [1:30:51<9:20:09,  7.78s/it, loss=0.4038, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 678/5000 [1:30:51<9:20:09,  7.78s/it, loss=1.0194, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 679/5000 [1:30:59<9:29:56,  7.91s/it, loss=1.0194, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 679/5000 [1:30:59<9:29:56,  7.91s/it, loss=1.0374, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 680/5000 [1:31:07<9:31:24,  7.94s/it, loss=1.0374, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 680/5000 [1:31:07<9:31:24,  7.94s/it, loss=1.0920, lr=9.96e-06]
[Step 680] Training Debug Info:
  Loss: 1.106510
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0264, std: 0.9219
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0269, std: 1.3594
  Model pred mean: 0.0251, std: 0.8555
  Sigmas: [0.07080078125]... (timesteps: [71.0])

[Step 680] Training Debug Info:
  Loss: 0.493512
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0153, std: 0.9141
  Noise mean: 0.0037, std: 1.0000
  Target mean: 0.0189, std: 1.3516
  Model pred mean: 0.0112, std: 1.1641
  Sigmas: [0.734375]... (timesteps: [736.0])

[Step 680] Training Debug Info:
  Loss: 0.696921
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0054, std: 0.8867
  Noise mean: 0.0038, std: 1.0000
  Target mean: 0.0092, std: 1.3359
  Model pred mean: 0.0079, std: 1.0547
  Sigmas: [0.51953125]... (timesteps: [521.0])

[Step 680] Training Debug Info:
  Loss: 0.426792
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0090, std: 0.8984
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0104, std: 1.3516
  Model pred mean: 0.0080, std: 1.1875
  Sigmas: [0.75390625]... (timesteps: [752.0])
Steps:  14%|‚ñà‚ñé        | 681/5000 [1:31:15<9:32:27,  7.95s/it, loss=1.0920, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 681/5000 [1:31:15<9:32:27,  7.95s/it, loss=0.4268, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 682/5000 [1:31:23<9:38:23,  8.04s/it, loss=0.4268, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 682/5000 [1:31:23<9:38:23,  8.04s/it, loss=0.5539, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 683/5000 [1:31:31<9:36:51,  8.02s/it, loss=0.5539, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 683/5000 [1:31:31<9:36:51,  8.02s/it, loss=1.1366, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 684/5000 [1:31:39<9:35:54,  8.01s/it, loss=1.1366, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 684/5000 [1:31:39<9:35:54,  8.01s/it, loss=1.1001, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 685/5000 [1:31:47<9:40:01,  8.07s/it, loss=1.1001, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 685/5000 [1:31:47<9:40:01,  8.07s/it, loss=0.4188, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 686/5000 [1:31:55<9:37:29,  8.03s/it, loss=0.4188, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 686/5000 [1:31:55<9:37:29,  8.03s/it, loss=1.0076, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 687/5000 [1:32:03<9:35:47,  8.01s/it, loss=1.0076, lr=9.96e-06]Steps:  14%|‚ñà‚ñé        | 687/5000 [1:32:03<9:35:47,  8.01s/it, loss=1.1189, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 688/5000 [1:32:11<9:38:30,  8.05s/it, loss=1.1189, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 688/5000 [1:32:11<9:38:30,  8.05s/it, loss=1.1432, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 689/5000 [1:32:19<9:35:48,  8.01s/it, loss=1.1432, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 689/5000 [1:32:19<9:35:48,  8.01s/it, loss=0.9388, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 690/5000 [1:32:27<9:41:24,  8.09s/it, loss=0.9388, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 690/5000 [1:32:27<9:41:24,  8.09s/it, loss=1.1039, lr=9.96e-06]
[Step 690] Training Debug Info:
  Loss: 0.347179
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0086, std: 0.9727
  Noise mean: 0.0029, std: 1.0000
  Target mean: -0.0057, std: 1.3906
  Model pred mean: -0.0177, std: 1.2500
  Sigmas: [0.8828125]... (timesteps: [884.0])

[Step 690] Training Debug Info:
  Loss: 1.109217
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0693, std: 0.9375
  Noise mean: -0.0022, std: 1.0000
  Target mean: 0.0674, std: 1.3672
  Model pred mean: 0.0640, std: 0.8711
  Sigmas: [0.0908203125]... (timesteps: [91.0])

[Step 690] Training Debug Info:
  Loss: 0.377032
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0099, std: 0.9453
  Noise mean: 0.0002, std: 1.0000
  Target mean: 0.0101, std: 1.3750
  Model pred mean: 0.0060, std: 1.2344
  Sigmas: [0.83203125]... (timesteps: [831.0])

[Step 690] Training Debug Info:
  Loss: 0.368837
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0023, std: 0.9297
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0020, std: 1.3672
  Model pred mean: -0.0059, std: 1.2266
  Sigmas: [0.84375]... (timesteps: [845.0])
Steps:  14%|‚ñà‚ñç        | 691/5000 [1:32:35<9:38:53,  8.06s/it, loss=1.1039, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 691/5000 [1:32:35<9:38:53,  8.06s/it, loss=0.3688, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 692/5000 [1:32:43<9:38:02,  8.05s/it, loss=0.3688, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 692/5000 [1:32:43<9:38:02,  8.05s/it, loss=0.5193, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 693/5000 [1:32:52<9:41:42,  8.10s/it, loss=0.5193, lr=9.96e-06]Steps:  14%|‚ñà‚ñç        | 693/5000 [1:32:52<9:41:42,  8.10s/it, loss=0.4927, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 694/5000 [1:33:00<9:39:58,  8.08s/it, loss=0.4927, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 694/5000 [1:33:00<9:39:58,  8.08s/it, loss=0.9452, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 695/5000 [1:33:08<9:38:00,  8.06s/it, loss=0.9452, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 695/5000 [1:33:08<9:38:00,  8.06s/it, loss=0.4137, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 696/5000 [1:33:16<9:41:21,  8.10s/it, loss=0.4137, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 696/5000 [1:33:16<9:41:21,  8.10s/it, loss=1.0760, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 697/5000 [1:33:24<9:38:46,  8.07s/it, loss=1.0760, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 697/5000 [1:33:24<9:38:46,  8.07s/it, loss=0.5627, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 698/5000 [1:33:32<9:42:27,  8.12s/it, loss=0.5627, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 698/5000 [1:33:32<9:42:27,  8.12s/it, loss=0.5540, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 699/5000 [1:33:40<9:39:00,  8.08s/it, loss=0.5540, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 699/5000 [1:33:40<9:39:00,  8.08s/it, loss=1.1353, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 700/5000 [1:33:48<9:35:26,  8.03s/it, loss=1.1353, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 700/5000 [1:33:48<9:35:26,  8.03s/it, loss=1.0606, lr=9.95e-06]01/30/2026 05:56:37 - INFO - __main__ - 
[Step 700] ‚úÖ Loss in normal range (1.0606)
01/30/2026 05:56:37 - INFO - __main__ -   Loss avg (last 100): 0.7533
01/30/2026 05:56:37 - INFO - __main__ -   Loss range: [0.3580, 1.2001]

[Step 700] Training Debug Info:
  Loss: 1.141349
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0019, std: 0.8867
  Noise mean: -0.0008, std: 1.0000
  Target mean: 0.0011, std: 1.3359
  Model pred mean: 0.0022, std: 0.8008
  Sigmas: [0.08984375]... (timesteps: [90.0])

[Step 700] Training Debug Info:
  Loss: 0.367443
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0084, std: 0.8789
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0092, std: 1.3281
  Model pred mean: -0.0031, std: 1.1875
  Sigmas: [0.88671875]... (timesteps: [885.0])

[Step 700] Training Debug Info:
  Loss: 0.569934
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0082, std: 0.8828
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0079, std: 1.3359
  Model pred mean: 0.0124, std: 1.0859
  Sigmas: [0.61328125]... (timesteps: [613.0])

[Step 700] Training Debug Info:
  Loss: 0.693258
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0159, std: 0.9062
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0172, std: 1.3516
  Model pred mean: -0.0060, std: 1.0703
  Sigmas: [0.984375]... (timesteps: [983.0])
Steps:  14%|‚ñà‚ñç        | 701/5000 [1:33:56<9:39:01,  8.08s/it, loss=1.0606, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 701/5000 [1:33:56<9:39:01,  8.08s/it, loss=0.6933, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 702/5000 [1:34:04<9:38:56,  8.08s/it, loss=0.6933, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 702/5000 [1:34:04<9:38:56,  8.08s/it, loss=0.8955, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 703/5000 [1:34:13<9:41:33,  8.12s/it, loss=0.8955, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 703/5000 [1:34:13<9:41:33,  8.12s/it, loss=0.7919, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 704/5000 [1:34:21<9:40:05,  8.10s/it, loss=0.7919, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 704/5000 [1:34:21<9:40:05,  8.10s/it, loss=0.4298, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 705/5000 [1:34:29<9:38:59,  8.09s/it, loss=0.4298, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 705/5000 [1:34:29<9:38:59,  8.09s/it, loss=0.3699, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 706/5000 [1:34:37<9:36:07,  8.05s/it, loss=0.3699, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 706/5000 [1:34:37<9:36:07,  8.05s/it, loss=0.9629, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 707/5000 [1:34:45<9:40:17,  8.11s/it, loss=0.9629, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 707/5000 [1:34:45<9:40:17,  8.11s/it, loss=0.3841, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 708/5000 [1:34:53<9:36:43,  8.06s/it, loss=0.3841, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 708/5000 [1:34:53<9:36:43,  8.06s/it, loss=1.1917, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 709/5000 [1:35:01<9:37:54,  8.08s/it, loss=1.1917, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 709/5000 [1:35:01<9:37:54,  8.08s/it, loss=0.4466, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 710/5000 [1:35:09<9:34:54,  8.04s/it, loss=0.4466, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 710/5000 [1:35:09<9:34:54,  8.04s/it, loss=0.6195, lr=9.95e-06]
[Step 710] Training Debug Info:
  Loss: 1.143176
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0337, std: 0.9219
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0325, std: 1.3594
  Model pred mean: 0.0347, std: 0.8359
  Sigmas: [0.1484375]... (timesteps: [148.0])

[Step 710] Training Debug Info:
  Loss: 0.986446
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0265, std: 0.9180
  Noise mean: -0.0018, std: 0.9961
  Target mean: -0.0283, std: 1.3594
  Model pred mean: -0.0234, std: 0.9141
  Sigmas: [0.32421875]... (timesteps: [325.0])

[Step 710] Training Debug Info:
  Loss: 1.011333
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0037, std: 0.8906
  Noise mean: -0.0011, std: 0.9961
  Target mean: 0.0026, std: 1.3359
  Model pred mean: 0.0050, std: 0.8672
  Sigmas: [0.357421875]... (timesteps: [358.0])

[Step 710] Training Debug Info:
  Loss: 0.399231
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0088, std: 0.8867
  Noise mean: -0.0009, std: 0.9961
  Target mean: -0.0097, std: 1.3359
  Model pred mean: -0.0084, std: 1.1719
  Sigmas: [0.8203125]... (timesteps: [819.0])
Steps:  14%|‚ñà‚ñç        | 711/5000 [1:35:17<9:35:10,  8.05s/it, loss=0.6195, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 711/5000 [1:35:17<9:35:10,  8.05s/it, loss=0.3992, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 712/5000 [1:35:25<9:37:18,  8.08s/it, loss=0.3992, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 712/5000 [1:35:25<9:37:18,  8.08s/it, loss=1.1101, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 713/5000 [1:35:33<9:34:56,  8.05s/it, loss=1.1101, lr=9.95e-06]Steps:  14%|‚ñà‚ñç        | 713/5000 [1:35:33<9:34:56,  8.05s/it, loss=0.6434, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 714/5000 [1:35:41<9:41:01,  8.13s/it, loss=0.6434, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 714/5000 [1:35:41<9:41:01,  8.13s/it, loss=0.3796, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 715/5000 [1:35:50<9:38:58,  8.11s/it, loss=0.3796, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 715/5000 [1:35:50<9:38:58,  8.11s/it, loss=0.6725, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 716/5000 [1:35:58<9:37:18,  8.09s/it, loss=0.6725, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 716/5000 [1:35:58<9:37:18,  8.09s/it, loss=1.1069, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 717/5000 [1:36:06<9:40:04,  8.13s/it, loss=1.1069, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 717/5000 [1:36:06<9:40:04,  8.13s/it, loss=0.3901, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 718/5000 [1:36:14<9:36:05,  8.07s/it, loss=0.3901, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 718/5000 [1:36:14<9:36:05,  8.07s/it, loss=1.1758, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 719/5000 [1:36:22<9:38:54,  8.11s/it, loss=1.1758, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 719/5000 [1:36:22<9:38:54,  8.11s/it, loss=1.0149, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 720/5000 [1:36:30<9:37:42,  8.10s/it, loss=1.0149, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 720/5000 [1:36:30<9:37:42,  8.10s/it, loss=0.3868, lr=9.94e-06]
[Step 720] Training Debug Info:
  Loss: 0.608812
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0005, std: 0.9180
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0006, std: 1.3516
  Model pred mean: 0.0255, std: 1.1094
  Sigmas: [0.9609375]... (timesteps: [962.0])

[Step 720] Training Debug Info:
  Loss: 0.441867
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0047, std: 0.8984
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0032, std: 1.3438
  Model pred mean: 0.0005, std: 1.1719
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 720] Training Debug Info:
  Loss: 0.398214
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0147, std: 0.8789
  Noise mean: -0.0038, std: 1.0000
  Target mean: 0.0109, std: 1.3359
  Model pred mean: 0.0149, std: 1.1719
  Sigmas: [0.8125]... (timesteps: [814.0])

[Step 720] Training Debug Info:
  Loss: 1.045361
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0272, std: 0.9297
  Noise mean: -0.0013, std: 1.0000
  Target mean: -0.0286, std: 1.3672
  Model pred mean: -0.0170, std: 0.9062
  Sigmas: [0.02294921875]... (timesteps: [23.0])
Steps:  14%|‚ñà‚ñç        | 721/5000 [1:36:38<9:35:30,  8.07s/it, loss=0.3868, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 721/5000 [1:36:38<9:35:30,  8.07s/it, loss=1.0454, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 722/5000 [1:36:46<9:34:09,  8.05s/it, loss=1.0454, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 722/5000 [1:36:46<9:34:09,  8.05s/it, loss=0.7930, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 723/5000 [1:36:54<9:37:45,  8.11s/it, loss=0.7930, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 723/5000 [1:36:54<9:37:45,  8.11s/it, loss=0.5101, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 724/5000 [1:37:02<9:34:37,  8.06s/it, loss=0.5101, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 724/5000 [1:37:02<9:34:37,  8.06s/it, loss=1.0531, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 725/5000 [1:37:10<9:37:42,  8.11s/it, loss=1.0531, lr=9.94e-06]Steps:  14%|‚ñà‚ñç        | 725/5000 [1:37:10<9:37:42,  8.11s/it, loss=0.7549, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 726/5000 [1:37:18<9:34:50,  8.07s/it, loss=0.7549, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 726/5000 [1:37:18<9:34:50,  8.07s/it, loss=0.5020, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 727/5000 [1:37:27<9:36:00,  8.09s/it, loss=0.5020, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 727/5000 [1:37:27<9:36:00,  8.09s/it, loss=1.0799, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 728/5000 [1:37:35<9:38:55,  8.13s/it, loss=1.0799, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 728/5000 [1:37:35<9:38:55,  8.13s/it, loss=0.4113, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 729/5000 [1:37:43<9:33:46,  8.06s/it, loss=0.4113, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 729/5000 [1:37:43<9:33:46,  8.06s/it, loss=1.1710, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 730/5000 [1:37:51<9:36:30,  8.10s/it, loss=1.1710, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 730/5000 [1:37:51<9:36:30,  8.10s/it, loss=1.1607, lr=9.94e-06]
[Step 730] Training Debug Info:
  Loss: 0.956840
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0513, std: 0.9219
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0498, std: 1.3594
  Model pred mean: -0.0525, std: 0.9492
  Sigmas: [0.28515625]... (timesteps: [285.0])

[Step 730] Training Debug Info:
  Loss: 1.087333
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0210, std: 0.9141
  Noise mean: -0.0002, std: 0.9961
  Target mean: -0.0211, std: 1.3516
  Model pred mean: -0.0209, std: 0.8672
  Sigmas: [0.2412109375]... (timesteps: [241.0])

[Step 730] Training Debug Info:
  Loss: 0.454082
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0146, std: 0.9219
  Noise mean: 0.0000, std: 1.0000
  Target mean: -0.0146, std: 1.3594
  Model pred mean: -0.0148, std: 1.1797
  Sigmas: [0.71484375]... (timesteps: [713.0])

[Step 730] Training Debug Info:
  Loss: 0.373673
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0366, std: 0.9258
  Noise mean: -0.0026, std: 1.0000
  Target mean: 0.0342, std: 1.3672
  Model pred mean: 0.0264, std: 1.2109
  Sigmas: [0.765625]... (timesteps: [766.0])
Steps:  15%|‚ñà‚ñç        | 731/5000 [1:37:59<9:32:12,  8.04s/it, loss=1.1607, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 731/5000 [1:37:59<9:32:12,  8.04s/it, loss=0.3737, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 732/5000 [1:38:07<9:30:44,  8.02s/it, loss=0.3737, lr=9.94e-06]Steps:  15%|‚ñà‚ñç        | 732/5000 [1:38:07<9:30:44,  8.02s/it, loss=1.1334, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 733/5000 [1:38:15<9:31:37,  8.04s/it, loss=1.1334, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 733/5000 [1:38:15<9:31:37,  8.04s/it, loss=1.1390, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 734/5000 [1:38:23<9:30:18,  8.02s/it, loss=1.1390, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 734/5000 [1:38:23<9:30:18,  8.02s/it, loss=0.9255, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 735/5000 [1:38:31<9:34:08,  8.08s/it, loss=0.9255, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 735/5000 [1:38:31<9:34:08,  8.08s/it, loss=1.1124, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 736/5000 [1:38:39<9:30:36,  8.03s/it, loss=1.1124, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 736/5000 [1:38:39<9:30:36,  8.03s/it, loss=0.8054, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 737/5000 [1:38:47<9:29:31,  8.02s/it, loss=0.8054, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 737/5000 [1:38:47<9:29:31,  8.02s/it, loss=1.0537, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 738/5000 [1:38:55<9:27:47,  7.99s/it, loss=1.0537, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 738/5000 [1:38:55<9:27:47,  7.99s/it, loss=1.1068, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 739/5000 [1:39:03<9:33:49,  8.08s/it, loss=1.1068, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 739/5000 [1:39:03<9:33:49,  8.08s/it, loss=0.4325, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 740/5000 [1:39:11<9:33:03,  8.07s/it, loss=0.4325, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 740/5000 [1:39:11<9:33:03,  8.07s/it, loss=0.3891, lr=9.93e-06]
[Step 740] Training Debug Info:
  Loss: 1.119051
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0210, std: 0.8984
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0205, std: 1.3438
  Model pred mean: -0.0189, std: 0.8320
  Sigmas: [0.2265625]... (timesteps: [227.0])

[Step 740] Training Debug Info:
  Loss: 1.014446
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0342, std: 0.9414
  Noise mean: 0.0014, std: 1.0000
  Target mean: -0.0327, std: 1.3750
  Model pred mean: -0.0303, std: 0.9414
  Sigmas: [0.0019989013671875]... (timesteps: [2.0])

[Step 740] Training Debug Info:
  Loss: 0.651575
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0199, std: 1.0078
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0176, std: 1.4219
  Model pred mean: -0.0130, std: 1.1719
  Sigmas: [0.609375]... (timesteps: [611.0])

[Step 740] Training Debug Info:
  Loss: 0.379293
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0018, std: 0.9492
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0028, std: 1.3750
  Model pred mean: -0.0067, std: 1.2266
  Sigmas: [0.8359375]... (timesteps: [837.0])
Steps:  15%|‚ñà‚ñç        | 741/5000 [1:39:19<9:36:21,  8.12s/it, loss=0.3891, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 741/5000 [1:39:19<9:36:21,  8.12s/it, loss=0.3793, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 742/5000 [1:39:27<9:32:10,  8.06s/it, loss=0.3793, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 742/5000 [1:39:27<9:32:10,  8.06s/it, loss=0.5346, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 743/5000 [1:39:35<9:30:27,  8.04s/it, loss=0.5346, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 743/5000 [1:39:35<9:30:27,  8.04s/it, loss=0.4348, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 744/5000 [1:39:44<9:33:49,  8.09s/it, loss=0.4348, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 744/5000 [1:39:44<9:33:49,  8.09s/it, loss=0.4899, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 745/5000 [1:39:51<9:31:07,  8.05s/it, loss=0.4899, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 745/5000 [1:39:51<9:31:07,  8.05s/it, loss=0.8296, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 746/5000 [1:40:00<9:34:05,  8.10s/it, loss=0.8296, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 746/5000 [1:40:00<9:34:05,  8.10s/it, loss=1.1487, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 747/5000 [1:40:08<9:31:07,  8.06s/it, loss=1.1487, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 747/5000 [1:40:08<9:31:07,  8.06s/it, loss=0.5159, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 748/5000 [1:40:16<9:30:05,  8.04s/it, loss=0.5159, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 748/5000 [1:40:16<9:30:05,  8.04s/it, loss=0.5618, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 749/5000 [1:40:24<9:34:32,  8.11s/it, loss=0.5618, lr=9.93e-06]Steps:  15%|‚ñà‚ñç        | 749/5000 [1:40:24<9:34:32,  8.11s/it, loss=1.1331, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 750/5000 [1:40:28<8:09:54,  6.92s/it, loss=1.1331, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 750/5000 [1:40:28<8:09:54,  6.92s/it, loss=0.7943, lr=9.92e-06]01/30/2026 06:03:17 - INFO - __main__ - 
==================================================
01/30/2026 06:03:17 - INFO - __main__ - Epoch 9 completed: avg_loss = 0.7756
01/30/2026 06:03:17 - INFO - __main__ - ==================================================


[Step 750] Training Debug Info:
  Loss: 0.999000
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0145, std: 0.8984
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0121, std: 1.3438
  Model pred mean: -0.0154, std: 0.8945
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 750] Training Debug Info:
  Loss: 0.767360
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0332, std: 1.0000
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0364, std: 1.4141
  Model pred mean: -0.0342, std: 1.1016
  Sigmas: [0.95703125]... (timesteps: [956.0])

[Step 750] Training Debug Info:
  Loss: 0.907698
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0356, std: 0.8711
  Noise mean: 0.0028, std: 1.0000
  Target mean: 0.0386, std: 1.3281
  Model pred mean: 0.0349, std: 0.9023
  Sigmas: [0.435546875]... (timesteps: [436.0])

[Step 750] Training Debug Info:
  Loss: 0.453245
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0106, std: 0.9453
  Noise mean: -0.0031, std: 1.0000
  Target mean: -0.0137, std: 1.3750
  Model pred mean: -0.0104, std: 1.1875
  Sigmas: [0.67578125]... (timesteps: [676.0])
Steps:  15%|‚ñà‚ñå        | 751/5000 [1:40:36<8:38:52,  7.33s/it, loss=0.7943, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 751/5000 [1:40:36<8:38:52,  7.33s/it, loss=0.4532, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 752/5000 [1:40:45<9:02:54,  7.67s/it, loss=0.4532, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 752/5000 [1:40:45<9:02:54,  7.67s/it, loss=0.3919, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 753/5000 [1:40:53<9:10:34,  7.78s/it, loss=0.3919, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 753/5000 [1:40:53<9:10:34,  7.78s/it, loss=1.0218, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 754/5000 [1:41:01<9:13:55,  7.83s/it, loss=1.0218, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 754/5000 [1:41:01<9:13:55,  7.83s/it, loss=1.0695, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 755/5000 [1:41:09<9:16:59,  7.87s/it, loss=1.0695, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 755/5000 [1:41:09<9:16:59,  7.87s/it, loss=0.3953, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 756/5000 [1:41:17<9:27:28,  8.02s/it, loss=0.3953, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 756/5000 [1:41:17<9:27:28,  8.02s/it, loss=0.6384, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 757/5000 [1:41:25<9:32:45,  8.10s/it, loss=0.6384, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 757/5000 [1:41:25<9:32:45,  8.10s/it, loss=0.4796, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 758/5000 [1:41:33<9:29:58,  8.06s/it, loss=0.4796, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 758/5000 [1:41:33<9:29:58,  8.06s/it, loss=0.4317, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 759/5000 [1:41:41<9:28:02,  8.04s/it, loss=0.4317, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 759/5000 [1:41:41<9:28:02,  8.04s/it, loss=0.7929, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 760/5000 [1:41:49<9:26:50,  8.02s/it, loss=0.7929, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 760/5000 [1:41:49<9:26:50,  8.02s/it, loss=0.6960, lr=9.92e-06]
[Step 760] Training Debug Info:
  Loss: 0.421505
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0015, std: 0.8477
  Noise mean: -0.0032, std: 1.0000
  Target mean: -0.0047, std: 1.3125
  Model pred mean: -0.0021, std: 1.1328
  Sigmas: [0.78515625]... (timesteps: [785.0])

[Step 760] Training Debug Info:
  Loss: 1.048350
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0277, std: 0.9180
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0262, std: 1.3594
  Model pred mean: 0.0276, std: 0.8867
  Sigmas: [0.330078125]... (timesteps: [330.0])

[Step 760] Training Debug Info:
  Loss: 0.572512
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0011, std: 0.8867
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0001, std: 1.3359
  Model pred mean: 0.0020, std: 1.1016
  Sigmas: [0.984375]... (timesteps: [985.0])

[Step 760] Training Debug Info:
  Loss: 1.110664
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0327, std: 0.9922
  Noise mean: 0.0004, std: 1.0000
  Target mean: -0.0325, std: 1.4062
  Model pred mean: -0.0330, std: 0.9297
  Sigmas: [0.1943359375]... (timesteps: [194.0])
Steps:  15%|‚ñà‚ñå        | 761/5000 [1:41:58<9:29:53,  8.07s/it, loss=0.6960, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 761/5000 [1:41:58<9:29:53,  8.07s/it, loss=1.1107, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 762/5000 [1:42:06<9:31:48,  8.10s/it, loss=1.1107, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 762/5000 [1:42:06<9:31:48,  8.10s/it, loss=0.6112, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 763/5000 [1:42:14<9:27:58,  8.04s/it, loss=0.6112, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 763/5000 [1:42:14<9:27:58,  8.04s/it, loss=0.7937, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 764/5000 [1:42:22<9:26:44,  8.03s/it, loss=0.7937, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 764/5000 [1:42:22<9:26:44,  8.03s/it, loss=0.4145, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 765/5000 [1:42:30<9:25:39,  8.01s/it, loss=0.4145, lr=9.92e-06]Steps:  15%|‚ñà‚ñå        | 765/5000 [1:42:30<9:25:39,  8.01s/it, loss=1.1021, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 766/5000 [1:42:38<9:28:34,  8.06s/it, loss=1.1021, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 766/5000 [1:42:38<9:28:34,  8.06s/it, loss=0.4625, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 767/5000 [1:42:46<9:32:31,  8.12s/it, loss=0.4625, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 767/5000 [1:42:46<9:32:31,  8.12s/it, loss=1.1753, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 768/5000 [1:42:54<9:30:23,  8.09s/it, loss=1.1753, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 768/5000 [1:42:54<9:30:23,  8.09s/it, loss=0.7885, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 769/5000 [1:43:02<9:28:16,  8.06s/it, loss=0.7885, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 769/5000 [1:43:02<9:28:16,  8.06s/it, loss=1.0375, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 770/5000 [1:43:10<9:27:30,  8.05s/it, loss=1.0375, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 770/5000 [1:43:10<9:27:30,  8.05s/it, loss=0.7296, lr=9.91e-06]
[Step 770] Training Debug Info:
  Loss: 0.541712
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0085, std: 0.8828
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0106, std: 1.3359
  Model pred mean: -0.0043, std: 1.1094
  Sigmas: [0.640625]... (timesteps: [640.0])

[Step 770] Training Debug Info:
  Loss: 0.523191
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0020, std: 0.9609
  Noise mean: 0.0028, std: 1.0000
  Target mean: 0.0008, std: 1.3828
  Model pred mean: -0.0068, std: 1.1953
  Sigmas: [0.88671875]... (timesteps: [888.0])

[Step 770] Training Debug Info:
  Loss: 0.419252
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0077, std: 0.9062
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0081, std: 1.3516
  Model pred mean: -0.0077, std: 1.1797
  Sigmas: [0.76953125]... (timesteps: [769.0])

[Step 770] Training Debug Info:
  Loss: 0.598079
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0259, std: 0.9180
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0281, std: 1.3594
  Model pred mean: 0.0322, std: 1.1094
  Sigmas: [0.58203125]... (timesteps: [582.0])
Steps:  15%|‚ñà‚ñå        | 771/5000 [1:43:18<9:27:08,  8.05s/it, loss=0.7296, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 771/5000 [1:43:18<9:27:08,  8.05s/it, loss=0.5981, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 772/5000 [1:43:26<9:31:06,  8.10s/it, loss=0.5981, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 772/5000 [1:43:26<9:31:06,  8.10s/it, loss=1.0727, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 773/5000 [1:43:34<9:32:31,  8.13s/it, loss=1.0727, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 773/5000 [1:43:34<9:32:31,  8.13s/it, loss=1.1588, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 774/5000 [1:43:42<9:29:29,  8.09s/it, loss=1.1588, lr=9.91e-06]Steps:  15%|‚ñà‚ñå        | 774/5000 [1:43:42<9:29:29,  8.09s/it, loss=1.1088, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 775/5000 [1:43:50<9:26:01,  8.04s/it, loss=1.1088, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 775/5000 [1:43:50<9:26:01,  8.04s/it, loss=0.9845, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 776/5000 [1:43:58<9:24:48,  8.02s/it, loss=0.9845, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 776/5000 [1:43:58<9:24:48,  8.02s/it, loss=1.1473, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 777/5000 [1:44:07<9:27:47,  8.07s/it, loss=1.1473, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 777/5000 [1:44:07<9:27:47,  8.07s/it, loss=0.4291, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 778/5000 [1:44:15<9:31:50,  8.13s/it, loss=0.4291, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 778/5000 [1:44:15<9:31:50,  8.13s/it, loss=1.0552, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 779/5000 [1:44:23<9:30:20,  8.11s/it, loss=1.0552, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 779/5000 [1:44:23<9:30:20,  8.11s/it, loss=1.1452, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 780/5000 [1:44:31<9:28:53,  8.09s/it, loss=1.1452, lr=9.91e-06]Steps:  16%|‚ñà‚ñå        | 780/5000 [1:44:31<9:28:53,  8.09s/it, loss=0.6968, lr=9.90e-06]
[Step 780] Training Debug Info:
  Loss: 0.846908
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0009, std: 0.9336
  Noise mean: 0.0033, std: 1.0000
  Target mean: 0.0042, std: 1.3672
  Model pred mean: 0.0008, std: 1.0000
  Sigmas: [0.361328125]... (timesteps: [362.0])

[Step 780] Training Debug Info:
  Loss: 0.664682
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0082, std: 0.8867
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0091, std: 1.3359
  Model pred mean: -0.0104, std: 1.0625
  Sigmas: [0.5546875]... (timesteps: [555.0])

[Step 780] Training Debug Info:
  Loss: 1.154420
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0162, std: 0.9023
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0156, std: 1.3438
  Model pred mean: -0.0143, std: 0.8008
  Sigmas: [0.185546875]... (timesteps: [186.0])

[Step 780] Training Debug Info:
  Loss: 0.518892
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0027, std: 0.8672
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0042, std: 1.3203
  Model pred mean: 0.0015, std: 1.1094
  Sigmas: [0.671875]... (timesteps: [673.0])
Steps:  16%|‚ñà‚ñå        | 781/5000 [1:44:39<9:25:59,  8.05s/it, loss=0.6968, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 781/5000 [1:44:39<9:25:59,  8.05s/it, loss=0.5189, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 782/5000 [1:44:47<9:30:01,  8.11s/it, loss=0.5189, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 782/5000 [1:44:47<9:30:01,  8.11s/it, loss=1.1589, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 783/5000 [1:44:55<9:27:15,  8.07s/it, loss=1.1589, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 783/5000 [1:44:55<9:27:15,  8.07s/it, loss=0.4353, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 784/5000 [1:45:03<9:29:20,  8.10s/it, loss=0.4353, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 784/5000 [1:45:03<9:29:20,  8.10s/it, loss=0.5227, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 785/5000 [1:45:11<9:25:54,  8.06s/it, loss=0.5227, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 785/5000 [1:45:11<9:25:54,  8.06s/it, loss=0.3724, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 786/5000 [1:45:19<9:25:27,  8.05s/it, loss=0.3724, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 786/5000 [1:45:19<9:25:27,  8.05s/it, loss=0.8096, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 787/5000 [1:45:27<9:22:42,  8.01s/it, loss=0.8096, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 787/5000 [1:45:27<9:22:42,  8.01s/it, loss=0.5739, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 788/5000 [1:45:35<9:26:51,  8.07s/it, loss=0.5739, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 788/5000 [1:45:35<9:26:51,  8.07s/it, loss=1.0931, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 789/5000 [1:45:44<9:28:58,  8.11s/it, loss=1.0931, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 789/5000 [1:45:44<9:28:58,  8.11s/it, loss=1.1109, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 790/5000 [1:45:52<9:27:44,  8.09s/it, loss=1.1109, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 790/5000 [1:45:52<9:27:44,  8.09s/it, loss=1.0249, lr=9.90e-06]
[Step 790] Training Debug Info:
  Loss: 0.573426
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0255, std: 0.8984
  Noise mean: 0.0001, std: 1.0000
  Target mean: -0.0254, std: 1.3438
  Model pred mean: -0.0250, std: 1.1172
  Sigmas: [0.9296875]... (timesteps: [929.0])

[Step 790] Training Debug Info:
  Loss: 1.170638
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0025, std: 0.8789
  Noise mean: 0.0015, std: 0.9961
  Target mean: -0.0009, std: 1.3281
  Model pred mean: -0.0034, std: 0.7656
  Sigmas: [0.205078125]... (timesteps: [205.0])

[Step 790] Training Debug Info:
  Loss: 0.449520
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0571, std: 0.9180
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0562, std: 1.3594
  Model pred mean: -0.0535, std: 1.1797
  Sigmas: [0.81640625]... (timesteps: [815.0])

[Step 790] Training Debug Info:
  Loss: 1.068368
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0122, std: 0.9062
  Noise mean: -0.0015, std: 1.0000
  Target mean: 0.0107, std: 1.3516
  Model pred mean: 0.0114, std: 0.8633
  Sigmas: [0.035888671875]... (timesteps: [36.0])
Steps:  16%|‚ñà‚ñå        | 791/5000 [1:46:00<9:28:33,  8.10s/it, loss=1.0249, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 791/5000 [1:46:00<9:28:33,  8.10s/it, loss=1.0684, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 792/5000 [1:46:08<9:25:48,  8.07s/it, loss=1.0684, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 792/5000 [1:46:08<9:25:48,  8.07s/it, loss=0.4667, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 793/5000 [1:46:16<9:28:14,  8.10s/it, loss=0.4667, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 793/5000 [1:46:16<9:28:14,  8.10s/it, loss=0.6171, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 794/5000 [1:46:24<9:31:04,  8.15s/it, loss=0.6171, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 794/5000 [1:46:24<9:31:04,  8.15s/it, loss=0.3693, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 795/5000 [1:46:32<9:29:09,  8.12s/it, loss=0.3693, lr=9.90e-06]Steps:  16%|‚ñà‚ñå        | 795/5000 [1:46:32<9:29:09,  8.12s/it, loss=0.4882, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 796/5000 [1:46:40<9:26:16,  8.08s/it, loss=0.4882, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 796/5000 [1:46:40<9:26:16,  8.08s/it, loss=0.7183, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 797/5000 [1:46:48<9:24:00,  8.05s/it, loss=0.7183, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 797/5000 [1:46:48<9:24:00,  8.05s/it, loss=0.4202, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 798/5000 [1:46:56<9:27:32,  8.10s/it, loss=0.4202, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 798/5000 [1:46:56<9:27:32,  8.10s/it, loss=1.1004, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 799/5000 [1:47:05<9:29:53,  8.14s/it, loss=1.1004, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 799/5000 [1:47:05<9:29:53,  8.14s/it, loss=0.3561, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 800/5000 [1:47:13<9:27:11,  8.10s/it, loss=0.3561, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 800/5000 [1:47:13<9:27:11,  8.10s/it, loss=1.1113, lr=9.89e-06]01/30/2026 06:10:02 - INFO - __main__ - 
[Step 800] ‚úÖ Loss in normal range (1.1113)
01/30/2026 06:10:02 - INFO - __main__ -   Loss avg (last 100): 0.7617
01/30/2026 06:10:02 - INFO - __main__ -   Loss range: [0.3561, 1.1917]

[Step 800] Training Debug Info:
  Loss: 1.127998
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0137, std: 0.9219
  Noise mean: 0.0019, std: 1.0000
  Target mean: 0.0156, std: 1.3594
  Model pred mean: 0.0128, std: 0.8516
  Sigmas: [0.216796875]... (timesteps: [217.0])

[Step 800] Training Debug Info:
  Loss: 1.091445
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0267, std: 0.9062
  Noise mean: -0.0002, std: 1.0000
  Target mean: 0.0266, std: 1.3516
  Model pred mean: 0.0251, std: 0.8516
  Sigmas: [0.06005859375]... (timesteps: [60.0])

[Step 800] Training Debug Info:
  Loss: 0.660629
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0193, std: 0.9102
  Noise mean: 0.0027, std: 1.0000
  Target mean: -0.0166, std: 1.3516
  Model pred mean: -0.0146, std: 1.0781
  Sigmas: [0.9765625]... (timesteps: [976.0])

[Step 800] Training Debug Info:
  Loss: 1.087770
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0356, std: 0.8945
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0383, std: 1.3438
  Model pred mean: -0.0334, std: 0.8398
  Sigmas: [0.049072265625]... (timesteps: [49.0])
Steps:  16%|‚ñà‚ñå        | 801/5000 [1:47:21<9:24:42,  8.07s/it, loss=1.1113, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 801/5000 [1:47:21<9:24:42,  8.07s/it, loss=1.0878, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 802/5000 [1:47:29<9:24:48,  8.07s/it, loss=1.0878, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 802/5000 [1:47:29<9:24:48,  8.07s/it, loss=0.4085, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 803/5000 [1:47:37<9:23:40,  8.06s/it, loss=0.4085, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 803/5000 [1:47:37<9:23:40,  8.06s/it, loss=0.5014, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 804/5000 [1:47:45<9:25:17,  8.08s/it, loss=0.5014, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 804/5000 [1:47:45<9:25:17,  8.08s/it, loss=1.1597, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 805/5000 [1:47:53<9:28:15,  8.13s/it, loss=1.1597, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 805/5000 [1:47:53<9:28:15,  8.13s/it, loss=1.1752, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 806/5000 [1:48:01<9:23:05,  8.06s/it, loss=1.1752, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 806/5000 [1:48:01<9:23:05,  8.06s/it, loss=0.3251, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 807/5000 [1:48:09<9:21:29,  8.03s/it, loss=0.3251, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 807/5000 [1:48:09<9:21:29,  8.03s/it, loss=1.0530, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 808/5000 [1:48:17<9:19:52,  8.01s/it, loss=1.0530, lr=9.89e-06]Steps:  16%|‚ñà‚ñå        | 808/5000 [1:48:17<9:19:52,  8.01s/it, loss=1.1326, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 809/5000 [1:48:25<9:23:01,  8.06s/it, loss=1.1326, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 809/5000 [1:48:25<9:23:01,  8.06s/it, loss=1.1454, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 810/5000 [1:48:33<9:26:30,  8.11s/it, loss=1.1454, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 810/5000 [1:48:33<9:26:30,  8.11s/it, loss=0.5300, lr=9.88e-06]
[Step 810] Training Debug Info:
  Loss: 0.537301
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0156, std: 0.9375
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0147, std: 1.3672
  Model pred mean: -0.0103, std: 1.1562
  Sigmas: [0.60546875]... (timesteps: [604.0])

[Step 810] Training Debug Info:
  Loss: 0.962214
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0053, std: 0.8711
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0046, std: 1.3203
  Model pred mean: 0.0059, std: 0.8906
  Sigmas: [0.3984375]... (timesteps: [399.0])

[Step 810] Training Debug Info:
  Loss: 1.093769
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0168, std: 0.8828
  Noise mean: 0.0018, std: 1.0000
  Target mean: 0.0186, std: 1.3281
  Model pred mean: 0.0148, std: 0.8164
  Sigmas: [0.052978515625]... (timesteps: [53.0])

[Step 810] Training Debug Info:
  Loss: 1.111634
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0437, std: 0.9102
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0425, std: 1.3516
  Model pred mean: 0.0420, std: 0.8477
  Sigmas: [0.275390625]... (timesteps: [276.0])
Steps:  16%|‚ñà‚ñå        | 811/5000 [1:48:41<9:22:08,  8.05s/it, loss=0.5300, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 811/5000 [1:48:41<9:22:08,  8.05s/it, loss=1.1116, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 812/5000 [1:48:49<9:20:39,  8.03s/it, loss=1.1116, lr=9.88e-06]Steps:  16%|‚ñà‚ñå        | 812/5000 [1:48:49<9:20:39,  8.03s/it, loss=0.7712, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 813/5000 [1:48:57<9:18:19,  8.00s/it, loss=0.7712, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 813/5000 [1:48:57<9:18:19,  8.00s/it, loss=0.9556, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 814/5000 [1:49:05<9:17:41,  7.99s/it, loss=0.9556, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 814/5000 [1:49:05<9:17:41,  7.99s/it, loss=0.4289, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 815/5000 [1:49:14<9:29:12,  8.16s/it, loss=0.4289, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 815/5000 [1:49:14<9:29:12,  8.16s/it, loss=0.5116, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 816/5000 [1:49:22<9:25:17,  8.11s/it, loss=0.5116, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 816/5000 [1:49:22<9:25:17,  8.11s/it, loss=0.3853, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 817/5000 [1:49:30<9:22:27,  8.07s/it, loss=0.3853, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 817/5000 [1:49:30<9:22:27,  8.07s/it, loss=1.0992, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 818/5000 [1:49:38<9:20:59,  8.05s/it, loss=1.0992, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 818/5000 [1:49:38<9:20:59,  8.05s/it, loss=0.6078, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 819/5000 [1:49:46<9:21:03,  8.05s/it, loss=0.6078, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 819/5000 [1:49:46<9:21:03,  8.05s/it, loss=0.9353, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 820/5000 [1:49:54<9:24:41,  8.11s/it, loss=0.9353, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 820/5000 [1:49:54<9:24:41,  8.11s/it, loss=0.4203, lr=9.88e-06]
[Step 820] Training Debug Info:
  Loss: 0.886536
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0139, std: 0.8789
  Noise mean: 0.0029, std: 1.0000
  Target mean: 0.0167, std: 1.3359
  Model pred mean: 0.0116, std: 0.9492
  Sigmas: [0.439453125]... (timesteps: [440.0])

[Step 820] Training Debug Info:
  Loss: 1.142516
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0186, std: 0.8672
  Noise mean: 0.0021, std: 1.0000
  Target mean: 0.0206, std: 1.3281
  Model pred mean: 0.0134, std: 0.7812
  Sigmas: [0.08203125]... (timesteps: [82.0])

[Step 820] Training Debug Info:
  Loss: 0.546767
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0137, std: 0.9883
  Noise mean: 0.0024, std: 1.0000
  Target mean: -0.0112, std: 1.4062
  Model pred mean: -0.0140, std: 1.2031
  Sigmas: [0.63671875]... (timesteps: [635.0])

[Step 820] Training Debug Info:
  Loss: 1.171966
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0006, std: 0.9102
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0010, std: 1.3516
  Model pred mean: -0.0044, std: 0.8164
  Sigmas: [0.2109375]... (timesteps: [211.0])
Steps:  16%|‚ñà‚ñã        | 821/5000 [1:50:02<9:25:50,  8.12s/it, loss=0.4203, lr=9.88e-06]Steps:  16%|‚ñà‚ñã        | 821/5000 [1:50:02<9:25:50,  8.12s/it, loss=1.1720, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 822/5000 [1:50:10<9:22:47,  8.08s/it, loss=1.1720, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 822/5000 [1:50:10<9:22:47,  8.08s/it, loss=1.0874, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 823/5000 [1:50:18<9:20:52,  8.06s/it, loss=1.0874, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 823/5000 [1:50:18<9:20:52,  8.06s/it, loss=1.1473, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 824/5000 [1:50:26<9:19:34,  8.04s/it, loss=1.1473, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 824/5000 [1:50:26<9:19:34,  8.04s/it, loss=1.1065, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 825/5000 [1:50:30<7:58:13,  6.87s/it, loss=1.1065, lr=9.87e-06]Steps:  16%|‚ñà‚ñã        | 825/5000 [1:50:30<7:58:13,  6.87s/it, loss=0.3802, lr=9.87e-06]01/30/2026 06:13:19 - INFO - __main__ - 
==================================================
01/30/2026 06:13:19 - INFO - __main__ - Epoch 10 completed: avg_loss = 0.7862
01/30/2026 06:13:19 - INFO - __main__ - ==================================================

Steps:  17%|‚ñà‚ñã        | 826/5000 [1:50:39<8:43:00,  7.52s/it, loss=0.3802, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 826/5000 [1:50:39<8:43:00,  7.52s/it, loss=0.6155, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 827/5000 [1:50:47<8:52:16,  7.65s/it, loss=0.6155, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 827/5000 [1:50:47<8:52:16,  7.65s/it, loss=0.9947, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 828/5000 [1:50:55<8:59:43,  7.76s/it, loss=0.9947, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 828/5000 [1:50:55<8:59:43,  7.76s/it, loss=0.7024, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 829/5000 [1:51:03<9:03:51,  7.82s/it, loss=0.7024, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 829/5000 [1:51:03<9:03:51,  7.82s/it, loss=0.8480, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 830/5000 [1:51:11<9:07:54,  7.88s/it, loss=0.8480, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 830/5000 [1:51:11<9:07:54,  7.88s/it, loss=0.8434, lr=9.87e-06]
[Step 830] Training Debug Info:
  Loss: 0.672841
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0260, std: 0.9258
  Noise mean: -0.0014, std: 1.0000
  Target mean: 0.0247, std: 1.3594
  Model pred mean: 0.0297, std: 1.0938
  Sigmas: [0.98828125]... (timesteps: [987.0])

[Step 830] Training Debug Info:
  Loss: 0.640849
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0142, std: 0.9102
  Noise mean: 0.0001, std: 1.0000
  Target mean: 0.0143, std: 1.3516
  Model pred mean: 0.0126, std: 1.0938
  Sigmas: [0.58984375]... (timesteps: [589.0])

[Step 830] Training Debug Info:
  Loss: 0.529366
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0078, std: 0.8906
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0084, std: 1.3438
  Model pred mean: 0.0066, std: 1.1172
  Sigmas: [0.63671875]... (timesteps: [636.0])

[Step 830] Training Debug Info:
  Loss: 0.456606
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0074, std: 0.8984
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0056, std: 1.3516
  Model pred mean: 0.0021, std: 1.1641
  Sigmas: [0.71484375]... (timesteps: [714.0])
Steps:  17%|‚ñà‚ñã        | 831/5000 [1:51:20<9:15:12,  7.99s/it, loss=0.8434, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 831/5000 [1:51:20<9:15:12,  7.99s/it, loss=0.4566, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 832/5000 [1:51:28<9:20:57,  8.08s/it, loss=0.4566, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 832/5000 [1:51:28<9:20:57,  8.08s/it, loss=0.5631, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 833/5000 [1:51:36<9:19:05,  8.05s/it, loss=0.5631, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 833/5000 [1:51:36<9:19:05,  8.05s/it, loss=0.4618, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 834/5000 [1:51:44<9:19:49,  8.06s/it, loss=0.4618, lr=9.87e-06]Steps:  17%|‚ñà‚ñã        | 834/5000 [1:51:44<9:19:49,  8.06s/it, loss=0.3728, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 835/5000 [1:51:52<9:17:37,  8.03s/it, loss=0.3728, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 835/5000 [1:51:52<9:17:37,  8.03s/it, loss=0.9549, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 836/5000 [1:52:00<9:15:22,  8.00s/it, loss=0.9549, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 836/5000 [1:52:00<9:15:22,  8.00s/it, loss=0.9885, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 837/5000 [1:52:08<9:24:25,  8.13s/it, loss=0.9885, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 837/5000 [1:52:08<9:24:25,  8.13s/it, loss=0.4521, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 838/5000 [1:52:16<9:20:24,  8.08s/it, loss=0.4521, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 838/5000 [1:52:16<9:20:24,  8.08s/it, loss=0.8295, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 839/5000 [1:52:24<9:17:17,  8.04s/it, loss=0.8295, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 839/5000 [1:52:24<9:17:17,  8.04s/it, loss=0.5267, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 840/5000 [1:52:32<9:16:07,  8.02s/it, loss=0.5267, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 840/5000 [1:52:32<9:16:07,  8.02s/it, loss=0.3533, lr=9.86e-06]
[Step 840] Training Debug Info:
  Loss: 0.948691
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0112, std: 0.9727
  Noise mean: 0.0019, std: 1.0000
  Target mean: -0.0094, std: 1.3906
  Model pred mean: -0.0130, std: 1.0156
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 840] Training Debug Info:
  Loss: 0.953938
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0693, std: 0.9336
  Noise mean: -0.0003, std: 1.0000
  Target mean: 0.0688, std: 1.3672
  Model pred mean: 0.0718, std: 0.9648
  Sigmas: [0.302734375]... (timesteps: [302.0])

[Step 840] Training Debug Info:
  Loss: 0.553736
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0088, std: 0.9453
  Noise mean: -0.0013, std: 1.0000
  Target mean: 0.0076, std: 1.3828
  Model pred mean: 0.0090, std: 1.1641
  Sigmas: [0.91015625]... (timesteps: [912.0])

[Step 840] Training Debug Info:
  Loss: 1.040616
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0006, std: 0.9297
  Noise mean: 0.0032, std: 1.0000
  Target mean: 0.0038, std: 1.3672
  Model pred mean: 0.0008, std: 0.9180
  Sigmas: [0.220703125]... (timesteps: [221.0])
Steps:  17%|‚ñà‚ñã        | 841/5000 [1:52:40<9:15:36,  8.02s/it, loss=0.3533, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 841/5000 [1:52:40<9:15:36,  8.02s/it, loss=1.0406, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 842/5000 [1:52:49<9:25:27,  8.16s/it, loss=1.0406, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 842/5000 [1:52:49<9:25:27,  8.16s/it, loss=1.1483, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 843/5000 [1:52:57<9:22:38,  8.12s/it, loss=1.1483, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 843/5000 [1:52:57<9:22:38,  8.12s/it, loss=0.4783, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 844/5000 [1:53:05<9:19:55,  8.08s/it, loss=0.4783, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 844/5000 [1:53:05<9:19:55,  8.08s/it, loss=1.0699, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 845/5000 [1:53:13<9:18:24,  8.06s/it, loss=1.0699, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 845/5000 [1:53:13<9:18:24,  8.06s/it, loss=0.4345, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 846/5000 [1:53:21<9:19:45,  8.08s/it, loss=0.4345, lr=9.86e-06]Steps:  17%|‚ñà‚ñã        | 846/5000 [1:53:21<9:19:45,  8.08s/it, loss=0.4189, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 847/5000 [1:53:29<9:22:53,  8.13s/it, loss=0.4189, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 847/5000 [1:53:29<9:22:53,  8.13s/it, loss=0.3850, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 848/5000 [1:53:37<9:24:26,  8.16s/it, loss=0.3850, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 848/5000 [1:53:37<9:24:26,  8.16s/it, loss=0.8274, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 849/5000 [1:53:45<9:20:04,  8.10s/it, loss=0.8274, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 849/5000 [1:53:45<9:20:04,  8.10s/it, loss=0.6810, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 850/5000 [1:53:53<9:16:12,  8.04s/it, loss=0.6810, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 850/5000 [1:53:53<9:16:12,  8.04s/it, loss=0.4471, lr=9.85e-06]
[Step 850] Training Debug Info:
  Loss: 1.112534
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0020, std: 0.8867
  Noise mean: -0.0029, std: 1.0000
  Target mean: -0.0009, std: 1.3359
  Model pred mean: 0.0043, std: 0.8242
  Sigmas: [0.28125]... (timesteps: [281.0])

[Step 850] Training Debug Info:
  Loss: 0.362364
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0082, std: 0.8750
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0072, std: 1.3281
  Model pred mean: -0.0062, std: 1.2031
  Sigmas: [0.86328125]... (timesteps: [862.0])

[Step 850] Training Debug Info:
  Loss: 1.169136
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0092, std: 0.8867
  Noise mean: 0.0027, std: 1.0000
  Target mean: 0.0120, std: 1.3359
  Model pred mean: 0.0112, std: 0.7852
  Sigmas: [0.17578125]... (timesteps: [176.0])

[Step 850] Training Debug Info:
  Loss: 1.092857
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0156, std: 0.9062
  Noise mean: -0.0009, std: 1.0000
  Target mean: -0.0166, std: 1.3516
  Model pred mean: -0.0186, std: 0.8594
  Sigmas: [0.26953125]... (timesteps: [270.0])
Steps:  17%|‚ñà‚ñã        | 851/5000 [1:54:01<9:15:34,  8.03s/it, loss=0.4471, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 851/5000 [1:54:01<9:15:34,  8.03s/it, loss=1.0929, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 852/5000 [1:54:09<9:14:59,  8.03s/it, loss=1.0929, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 852/5000 [1:54:09<9:14:59,  8.03s/it, loss=0.4664, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 853/5000 [1:54:18<9:22:36,  8.14s/it, loss=0.4664, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 853/5000 [1:54:18<9:22:36,  8.14s/it, loss=0.5945, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 854/5000 [1:54:26<9:21:13,  8.12s/it, loss=0.5945, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 854/5000 [1:54:26<9:21:13,  8.12s/it, loss=0.4456, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 855/5000 [1:54:34<9:19:04,  8.09s/it, loss=0.4456, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 855/5000 [1:54:34<9:19:04,  8.09s/it, loss=1.0970, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 856/5000 [1:54:42<9:15:30,  8.04s/it, loss=1.0970, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 856/5000 [1:54:42<9:15:30,  8.04s/it, loss=0.3836, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 857/5000 [1:54:50<9:15:03,  8.04s/it, loss=0.3836, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 857/5000 [1:54:50<9:15:03,  8.04s/it, loss=0.3923, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 858/5000 [1:54:58<9:24:33,  8.18s/it, loss=0.3923, lr=9.85e-06]Steps:  17%|‚ñà‚ñã        | 858/5000 [1:54:58<9:24:33,  8.18s/it, loss=0.9320, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 859/5000 [1:55:06<9:19:14,  8.10s/it, loss=0.9320, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 859/5000 [1:55:06<9:19:14,  8.10s/it, loss=0.4226, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 860/5000 [1:55:14<9:15:22,  8.05s/it, loss=0.4226, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 860/5000 [1:55:14<9:15:22,  8.05s/it, loss=0.3960, lr=9.84e-06]
[Step 860] Training Debug Info:
  Loss: 0.486345
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0352, std: 0.9219
  Noise mean: 0.0004, std: 1.0000
  Target mean: 0.0356, std: 1.3594
  Model pred mean: 0.0306, std: 1.1562
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 860] Training Debug Info:
  Loss: 0.536035
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0259, std: 0.9219
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0248, std: 1.3594
  Model pred mean: -0.0277, std: 1.1484
  Sigmas: [0.62890625]... (timesteps: [630.0])

[Step 860] Training Debug Info:
  Loss: 1.007393
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0065, std: 0.8906
  Noise mean: 0.0051, std: 1.0000
  Target mean: 0.0116, std: 1.3438
  Model pred mean: 0.0052, std: 0.8906
  Sigmas: [0.361328125]... (timesteps: [362.0])

[Step 860] Training Debug Info:
  Loss: 1.102784
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0115, std: 0.8867
  Noise mean: 0.0020, std: 1.0000
  Target mean: -0.0095, std: 1.3359
  Model pred mean: -0.0071, std: 0.8242
  Sigmas: [0.06103515625]... (timesteps: [61.0])
Steps:  17%|‚ñà‚ñã        | 861/5000 [1:55:22<9:15:41,  8.06s/it, loss=0.3960, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 861/5000 [1:55:22<9:15:41,  8.06s/it, loss=1.1028, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 862/5000 [1:55:30<9:12:47,  8.02s/it, loss=1.1028, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 862/5000 [1:55:30<9:12:47,  8.02s/it, loss=0.5434, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 863/5000 [1:55:38<9:12:03,  8.01s/it, loss=0.5434, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 863/5000 [1:55:38<9:12:03,  8.01s/it, loss=0.4762, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 864/5000 [1:55:46<9:16:59,  8.08s/it, loss=0.4762, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 864/5000 [1:55:46<9:16:59,  8.08s/it, loss=0.7763, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 865/5000 [1:55:54<9:15:52,  8.07s/it, loss=0.7763, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 865/5000 [1:55:54<9:15:52,  8.07s/it, loss=0.6579, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 866/5000 [1:56:02<9:14:45,  8.05s/it, loss=0.6579, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 866/5000 [1:56:02<9:14:45,  8.05s/it, loss=0.3794, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 867/5000 [1:56:10<9:12:28,  8.02s/it, loss=0.3794, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 867/5000 [1:56:10<9:12:28,  8.02s/it, loss=1.1821, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 868/5000 [1:56:18<9:11:13,  8.00s/it, loss=1.1821, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 868/5000 [1:56:18<9:11:13,  8.00s/it, loss=0.6803, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 869/5000 [1:56:27<9:20:36,  8.14s/it, loss=0.6803, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 869/5000 [1:56:27<9:20:36,  8.14s/it, loss=0.8394, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 870/5000 [1:56:35<9:18:56,  8.12s/it, loss=0.8394, lr=9.84e-06]Steps:  17%|‚ñà‚ñã        | 870/5000 [1:56:35<9:18:56,  8.12s/it, loss=0.4184, lr=9.83e-06]
[Step 870] Training Debug Info:
  Loss: 1.152308
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0022, std: 0.9180
  Noise mean: 0.0010, std: 1.0000
  Target mean: 0.0032, std: 1.3594
  Model pred mean: 0.0020, std: 0.8203
  Sigmas: [0.1953125]... (timesteps: [195.0])

[Step 870] Training Debug Info:
  Loss: 0.414118
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0056, std: 0.8945
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0061, std: 1.3438
  Model pred mean: -0.0033, std: 1.1797
  Sigmas: [0.90625]... (timesteps: [908.0])

[Step 870] Training Debug Info:
  Loss: 1.104030
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0139, std: 0.8789
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0160, std: 1.3281
  Model pred mean: 0.0167, std: 0.8125
  Sigmas: [0.05810546875]... (timesteps: [58.0])

[Step 870] Training Debug Info:
  Loss: 0.959962
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0295, std: 0.9258
  Noise mean: 0.0039, std: 1.0000
  Target mean: -0.0256, std: 1.3594
  Model pred mean: -0.0276, std: 0.9414
  Sigmas: [0.26171875]... (timesteps: [262.0])
Steps:  17%|‚ñà‚ñã        | 871/5000 [1:56:43<9:18:08,  8.11s/it, loss=0.4184, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 871/5000 [1:56:43<9:18:08,  8.11s/it, loss=0.9600, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 872/5000 [1:56:51<9:15:45,  8.08s/it, loss=0.9600, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 872/5000 [1:56:51<9:15:45,  8.08s/it, loss=0.3803, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 873/5000 [1:56:59<9:14:06,  8.06s/it, loss=0.3803, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 873/5000 [1:56:59<9:14:06,  8.06s/it, loss=0.4562, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 874/5000 [1:57:07<9:21:26,  8.16s/it, loss=0.4562, lr=9.83e-06]Steps:  17%|‚ñà‚ñã        | 874/5000 [1:57:07<9:21:26,  8.16s/it, loss=0.4141, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 875/5000 [1:57:15<9:17:50,  8.11s/it, loss=0.4141, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 875/5000 [1:57:15<9:17:50,  8.11s/it, loss=0.6719, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 876/5000 [1:57:23<9:14:22,  8.07s/it, loss=0.6719, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 876/5000 [1:57:23<9:14:22,  8.07s/it, loss=0.8489, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 877/5000 [1:57:31<9:15:08,  8.08s/it, loss=0.8489, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 877/5000 [1:57:31<9:15:08,  8.08s/it, loss=1.1326, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 878/5000 [1:57:39<9:15:00,  8.08s/it, loss=1.1326, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 878/5000 [1:57:39<9:15:00,  8.08s/it, loss=1.0869, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 879/5000 [1:57:47<9:15:40,  8.09s/it, loss=1.0869, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 879/5000 [1:57:47<9:15:40,  8.09s/it, loss=0.5883, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 880/5000 [1:57:56<9:17:48,  8.12s/it, loss=0.5883, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 880/5000 [1:57:56<9:17:48,  8.12s/it, loss=1.1917, lr=9.83e-06]
[Step 880] Training Debug Info:
  Loss: 0.378165
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0520, std: 0.9180
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0505, std: 1.3594
  Model pred mean: -0.0474, std: 1.2031
  Sigmas: [0.84375]... (timesteps: [845.0])

[Step 880] Training Debug Info:
  Loss: 0.440301
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0197, std: 0.9141
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0221, std: 1.3516
  Model pred mean: -0.0136, std: 1.1953
  Sigmas: [0.8984375]... (timesteps: [900.0])

[Step 880] Training Debug Info:
  Loss: 0.440025
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0140, std: 0.9180
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0126, std: 1.3594
  Model pred mean: -0.0149, std: 1.1875
  Sigmas: [0.890625]... (timesteps: [891.0])

[Step 880] Training Debug Info:
  Loss: 0.354222
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0364, std: 0.9258
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0369, std: 1.3594
  Model pred mean: 0.0354, std: 1.2188
  Sigmas: [0.796875]... (timesteps: [796.0])
Steps:  18%|‚ñà‚ñä        | 881/5000 [1:58:04<9:13:50,  8.07s/it, loss=1.1917, lr=9.83e-06]Steps:  18%|‚ñà‚ñä        | 881/5000 [1:58:04<9:13:50,  8.07s/it, loss=0.3542, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 882/5000 [1:58:12<9:12:03,  8.04s/it, loss=0.3542, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 882/5000 [1:58:12<9:12:03,  8.04s/it, loss=0.5525, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 883/5000 [1:58:20<9:10:46,  8.03s/it, loss=0.5525, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 883/5000 [1:58:20<9:10:46,  8.03s/it, loss=1.1464, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 884/5000 [1:58:28<9:09:21,  8.01s/it, loss=1.1464, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 884/5000 [1:58:28<9:09:21,  8.01s/it, loss=0.3840, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 885/5000 [1:58:36<9:17:34,  8.13s/it, loss=0.3840, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 885/5000 [1:58:36<9:17:34,  8.13s/it, loss=0.6011, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 886/5000 [1:58:44<9:14:05,  8.08s/it, loss=0.6011, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 886/5000 [1:58:44<9:14:05,  8.08s/it, loss=0.4034, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 887/5000 [1:58:52<9:12:35,  8.06s/it, loss=0.4034, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 887/5000 [1:58:52<9:12:35,  8.06s/it, loss=0.9040, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 888/5000 [1:59:00<9:09:46,  8.02s/it, loss=0.9040, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 888/5000 [1:59:00<9:09:46,  8.02s/it, loss=0.4253, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 889/5000 [1:59:08<9:08:34,  8.01s/it, loss=0.4253, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 889/5000 [1:59:08<9:08:34,  8.01s/it, loss=0.6867, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 890/5000 [1:59:16<9:17:56,  8.15s/it, loss=0.6867, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 890/5000 [1:59:16<9:17:56,  8.15s/it, loss=1.2045, lr=9.82e-06]
[Step 890] Training Debug Info:
  Loss: 1.151489
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0212, std: 0.8984
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0236, std: 1.3438
  Model pred mean: -0.0181, std: 0.8203
  Sigmas: [0.1494140625]... (timesteps: [149.0])

[Step 890] Training Debug Info:
  Loss: 1.043706
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0337, std: 0.9414
  Noise mean: -0.0024, std: 1.0000
  Target mean: -0.0361, std: 1.3750
  Model pred mean: -0.0245, std: 0.9414
  Sigmas: [0.02099609375]... (timesteps: [21.0])

[Step 890] Training Debug Info:
  Loss: 0.545964
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0203, std: 1.0078
  Noise mean: -0.0026, std: 1.0000
  Target mean: -0.0228, std: 1.4219
  Model pred mean: -0.0149, std: 1.2109
  Sigmas: [0.86328125]... (timesteps: [862.0])

[Step 890] Training Debug Info:
  Loss: 0.400259
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0007, std: 0.9453
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0003, std: 1.3750
  Model pred mean: -0.0001, std: 1.2188
  Sigmas: [0.765625]... (timesteps: [767.0])
Steps:  18%|‚ñà‚ñä        | 891/5000 [1:59:24<9:14:39,  8.10s/it, loss=1.2045, lr=9.82e-06]Steps:  18%|‚ñà‚ñä        | 891/5000 [1:59:24<9:14:39,  8.10s/it, loss=0.4003, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 892/5000 [1:59:32<9:11:10,  8.05s/it, loss=0.4003, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 892/5000 [1:59:32<9:11:10,  8.05s/it, loss=1.1039, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 893/5000 [1:59:40<9:09:51,  8.03s/it, loss=1.1039, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 893/5000 [1:59:40<9:09:51,  8.03s/it, loss=0.3398, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 894/5000 [1:59:48<9:11:17,  8.06s/it, loss=0.3398, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 894/5000 [1:59:48<9:11:17,  8.06s/it, loss=0.4442, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 895/5000 [1:59:57<9:13:22,  8.09s/it, loss=0.4442, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 895/5000 [1:59:57<9:13:22,  8.09s/it, loss=0.6525, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 896/5000 [2:00:05<9:14:24,  8.11s/it, loss=0.6525, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 896/5000 [2:00:05<9:14:24,  8.11s/it, loss=0.7096, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 897/5000 [2:00:13<9:10:48,  8.05s/it, loss=0.7096, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 897/5000 [2:00:13<9:10:48,  8.05s/it, loss=1.1196, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 898/5000 [2:00:21<9:09:30,  8.04s/it, loss=1.1196, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 898/5000 [2:00:21<9:09:30,  8.04s/it, loss=1.0903, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 899/5000 [2:00:29<9:08:50,  8.03s/it, loss=1.0903, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 899/5000 [2:00:29<9:08:50,  8.03s/it, loss=1.0499, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 900/5000 [2:00:33<7:48:59,  6.86s/it, loss=1.0499, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 900/5000 [2:00:33<7:48:59,  6.86s/it, loss=0.4349, lr=9.81e-06]01/30/2026 06:23:22 - INFO - __main__ - 
[Step 900] ‚úÖ Loss in normal range (0.4349)
01/30/2026 06:23:22 - INFO - __main__ -   Loss avg (last 100): 0.7255
01/30/2026 06:23:22 - INFO - __main__ -   Loss range: [0.3251, 1.2045]
01/30/2026 06:23:22 - INFO - __main__ - 
==================================================
01/30/2026 06:23:22 - INFO - __main__ - Epoch 11 completed: avg_loss = 0.6921
01/30/2026 06:23:22 - INFO - __main__ - ==================================================


[Step 900] Training Debug Info:
  Loss: 1.140028
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0136, std: 0.8984
  Noise mean: -0.0021, std: 1.0000
  Target mean: -0.0156, std: 1.3438
  Model pred mean: -0.0092, std: 0.8047
  Sigmas: [0.1982421875]... (timesteps: [198.0])

[Step 900] Training Debug Info:
  Loss: 0.521392
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0322, std: 1.0000
  Noise mean: 0.0025, std: 1.0000
  Target mean: -0.0297, std: 1.4141
  Model pred mean: -0.0322, std: 1.2266
  Sigmas: [0.77734375]... (timesteps: [776.0])

[Step 900] Training Debug Info:
  Loss: 0.669002
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0356, std: 0.8672
  Noise mean: -0.0004, std: 1.0000
  Target mean: 0.0352, std: 1.3281
  Model pred mean: 0.0400, std: 1.0469
  Sigmas: [0.56640625]... (timesteps: [568.0])

[Step 900] Training Debug Info:
  Loss: 0.407781
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0099, std: 0.9492
  Noise mean: -0.0002, std: 1.0000
  Target mean: -0.0101, std: 1.3750
  Model pred mean: -0.0062, std: 1.2266
  Sigmas: [0.7421875]... (timesteps: [742.0])
Steps:  18%|‚ñà‚ñä        | 901/5000 [2:00:42<8:34:39,  7.53s/it, loss=0.4349, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 901/5000 [2:00:42<8:34:39,  7.53s/it, loss=0.4078, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 902/5000 [2:00:50<8:43:20,  7.66s/it, loss=0.4078, lr=9.81e-06]Steps:  18%|‚ñà‚ñä        | 902/5000 [2:00:50<8:43:20,  7.66s/it, loss=0.7456, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 903/5000 [2:00:58<8:52:43,  7.80s/it, loss=0.7456, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 903/5000 [2:00:58<8:52:43,  7.80s/it, loss=1.0038, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 904/5000 [2:01:06<8:55:22,  7.84s/it, loss=1.0038, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 904/5000 [2:01:06<8:55:22,  7.84s/it, loss=0.7164, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 905/5000 [2:01:14<8:58:19,  7.89s/it, loss=0.7164, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 905/5000 [2:01:14<8:58:19,  7.89s/it, loss=0.9191, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 906/5000 [2:01:22<9:04:27,  7.98s/it, loss=0.9191, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 906/5000 [2:01:22<9:04:27,  7.98s/it, loss=0.9532, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 907/5000 [2:01:30<9:10:14,  8.07s/it, loss=0.9532, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 907/5000 [2:01:30<9:10:14,  8.07s/it, loss=1.1693, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 908/5000 [2:01:38<9:08:26,  8.04s/it, loss=1.1693, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 908/5000 [2:01:38<9:08:26,  8.04s/it, loss=0.4796, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 909/5000 [2:01:46<9:07:38,  8.03s/it, loss=0.4796, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 909/5000 [2:01:46<9:07:38,  8.03s/it, loss=1.1005, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 910/5000 [2:01:54<9:06:46,  8.02s/it, loss=1.1005, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 910/5000 [2:01:54<9:06:46,  8.02s/it, loss=1.0451, lr=9.80e-06]
[Step 910] Training Debug Info:
  Loss: 0.414866
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0007, std: 0.8516
  Noise mean: -0.0030, std: 0.9961
  Target mean: -0.0023, std: 1.3125
  Model pred mean: 0.0024, std: 1.1484
  Sigmas: [0.92578125]... (timesteps: [926.0])

[Step 910] Training Debug Info:
  Loss: 0.569820
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0281, std: 0.9180
  Noise mean: -0.0012, std: 1.0000
  Target mean: 0.0269, std: 1.3594
  Model pred mean: 0.0248, std: 1.1328
  Sigmas: [0.61328125]... (timesteps: [615.0])

[Step 910] Training Debug Info:
  Loss: 0.663394
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0013, std: 0.8867
  Noise mean: -0.0010, std: 1.0000
  Target mean: -0.0023, std: 1.3359
  Model pred mean: 0.0009, std: 1.0703
  Sigmas: [0.55859375]... (timesteps: [557.0])

[Step 910] Training Debug Info:
  Loss: 1.058650
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0339, std: 0.9922
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0311, std: 1.4062
  Model pred mean: -0.0312, std: 0.9609
  Sigmas: [0.2578125]... (timesteps: [258.0])
Steps:  18%|‚ñà‚ñä        | 911/5000 [2:02:02<9:07:02,  8.03s/it, loss=1.0451, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 911/5000 [2:02:02<9:07:02,  8.03s/it, loss=1.0587, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 912/5000 [2:02:11<9:13:57,  8.13s/it, loss=1.0587, lr=9.80e-06]Steps:  18%|‚ñà‚ñä        | 912/5000 [2:02:11<9:13:57,  8.13s/it, loss=1.1283, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 913/5000 [2:02:19<9:10:09,  8.08s/it, loss=1.1283, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 913/5000 [2:02:19<9:10:09,  8.08s/it, loss=0.4892, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 914/5000 [2:02:27<9:07:10,  8.03s/it, loss=0.4892, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 914/5000 [2:02:27<9:07:10,  8.03s/it, loss=0.6100, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 915/5000 [2:02:35<9:06:36,  8.03s/it, loss=0.6100, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 915/5000 [2:02:35<9:06:36,  8.03s/it, loss=0.3736, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 916/5000 [2:02:43<9:05:39,  8.02s/it, loss=0.3736, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 916/5000 [2:02:43<9:05:39,  8.02s/it, loss=0.7600, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 917/5000 [2:02:51<9:14:48,  8.15s/it, loss=0.7600, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 917/5000 [2:02:51<9:14:48,  8.15s/it, loss=1.2050, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 918/5000 [2:02:59<9:11:51,  8.11s/it, loss=1.2050, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 918/5000 [2:02:59<9:11:51,  8.11s/it, loss=0.4735, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 919/5000 [2:03:07<9:10:59,  8.10s/it, loss=0.4735, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 919/5000 [2:03:07<9:10:59,  8.10s/it, loss=0.4157, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 920/5000 [2:03:15<9:08:44,  8.07s/it, loss=0.4157, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 920/5000 [2:03:15<9:08:44,  8.07s/it, loss=0.4135, lr=9.79e-06]
[Step 920] Training Debug Info:
  Loss: 0.953754
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0077, std: 0.8828
  Noise mean: 0.0009, std: 1.0000
  Target mean: -0.0068, std: 1.3359
  Model pred mean: -0.0079, std: 0.9102
  Sigmas: [0.388671875]... (timesteps: [389.0])

[Step 920] Training Debug Info:
  Loss: 1.127581
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0019, std: 0.9570
  Noise mean: -0.0018, std: 1.0000
  Target mean: -0.0037, std: 1.3828
  Model pred mean: -0.0042, std: 0.8945
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 920] Training Debug Info:
  Loss: 0.710759
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0087, std: 0.9062
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0077, std: 1.3516
  Model pred mean: -0.0064, std: 1.0547
  Sigmas: [0.51171875]... (timesteps: [513.0])

[Step 920] Training Debug Info:
  Loss: 0.713046
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0270, std: 0.9141
  Noise mean: -0.0025, std: 0.9961
  Target mean: 0.0245, std: 1.3516
  Model pred mean: 0.0272, std: 1.0625
  Sigmas: [0.50390625]... (timesteps: [505.0])
Steps:  18%|‚ñà‚ñä        | 921/5000 [2:03:23<9:08:02,  8.06s/it, loss=0.4135, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 921/5000 [2:03:23<9:08:02,  8.06s/it, loss=0.7130, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 922/5000 [2:03:31<9:10:04,  8.09s/it, loss=0.7130, lr=9.79e-06]Steps:  18%|‚ñà‚ñä        | 922/5000 [2:03:31<9:10:04,  8.09s/it, loss=0.3751, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 923/5000 [2:03:40<9:12:45,  8.13s/it, loss=0.3751, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 923/5000 [2:03:40<9:12:45,  8.13s/it, loss=0.5601, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 924/5000 [2:03:48<9:10:07,  8.10s/it, loss=0.5601, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 924/5000 [2:03:48<9:10:07,  8.10s/it, loss=0.5043, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 925/5000 [2:03:56<9:06:01,  8.04s/it, loss=0.5043, lr=9.78e-06]Steps:  18%|‚ñà‚ñä        | 925/5000 [2:03:56<9:06:01,  8.04s/it, loss=1.1347, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 926/5000 [2:04:04<9:04:40,  8.02s/it, loss=1.1347, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 926/5000 [2:04:04<9:04:40,  8.02s/it, loss=0.4892, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 927/5000 [2:04:12<9:08:27,  8.08s/it, loss=0.4892, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 927/5000 [2:04:12<9:08:27,  8.08s/it, loss=0.4704, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 928/5000 [2:04:20<9:12:56,  8.15s/it, loss=0.4704, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 928/5000 [2:04:20<9:12:56,  8.15s/it, loss=0.8119, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 929/5000 [2:04:28<9:11:34,  8.13s/it, loss=0.8119, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 929/5000 [2:04:28<9:11:34,  8.13s/it, loss=0.8484, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 930/5000 [2:04:36<9:09:32,  8.10s/it, loss=0.8484, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 930/5000 [2:04:36<9:09:32,  8.10s/it, loss=0.3766, lr=9.78e-06]
[Step 930] Training Debug Info:
  Loss: 1.052375
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0017, std: 0.9336
  Noise mean: 0.0011, std: 1.0000
  Target mean: 0.0028, std: 1.3672
  Model pred mean: 0.0058, std: 0.9297
  Sigmas: [0.02294921875]... (timesteps: [23.0])

[Step 930] Training Debug Info:
  Loss: 1.164568
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0093, std: 0.8867
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0113, std: 1.3359
  Model pred mean: -0.0112, std: 0.7891
  Sigmas: [0.212890625]... (timesteps: [213.0])

[Step 930] Training Debug Info:
  Loss: 0.600595
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0164, std: 0.9023
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0168, std: 1.3438
  Model pred mean: -0.0183, std: 1.1094
  Sigmas: [0.578125]... (timesteps: [579.0])

[Step 930] Training Debug Info:
  Loss: 1.118362
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0037, std: 0.8633
  Noise mean: -0.0009, std: 1.0000
  Target mean: 0.0028, std: 1.3203
  Model pred mean: 0.0040, std: 0.8125
  Sigmas: [0.06494140625]... (timesteps: [65.0])
Steps:  19%|‚ñà‚ñä        | 931/5000 [2:04:44<9:06:10,  8.05s/it, loss=0.3766, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 931/5000 [2:04:44<9:06:10,  8.05s/it, loss=1.1184, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 932/5000 [2:04:52<9:04:57,  8.04s/it, loss=1.1184, lr=9.78e-06]Steps:  19%|‚ñà‚ñä        | 932/5000 [2:04:52<9:04:57,  8.04s/it, loss=1.0953, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 933/5000 [2:05:00<9:08:06,  8.09s/it, loss=1.0953, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 933/5000 [2:05:00<9:08:06,  8.09s/it, loss=0.5462, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 934/5000 [2:05:08<9:09:10,  8.10s/it, loss=0.5462, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 934/5000 [2:05:08<9:09:10,  8.10s/it, loss=0.6639, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 935/5000 [2:05:16<9:04:41,  8.04s/it, loss=0.6639, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 935/5000 [2:05:16<9:04:41,  8.04s/it, loss=0.4638, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 936/5000 [2:05:24<9:05:21,  8.05s/it, loss=0.4638, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 936/5000 [2:05:24<9:05:21,  8.05s/it, loss=0.8905, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 937/5000 [2:05:32<9:02:40,  8.01s/it, loss=0.8905, lr=9.77e-06]Steps:  19%|‚ñà‚ñä        | 937/5000 [2:05:32<9:02:40,  8.01s/it, loss=1.1070, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 938/5000 [2:05:41<9:06:04,  8.07s/it, loss=1.1070, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 938/5000 [2:05:41<9:06:04,  8.07s/it, loss=0.4984, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 939/5000 [2:05:49<9:09:46,  8.12s/it, loss=0.4984, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 939/5000 [2:05:49<9:09:46,  8.12s/it, loss=0.3645, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 940/5000 [2:05:57<9:08:42,  8.11s/it, loss=0.3645, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 940/5000 [2:05:57<9:08:42,  8.11s/it, loss=0.8406, lr=9.77e-06]
[Step 940] Training Debug Info:
  Loss: 0.788200
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0237, std: 0.8945
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0245, std: 1.3438
  Model pred mean: -0.0271, std: 1.0078
  Sigmas: [0.4296875]... (timesteps: [430.0])

[Step 940] Training Debug Info:
  Loss: 1.160534
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0036, std: 0.8828
  Noise mean: 0.0007, std: 1.0000
  Target mean: -0.0028, std: 1.3359
  Model pred mean: -0.0023, std: 0.7969
  Sigmas: [0.244140625]... (timesteps: [244.0])

[Step 940] Training Debug Info:
  Loss: 1.123057
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0574, std: 0.9180
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0562, std: 1.3594
  Model pred mean: -0.0554, std: 0.8477
  Sigmas: [0.10986328125]... (timesteps: [110.0])

[Step 940] Training Debug Info:
  Loss: 0.812771
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0167, std: 0.9062
  Noise mean: 0.0023, std: 1.0000
  Target mean: 0.0190, std: 1.3438
  Model pred mean: 0.0149, std: 1.0078
  Sigmas: [0.453125]... (timesteps: [453.0])
Steps:  19%|‚ñà‚ñâ        | 941/5000 [2:06:05<9:06:57,  8.09s/it, loss=0.8406, lr=9.77e-06]Steps:  19%|‚ñà‚ñâ        | 941/5000 [2:06:05<9:06:57,  8.09s/it, loss=0.8128, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 942/5000 [2:06:13<9:05:00,  8.06s/it, loss=0.8128, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 942/5000 [2:06:13<9:05:00,  8.06s/it, loss=0.3791, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 943/5000 [2:06:21<9:05:10,  8.06s/it, loss=0.3791, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 943/5000 [2:06:21<9:05:10,  8.06s/it, loss=1.2084, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 944/5000 [2:06:29<9:12:26,  8.17s/it, loss=1.2084, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 944/5000 [2:06:29<9:12:26,  8.17s/it, loss=1.0622, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 945/5000 [2:06:37<9:10:22,  8.14s/it, loss=1.0622, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 945/5000 [2:06:37<9:10:22,  8.14s/it, loss=0.9535, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 946/5000 [2:06:45<9:07:11,  8.10s/it, loss=0.9535, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 946/5000 [2:06:45<9:07:11,  8.10s/it, loss=0.4022, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 947/5000 [2:06:53<9:05:08,  8.07s/it, loss=0.4022, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 947/5000 [2:06:53<9:05:08,  8.07s/it, loss=0.7301, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 948/5000 [2:07:01<9:03:32,  8.05s/it, loss=0.7301, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 948/5000 [2:07:01<9:03:32,  8.05s/it, loss=0.5778, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 949/5000 [2:07:10<9:05:56,  8.09s/it, loss=0.5778, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 949/5000 [2:07:10<9:05:56,  8.09s/it, loss=0.5383, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 950/5000 [2:07:18<9:07:54,  8.12s/it, loss=0.5383, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 950/5000 [2:07:18<9:07:54,  8.12s/it, loss=0.3890, lr=9.76e-06]
[Step 950] Training Debug Info:
  Loss: 0.516580
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0137, std: 0.9219
  Noise mean: 0.0017, std: 0.9961
  Target mean: 0.0154, std: 1.3594
  Model pred mean: 0.0105, std: 1.1484
  Sigmas: [0.66015625]... (timesteps: [662.0])

[Step 950] Training Debug Info:
  Loss: 0.376281
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0273, std: 0.9062
  Noise mean: 0.0006, std: 1.0000
  Target mean: 0.0280, std: 1.3516
  Model pred mean: 0.0189, std: 1.1953
  Sigmas: [0.8984375]... (timesteps: [900.0])

[Step 950] Training Debug Info:
  Loss: 1.143532
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0200, std: 0.9102
  Noise mean: -0.0014, std: 1.0000
  Target mean: -0.0215, std: 1.3516
  Model pred mean: -0.0208, std: 0.8242
  Sigmas: [0.1865234375]... (timesteps: [187.0])

[Step 950] Training Debug Info:
  Loss: 0.665167
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0371, std: 0.8945
  Noise mean: 0.0034, std: 1.0000
  Target mean: -0.0337, std: 1.3438
  Model pred mean: -0.0081, std: 1.0703
  Sigmas: [0.96875]... (timesteps: [970.0])
Steps:  19%|‚ñà‚ñâ        | 951/5000 [2:07:26<9:05:02,  8.08s/it, loss=0.3890, lr=9.76e-06]Steps:  19%|‚ñà‚ñâ        | 951/5000 [2:07:26<9:05:02,  8.08s/it, loss=0.6652, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 952/5000 [2:07:34<9:05:09,  8.08s/it, loss=0.6652, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 952/5000 [2:07:34<9:05:09,  8.08s/it, loss=1.1602, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 953/5000 [2:07:42<9:03:37,  8.06s/it, loss=1.1602, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 953/5000 [2:07:42<9:03:37,  8.06s/it, loss=0.4094, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 954/5000 [2:07:50<9:04:13,  8.07s/it, loss=0.4094, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 954/5000 [2:07:50<9:04:13,  8.07s/it, loss=0.9479, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 955/5000 [2:07:58<9:06:24,  8.10s/it, loss=0.9479, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 955/5000 [2:07:58<9:06:24,  8.10s/it, loss=0.6211, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 956/5000 [2:08:06<9:02:09,  8.04s/it, loss=0.6211, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 956/5000 [2:08:06<9:02:09,  8.04s/it, loss=1.1074, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 957/5000 [2:08:14<9:00:47,  8.03s/it, loss=1.1074, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 957/5000 [2:08:14<9:00:47,  8.03s/it, loss=1.0284, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 958/5000 [2:08:22<8:59:54,  8.01s/it, loss=1.0284, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 958/5000 [2:08:22<8:59:54,  8.01s/it, loss=0.8738, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 959/5000 [2:08:30<9:03:41,  8.07s/it, loss=0.8738, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 959/5000 [2:08:30<9:03:41,  8.07s/it, loss=1.0922, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 960/5000 [2:08:38<9:01:53,  8.05s/it, loss=1.0922, lr=9.75e-06]Steps:  19%|‚ñà‚ñâ        | 960/5000 [2:08:38<9:01:53,  8.05s/it, loss=0.9431, lr=9.74e-06]
[Step 960] Training Debug Info:
  Loss: 1.129226
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0153, std: 0.9375
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0140, std: 1.3672
  Model pred mean: -0.0147, std: 0.8750
  Sigmas: [0.1767578125]... (timesteps: [177.0])

[Step 960] Training Debug Info:
  Loss: 0.674800
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0051, std: 0.8711
  Noise mean: -0.0042, std: 1.0000
  Target mean: 0.0009, std: 1.3203
  Model pred mean: 0.0064, std: 1.0547
  Sigmas: [0.55859375]... (timesteps: [558.0])

[Step 960] Training Debug Info:
  Loss: 0.971352
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0162, std: 0.8789
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0170, std: 1.3281
  Model pred mean: 0.0164, std: 0.9062
  Sigmas: [0.38671875]... (timesteps: [386.0])

[Step 960] Training Debug Info:
  Loss: 1.117036
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0425, std: 0.9102
  Noise mean: -0.0006, std: 1.0000
  Target mean: 0.0417, std: 1.3516
  Model pred mean: 0.0442, std: 0.8633
  Sigmas: [0.27734375]... (timesteps: [278.0])
Steps:  19%|‚ñà‚ñâ        | 961/5000 [2:08:46<9:04:18,  8.09s/it, loss=0.9431, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 961/5000 [2:08:46<9:04:18,  8.09s/it, loss=1.1170, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 962/5000 [2:08:54<9:02:12,  8.06s/it, loss=1.1170, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 962/5000 [2:08:54<9:02:12,  8.06s/it, loss=0.4031, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 963/5000 [2:09:02<8:59:48,  8.02s/it, loss=0.4031, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 963/5000 [2:09:02<8:59:48,  8.02s/it, loss=1.1425, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 964/5000 [2:09:10<8:59:03,  8.01s/it, loss=1.1425, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 964/5000 [2:09:10<8:59:03,  8.01s/it, loss=0.4222, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 965/5000 [2:09:19<9:04:02,  8.09s/it, loss=0.4222, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 965/5000 [2:09:19<9:04:02,  8.09s/it, loss=1.1472, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 966/5000 [2:09:27<9:05:05,  8.11s/it, loss=1.1472, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 966/5000 [2:09:27<9:05:05,  8.11s/it, loss=0.7107, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 967/5000 [2:09:35<9:02:04,  8.06s/it, loss=0.7107, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 967/5000 [2:09:35<9:02:04,  8.06s/it, loss=0.6274, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 968/5000 [2:09:43<9:00:31,  8.04s/it, loss=0.6274, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 968/5000 [2:09:43<9:00:31,  8.04s/it, loss=1.2023, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 969/5000 [2:09:51<8:59:37,  8.03s/it, loss=1.2023, lr=9.74e-06]Steps:  19%|‚ñà‚ñâ        | 969/5000 [2:09:51<8:59:37,  8.03s/it, loss=1.0780, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 970/5000 [2:09:59<9:02:07,  8.07s/it, loss=1.0780, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 970/5000 [2:09:59<9:02:07,  8.07s/it, loss=0.7160, lr=9.73e-06]
[Step 970] Training Debug Info:
  Loss: 0.888303
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0128, std: 0.8789
  Noise mean: -0.0027, std: 1.0000
  Target mean: 0.0101, std: 1.3359
  Model pred mean: 0.0143, std: 0.9414
  Sigmas: [0.435546875]... (timesteps: [435.0])

[Step 970] Training Debug Info:
  Loss: 1.084391
  Latent shape: torch.Size([1, 32, 66, 138]), Packed shape: torch.Size([1, 2277, 128])
  Latent mean: -0.0192, std: 0.8672
  Noise mean: -0.0033, std: 1.0000
  Target mean: 0.0159, std: 1.3281
  Model pred mean: 0.0177, std: 0.8281
  Sigmas: [0.0439453125]... (timesteps: [44.0])

[Step 970] Training Debug Info:
  Loss: 1.099497
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0130, std: 0.9883
  Noise mean: -0.0005, std: 1.0000
  Target mean: -0.0134, std: 1.4062
  Model pred mean: -0.0132, std: 0.9375
  Sigmas: [0.06689453125]... (timesteps: [67.0])

[Step 970] Training Debug Info:
  Loss: 0.573156
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0010, std: 0.9102
  Noise mean: 0.0005, std: 1.0000
  Target mean: -0.0004, std: 1.3516
  Model pred mean: -0.0021, std: 1.1172
  Sigmas: [0.6171875]... (timesteps: [616.0])
Steps:  19%|‚ñà‚ñâ        | 971/5000 [2:10:07<9:04:39,  8.11s/it, loss=0.7160, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 971/5000 [2:10:07<9:04:39,  8.11s/it, loss=0.5732, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 972/5000 [2:10:15<9:01:52,  8.07s/it, loss=0.5732, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 972/5000 [2:10:15<9:01:52,  8.07s/it, loss=0.4791, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 973/5000 [2:10:23<9:01:21,  8.07s/it, loss=0.4791, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 973/5000 [2:10:23<9:01:21,  8.07s/it, loss=0.9218, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 974/5000 [2:10:31<8:59:50,  8.05s/it, loss=0.9218, lr=9.73e-06]Steps:  19%|‚ñà‚ñâ        | 974/5000 [2:10:31<8:59:50,  8.05s/it, loss=0.4420, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 975/5000 [2:10:35<7:41:19,  6.88s/it, loss=0.4420, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 975/5000 [2:10:35<7:41:19,  6.88s/it, loss=0.5063, lr=9.73e-06]01/30/2026 06:33:24 - INFO - __main__ - 
==================================================
01/30/2026 06:33:24 - INFO - __main__ - Epoch 12 completed: avg_loss = 0.7564
01/30/2026 06:33:24 - INFO - __main__ - ==================================================

Steps:  20%|‚ñà‚ñâ        | 976/5000 [2:10:44<8:17:51,  7.42s/it, loss=0.5063, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 976/5000 [2:10:44<8:17:51,  7.42s/it, loss=0.4113, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 977/5000 [2:10:52<8:35:47,  7.69s/it, loss=0.4113, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 977/5000 [2:10:52<8:35:47,  7.69s/it, loss=1.1545, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 978/5000 [2:11:00<8:42:27,  7.79s/it, loss=1.1545, lr=9.73e-06]Steps:  20%|‚ñà‚ñâ        | 978/5000 [2:11:00<8:42:27,  7.79s/it, loss=0.5860, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 979/5000 [2:11:08<8:45:13,  7.84s/it, loss=0.5860, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 979/5000 [2:11:08<8:45:13,  7.84s/it, loss=0.8823, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 980/5000 [2:11:16<8:48:01,  7.88s/it, loss=0.8823, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 980/5000 [2:11:16<8:48:01,  7.88s/it, loss=0.8781, lr=9.72e-06]
[Step 980] Training Debug Info:
  Loss: 1.109441
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0238, std: 0.9258
  Noise mean: -0.0005, std: 1.0000
  Target mean: 0.0233, std: 1.3594
  Model pred mean: 0.0245, std: 0.8555
  Sigmas: [0.06494140625]... (timesteps: [65.0])

[Step 980] Training Debug Info:
  Loss: 1.145237
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0137, std: 0.9141
  Noise mean: 0.0005, std: 1.0000
  Target mean: 0.0142, std: 1.3594
  Model pred mean: 0.0109, std: 0.8320
  Sigmas: [0.271484375]... (timesteps: [272.0])

[Step 980] Training Debug Info:
  Loss: 1.029033
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0068, std: 0.8867
  Noise mean: -0.0032, std: 1.0000
  Target mean: 0.0036, std: 1.3359
  Model pred mean: 0.0110, std: 0.8633
  Sigmas: [0.010986328125]... (timesteps: [11.0])

[Step 980] Training Debug Info:
  Loss: 0.459395
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0070, std: 0.8984
  Noise mean: 0.0036, std: 1.0000
  Target mean: 0.0105, std: 1.3438
  Model pred mean: 0.0094, std: 1.1641
  Sigmas: [0.7109375]... (timesteps: [712.0])
Steps:  20%|‚ñà‚ñâ        | 981/5000 [2:11:24<8:55:01,  7.99s/it, loss=0.8781, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 981/5000 [2:11:24<8:55:01,  7.99s/it, loss=0.4594, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 982/5000 [2:11:33<8:59:52,  8.06s/it, loss=0.4594, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 982/5000 [2:11:33<8:59:52,  8.06s/it, loss=0.4646, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 983/5000 [2:11:41<8:58:32,  8.04s/it, loss=0.4646, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 983/5000 [2:11:41<8:58:32,  8.04s/it, loss=1.1491, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 984/5000 [2:11:49<8:57:14,  8.03s/it, loss=1.1491, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 984/5000 [2:11:49<8:57:14,  8.03s/it, loss=0.4224, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 985/5000 [2:11:57<8:56:07,  8.01s/it, loss=0.4224, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 985/5000 [2:11:57<8:56:07,  8.01s/it, loss=1.0639, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 986/5000 [2:12:05<8:58:42,  8.05s/it, loss=1.0639, lr=9.72e-06]Steps:  20%|‚ñà‚ñâ        | 986/5000 [2:12:05<8:58:42,  8.05s/it, loss=0.8638, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 987/5000 [2:12:13<8:56:56,  8.03s/it, loss=0.8638, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 987/5000 [2:12:13<8:56:56,  8.03s/it, loss=0.5281, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 988/5000 [2:12:21<9:01:42,  8.10s/it, loss=0.5281, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 988/5000 [2:12:21<9:01:42,  8.10s/it, loss=0.4561, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 989/5000 [2:12:29<8:58:15,  8.05s/it, loss=0.4561, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 989/5000 [2:12:29<8:58:15,  8.05s/it, loss=0.6840, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 990/5000 [2:12:37<8:57:03,  8.04s/it, loss=0.6840, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 990/5000 [2:12:37<8:57:03,  8.04s/it, loss=0.3454, lr=9.71e-06]
[Step 990] Training Debug Info:
  Loss: 0.522087
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0084, std: 0.9727
  Noise mean: 0.0028, std: 1.0000
  Target mean: -0.0056, std: 1.3984
  Model pred mean: -0.0103, std: 1.1953
  Sigmas: [0.5234375]... (timesteps: [524.0])

[Step 990] Training Debug Info:
  Loss: 0.502044
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0693, std: 0.9336
  Noise mean: -0.0007, std: 1.0000
  Target mean: 0.0688, std: 1.3672
  Model pred mean: 0.0732, std: 1.1719
  Sigmas: [0.59375]... (timesteps: [594.0])

[Step 990] Training Debug Info:
  Loss: 0.407399
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0099, std: 0.9492
  Noise mean: 0.0000, std: 1.0000
  Target mean: 0.0100, std: 1.3828
  Model pred mean: 0.0058, std: 1.2266
  Sigmas: [0.703125]... (timesteps: [705.0])

[Step 990] Training Debug Info:
  Loss: 1.067027
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0016, std: 0.9297
  Noise mean: 0.0022, std: 1.0000
  Target mean: 0.0038, std: 1.3672
  Model pred mean: 0.0044, std: 0.9102
  Sigmas: [0.0380859375]... (timesteps: [38.0])
Steps:  20%|‚ñà‚ñâ        | 991/5000 [2:12:45<8:56:03,  8.02s/it, loss=0.3454, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 991/5000 [2:12:45<8:56:03,  8.02s/it, loss=1.0670, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 992/5000 [2:12:53<9:00:54,  8.10s/it, loss=1.0670, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 992/5000 [2:12:53<9:00:54,  8.10s/it, loss=0.9321, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 993/5000 [2:13:01<9:03:08,  8.13s/it, loss=0.9321, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 993/5000 [2:13:01<9:03:08,  8.13s/it, loss=0.5947, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 994/5000 [2:13:10<9:00:36,  8.10s/it, loss=0.5947, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 994/5000 [2:13:10<9:00:36,  8.10s/it, loss=1.0246, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 995/5000 [2:13:18<8:58:46,  8.07s/it, loss=1.0246, lr=9.71e-06]Steps:  20%|‚ñà‚ñâ        | 995/5000 [2:13:18<8:58:46,  8.07s/it, loss=0.8326, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 996/5000 [2:13:26<8:57:22,  8.05s/it, loss=0.8326, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 996/5000 [2:13:26<8:57:22,  8.05s/it, loss=0.9406, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 997/5000 [2:13:34<8:58:50,  8.08s/it, loss=0.9406, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 997/5000 [2:13:34<8:58:50,  8.08s/it, loss=0.3965, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 998/5000 [2:13:42<9:01:27,  8.12s/it, loss=0.3965, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 998/5000 [2:13:42<9:01:27,  8.12s/it, loss=0.6184, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 999/5000 [2:13:50<8:58:32,  8.08s/it, loss=0.6184, lr=9.70e-06]Steps:  20%|‚ñà‚ñâ        | 999/5000 [2:13:50<8:58:32,  8.08s/it, loss=0.6049, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1000/5000 [2:13:58<8:55:31,  8.03s/it, loss=0.6049, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1000/5000 [2:13:58<8:55:31,  8.03s/it, loss=0.8513, lr=9.70e-06]01/30/2026 06:36:47 - INFO - __main__ - 
[Step 1000] ‚úÖ Loss in normal range (0.8513)
01/30/2026 06:36:47 - INFO - __main__ -   Loss avg (last 100): 0.7494
01/30/2026 06:36:47 - INFO - __main__ -   Loss range: [0.3454, 1.2084]
Configuration saved in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/transformer/config.json
Model weights saved in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/transformer/diffusion_pytorch_model.safetensors
01/30/2026 06:36:47 - INFO - __main__ - Saved checkpoint to /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000
01/30/2026 06:36:47 - INFO - accelerate.accelerator - Saving current state to /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/accelerator
01/30/2026 06:36:47 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
01/30/2026 06:37:35 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/accelerator/pytorch_model
01/30/2026 06:37:35 - INFO - accelerate.checkpointing - Scheduler state saved in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/accelerator/scheduler.bin
01/30/2026 06:37:35 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/accelerator/sampler.bin
01/30/2026 06:37:35 - INFO - accelerate.checkpointing - Random states saved in /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/checkpoint-1000/accelerator/random_states_0.pkl
01/30/2026 06:37:35 - INFO - __main__ - 
üîç Running validation at step 1000...
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1000 (parquet mode)...
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
============================================================
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Running validation at step 1000...
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder to GPU...
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 1/4: The figure illustrates a process hooking mechanism using the LD_PRELOAD environm...
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_001000/step001000_prompt00_0_The_figure_illustrates_a_process_hooking_mechanism.png
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 2/4: The figure presents a comparative diagram of four different defect detection tas...
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_001000/step001000_prompt01_0_The_figure_presents_a_comparative_diagram_of_four.png
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 3/4: The figure illustrates a linear probing framework applied to a frozen multimodal...
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_001000/step001000_prompt02_0_The_figure_illustrates_a_linear_probing_framework.png
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Generating image 4/4: The figure presents a conceptual comparison of four different point cloud comple...
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Error generating image: 'weight' must be 2-D
01/30/2026 06:37:36 - ERROR - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - Traceback (most recent call last):
  File "/home/v-yuxluo/WORK_local/ArXivQwenImage/OpenSciDraw/validation_funcs/Flux2Klein_fulltune_validation_func.py", line 157, in Flux2Klein_fulltune_validation_func
    output = pipeline(**pipeline_kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 733, in __call__
    prompt_embeds, text_ids = self.encode_prompt(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 442, in encode_prompt
    prompt_embeds = self._get_qwen3_prompt_embeds(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/diffusers/pipelines/flux2/pipeline_flux2_klein.py", line 248, in _get_qwen3_prompt_embeds
    output = text_encoder(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 371, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/v-yuxluo/miniconda3/envs/flux2/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D

01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -     Saved to: /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_001000/step001000_prompt03_0_The_figure_presents_a_conceptual_comparison_of_fou.png
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -   Moving VAE and text_encoder back to CPU...
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - 
  ‚úÖ Validation complete! Saved 4 images to:
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func -      /home/v-yuxluo/data/experiments/flux2klein_saveh_test_5k/validation_images/step_001000
01/30/2026 06:37:36 - INFO - OpenSciDraw.validation_funcs.Flux2Klein_fulltune_validation_func - ============================================================


[Step 1000] Training Debug Info:
  Loss: 0.392566
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0009, std: 0.8867
  Noise mean: 0.0020, std: 1.0000
  Target mean: 0.0029, std: 1.3359
  Model pred mean: 0.0020, std: 1.1797
  Sigmas: [0.7734375]... (timesteps: [774.0])

[Step 1000] Training Debug Info:
  Loss: 0.824678
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0086, std: 0.8789
  Noise mean: 0.0015, std: 1.0000
  Target mean: -0.0071, std: 1.3281
  Model pred mean: -0.0089, std: 0.9648
  Sigmas: [0.443359375]... (timesteps: [444.0])

[Step 1000] Training Debug Info:
  Loss: 0.582060
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0105, std: 0.8828
  Noise mean: 0.0026, std: 0.9961
  Target mean: 0.0131, std: 1.3359
  Model pred mean: -0.0271, std: 1.1094
  Sigmas: [1.0]... (timesteps: [999.0])

[Step 1000] Training Debug Info:
  Loss: 0.730824
  Latent shape: torch.Size([1, 32, 108, 84]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0153, std: 0.9062
  Noise mean: -0.0004, std: 1.0000
  Target mean: -0.0157, std: 1.3516
  Model pred mean: -0.0204, std: 1.0391
  Sigmas: [0.49609375]... (timesteps: [496.0])
Steps:  20%|‚ñà‚ñà        | 1001/5000 [2:14:55<25:23:07, 22.85s/it, loss=0.8513, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1001/5000 [2:14:55<25:23:07, 22.85s/it, loss=0.7308, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1002/5000 [2:15:04<20:31:53, 18.49s/it, loss=0.7308, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1002/5000 [2:15:04<20:31:53, 18.49s/it, loss=0.6711, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1003/5000 [2:15:12<17:02:43, 15.35s/it, loss=0.6711, lr=9.70e-06]Steps:  20%|‚ñà‚ñà        | 1003/5000 [2:15:12<17:02:43, 15.35s/it, loss=0.3995, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1004/5000 [2:15:20<14:39:26, 13.20s/it, loss=0.3995, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1004/5000 [2:15:20<14:39:26, 13.20s/it, loss=0.5872, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1005/5000 [2:15:28<12:57:10, 11.67s/it, loss=0.5872, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1005/5000 [2:15:28<12:57:10, 11.67s/it, loss=1.1195, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1006/5000 [2:15:36<11:48:58, 10.65s/it, loss=1.1195, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1006/5000 [2:15:36<11:48:58, 10.65s/it, loss=1.1853, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1007/5000 [2:15:44<10:58:10,  9.89s/it, loss=1.1853, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1007/5000 [2:15:44<10:58:10,  9.89s/it, loss=1.1301, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1008/5000 [2:15:52<10:25:15,  9.40s/it, loss=1.1301, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1008/5000 [2:15:52<10:25:15,  9.40s/it, loss=0.4130, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1009/5000 [2:16:00<9:57:16,  8.98s/it, loss=0.4130, lr=9.69e-06] Steps:  20%|‚ñà‚ñà        | 1009/5000 [2:16:00<9:57:16,  8.98s/it, loss=0.7728, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1010/5000 [2:16:08<9:37:52,  8.69s/it, loss=0.7728, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1010/5000 [2:16:08<9:37:52,  8.69s/it, loss=1.1179, lr=9.69e-06]
[Step 1010] Training Debug Info:
  Loss: 0.543265
  Latent shape: torch.Size([1, 32, 48, 180]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0342, std: 0.9219
  Noise mean: 0.0042, std: 1.0000
  Target mean: 0.0383, std: 1.3594
  Model pred mean: 0.0366, std: 1.1406
  Sigmas: [0.59765625]... (timesteps: [597.0])

[Step 1010] Training Debug Info:
  Loss: 1.139139
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0259, std: 0.9180
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0247, std: 1.3594
  Model pred mean: -0.0253, std: 0.8398
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 1010] Training Debug Info:
  Loss: 1.191029
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0045, std: 0.8906
  Noise mean: 0.0008, std: 1.0000
  Target mean: 0.0052, std: 1.3438
  Model pred mean: 0.0022, std: 0.7734
  Sigmas: [0.173828125]... (timesteps: [174.0])

[Step 1010] Training Debug Info:
  Loss: 1.124991
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0105, std: 0.8867
  Noise mean: 0.0007, std: 0.9961
  Target mean: -0.0098, std: 1.3359
  Model pred mean: -0.0123, std: 0.8047
  Sigmas: [0.27734375]... (timesteps: [278.0])
Steps:  20%|‚ñà‚ñà        | 1011/5000 [2:16:17<9:30:54,  8.59s/it, loss=1.1179, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1011/5000 [2:16:17<9:30:54,  8.59s/it, loss=1.1250, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1012/5000 [2:16:25<9:18:52,  8.41s/it, loss=1.1250, lr=9.69e-06]Steps:  20%|‚ñà‚ñà        | 1012/5000 [2:16:25<9:18:52,  8.41s/it, loss=0.8960, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1013/5000 [2:16:33<9:13:54,  8.34s/it, loss=0.8960, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1013/5000 [2:16:33<9:13:54,  8.34s/it, loss=0.8473, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1014/5000 [2:16:41<9:07:59,  8.25s/it, loss=0.8473, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1014/5000 [2:16:41<9:07:59,  8.25s/it, loss=0.3663, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1015/5000 [2:16:49<9:04:00,  8.19s/it, loss=0.3663, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1015/5000 [2:16:49<9:04:00,  8.19s/it, loss=1.0812, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1016/5000 [2:16:57<9:04:34,  8.20s/it, loss=1.0812, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1016/5000 [2:16:57<9:04:34,  8.20s/it, loss=0.5989, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1017/5000 [2:17:05<8:59:48,  8.13s/it, loss=0.5989, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1017/5000 [2:17:05<8:59:48,  8.13s/it, loss=1.0261, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1018/5000 [2:17:14<9:01:28,  8.16s/it, loss=1.0261, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1018/5000 [2:17:14<9:01:28,  8.16s/it, loss=1.0324, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1019/5000 [2:17:22<8:58:33,  8.12s/it, loss=1.0324, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1019/5000 [2:17:22<8:58:33,  8.12s/it, loss=0.5478, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1020/5000 [2:17:30<8:57:17,  8.10s/it, loss=0.5478, lr=9.68e-06]Steps:  20%|‚ñà‚ñà        | 1020/5000 [2:17:30<8:57:17,  8.10s/it, loss=0.5950, lr=9.67e-06]
[Step 1020] Training Debug Info:
  Loss: 1.022324
  Latent shape: torch.Size([1, 32, 102, 90]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: -0.0023, std: 0.9180
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0026, std: 1.3516
  Model pred mean: 0.0071, std: 0.9062
  Sigmas: [0.326171875]... (timesteps: [327.0])

[Step 1020] Training Debug Info:
  Loss: 0.755861
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0060, std: 0.8945
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0057, std: 1.3438
  Model pred mean: -0.0033, std: 1.0312
  Sigmas: [0.453125]... (timesteps: [453.0])

[Step 1020] Training Debug Info:
  Loss: 1.030928
  Latent shape: torch.Size([1, 32, 48, 174]), Packed shape: torch.Size([1, 2088, 128])
  Latent mean: -0.0140, std: 0.8789
  Noise mean: 0.0017, std: 1.0000
  Target mean: 0.0157, std: 1.3359
  Model pred mean: 0.0162, std: 0.8750
  Sigmas: [0.01202392578125]... (timesteps: [12.0])

[Step 1020] Training Debug Info:
  Loss: 0.719469
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0284, std: 0.9297
  Noise mean: -0.0019, std: 1.0000
  Target mean: -0.0303, std: 1.3672
  Model pred mean: 0.0008, std: 1.0859
  Sigmas: [0.98828125]... (timesteps: [988.0])
Steps:  20%|‚ñà‚ñà        | 1021/5000 [2:17:38<8:55:45,  8.08s/it, loss=0.5950, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1021/5000 [2:17:38<8:55:45,  8.08s/it, loss=0.7195, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1022/5000 [2:17:46<8:59:02,  8.13s/it, loss=0.7195, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1022/5000 [2:17:46<8:59:02,  8.13s/it, loss=0.5008, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1023/5000 [2:17:54<8:56:04,  8.09s/it, loss=0.5008, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1023/5000 [2:17:54<8:56:04,  8.09s/it, loss=0.9600, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1024/5000 [2:18:02<8:58:39,  8.13s/it, loss=0.9600, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1024/5000 [2:18:02<8:58:39,  8.13s/it, loss=1.0805, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1025/5000 [2:18:10<8:57:19,  8.11s/it, loss=1.0805, lr=9.67e-06]Steps:  20%|‚ñà‚ñà        | 1025/5000 [2:18:10<8:57:19,  8.11s/it, loss=1.1904, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1026/5000 [2:18:18<8:57:16,  8.11s/it, loss=1.1904, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1026/5000 [2:18:18<8:57:16,  8.11s/it, loss=0.5512, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1027/5000 [2:18:27<9:11:13,  8.32s/it, loss=0.5512, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1027/5000 [2:18:27<9:11:13,  8.32s/it, loss=0.4663, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1028/5000 [2:18:35<9:06:32,  8.26s/it, loss=0.4663, lr=9.67e-06]Steps:  21%|‚ñà‚ñà        | 1028/5000 [2:18:35<9:06:32,  8.26s/it, loss=0.8477, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1029/5000 [2:18:43<9:06:25,  8.26s/it, loss=0.8477, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1029/5000 [2:18:43<9:06:25,  8.26s/it, loss=1.1775, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1030/5000 [2:18:52<9:02:17,  8.20s/it, loss=1.1775, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1030/5000 [2:18:52<9:02:17,  8.20s/it, loss=0.7113, lr=9.66e-06]
[Step 1030] Training Debug Info:
  Loss: 0.376862
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0505, std: 0.9219
  Noise mean: -0.0015, std: 1.0000
  Target mean: -0.0520, std: 1.3594
  Model pred mean: -0.0493, std: 1.2109
  Sigmas: [0.80078125]... (timesteps: [800.0])

[Step 1030] Training Debug Info:
  Loss: 0.945318
  Latent shape: torch.Size([1, 32, 72, 126]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0187, std: 0.9141
  Noise mean: -0.0016, std: 0.9961
  Target mean: -0.0203, std: 1.3516
  Model pred mean: -0.0167, std: 0.9414
  Sigmas: [0.345703125]... (timesteps: [345.0])

[Step 1030] Training Debug Info:
  Loss: 0.594627
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0140, std: 0.9180
  Noise mean: -0.0028, std: 1.0000
  Target mean: -0.0168, std: 1.3594
  Model pred mean: -0.0093, std: 1.1172
  Sigmas: [0.5625]... (timesteps: [561.0])

[Step 1030] Training Debug Info:
  Loss: 0.323501
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: -0.0371, std: 0.9258
  Noise mean: -0.0039, std: 1.0000
  Target mean: 0.0332, std: 1.3594
  Model pred mean: 0.0311, std: 1.2344
  Sigmas: [0.87109375]... (timesteps: [871.0])
Steps:  21%|‚ñà‚ñà        | 1031/5000 [2:18:59<8:57:36,  8.13s/it, loss=0.7113, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1031/5000 [2:18:59<8:57:36,  8.13s/it, loss=0.3235, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1032/5000 [2:19:08<8:57:25,  8.13s/it, loss=0.3235, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1032/5000 [2:19:08<8:57:25,  8.13s/it, loss=0.4901, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1033/5000 [2:19:16<9:03:05,  8.21s/it, loss=0.4901, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1033/5000 [2:19:16<9:03:05,  8.21s/it, loss=1.0371, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1034/5000 [2:19:24<9:05:09,  8.25s/it, loss=1.0371, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1034/5000 [2:19:24<9:05:09,  8.25s/it, loss=0.6751, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1035/5000 [2:19:32<9:01:07,  8.19s/it, loss=0.6751, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1035/5000 [2:19:32<9:01:07,  8.19s/it, loss=0.6571, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1036/5000 [2:19:40<8:57:56,  8.14s/it, loss=0.6571, lr=9.66e-06]Steps:  21%|‚ñà‚ñà        | 1036/5000 [2:19:40<8:57:56,  8.14s/it, loss=0.5073, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1037/5000 [2:19:48<8:56:05,  8.12s/it, loss=0.5073, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1037/5000 [2:19:48<8:56:05,  8.12s/it, loss=0.5203, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1038/5000 [2:19:57<8:58:38,  8.16s/it, loss=0.5203, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1038/5000 [2:19:57<8:58:38,  8.16s/it, loss=0.4825, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1039/5000 [2:20:05<8:56:38,  8.13s/it, loss=0.4825, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1039/5000 [2:20:05<8:56:38,  8.13s/it, loss=0.4234, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1040/5000 [2:20:13<8:59:20,  8.17s/it, loss=0.4234, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1040/5000 [2:20:13<8:59:20,  8.17s/it, loss=0.6808, lr=9.65e-06]
[Step 1040] Training Debug Info:
  Loss: 1.015813
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0216, std: 0.8984
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0225, std: 1.3438
  Model pred mean: -0.0249, std: 0.8867
  Sigmas: [0.30859375]... (timesteps: [308.0])

[Step 1040] Training Debug Info:
  Loss: 0.443609
  Latent shape: torch.Size([1, 32, 48, 192]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0349, std: 0.9414
  Noise mean: 0.0015, std: 0.9961
  Target mean: -0.0334, std: 1.3750
  Model pred mean: -0.0179, std: 1.1953
  Sigmas: [0.8984375]... (timesteps: [898.0])

[Step 1040] Training Debug Info:
  Loss: 1.134445
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0203, std: 1.0078
  Noise mean: 0.0003, std: 1.0000
  Target mean: -0.0200, std: 1.4219
  Model pred mean: -0.0156, std: 0.9492
  Sigmas: [0.234375]... (timesteps: [234.0])

[Step 1040] Training Debug Info:
  Loss: 1.049071
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: 0.0016, std: 0.9492
  Noise mean: -0.0006, std: 1.0000
  Target mean: -0.0022, std: 1.3750
  Model pred mean: 0.0032, std: 0.9258
  Sigmas: [0.02294921875]... (timesteps: [23.0])
Steps:  21%|‚ñà‚ñà        | 1041/5000 [2:20:21<8:56:17,  8.13s/it, loss=0.6808, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1041/5000 [2:20:21<8:56:17,  8.13s/it, loss=1.0491, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1042/5000 [2:20:29<8:52:55,  8.08s/it, loss=1.0491, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1042/5000 [2:20:29<8:52:55,  8.08s/it, loss=0.9500, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1043/5000 [2:20:37<8:50:38,  8.05s/it, loss=0.9500, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1043/5000 [2:20:37<8:50:38,  8.05s/it, loss=0.4109, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1044/5000 [2:20:45<8:54:06,  8.10s/it, loss=0.4109, lr=9.65e-06]Steps:  21%|‚ñà‚ñà        | 1044/5000 [2:20:45<8:54:06,  8.10s/it, loss=0.9435, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1045/5000 [2:20:53<8:56:37,  8.14s/it, loss=0.9435, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1045/5000 [2:20:53<8:56:37,  8.14s/it, loss=1.0707, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1046/5000 [2:21:01<8:52:38,  8.08s/it, loss=1.0707, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1046/5000 [2:21:01<8:52:38,  8.08s/it, loss=1.1718, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1047/5000 [2:21:09<8:49:58,  8.04s/it, loss=1.1718, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1047/5000 [2:21:09<8:49:58,  8.04s/it, loss=0.5249, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1048/5000 [2:21:17<8:50:35,  8.06s/it, loss=0.5249, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1048/5000 [2:21:17<8:50:35,  8.06s/it, loss=1.1436, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1049/5000 [2:21:26<8:53:05,  8.10s/it, loss=1.1436, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1049/5000 [2:21:26<8:53:05,  8.10s/it, loss=0.7277, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1050/5000 [2:21:30<7:35:00,  6.91s/it, loss=0.7277, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1050/5000 [2:21:30<7:35:00,  6.91s/it, loss=0.3876, lr=9.64e-06]01/30/2026 06:44:19 - INFO - __main__ - 
==================================================
01/30/2026 06:44:19 - INFO - __main__ - Epoch 13 completed: avg_loss = 0.7578
01/30/2026 06:44:19 - INFO - __main__ - ==================================================


[Step 1050] Training Debug Info:
  Loss: 0.632507
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0150, std: 0.8984
  Noise mean: 0.0012, std: 0.9961
  Target mean: -0.0138, std: 1.3438
  Model pred mean: -0.0117, std: 1.0859
  Sigmas: [0.546875]... (timesteps: [545.0])

[Step 1050] Training Debug Info:
  Loss: 0.503792
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0327, std: 1.0000
  Noise mean: -0.0003, std: 1.0000
  Target mean: -0.0330, std: 1.4141
  Model pred mean: -0.0330, std: 1.2188
  Sigmas: [0.83203125]... (timesteps: [832.0])

[Step 1050] Training Debug Info:
  Loss: 0.673606
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: -0.0344, std: 0.8711
  Noise mean: -0.0048, std: 1.0000
  Target mean: 0.0297, std: 1.3281
  Model pred mean: 0.0388, std: 1.0391
  Sigmas: [0.5625]... (timesteps: [564.0])

[Step 1050] Training Debug Info:
  Loss: 0.791163
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0101, std: 0.9453
  Noise mean: 0.0011, std: 1.0000
  Target mean: -0.0090, std: 1.3750
  Model pred mean: -0.0045, std: 1.0547
  Sigmas: [0.4140625]... (timesteps: [414.0])
Steps:  21%|‚ñà‚ñà        | 1051/5000 [2:21:39<8:10:13,  7.45s/it, loss=0.3876, lr=9.64e-06]Steps:  21%|‚ñà‚ñà        | 1051/5000 [2:21:39<8:10:13,  7.45s/it, loss=0.7912, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1052/5000 [2:21:46<8:19:59,  7.60s/it, loss=0.7912, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1052/5000 [2:21:46<8:19:59,  7.60s/it, loss=0.7284, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1053/5000 [2:21:54<8:28:25,  7.73s/it, loss=0.7284, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1053/5000 [2:21:54<8:28:25,  7.73s/it, loss=1.0848, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1054/5000 [2:22:02<8:32:22,  7.79s/it, loss=1.0848, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1054/5000 [2:22:02<8:32:22,  7.79s/it, loss=0.4834, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1055/5000 [2:22:11<8:43:54,  7.97s/it, loss=0.4834, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1055/5000 [2:22:11<8:43:54,  7.97s/it, loss=0.4100, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1056/5000 [2:22:19<8:48:18,  8.04s/it, loss=0.4100, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1056/5000 [2:22:19<8:48:18,  8.04s/it, loss=0.4297, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1057/5000 [2:22:27<8:47:54,  8.03s/it, loss=0.4297, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1057/5000 [2:22:27<8:47:54,  8.03s/it, loss=0.5543, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1058/5000 [2:22:35<8:46:57,  8.02s/it, loss=0.5543, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1058/5000 [2:22:35<8:46:57,  8.02s/it, loss=0.6227, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1059/5000 [2:22:43<8:46:30,  8.02s/it, loss=0.6227, lr=9.63e-06]Steps:  21%|‚ñà‚ñà        | 1059/5000 [2:22:43<8:46:30,  8.02s/it, loss=0.4596, lr=9.62e-06]Steps:  21%|‚ñà‚ñà        | 1060/5000 [2:22:51<8:52:39,  8.11s/it, loss=0.4596, lr=9.62e-06]Steps:  21%|‚ñà‚ñà        | 1060/5000 [2:22:51<8:52:39,  8.11s/it, loss=0.5504, lr=9.62e-06]
[Step 1060] Training Debug Info:
  Loss: 0.530990
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0013, std: 0.8516
  Noise mean: -0.0012, std: 1.0000
  Target mean: -0.0025, std: 1.3125
  Model pred mean: -0.0056, std: 1.0703
  Sigmas: [0.66796875]... (timesteps: [668.0])

[Step 1060] Training Debug Info:
  Loss: 1.182712
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0287, std: 0.9180
  Noise mean: 0.0033, std: 1.0000
  Target mean: 0.0320, std: 1.3594
  Model pred mean: 0.0236, std: 0.8164
  Sigmas: [0.166015625]... (timesteps: [166.0])

[Step 1060] Training Debug Info:
  Loss: 0.913702
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0015, std: 0.8867
  Noise mean: 0.0013, std: 1.0000
  Target mean: -0.0002, std: 1.3359
  Model pred mean: 0.0003, std: 0.9336
  Sigmas: [0.416015625]... (timesteps: [416.0])

[Step 1060] Training Debug Info:
  Loss: 0.779505
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0342, std: 0.9922
  Noise mean: -0.0060, std: 0.9961
  Target mean: -0.0403, std: 1.4062
  Model pred mean: -0.0398, std: 1.1016
  Sigmas: [0.96484375]... (timesteps: [966.0])
Steps:  21%|‚ñà‚ñà        | 1061/5000 [2:22:59<8:49:25,  8.06s/it, loss=0.5504, lr=9.62e-06]Steps:  21%|‚ñà‚ñà        | 1061/5000 [2:22:59<8:49:25,  8.06s/it, loss=0.7795, lr=9.62e-06]Steps:  21%|‚ñà‚ñà        | 1062/5000 [2:23:08<8:51:52,  8.10s/it, loss=0.7795, lr=9.62e-06]Steps:  21%|‚ñà‚ñà        | 1062/5000 [2:23:08<8:51:52,  8.10s/it, loss=0.5322, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1063/5000 [2:23:15<8:48:46,  8.06s/it, loss=0.5322, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1063/5000 [2:23:15<8:48:46,  8.06s/it, loss=1.0334, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1064/5000 [2:23:23<8:46:02,  8.02s/it, loss=1.0334, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1064/5000 [2:23:23<8:46:02,  8.02s/it, loss=1.1490, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1065/5000 [2:23:32<8:49:48,  8.08s/it, loss=1.1490, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1065/5000 [2:23:32<8:49:48,  8.08s/it, loss=0.4158, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1066/5000 [2:23:40<8:47:15,  8.04s/it, loss=0.4158, lr=9.62e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1066/5000 [2:23:40<8:47:15,  8.04s/it, loss=1.0708, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1067/5000 [2:23:48<8:51:38,  8.11s/it, loss=1.0708, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1067/5000 [2:23:48<8:51:38,  8.11s/it, loss=1.1090, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1068/5000 [2:23:56<8:49:55,  8.09s/it, loss=1.1090, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1068/5000 [2:23:56<8:49:55,  8.09s/it, loss=0.7761, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1069/5000 [2:24:04<8:49:18,  8.08s/it, loss=0.7761, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1069/5000 [2:24:04<8:49:18,  8.08s/it, loss=0.4268, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1070/5000 [2:24:12<8:48:06,  8.06s/it, loss=0.4268, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1070/5000 [2:24:12<8:48:06,  8.06s/it, loss=0.6343, lr=9.61e-06]
[Step 1070] Training Debug Info:
  Loss: 0.656467
  Latent shape: torch.Size([1, 32, 60, 144]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: 0.0079, std: 0.8828
  Noise mean: -0.0008, std: 1.0000
  Target mean: -0.0087, std: 1.3359
  Model pred mean: -0.0065, std: 1.0469
  Sigmas: [0.55859375]... (timesteps: [557.0])

[Step 1070] Training Debug Info:
  Loss: 0.517460
  Latent shape: torch.Size([1, 32, 60, 150]), Packed shape: torch.Size([1, 2250, 128])
  Latent mean: 0.0014, std: 0.9609
  Noise mean: -0.0011, std: 1.0000
  Target mean: -0.0025, std: 1.3828
  Model pred mean: -0.0063, std: 1.1797
  Sigmas: [0.6484375]... (timesteps: [649.0])

[Step 1070] Training Debug Info:
  Loss: 1.164638
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0086, std: 0.9062
  Noise mean: 0.0012, std: 1.0000
  Target mean: -0.0074, std: 1.3516
  Model pred mean: -0.0085, std: 0.7969
  Sigmas: [0.177734375]... (timesteps: [178.0])

[Step 1070] Training Debug Info:
  Loss: 0.650157
  Latent shape: torch.Size([1, 32, 54, 168]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0271, std: 0.9180
  Noise mean: -0.0017, std: 1.0000
  Target mean: 0.0254, std: 1.3594
  Model pred mean: 0.0264, std: 1.0859
  Sigmas: [0.546875]... (timesteps: [547.0])
Steps:  21%|‚ñà‚ñà‚ñè       | 1071/5000 [2:24:20<8:52:38,  8.13s/it, loss=0.6343, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1071/5000 [2:24:20<8:52:38,  8.13s/it, loss=0.6502, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1072/5000 [2:24:28<8:53:13,  8.14s/it, loss=0.6502, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1072/5000 [2:24:28<8:53:13,  8.14s/it, loss=1.1372, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1073/5000 [2:24:36<8:49:54,  8.10s/it, loss=1.1372, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1073/5000 [2:24:36<8:49:54,  8.10s/it, loss=0.5731, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1074/5000 [2:24:44<8:47:30,  8.06s/it, loss=0.5731, lr=9.61e-06]Steps:  21%|‚ñà‚ñà‚ñè       | 1074/5000 [2:24:44<8:47:30,  8.06s/it, loss=1.0518, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1075/5000 [2:24:52<8:46:47,  8.05s/it, loss=1.0518, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1075/5000 [2:24:52<8:46:47,  8.05s/it, loss=0.7289, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1076/5000 [2:25:01<8:48:59,  8.09s/it, loss=0.7289, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1076/5000 [2:25:01<8:48:59,  8.09s/it, loss=1.1237, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1077/5000 [2:25:09<8:47:10,  8.06s/it, loss=1.1237, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1077/5000 [2:25:09<8:47:10,  8.06s/it, loss=0.4967, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1078/5000 [2:25:17<8:49:50,  8.11s/it, loss=0.4967, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1078/5000 [2:25:17<8:49:50,  8.11s/it, loss=1.0869, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1079/5000 [2:25:25<8:49:10,  8.10s/it, loss=1.0869, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1079/5000 [2:25:25<8:49:10,  8.10s/it, loss=1.0750, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1080/5000 [2:25:33<8:48:03,  8.08s/it, loss=1.0750, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1080/5000 [2:25:33<8:48:03,  8.08s/it, loss=0.6722, lr=9.60e-06]
[Step 1080] Training Debug Info:
  Loss: 1.068473
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: -0.0010, std: 0.9336
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0024, std: 1.3672
  Model pred mean: 0.0011, std: 0.8906
  Sigmas: [0.04296875]... (timesteps: [43.0])

[Step 1080] Training Debug Info:
  Loss: 1.153179
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0096, std: 0.8867
  Noise mean: -0.0022, std: 1.0000
  Target mean: -0.0118, std: 1.3359
  Model pred mean: -0.0134, std: 0.7891
  Sigmas: [0.224609375]... (timesteps: [225.0])

[Step 1080] Training Debug Info:
  Loss: 0.407943
  Latent shape: torch.Size([1, 32, 48, 186]), Packed shape: torch.Size([1, 2232, 128])
  Latent mean: 0.0159, std: 0.9023
  Noise mean: -0.0020, std: 1.0000
  Target mean: -0.0179, std: 1.3438
  Model pred mean: -0.0181, std: 1.1875
  Sigmas: [0.79296875]... (timesteps: [793.0])

[Step 1080] Training Debug Info:
  Loss: 1.094476
  Latent shape: torch.Size([1, 32, 66, 132]), Packed shape: torch.Size([1, 2178, 128])
  Latent mean: -0.0016, std: 0.8633
  Noise mean: -0.0018, std: 0.9961
  Target mean: -0.0002, std: 1.3203
  Model pred mean: 0.0019, std: 0.8047
  Sigmas: [0.054931640625]... (timesteps: [55.0])
Steps:  22%|‚ñà‚ñà‚ñè       | 1081/5000 [2:25:41<8:45:41,  8.05s/it, loss=0.6722, lr=9.60e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1081/5000 [2:25:41<8:45:41,  8.05s/it, loss=1.0945, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1082/5000 [2:25:49<8:52:07,  8.15s/it, loss=1.0945, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1082/5000 [2:25:49<8:52:07,  8.15s/it, loss=1.0108, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1083/5000 [2:25:57<8:52:28,  8.16s/it, loss=1.0108, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1083/5000 [2:25:57<8:52:28,  8.16s/it, loss=1.0666, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1084/5000 [2:26:05<8:48:23,  8.10s/it, loss=1.0666, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1084/5000 [2:26:05<8:48:23,  8.10s/it, loss=0.4335, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1085/5000 [2:26:13<8:45:14,  8.05s/it, loss=0.4335, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1085/5000 [2:26:13<8:45:14,  8.05s/it, loss=1.0447, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1086/5000 [2:26:21<8:45:22,  8.05s/it, loss=1.0447, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1086/5000 [2:26:21<8:45:22,  8.05s/it, loss=1.1803, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1087/5000 [2:26:30<8:46:47,  8.08s/it, loss=1.1803, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1087/5000 [2:26:30<8:46:47,  8.08s/it, loss=1.1102, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1088/5000 [2:26:38<8:49:20,  8.12s/it, loss=1.1102, lr=9.59e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1088/5000 [2:26:38<8:49:20,  8.12s/it, loss=1.0628, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1089/5000 [2:26:46<8:49:04,  8.12s/it, loss=1.0628, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1089/5000 [2:26:46<8:49:04,  8.12s/it, loss=1.1131, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1090/5000 [2:26:54<8:47:54,  8.10s/it, loss=1.1131, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1090/5000 [2:26:54<8:47:54,  8.10s/it, loss=0.4966, lr=9.58e-06]
[Step 1090] Training Debug Info:
  Loss: 0.603318
  Latent shape: torch.Size([1, 32, 66, 126]), Packed shape: torch.Size([1, 2079, 128])
  Latent mean: 0.0232, std: 0.8984
  Noise mean: -0.0044, std: 1.0000
  Target mean: -0.0275, std: 1.3438
  Model pred mean: -0.0280, std: 1.1016
  Sigmas: [0.5625]... (timesteps: [564.0])

[Step 1090] Training Debug Info:
  Loss: 0.815128
  Latent shape: torch.Size([1, 32, 90, 102]), Packed shape: torch.Size([1, 2295, 128])
  Latent mean: 0.0036, std: 0.8789
  Noise mean: 0.0022, std: 1.0000
  Target mean: -0.0013, std: 1.3281
  Model pred mean: -0.0045, std: 0.9883
  Sigmas: [0.462890625]... (timesteps: [463.0])

[Step 1090] Training Debug Info:
  Loss: 0.647374
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: 0.0588, std: 0.9180
  Noise mean: 0.0010, std: 1.0000
  Target mean: -0.0576, std: 1.3594
  Model pred mean: -0.0608, std: 1.0938
  Sigmas: [0.50390625]... (timesteps: [504.0])

[Step 1090] Training Debug Info:
  Loss: 0.533470
  Latent shape: torch.Size([1, 32, 72, 120]), Packed shape: torch.Size([1, 2160, 128])
  Latent mean: -0.0150, std: 0.9062
  Noise mean: 0.0084, std: 1.0000
  Target mean: 0.0234, std: 1.3516
  Model pred mean: 0.0150, std: 1.1328
  Sigmas: [0.6328125]... (timesteps: [633.0])
Steps:  22%|‚ñà‚ñà‚ñè       | 1091/5000 [2:27:02<8:46:49,  8.09s/it, loss=0.4966, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1091/5000 [2:27:02<8:46:49,  8.09s/it, loss=0.5335, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1092/5000 [2:27:10<8:49:01,  8.12s/it, loss=0.5335, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1092/5000 [2:27:10<8:49:01,  8.12s/it, loss=0.5694, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1093/5000 [2:27:18<8:50:55,  8.15s/it, loss=0.5694, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1093/5000 [2:27:18<8:50:55,  8.15s/it, loss=0.9385, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1094/5000 [2:27:26<8:48:15,  8.11s/it, loss=0.9385, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1094/5000 [2:27:26<8:48:15,  8.11s/it, loss=0.3771, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1095/5000 [2:27:35<8:49:33,  8.14s/it, loss=0.3771, lr=9.58e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1095/5000 [2:27:35<8:49:33,  8.14s/it, loss=0.8450, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1096/5000 [2:27:43<8:46:44,  8.10s/it, loss=0.8450, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1096/5000 [2:27:43<8:46:44,  8.10s/it, loss=0.6099, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1097/5000 [2:27:51<8:44:20,  8.06s/it, loss=0.6099, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1097/5000 [2:27:51<8:44:20,  8.06s/it, loss=1.0349, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1098/5000 [2:27:59<8:47:57,  8.12s/it, loss=1.0349, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1098/5000 [2:27:59<8:47:57,  8.12s/it, loss=0.6508, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1099/5000 [2:28:07<8:48:37,  8.13s/it, loss=0.6508, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1099/5000 [2:28:07<8:48:37,  8.13s/it, loss=1.0282, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1100/5000 [2:28:15<8:46:01,  8.09s/it, loss=1.0282, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1100/5000 [2:28:15<8:46:01,  8.09s/it, loss=0.5962, lr=9.57e-06]01/30/2026 06:51:04 - INFO - __main__ - 
[Step 1100] ‚úÖ Loss in normal range (0.5962)
01/30/2026 06:51:04 - INFO - __main__ -   Loss avg (last 100): 0.7806
01/30/2026 06:51:04 - INFO - __main__ -   Loss range: [0.3235, 1.1904]

[Step 1100] Training Debug Info:
  Loss: 0.523258
  Latent shape: torch.Size([1, 32, 96, 96]), Packed shape: torch.Size([1, 2304, 128])
  Latent mean: -0.0156, std: 0.9258
  Noise mean: 0.0014, std: 1.0000
  Target mean: 0.0170, std: 1.3594
  Model pred mean: 0.0093, std: 1.1562
  Sigmas: [0.65625]... (timesteps: [656.0])

[Step 1100] Training Debug Info:
  Loss: 0.950543
  Latent shape: torch.Size([1, 32, 78, 114]), Packed shape: torch.Size([1, 2223, 128])
  Latent mean: -0.0269, std: 0.9062
  Noise mean: 0.0003, std: 1.0000
  Target mean: 0.0271, std: 1.3516
  Model pred mean: 0.0261, std: 0.9336
  Sigmas: [0.359375]... (timesteps: [359.0])

[Step 1100] Training Debug Info:
  Loss: 0.387942
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0198, std: 0.9102
  Noise mean: 0.0008, std: 1.0000
  Target mean: -0.0190, std: 1.3516
  Model pred mean: -0.0258, std: 1.2031
  Sigmas: [0.828125]... (timesteps: [828.0])

[Step 1100] Training Debug Info:
  Loss: 0.896153
  Latent shape: torch.Size([1, 32, 84, 108]), Packed shape: torch.Size([1, 2268, 128])
  Latent mean: 0.0354, std: 0.8945
  Noise mean: 0.0023, std: 1.0000
  Target mean: -0.0332, std: 1.3359
  Model pred mean: -0.0354, std: 0.9609
  Sigmas: [0.392578125]... (timesteps: [392.0])
Steps:  22%|‚ñà‚ñà‚ñè       | 1101/5000 [2:28:23<8:46:23,  8.10s/it, loss=0.5962, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1101/5000 [2:28:23<8:46:23,  8.10s/it, loss=0.8962, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1102/5000 [2:28:31<8:46:39,  8.11s/it, loss=0.8962, lr=9.57e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1102/5000 [2:28:31<8:46:39,  8.11s/it, loss=1.0766, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1103/5000 [2:28:39<8:48:27,  8.14s/it, loss=1.0766, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1103/5000 [2:28:39<8:48:27,  8.14s/it, loss=0.7774, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1104/5000 [2:28:48<8:47:47,  8.13s/it, loss=0.7774, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1104/5000 [2:28:48<8:47:47,  8.13s/it, loss=0.6429, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1105/5000 [2:28:56<8:44:07,  8.07s/it, loss=0.6429, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1105/5000 [2:28:56<8:44:07,  8.07s/it, loss=0.6410, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1106/5000 [2:29:03<8:40:22,  8.02s/it, loss=0.6410, lr=9.56e-06]Steps:  22%|‚ñà‚ñà‚ñè       | 1106/5000 [2:29:03<8:40:22,  8.02s/it, loss=0.4697, lr=9.56e-06]