# DeepSpeed ZeRO-3 Configuration for QwenImage-2512 (20B) 
# CPU offload with Python (non-compiled) optimizer
# Avoids CUDA version mismatch by not using compiled CPU Adam

compute_environment: LOCAL_MACHINE
debug: false
distributed_type: DEEPSPEED
downcast_bf16: 'no'
enable_cpu_affinity: false
gpu_ids: 0,1,2,3
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
deepspeed_config:
  gradient_accumulation_steps: 4
  gradient_clipping: 1.0
  # Use CPU offload but with regular AdamW (not DeepSpeed's compiled CPU Adam)
  offload_optimizer_device: cpu
  offload_optimizer_pin_memory: true
  offload_param_device: none
  zero3_init_flag: true
  zero3_save_16bit_model: true
  zero_stage: 3
  train_micro_batch_size_per_gpu: 1
  # Force PyTorch AdamW instead of DeepSpeed CPU Adam
  # This is slower but avoids CUDA version mismatch
  optimizer:
    type: AdamW
    params:
      lr: 5e-6
      betas: [0.9, 0.999]
      eps: 1e-8
      weight_decay: 0.01
